{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/010-CUB-27-imgnet_OOD_cnext26_img=224_nprotos=20'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/031-CUB-18-imgnet_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/032-CUB-18-imgnet_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/035-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/043-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/036-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel_uniformity\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/041-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/042-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/044-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20-or-4per-desc_orth-on-rel\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/046-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=10per-desc_orth-on-rel\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/047-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=5per-desc_tanh-desc\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/048-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=5per-desc_tanh-desc_unit-sphere\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/051-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_tanh-desc_unit-sphere_AW=5-TW=2-UW=2-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/052-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=4per-desc_tanh-desc_unit-sphere_AW=5-TW=2-UW=2-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/055-CUB-18_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/056-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/057-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/058-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "\n",
    "# with unit sphere\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/059-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# unit sphere with softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/065-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# original hpipnet with 20 protos per node no KO, no OOD, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/062-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD\"\n",
    "\n",
    "# original hpipnet with 20 protos per node no KO, no OOD, WITH tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/063-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD_tanh-desc\"\n",
    "\n",
    "# with unit sphere but no AL+UNI\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/066-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_no-softmax_no-align_no-uni_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, with softmax, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/067-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, with softmax, no tanh-desc, INCORRECT\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/067-incorrect-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, no softmax, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/068-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 071 with bias\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/071-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_with-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 072 gumbel softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/072-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-gumbel-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 073 gumbel softmax, tau-1.0\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/073-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-gumbel-softmax-tau=1_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 075 068 with focal loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/075-068-with-focal_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_no-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 076 cs followed by softmax. Uses align_pf along with align+uni\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/076_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_align-pf-during-training_no-meanpool_no-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2-APW=5_batch=20\"\n",
    "\n",
    "# 074 multiply_cs_softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/074-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_multi-cs-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 077 unit sphere protopool with cosin no softmax constant 20 protos per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/077_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20-sphere-protopool_finetune=5_align-pf-during-training_no-meanpool_no-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 080 unit sphere protopool with cosin and softmax constant 20 protos per node (other details not sure)\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/080-CUB-18-imgnet_with-equalize-aug_cnext7_img=224_nprotos=20_unit-sphere-protopool_finetune=5_align-pf-during-training_no-meanpool_with-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_weighted-ce_batch=20\"\n",
    "\n",
    "# 082 unit sphere cs followed by softmax with minmazimize loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/082-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 083 unit sphere cs followed by softmax with minmazimize loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/083-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_no-align_no-uni_no-mm-loss_batch=48\"\n",
    "\n",
    "# 085 unit sphere cs followed by softmax-with-tau with minmazimize loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/085-notebook-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=12\"\n",
    "\n",
    "# 091 basic gaussian multiplier on stage 4\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/091-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_latent-dim=256_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 092 basic gaussian multiplier on stage 3, 4\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/092-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=3,4|1.0|50_img=224_latent-dim=256_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 093 128 dim linear\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/093-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_latent-dim=128_nprotos=20_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=1-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 094 128 dim linear\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/094-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_latent-dim=128_nprotos=20_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=1-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 095 ablation 091 without AL+UNI\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/095-091-woALUNI-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_no-AL_no-UNI_mm-loss_batch=48\"\n",
    "\n",
    "# 096 ablation 091 without AL+UNI\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/096-091-wfocal-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 097 - 091 with bg\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/097-091-wbg-CUB-18_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 0100 cub29 with 20 per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/100_CUB-29-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=20_unit-sphere-protopool_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 0101 baseline with 4 per desc per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/101-baseline-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_no-KO_no-OOD\"\n",
    "\n",
    "# 0103 091 with 20 per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/103-091-wProtoPool20PerNode_CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=20_unit-sphere-protopool_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_batch=48\"\n",
    "\n",
    "# 098 091 without AL + UNI\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/098-091-woALUNI_finetune=0_CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=4per-leaf-desc_unit-sphere_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48'\n",
    "\n",
    "# 0107 091 with 20 per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/107-baseline_LOU_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD\"\n",
    "\n",
    "# 109 flat structure 18 species - HPIPNet\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/109-FlatStructure180protos_CUB-18-imgnet-bg_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=180_unit-sphere-protopool_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_batch=48'\n",
    "\n",
    "# 110 flat structure 18 species - HPIPNet no AL+UNI\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/110-FlatStructure180protosNoALUNI_CUB-18-imgnet-bg_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=180_unit-sphere-protopool_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_batch=48'\n",
    "\n",
    "# 111 flat structure 18 species - Naive-HPIPNet\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/111-NaiveHPIPNetFlatStructure180-baseline_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=180_no-KO_no-OOD'\n",
    "\n",
    "# 112 flat structure 190 species - Naive-HPIPNet\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/112-NaiveHPIPNetFlatStructure_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD\"\n",
    "\n",
    "# 113 flat structure 190 species - Naive-HPIPNet no AL_PF+TANH\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/113-NaiveHPIPNetFlatStructureNoAlNoTanh_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD_no-AL_no-TANH\"\n",
    "\n",
    "# 116 BYOL Optimizer 2\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/116-HPIPNetBYOLOpt2_CUB-18-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=20_BYOL_no-KO_no-OOD_no-AL_no-TANH'\n",
    "\n",
    "# 118 Project dist with BYOL, HPIPNetBYOLOpt2ProtopoolProjDist\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/118-HPIPNetBYOLOpt2ProtopoolProjDist_CUB-18-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=20_BYOL_no-KO_no-OOD_no-AL_no-TANH\"\n",
    "\n",
    "# 126 BYOL with CL with ClusDesc only backpropagating CL\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/126-checkingBYOL05_bpOnlyCLNotClusDesc_with-CL-ClusDesc_byol=2'\n",
    "\n",
    "# 127 Just CL and ClusDesc, no BYOL\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/127-HPIPNetwCLwClusDesc_noBYOL_CUB-18-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=20'\n",
    "\n",
    "# 137 Naive HPIPNet frozen backbone\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/137-NaiveHPIPNetFrozenBackbone_cnext26_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# 138 Naive HPIPNet with TanhDesc loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/138-NaiveHPIPNetwithTanhDesc_cnext26_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# 142 ConciseProtoPNet\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/142-ConciseProtoPNet_cnext26_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# 148 ConciseProtoPNetNoProtoPoolWithKO=0.5WithTanhDesc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/148-ConciseProtoPNetNoProtoPoolWithKO=0.5WithTanhDesc_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/154-PruningNaiveHPIPNet_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/158-PruningNaiveHPIPNetExpWeightPruning_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/159-PruningNaiveHPIPNetMaskL1=1.0_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/160-PruningNaiveHPIPNetMaskL1=0.5_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/161-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15eps_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/162-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/163-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.2MinCont=0.1_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "run_path = \"/home/harishbabu/projects/PIPNet/runs/164-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "try:\n",
    "    sys.path.remove('/home/harishbabu/projects/PIPNet')\n",
    "except:\n",
    "    pass\n",
    "sys.path.insert(0, os.path.join(run_path, 'source_clone'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/projects/PIPNet/runs/164-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\n"
     ]
    }
   ],
   "source": [
    "print(run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import sys, os\n",
    "import random\n",
    "import numpy as np\n",
    "from shutil import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "# from skimage.filters import threshold_local, gaussian\n",
    "import ntpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/harishbabu/projects/PIPNet/runs/164-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20/source_clone', '/home/harishbabu/.conda/envs/hpnet4/lib/python39.zip', '/home/harishbabu/.conda/envs/hpnet4/lib/python3.9', '/home/harishbabu/.conda/envs/hpnet4/lib/python3.9/lib-dynload', '', '/home/harishbabu/.conda/envs/hpnet4/lib/python3.9/site-packages']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/projects/PIPNet/runs/164-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20/source_clone/util/node.py\n"
     ]
    }
   ],
   "source": [
    "# import pipnet.pipnet\n",
    "# from pipnet.pipnet import PIPNet, get_network\n",
    "# # from pipnet import pipnet\n",
    "# print(pipnet.__file__)\n",
    "from util import node\n",
    "print(node.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmaps showing where a prototype is found will not be generated because OpenCV is not installed.\n"
     ]
    }
   ],
   "source": [
    "from pipnet.pipnet import PIPNet, get_network\n",
    "from util.log import Log\n",
    "from util.args import get_args, save_args, get_optimizer_nn\n",
    "from util.data import get_dataloaders\n",
    "from util.func import init_weights_xavier\n",
    "from pipnet.train import train_pipnet, test_pipnet\n",
    "# from pipnet.test import eval_pipnet, get_thresholds, eval_ood\n",
    "from util.eval_cub_csv import eval_prototypes_cub_parts_csv, get_topk_cub, get_proto_patches_cub\n",
    "from util.vis_pipnet import visualize, visualize_topk\n",
    "from util.visualize_prediction import vis_pred, vis_pred_experiments\n",
    "from util.node import Node\n",
    "from util.phylo_utils import construct_phylo_tree, construct_discretized_phylo_tree\n",
    "from util.func import get_patch_size\n",
    "from util.data import ModifiedLabelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "def get_bb_gaussian_threshold(latent_activation, sigma=1.0, percentile=97, extend_h=0, extend_w=0):\n",
    "    # latent_activation -> []\n",
    "    upscaled_similarity = get_upscaled_activation_uninterpolated(latent_activation, \\\n",
    "                                                                 image_size=(args.image_size, args.image_size))\n",
    "    upscaled_similarity = minmaxscale(upscaled_similarity)\n",
    "    upscaled_similarity = gaussian(upscaled_similarity, sigma=sigma)\n",
    "    upscaled_similarity = threshold_local(upscaled_similarity, block_size=15, method='mean')\n",
    "    h_min, h_max, w_min, w_max = find_top_percentile_bbox(upscaled_similarity ,percentile=97)\n",
    "    h_min = max(0, h_min-extend_h)\n",
    "    h_max = min(upscaled_similarity.shape[0], h_max+extend_h)\n",
    "    w_min = max(0, w_min-extend_w)\n",
    "    w_max = min(upscaled_similarity.shape[1], w_max+extend_w)\n",
    "    return h_min, h_max, w_min, w_max\n",
    "\n",
    "\n",
    "def minmaxscale(tensor):\n",
    "    return (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def unshuffle_dataloader(dataloader):\n",
    "    if type(dataloader.dataset) == ImageFolder:\n",
    "        dataset = dataloader.dataset\n",
    "    else:\n",
    "        dataset = dataloader.dataset.dataset.dataset\n",
    "    new_dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=dataloader.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=dataloader.num_workers,\n",
    "        pin_memory=dataloader.pin_memory,\n",
    "        drop_last=dataloader.drop_last,\n",
    "        timeout=dataloader.timeout,\n",
    "        worker_init_fn=dataloader.worker_init_fn,\n",
    "        multiprocessing_context=dataloader.multiprocessing_context,\n",
    "        generator=dataloader.generator,\n",
    "        prefetch_factor=dataloader.prefetch_factor,\n",
    "        persistent_workers=dataloader.persistent_workers\n",
    "    )\n",
    "    return new_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- No discretization -------------------------\n"
     ]
    }
   ],
   "source": [
    "args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "args = pickle.load(args_file)\n",
    "\n",
    "if args.phylo_config:\n",
    "    phylo_config = OmegaConf.load(args.phylo_config)\n",
    "\n",
    "if args.phylo_config:\n",
    "    # construct the phylo tree\n",
    "    if phylo_config.phyloDistances_string == 'None':\n",
    "        if '031' in run_path: # this run uses a different phylogeny file that had an extra root node which is a mistake\n",
    "            root = construct_phylo_tree('/home/harishbabu/data/phlyogenyCUB/18Species-with-extra-root-node/1_tree-consensus-Hacket-18Species-modified_cub-names_v1.phy')\n",
    "        else:\n",
    "            root = construct_phylo_tree(phylo_config.phylogeny_path)\n",
    "        print('-'*25 + ' No discretization ' + '-'*25)\n",
    "    else:\n",
    "        root = construct_discretized_phylo_tree(phylo_config.phylogeny_path, phylo_config.phyloDistances_string)\n",
    "        print('-'*25 + ' Discretized ' + '-'*25)\n",
    "else:\n",
    "    # construct the tree (original hierarchy as described in the paper)\n",
    "    root = Node(\"root\")\n",
    "    root.add_children(['animal','vehicle','everyday_object','weapon','scuba_diver'])\n",
    "    root.add_children_to('animal',['non_primate','primate'])\n",
    "    root.add_children_to('non_primate',['African_elephant','giant_panda','lion'])\n",
    "    root.add_children_to('primate',['capuchin','gibbon','orangutan'])\n",
    "    root.add_children_to('vehicle',['ambulance','pickup','sports_car'])\n",
    "    root.add_children_to('everyday_object',['laptop','sandal','wine_bottle'])\n",
    "    root.add_children_to('weapon',['assault_rifle','rifle'])\n",
    "    # flat root\n",
    "    # root.add_children(['scuba_diver','African_elephant','giant_panda','lion','capuchin','gibbon','orangutan','ambulance','pickup','sports_car','laptop','sandal','wine_bottle','assault_rifle','rifle'])\n",
    "root.assign_all_descendents()\n",
    "\n",
    "exp_no = int(os.path.basename(run_path)[:3])\n",
    "\n",
    "if exp_no < 77:\n",
    "    if ('num_protos_per_descendant' in args) and (args.num_protos_per_descendant > 0):\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(args.num_protos_per_descendant)\n",
    "if exp_no == 77:\n",
    "    # update num of protos per node based on num_protos_per_descendant\n",
    "    if args.num_features == 0 and args.num_protos_per_descendant == 0:\n",
    "        raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "    for node in root.nodes_with_children():\n",
    "        node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                                            min_protos=args.num_features)\n",
    "else:\n",
    "    if ('num_protos_per_descendant' in args):\n",
    "        # update num of protos per node based on num_protos_per_descendant\n",
    "        if args.num_features == 0 and args.num_protos_per_descendant == 0:\n",
    "            raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                min_protos=args.num_features,\\\n",
    "                                split_protos=('protopool' in args) and (args.protopool == 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illegal option --\n",
      "Usage: /usr/bin/which [-a] args\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "CUB-18-imgnet-224\n"
     ]
    }
   ],
   "source": [
    "args.batch_size = 1\n",
    "\n",
    "print(args.batch_size)\n",
    "print(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 samples from trainloader\n",
      "Dropping 0 samples from trainloader_normal\n",
      "Dropping 0 samples from trainloader_normal_augment\n",
      "Num classes (k) =  18 ['cub_001_Black_footed_Albatross', 'cub_002_Laysan_Albatross', 'cub_003_Sooty_Albatross', 'cub_004_Groove_billed_Ani', 'cub_023_Brandt_Cormorant'] etc.\n",
      "1 1\n",
      "Classes:  {'cub_001_Black_footed_Albatross': 0, 'cub_002_Laysan_Albatross': 1, 'cub_003_Sooty_Albatross': 2, 'cub_004_Groove_billed_Ani': 3, 'cub_023_Brandt_Cormorant': 4, 'cub_024_Red_faced_Cormorant': 5, 'cub_025_Pelagic_Cormorant': 6, 'cub_031_Black_billed_Cuckoo': 7, 'cub_032_Mangrove_Cuckoo': 8, 'cub_033_Yellow_billed_Cuckoo': 9, 'cub_045_Northern_Fulmar': 10, 'cub_050_Eared_Grebe': 11, 'cub_051_Horned_Grebe': 12, 'cub_052_Pied_billed_Grebe': 13, 'cub_053_Western_Grebe': 14, 'cub_086_Pacific_Loon': 15, 'cub_100_Brown_Pelican': 16, 'cub_101_White_Pelican': 17}\n",
      "Number of prototypes:  20\n",
      "----------Prototypes per descendant: 0----------\n",
      "Assigned 20 protos to node root\n",
      "Assigned 20 protos to node 052+053\n",
      "Assigned 20 protos to node 004+086\n",
      "Assigned 20 protos to node 053+050\n",
      "Assigned 20 protos to node 004+032\n",
      "Assigned 20 protos to node 086+045\n",
      "Assigned 20 protos to node 050+051\n",
      "Assigned 20 protos to node 032+033\n",
      "Assigned 20 protos to node 045+101\n",
      "Assigned 20 protos to node 033+031\n",
      "Assigned 20 protos to node 045+003\n",
      "Assigned 20 protos to node 101+023\n",
      "Assigned 20 protos to node 003+002\n",
      "Assigned 20 protos to node 101+100\n",
      "Assigned 20 protos to node 023+025\n",
      "Assigned 20 protos to node 002+001\n",
      "Assigned 20 protos to node 025+024\n",
      "Output shape:  torch.Size([1, 20, 13, 13])\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    device_ids = [torch.cuda.current_device()]\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    device_ids = []\n",
    "\n",
    "# args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "# args = pickle.load(args_file)\n",
    "\n",
    "# ckpt_file_name = 'net_overspecific_pruned_replaced_thresh=0.5_last'\n",
    "# ckpt_file_name = 'net_trained_30'\n",
    "# ckpt_file_name = 'net_trained_10'\n",
    "# ckpt_file_name = 'net_pretrained'\n",
    "ckpt_file_name = 'net_trained_last'\n",
    "epoch = ckpt_file_name.split('_')[-1]\n",
    "\n",
    "ckpt_path = os.path.join(run_path, 'checkpoints', ckpt_file_name)\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "if ckpt_file_name != 'net_trained_last':\n",
    "    print('\\n', (10*'-')+'WARNING: Not using the final trained model'+(10*'-'), '\\n')\n",
    "\n",
    "# Obtain the dataset and dataloaders\n",
    "trainloader, trainloader_pretraining, trainloader_normal, trainloader_normal_augment, projectloader, testloader, test_projectloader, classes = get_dataloaders(args, device)\n",
    "\n",
    "print(args.batch_size, trainloader.batch_size)\n",
    "\n",
    "if len(classes)<=20:\n",
    "    if args.validation_size == 0.:\n",
    "        print(\"Classes: \", testloader.dataset.class_to_idx, flush=True)\n",
    "    else:\n",
    "        print(\"Classes: \", str(classes), flush=True)\n",
    "\n",
    "# Create a convolutional network based on arguments and add 1x1 conv layer\n",
    "feature_net, add_on_layers, pool_layer, classification_layers, num_prototypes = get_network(len(classes), args, root=root)\n",
    "   \n",
    "# Create a PIP-Net\n",
    "net = PIPNet(num_classes=len(classes),\n",
    "                    num_prototypes=num_prototypes,\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "\n",
    "# Create a PIP-Net\n",
    "if ('byol' in args) and (args.byol == 'y'):\n",
    "    from pipnet.pipnet import PIPNetBYOL\n",
    "    net = PIPNetBYOL(num_classes=len(classes),\n",
    "                        num_prototypes=num_prototypes,\n",
    "                        feature_net = feature_net,\n",
    "                        args = args,\n",
    "                        add_on_layers = add_on_layers,\n",
    "                        pool_layer = pool_layer,\n",
    "                        classification_layers = classification_layers,\n",
    "                        num_parent_nodes = len(root.nodes_with_children()),\n",
    "                        root = root\n",
    "                        )\n",
    "else:\n",
    "    net = PIPNet(num_classes=len(classes),\n",
    "                    num_prototypes=num_prototypes,\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "        \n",
    "net = net.to(device=device)\n",
    "net = nn.DataParallel(net, device_ids = device_ids)    \n",
    "net.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "# print(net.eval())\n",
    "criterion = nn.NLLLoss(reduction='mean').to(device)\n",
    "\n",
    "# Forward one batch through the backbone to get the latent output size\n",
    "with torch.no_grad():\n",
    "    xs1, _, _ = next(iter(trainloader))\n",
    "    xs1 = xs1.to(device)\n",
    "    _, proto_features, _, _ = net(xs1)\n",
    "    wshape = proto_features['root'].shape[-1]\n",
    "    args.wshape = wshape #needed for calculating image patch size\n",
    "    print(\"Output shape: \", proto_features['root'].shape, flush=True)\n",
    "    \n",
    "print(args.wshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.7\n",
      "2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[2.3546, 2.9397, 0.0000, 3.9253, 1.8041, 0.0000, 0.0000, 0.0000, 1.1224,\n",
       "         0.8950, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 3.0212, 3.5481, 3.7509, 4.0793, 2.5177, 0.0000, 1.0699, 0.0000,\n",
       "         2.7102, 3.4922]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.module._root_classification.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.basic_cnext_gaussian_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/harishbabu/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/harishbabu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/harishbabu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/harishbabu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "# def count_parameters(model):\n",
    "#     \"\"\"\n",
    "#     Counts the number of trainable and non-trainable parameters in a model.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - model: The PyTorch model\n",
    "    \n",
    "#     Returns:\n",
    "#     - Tuple of (total_parameters, trainable_parameters)\n",
    "#     \"\"\"\n",
    "#     total_params = sum(p.numel() for p in model.parameters())\n",
    "#     trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "#     return total_params, trainable_params\n",
    "\n",
    "# count_parameters(net.module._net)\n",
    "\n",
    "dinov2_vits14_reg = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14_reg').cuda()\n",
    "\n",
    "dinov2_vits14_reg\n",
    "\n",
    "with torch.no_grad():\n",
    "    xs1, _, _ = next(iter(trainloader))\n",
    "    xs1 = xs1.to(device)\n",
    "    out = dinov2_vits14_reg(xs1)\n",
    "#     wshape = proto_features['root'].shape[-1]\n",
    "#     args.wshape = wshape #needed for calculating image patch size\n",
    "#     print(\"Output shape: \", proto_features['root'].shape, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images using either NAIVE-HPIPNET or UNIT-SPACE-PROTOPOOL with HEATMAP (CANON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:10, 52.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node root\n",
      "Num protos for 052+053 8\n",
      "Num protos for 004+086 5\n",
      "\t Child: 052+053\n",
      "\t\tProto:0 001:(0.6428) 002:(0.1453) 003:(0.0323) 004:(0.0034) 023:(0.4831) 024:(0.0163) 025:(0.0377) 031:(0.1337) 032:(0.1573) 033:(0.0107) 045:(0.1626) 086:(0.8483) 100:(0.2801) 101:(0.7501) \n",
      "\t\tProto:3 001:(0.5735) 002:(0.0406) 003:(0.1328) 004:(0.0019) 023:(0.9766) 024:(0.5093) 025:(0.9316) 031:(0.0022) 032:(0.0285) 033:(0.0032) 045:(0.0765) 086:(0.9967) 100:(0.9219) 101:(0.1882) \n",
      "\t\tProto:4 001:(0.0184) 002:(0.0071) 003:(0.0021) 004:(0.0017) 023:(0.0284) 024:(0.0604) 025:(0.0405) 031:(0.0017) 032:(0.0151) 033:(0.0048) 045:(0.0156) 086:(0.1462) 100:(0.0178) 101:(0.0085) \n",
      "\t\tProto:5 001:(0.1252) 002:(0.0091) 003:(0.0027) 004:(0.0006) 023:(0.2039) 024:(0.1444) 025:(0.011) 031:(0.1253) 032:(0.1321) 033:(0.0421) 045:(0.0118) 086:(0.257) 100:(0.017) 101:(0.0257) \n",
      "\t\tProto:6 001:(0.1734) 002:(0.0013) 003:(0.0017) 004:(0.0015) 023:(0.0202) 024:(0.0559) 025:(0.0434) 031:(0.0744) 032:(0.0559) 033:(0.153) 045:(0.0113) 086:(0.178) 100:(0.141) 101:(0.0018) \n",
      "\t\tProto:7 001:(0.0135) 002:(0.008) 003:(0.0007) 004:(0.0002) 023:(0.081) 024:(0.0104) 025:(0.0035) 031:(0.0005) 032:(0.0035) 033:(0.0621) 045:(0.0357) 086:(0.2235) 100:(0.0039) 101:(0.0105) \n",
      "\t\tProto:8 001:(0.1121) 002:(0.0036) 003:(0.0041) 004:(0.0018) 023:(0.0456) 024:(0.1057) 025:(0.1964) 031:(0.277) 032:(0.075) 033:(0.0132) 045:(0.0064) 086:(0.201) 100:(0.0047) 101:(0.0022) \n",
      "\t\tProto:9 001:(0.0932) 002:(0.0109) 003:(0.0018) 004:(0.0077) 023:(0.0135) 024:(0.0226) 025:(0.0082) 031:(0.1524) 032:(0.0455) 033:(0.0778) 045:(0.0129) 086:(0.0858) 100:(0.0405) 101:(0.015) \n",
      "\t Child: 004+086\n",
      "\t\tProto:10 050:(0.9354) 051:(0.974) 052:(0.9989) 053:(0.8779) \n",
      "\t\tProto:11 050:(0.988) 051:(0.9967) 052:(0.9995) 053:(0.9919) \n",
      "\t\tProto:13 050:(0.995) 051:(0.9951) 052:(0.9984) 053:(0.5858) \n",
      "\t\tProto:14 050:(0.9542) 051:(0.9944) 052:(0.9637) 053:(0.9165) \n",
      "\t\tProto:19 050:(0.9876) 051:(0.999) 052:(0.9944) 053:(0.5493) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 38.14it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "Num protos for cub_052_Pied_billed_Grebe 10\n",
      "Num protos for 053+050 8\n",
      "\t Child: cub_052_Pied_billed_Grebe\n",
      "\t\tProto:0 050:(0.0618) 051:(0.0442) 053:(0.0516) \n",
      "\t\tProto:1 050:(0.2042) 051:(0.0467) 053:(0.0231) \n",
      "\t\tProto:2 050:(0.274) 051:(0.0216) 053:(0.0859) \n",
      "\t\tProto:3 050:(0.1134) 051:(0.0227) 053:(0.1572) \n",
      "\t\tProto:4 050:(0.0057) 051:(0.0075) 053:(0.0032) \n",
      "\t\tProto:5 050:(0.7028) 051:(0.3149) 053:(0.1681) \n",
      "\t\tProto:6 050:(0.845) 051:(0.0517) 053:(0.1925) \n",
      "\t\tProto:7 050:(0.0057) 051:(0.0023) 053:(0.0012) \n",
      "\t\tProto:8 050:(0.1178) 051:(0.0084) 053:(0.0263) \n",
      "\t\tProto:9 050:(0.0322) 051:(0.0007) 053:(0.0072) \n",
      "\t Child: 053+050\n",
      "\t\tProto:11 052:(0.265) \n",
      "\t\tProto:12 052:(0.7051) \n",
      "\t\tProto:13 052:(0.8769) \n",
      "\t\tProto:15 052:(0.8015) \n",
      "\t\tProto:16 052:(0.6059) \n",
      "\t\tProto:17 052:(0.3051) \n",
      "\t\tProto:18 052:(0.1815) \n",
      "\t\tProto:19 052:(0.5984) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:08, 51.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "Num protos for 004+032 8\n",
      "Num protos for 086+045 8\n",
      "\t Child: 004+032\n",
      "\t\tProto:0 001:(0.0453) 002:(0.0047) 003:(0.0149) 023:(0.0089) 024:(0.0015) 025:(0.0242) 045:(0.0198) 086:(0.1152) 100:(0.0024) 101:(0.0199) \n",
      "\t\tProto:1 001:(0.0014) 002:(0.0208) 003:(0.0033) 023:(0.0503) 024:(0.0048) 025:(0.0035) 045:(0.0201) 086:(0.1441) 100:(0.0431) 101:(0.1683) \n",
      "\t\tProto:2 001:(0.0643) 002:(0.1444) 003:(0.0963) 023:(0.0667) 024:(0.0439) 025:(0.2075) 045:(0.1705) 086:(0.131) 100:(0.0869) 101:(0.3154) \n",
      "\t\tProto:3 001:(0.0025) 002:(0.0201) 003:(0.0044) 023:(0.0107) 024:(0.0005) 025:(0.0008) 045:(0.0252) 086:(0.0126) 100:(0.0004) 101:(0.1809) \n",
      "\t\tProto:5 001:(0.0142) 002:(0.1111) 003:(0.021) 023:(0.023) 024:(0.0024) 025:(0.0027) 045:(0.0101) 086:(0.0161) 100:(0.0019) 101:(0.0231) \n",
      "\t\tProto:6 001:(0.2355) 002:(0.1669) 003:(0.0285) 023:(0.0219) 024:(0.0186) 025:(0.0555) 045:(0.1655) 086:(0.1883) 100:(0.0022) 101:(0.0349) \n",
      "\t\tProto:7 001:(0.016) 002:(0.021) 003:(0.0156) 023:(0.0857) 024:(0.0231) 025:(0.1402) 045:(0.0797) 086:(0.0872) 100:(0.001) 101:(0.268) \n",
      "\t\tProto:8 001:(0.013) 002:(0.1497) 003:(0.0157) 023:(0.0002) 024:(0.0004) 025:(0.0008) 045:(0.0033) 086:(0.159) 100:(0.0002) 101:(0.1909) \n",
      "\t Child: 086+045\n",
      "\t\tProto:11 004:(0.1677) 031:(0.0735) 032:(0.1085) 033:(0.0718) \n",
      "\t\tProto:13 004:(0.9461) 031:(0.5818) 032:(0.2076) 033:(0.5166) \n",
      "\t\tProto:14 004:(0.9358) 031:(0.598) 032:(0.2447) 033:(0.4107) \n",
      "\t\tProto:15 004:(0.7683) 031:(0.543) 032:(0.2533) 033:(0.5809) \n",
      "\t\tProto:16 004:(0.3364) 031:(0.0205) 032:(0.0592) 033:(0.2472) \n",
      "\t\tProto:17 004:(0.5126) 031:(0.05) 032:(0.0543) 033:(0.0886) \n",
      "\t\tProto:18 004:(0.4691) 031:(0.3997) 032:(0.2584) 033:(0.1552) \n",
      "\t\tProto:19 004:(0.9547) 031:(0.5929) 032:(0.7068) 033:(0.558) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 36.10it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "Num protos for cub_053_Western_Grebe 8\n",
      "Num protos for 050+051 9\n",
      "\t Child: cub_053_Western_Grebe\n",
      "\t\tProto:0 050:(0.3182) 051:(0.4065) \n",
      "\t\tProto:2 050:(0.3654) 051:(0.2956) \n",
      "\t\tProto:3 050:(0.4759) 051:(0.3399) \n",
      "\t\tProto:5 050:(0.6928) 051:(0.479) \n",
      "\t\tProto:6 050:(0.4657) 051:(0.681) \n",
      "\t\tProto:7 050:(0.6389) 051:(0.3735) \n",
      "\t\tProto:8 050:(0.0422) 051:(0.4616) \n",
      "\t\tProto:9 050:(0.2804) 051:(0.181) \n",
      "\t Child: 050+051\n",
      "\t\tProto:10 053:(0.003) \n",
      "\t\tProto:11 053:(0.0129) \n",
      "\t\tProto:13 053:(0.0053) \n",
      "\t\tProto:14 053:(0.0092) \n",
      "\t\tProto:15 053:(0.0063) \n",
      "\t\tProto:16 053:(0.0077) \n",
      "\t\tProto:17 053:(0.0011) \n",
      "\t\tProto:18 053:(0.0019) \n",
      "\t\tProto:19 053:(0.0014) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 39.22it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "Num protos for cub_004_Groove_billed_Ani 10\n",
      "Num protos for 032+033 8\n",
      "\t Child: cub_004_Groove_billed_Ani\n",
      "\t\tProto:0 031:(0.0045) 032:(0.0103) 033:(0.0272) \n",
      "\t\tProto:1 031:(0.0104) 032:(0.0028) 033:(0.0076) \n",
      "\t\tProto:2 031:(0.1062) 032:(0.1683) 033:(0.0408) \n",
      "\t\tProto:3 031:(0.0207) 032:(0.051) 033:(0.0214) \n",
      "\t\tProto:4 031:(0.0003) 032:(0.0115) 033:(0.0072) \n",
      "\t\tProto:5 031:(0.0092) 032:(0.0132) 033:(0.0057) \n",
      "\t\tProto:6 031:(0.0193) 032:(0.0352) 033:(0.0138) \n",
      "\t\tProto:7 031:(0.2718) 032:(0.8521) 033:(0.1119) \n",
      "\t\tProto:8 031:(0.0029) 032:(0.1509) 033:(0.0185) \n",
      "\t\tProto:9 031:(0.0253) 032:(0.1138) 033:(0.0056) \n",
      "\t Child: 032+033\n",
      "\t\tProto:10 004:(0.0063) \n",
      "\t\tProto:12 004:(0.0016) \n",
      "\t\tProto:13 004:(0.2887) \n",
      "\t\tProto:14 004:(0.0326) \n",
      "\t\tProto:15 004:(0.2322) \n",
      "\t\tProto:16 004:(0.3081) \n",
      "\t\tProto:18 004:(0.0451) \n",
      "\t\tProto:19 004:(0.279) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:06, 48.23it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "Num protos for cub_086_Pacific_Loon 9\n",
      "Num protos for 045+101 6\n",
      "\t Child: cub_086_Pacific_Loon\n",
      "\t\tProto:0 001:(0.0131) 002:(0.1018) 003:(0.063) 023:(0.2604) 024:(0.0047) 025:(0.2463) 045:(0.0538) 100:(0.0604) 101:(0.0127) \n",
      "\t\tProto:1 001:(0.0037) 002:(0.0226) 003:(0.0605) 023:(0.1507) 024:(0.0063) 025:(0.1629) 045:(0.0219) 100:(0.0102) 101:(0.0193) \n",
      "\t\tProto:2 001:(0.023) 002:(0.0128) 003:(0.0216) 023:(0.1875) 024:(0.0017) 025:(0.1821) 045:(0.0065) 100:(0.1044) 101:(0.0065) \n",
      "\t\tProto:3 001:(0.0007) 002:(0.0006) 003:(0.0529) 023:(0.0485) 024:(0.0006) 025:(0.0082) 045:(0.0147) 100:(0.0092) 101:(0.0097) \n",
      "\t\tProto:4 001:(0.0015) 002:(0.0054) 003:(0.0187) 023:(0.025) 024:(0.0012) 025:(0.1077) 045:(0.0039) 100:(0.0245) 101:(0.0134) \n",
      "\t\tProto:5 001:(0.0119) 002:(0.0007) 003:(0.0723) 023:(0.1693) 024:(0.0003) 025:(0.0928) 045:(0.0024) 100:(0.0355) 101:(0.0216) \n",
      "\t\tProto:6 001:(0.0004) 002:(0.0129) 003:(0.0834) 023:(0.0786) 024:(0.0006) 025:(0.0153) 045:(0.002) 100:(0.0079) 101:(0.0006) \n",
      "\t\tProto:8 001:(0.0202) 002:(0.0005) 003:(0.0212) 023:(0.1336) 024:(0.0009) 025:(0.1021) 045:(0.0154) 100:(0.1156) 101:(0.017) \n",
      "\t\tProto:9 001:(0.001) 002:(0.0289) 003:(0.1745) 023:(0.0764) 024:(0.002) 025:(0.0998) 045:(0.0071) 100:(0.0171) 101:(0.0083) \n",
      "\t Child: 045+101\n",
      "\t\tProto:11 086:(0.4099) \n",
      "\t\tProto:12 086:(0.9998) \n",
      "\t\tProto:14 086:(0.6702) \n",
      "\t\tProto:15 086:(0.8868) \n",
      "\t\tProto:17 086:(0.8479) \n",
      "\t\tProto:18 086:(0.985) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 30.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 050+051\n",
      "Num protos for cub_050_Eared_Grebe 7\n",
      "Num protos for cub_051_Horned_Grebe 8\n",
      "\t Child: cub_050_Eared_Grebe\n",
      "\t\tProto:0 051:(0.774) \n",
      "\t\tProto:1 051:(0.998) \n",
      "\t\tProto:4 051:(0.6312) \n",
      "\t\tProto:5 051:(0.9946) \n",
      "\t\tProto:7 051:(0.6276) \n",
      "\t\tProto:8 051:(0.8158) \n",
      "\t\tProto:9 051:(0.9882) \n",
      "\t Child: cub_051_Horned_Grebe\n",
      "\t\tProto:10 050:(0.9715) \n",
      "\t\tProto:11 050:(0.1458) \n",
      "\t\tProto:12 050:(0.0319) \n",
      "\t\tProto:13 050:(0.0047) \n",
      "\t\tProto:14 050:(0.0218) \n",
      "\t\tProto:15 050:(0.4781) \n",
      "\t\tProto:16 050:(0.0312) \n",
      "\t\tProto:17 050:(0.9932) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 36.88it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "Num protos for cub_032_Mangrove_Cuckoo 7\n",
      "Num protos for 033+031 8\n",
      "\t Child: cub_032_Mangrove_Cuckoo\n",
      "\t\tProto:0 031:(0.8526) 033:(0.9365) \n",
      "\t\tProto:2 031:(0.0476) 033:(0.5157) \n",
      "\t\tProto:5 031:(0.0658) 033:(0.3938) \n",
      "\t\tProto:6 031:(0.1281) 033:(0.5313) \n",
      "\t\tProto:7 031:(0.1072) 033:(0.7519) \n",
      "\t\tProto:8 031:(0.0151) 033:(0.1925) \n",
      "\t\tProto:9 031:(0.0343) 033:(0.3664) \n",
      "\t Child: 033+031\n",
      "\t\tProto:10 032:(0.1771) \n",
      "\t\tProto:11 032:(0.166) \n",
      "\t\tProto:12 032:(0.0775) \n",
      "\t\tProto:14 032:(0.2862) \n",
      "\t\tProto:15 032:(0.0692) \n",
      "\t\tProto:16 032:(0.1715) \n",
      "\t\tProto:18 032:(0.1577) \n",
      "\t\tProto:19 032:(0.1644) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:05, 48.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "Num protos for 045+003 8\n",
      "Num protos for 101+023 7\n",
      "\t Child: 045+003\n",
      "\t\tProto:0 023:(0.0714) 024:(0.0259) 025:(0.1836) 100:(0.059) 101:(0.2375) \n",
      "\t\tProto:1 023:(0.0076) 024:(0.008) 025:(0.1805) 100:(0.0176) 101:(0.0809) \n",
      "\t\tProto:2 023:(0.0085) 024:(0.0059) 025:(0.0404) 100:(0.0157) 101:(0.1069) \n",
      "\t\tProto:4 023:(0.0008) 024:(0.0014) 025:(0.0081) 100:(0.0079) 101:(0.2204) \n",
      "\t\tProto:5 023:(0.0001) 024:(0.0021) 025:(0.0287) 100:(0.0123) 101:(0.0832) \n",
      "\t\tProto:7 023:(0.0006) 024:(0.0007) 025:(0.0167) 100:(0.0222) 101:(0.176) \n",
      "\t\tProto:8 023:(0.1279) 024:(0.0286) 025:(0.3453) 100:(0.1723) 101:(0.8374) \n",
      "\t\tProto:9 023:(0.0025) 024:(0.0041) 025:(0.196) 100:(0.136) 101:(0.0812) \n",
      "\t Child: 101+023\n",
      "\t\tProto:10 001:(0.0505) 002:(0.0077) 003:(0.0099) 045:(0.1338) \n",
      "\t\tProto:11 001:(0.1211) 002:(0.0429) 003:(0.0945) 045:(0.3308) \n",
      "\t\tProto:13 001:(0.4891) 002:(0.3443) 003:(0.1536) 045:(0.23) \n",
      "\t\tProto:14 001:(0.1003) 002:(0.0351) 003:(0.0543) 045:(0.0528) \n",
      "\t\tProto:16 001:(0.4394) 002:(0.2974) 003:(0.1791) 045:(0.09) \n",
      "\t\tProto:18 001:(0.1759) 002:(0.0219) 003:(0.0413) 045:(0.0146) \n",
      "\t\tProto:19 001:(0.0759) 002:(0.1259) 003:(0.1109) 045:(0.0841) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 31.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 033+031\n",
      "Num protos for cub_033_Yellow_billed_Cuckoo 9\n",
      "Num protos for cub_031_Black_billed_Cuckoo 9\n",
      "\t Child: cub_033_Yellow_billed_Cuckoo\n",
      "\t\tProto:1 031:(0.5218) \n",
      "\t\tProto:2 031:(0.3773) \n",
      "\t\tProto:3 031:(0.9643) \n",
      "\t\tProto:4 031:(0.3707) \n",
      "\t\tProto:5 031:(0.9255) \n",
      "\t\tProto:6 031:(0.0523) \n",
      "\t\tProto:7 031:(0.7361) \n",
      "\t\tProto:8 031:(0.5236) \n",
      "\t\tProto:9 031:(0.162) \n",
      "\t Child: cub_031_Black_billed_Cuckoo\n",
      "\t\tProto:10 033:(0.6364) \n",
      "\t\tProto:11 033:(0.0262) \n",
      "\t\tProto:12 033:(0.3) \n",
      "\t\tProto:13 033:(0.041) \n",
      "\t\tProto:14 033:(0.2743) \n",
      "\t\tProto:15 033:(0.0043) \n",
      "\t\tProto:16 033:(0.2462) \n",
      "\t\tProto:17 033:(0.0735) \n",
      "\t\tProto:18 033:(0.0521) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 40.15it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "Num protos for cub_045_Northern_Fulmar 8\n",
      "Num protos for 003+002 8\n",
      "\t Child: cub_045_Northern_Fulmar\n",
      "\t\tProto:0 001:(0.1072) 002:(0.1787) 003:(0.1108) \n",
      "\t\tProto:1 001:(0.0449) 002:(0.25) 003:(0.1918) \n",
      "\t\tProto:3 001:(0.0472) 002:(0.1378) 003:(0.0235) \n",
      "\t\tProto:4 001:(0.0244) 002:(0.0584) 003:(0.0149) \n",
      "\t\tProto:6 001:(0.0115) 002:(0.0859) 003:(0.0039) \n",
      "\t\tProto:7 001:(0.0041) 002:(0.0028) 003:(0.0091) \n",
      "\t\tProto:8 001:(0.1046) 002:(0.1902) 003:(0.0185) \n",
      "\t\tProto:9 001:(0.028) 002:(0.1941) 003:(0.061) \n",
      "\t Child: 003+002\n",
      "\t\tProto:10 045:(0.6956) \n",
      "\t\tProto:12 045:(0.3677) \n",
      "\t\tProto:13 045:(0.7161) \n",
      "\t\tProto:15 045:(0.4534) \n",
      "\t\tProto:16 045:(0.6205) \n",
      "\t\tProto:17 045:(0.6889) \n",
      "\t\tProto:18 045:(0.9057) \n",
      "\t\tProto:19 045:(0.7243) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 42.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "Num protos for 101+100 10\n",
      "Num protos for 023+025 8\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 023:(0.3369) 024:(0.1296) 025:(0.3552) \n",
      "\t\tProto:1 023:(0.0552) 024:(0.0106) 025:(0.1647) \n",
      "\t\tProto:2 023:(0.0601) 024:(0.1627) 025:(0.1392) \n",
      "\t\tProto:3 023:(0.0665) 024:(0.0187) 025:(0.0021) \n",
      "\t\tProto:4 023:(0.0081) 024:(0.0168) 025:(0.0009) \n",
      "\t\tProto:5 023:(0.0107) 024:(0.0064) 025:(0.0162) \n",
      "\t\tProto:6 023:(0.01) 024:(0.0334) 025:(0.0047) \n",
      "\t\tProto:7 023:(0.0049) 024:(0.0275) 025:(0.0015) \n",
      "\t\tProto:8 023:(0.0316) 024:(0.1333) 025:(0.0116) \n",
      "\t\tProto:9 023:(0.9852) 024:(0.8183) 025:(0.8232) \n",
      "\t Child: 023+025\n",
      "\t\tProto:10 100:(0.1685) 101:(0.0343) \n",
      "\t\tProto:11 100:(0.3137) 101:(0.0233) \n",
      "\t\tProto:13 100:(0.1923) 101:(0.0071) \n",
      "\t\tProto:14 100:(0.0106) 101:(0.0254) \n",
      "\t\tProto:15 100:(0.1512) 101:(0.082) \n",
      "\t\tProto:16 100:(0.3051) 101:(0.1641) \n",
      "\t\tProto:17 100:(0.1987) 101:(0.0274) \n",
      "\t\tProto:19 100:(0.2259) 101:(0.2511) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 37.28it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "Num protos for cub_003_Sooty_Albatross 7\n",
      "Num protos for 002+001 7\n",
      "\t Child: cub_003_Sooty_Albatross\n",
      "\t\tProto:0 001:(0.2988) 002:(0.0929) \n",
      "\t\tProto:1 001:(0.1553) 002:(0.0134) \n",
      "\t\tProto:3 001:(0.0548) 002:(0.0527) \n",
      "\t\tProto:5 001:(0.2914) 002:(0.1382) \n",
      "\t\tProto:6 001:(0.0574) 002:(0.0169) \n",
      "\t\tProto:7 001:(0.8914) 002:(0.0941) \n",
      "\t\tProto:9 001:(0.128) 002:(0.0185) \n",
      "\t Child: 002+001\n",
      "\t\tProto:11 003:(0.2726) \n",
      "\t\tProto:12 003:(0.2218) \n",
      "\t\tProto:13 003:(0.1497) \n",
      "\t\tProto:14 003:(0.0355) \n",
      "\t\tProto:15 003:(0.4611) \n",
      "\t\tProto:16 003:(0.1429) \n",
      "\t\tProto:18 003:(0.1046) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 32.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+100\n",
      "Num protos for cub_101_White_Pelican 8\n",
      "Num protos for cub_100_Brown_Pelican 9\n",
      "\t Child: cub_101_White_Pelican\n",
      "\t\tProto:0 100:(0.1996) \n",
      "\t\tProto:1 100:(0.0098) \n",
      "\t\tProto:2 100:(0.0466) \n",
      "\t\tProto:4 100:(0.1411) \n",
      "\t\tProto:5 100:(0.2632) \n",
      "\t\tProto:7 100:(0.0956) \n",
      "\t\tProto:8 100:(0.312) \n",
      "\t\tProto:9 100:(0.0027) \n",
      "\t Child: cub_100_Brown_Pelican\n",
      "\t\tProto:10 101:(0.0773) \n",
      "\t\tProto:11 101:(0.3693) \n",
      "\t\tProto:12 101:(0.4801) \n",
      "\t\tProto:13 101:(0.4703) \n",
      "\t\tProto:14 101:(0.7498) \n",
      "\t\tProto:15 101:(0.4867) \n",
      "\t\tProto:16 101:(0.0885) \n",
      "\t\tProto:17 101:(0.6618) \n",
      "\t\tProto:19 101:(0.6939) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 36.41it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "Num protos for cub_023_Brandt_Cormorant 8\n",
      "Num protos for 025+024 8\n",
      "\t Child: cub_023_Brandt_Cormorant\n",
      "\t\tProto:1 024:(0.0529) 025:(0.4504) \n",
      "\t\tProto:2 024:(0.0564) 025:(0.7746) \n",
      "\t\tProto:3 024:(0.0335) 025:(0.5103) \n",
      "\t\tProto:5 024:(0.0173) 025:(0.7512) \n",
      "\t\tProto:6 024:(0.0549) 025:(0.6854) \n",
      "\t\tProto:7 024:(0.2083) 025:(0.9589) \n",
      "\t\tProto:8 024:(0.0256) 025:(0.2207) \n",
      "\t\tProto:9 024:(0.0669) 025:(0.634) \n",
      "\t Child: 025+024\n",
      "\t\tProto:10 023:(0.334) \n",
      "\t\tProto:11 023:(0.1901) \n",
      "\t\tProto:13 023:(0.4785) \n",
      "\t\tProto:14 023:(0.2731) \n",
      "\t\tProto:16 023:(0.6317) \n",
      "\t\tProto:17 023:(0.9205) \n",
      "\t\tProto:18 023:(0.3452) \n",
      "\t\tProto:19 023:(0.7115) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 31.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 002+001\n",
      "Num protos for cub_002_Laysan_Albatross 9\n",
      "Num protos for cub_001_Black_footed_Albatross 8\n",
      "\t Child: cub_002_Laysan_Albatross\n",
      "\t\tProto:0 001:(0.029) \n",
      "\t\tProto:1 001:(0.1019) \n",
      "\t\tProto:2 001:(0.0103) \n",
      "\t\tProto:3 001:(0.0011) \n",
      "\t\tProto:4 001:(0.024) \n",
      "\t\tProto:5 001:(0.0632) \n",
      "\t\tProto:6 001:(0.0273) \n",
      "\t\tProto:7 001:(0.1245) \n",
      "\t\tProto:9 001:(0.002) \n",
      "\t Child: cub_001_Black_footed_Albatross\n",
      "\t\tProto:11 002:(0.1361) \n",
      "\t\tProto:12 002:(0.0883) \n",
      "\t\tProto:13 002:(0.1064) \n",
      "\t\tProto:14 002:(0.0493) \n",
      "\t\tProto:16 002:(0.1963) \n",
      "\t\tProto:17 002:(0.0057) \n",
      "\t\tProto:18 002:(0.0416) \n",
      "\t\tProto:19 002:(0.107) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 31.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 025+024\n",
      "Num protos for cub_025_Pelagic_Cormorant 7\n",
      "Num protos for cub_024_Red_faced_Cormorant 8\n",
      "\t Child: cub_025_Pelagic_Cormorant\n",
      "\t\tProto:0 024:(0.9969) \n",
      "\t\tProto:1 024:(0.9904) \n",
      "\t\tProto:3 024:(0.4729) \n",
      "\t\tProto:6 024:(0.6273) \n",
      "\t\tProto:7 024:(0.8821) \n",
      "\t\tProto:8 024:(0.9333) \n",
      "\t\tProto:9 024:(0.7266) \n",
      "\t Child: cub_024_Red_faced_Cormorant\n",
      "\t\tProto:10 025:(0.0262) \n",
      "\t\tProto:11 025:(0.0001) \n",
      "\t\tProto:12 025:(0.0001) \n",
      "\t\tProto:14 025:(0.0094) \n",
      "\t\tProto:16 025:(0.0017) \n",
      "\t\tProto:17 025:(0.0222) \n",
      "\t\tProto:18 025:(0.0021) \n",
      "\t\tProto:19 025:(0.011) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "def find_top_percentile_bbox(image, percentile=95):\n",
    "    threshold = np.percentile(image.flatten(), percentile)\n",
    "    mask = image >= threshold\n",
    "    coords = np.argwhere(mask)\n",
    "    if coords.size == 0:\n",
    "        return None, None, None, None\n",
    "    h_min, w_min = coords.min(axis=0)\n",
    "    h_max, w_max = coords.max(axis=0)\n",
    "    h_min, h_max, w_min, w_max = map(int, [h_min, h_max, w_min, w_max])\n",
    "    return h_min, h_max, w_min, w_max\n",
    "\n",
    "def find_high_activation_crop(activation_map, percentile=95):\n",
    "    threshold = np.percentile(activation_map, percentile)\n",
    "    mask = np.ones(activation_map.shape)\n",
    "    mask[activation_map < threshold] = 0\n",
    "    lower_y, upper_y, lower_x, upper_x = 0, 0, 0, 0\n",
    "    for i in range(mask.shape[0]):\n",
    "        if np.amax(mask[i]) > 0.5:\n",
    "            lower_y = i\n",
    "            break\n",
    "    for i in reversed(range(mask.shape[0])):\n",
    "        if np.amax(mask[i]) > 0.5:\n",
    "            upper_y = i\n",
    "            break\n",
    "    for j in range(mask.shape[1]):\n",
    "        if np.amax(mask[:,j]) > 0.5:\n",
    "            lower_x = j\n",
    "            break\n",
    "    for j in reversed(range(mask.shape[1])):\n",
    "        if np.amax(mask[:,j]) > 0.5:\n",
    "            upper_x = j\n",
    "            break\n",
    "    return lower_y, upper_y+1, lower_x, upper_x+1\n",
    "\n",
    "def get_upscaled_activation_uninterpolated(latent_activation, image_size):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    min_image_a = image_a.min()\n",
    "    max_image_a = image_a.max()\n",
    "    image_a = (image_a - min_image_a) / (max_image_a - min_image_a)\n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((image_size[-1], \\\n",
    "                                                                                            image_size[-2]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    reshaped_image_a = (reshaped_image_a / 255).astype('float16')\n",
    "    reshaped_image_a = (reshaped_image_a * (max_image_a - min_image_a)) + min_image_a\n",
    "    return reshaped_image_a\n",
    "\n",
    "# added for NUMPY SAVING\n",
    "def get_upscaled_activation_interpolated(latent_activation, image_size):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    min_image_a = image_a.min()\n",
    "    max_image_a = image_a.max()\n",
    "    image_a = (image_a - min_image_a) / (max_image_a - min_image_a)\n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((image_size[-1], \\\n",
    "                                                                                            image_size[-2])))    \n",
    "    reshaped_image_a = (reshaped_image_a / 255).astype('float16')\n",
    "    reshaped_image_a = (reshaped_image_a * (max_image_a - min_image_a)) + min_image_a\n",
    "    return reshaped_image_a\n",
    "\n",
    "def functional_UnitConv2D(in_features, weight, bias, stride = 1, padding=0):\n",
    "    normalized_weight = F.normalize(weight.data, p=2, dim=(1, 2, 3)) # Normalize the kernels to unit vectors\n",
    "    normalized_input = F.normalize(in_features, p=2, dim=1) # Normalize the input to unit vectors\n",
    "    if bias is not None:\n",
    "        normalized_bias = F.normalize(bias.data, p=2, dim=0) # Normalize the kernels to unit vectors\n",
    "    else:\n",
    "        normalized_bias = None\n",
    "    return F.conv2d(normalized_input, normalized_weight, normalized_bias, stride=stride, padding=padding)\n",
    "\n",
    "def findCorrespondingToMax(base, target):\n",
    "    global args\n",
    "    output, indices = F.max_pool2d(base, kernel_size=(args.wshape, args.wshape), return_indices=True)# these are logits\n",
    "    tensor_flattened = target.view(target.shape[0], target.shape[1], -1)\n",
    "    indices_flattened = indices.view(target.shape[0], target.shape[1], -1)\n",
    "    corresponding_values_in_target = torch.gather(tensor_flattened, 2, indices_flattened)\n",
    "    corresponding_values_in_target = corresponding_values_in_target.view(target.shape[0],\\\n",
    "                                     target.shape[1], 1, 1)\n",
    "    pooled_target = corresponding_values_in_target\n",
    "    return pooled_target\n",
    "\n",
    "def customForwardWithCSandSoftmax(net, xs,  inference=False):\n",
    "    features = net.module._net(xs) \n",
    "    proto_features = {}\n",
    "    proto_features_cs = {}\n",
    "    proto_features_softmaxed = {}\n",
    "    proto_features_pre_softmax = {}\n",
    "    pooled = {}\n",
    "    pooled_cs = {}\n",
    "    pooled_softmaxed = {}\n",
    "    out = {}\n",
    "    for node in net.module.root.nodes_with_children():\n",
    "        # this may or may not be cosine similarity based on UniConv2D or Conv2d\n",
    "        proto_features[node.name] = getattr(net.module, '_'+node.name+'_add_on')(features)\n",
    "        proto_features_pre_softmax[node.name] = proto_features[node.name]\n",
    "        \n",
    "        #calculating cosine similarity\n",
    "        prototypes = getattr(net.module, '_'+node.name+'_add_on')\n",
    "        proto_features_cs[node.name] = functional_UnitConv2D(features, prototypes.weight, prototypes.bias)\n",
    "\n",
    "        if net.module.args.softmax.split('|')[0] == 'y':\n",
    "            if len(net.module.args.softmax.split('|')) > 1:\n",
    "                softmax_tau = int(net.module.args.softmax.split('|')[1])\n",
    "            else:\n",
    "                softmax_tau = 0.2\n",
    "            if ('conc_log_ip' in net.module.args) and ('y' in net.module.args.conc_log_ip):\n",
    "                # softmax over the channel instead of over the patch\n",
    "                B, C, H, W = proto_features[node.name].shape\n",
    "                proto_features[node.name] = proto_features[node.name].reshape(B, C, -1)\n",
    "                proto_features_softmaxed[node.name] = F.softmax(proto_features[node.name], dim=-1)\n",
    "                proto_features_softmaxed[node.name] = proto_features_softmaxed[node.name].reshape(B, C, H, W)\n",
    "                proto_features[node.name] = proto_features_softmaxed[node.name]\n",
    "            else:\n",
    "                proto_features[node.name] = proto_features[node.name] / softmax_tau\n",
    "                proto_features_softmaxed[node.name] = net.module._softmax(proto_features[node.name])\n",
    "                proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "                \n",
    "            # proto_features[node.name] = proto_features[node.name] / softmax_tau\n",
    "            # proto_features_softmaxed[node.name] = net.module._softmax(proto_features[node.name])\n",
    "            # proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "        elif net.module.args.gumbel_softmax == 'y':\n",
    "            proto_features_softmaxed[node.name] = net.module._gumbel_softmax(proto_features[node.name])\n",
    "            proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "\n",
    "        if net.module.args.multiply_cs_softmax == 'y':\n",
    "            proto_features[node.name] = proto_features_cs[node.name] * proto_features_softmaxed[node.name]\n",
    "        pooled[node.name] = net.module._pool(proto_features[node.name])\n",
    "        \n",
    "        # this could be softmax or cosine similarity\n",
    "        pooled_cs[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                     target=proto_features_cs[node.name])\n",
    "        \n",
    "        # only if the model uses softmax or gumbel softmax\n",
    "        if (net.module.args.softmax == 'y') or (net.module.args.gumbel_softmax == 'y'):\n",
    "            pooled_softmaxed[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                         target=proto_features_softmaxed[node.name])\n",
    "\n",
    "        if inference:\n",
    "            pooled[node.name] = torch.where(pooled[node.name] < 0.1, 0., pooled[node.name])  #during inference, ignore all prototypes that have 0.1 similarity or lower\n",
    "        out[node.name] = getattr(net.module, '_'+node.name+'_classification')(pooled[node.name]) #shape (bs*2, num_classes) # these are logits\n",
    "    \"\"\"\n",
    "    features -> Raw features generated by the backbone before the prototype layer\n",
    "    proto_features -> Output of prototype layer (UnitConv2D or Conv2D based on the network configuration used), and softmaxed\n",
    "    proto_features_cs -> Cosine similarity between features and prototypes\n",
    "    proto_features_softmaxed -> Same as proto_features\n",
    "    pooled -> max pooled on proto_features\n",
    "    pooled_cs -> cosine values corresponding to max indices in proto_features\n",
    "    \"\"\"\n",
    "    return features, proto_features_pre_softmax, proto_features, proto_features_cs, proto_features_softmaxed, pooled, pooled_cs, pooled_softmaxed, out\n",
    "#     return features, proto_features, pooled, pooled_cs, pooled_softmaxed, out\n",
    "\n",
    "def customForwardWithProjDistandSoftmax(net, xs,  inference=False):\n",
    "    features = net.module._net(xs) \n",
    "    proto_features = {}\n",
    "    proto_features_cs = {}\n",
    "    proto_features_softmaxed = {}\n",
    "    pooled = {}\n",
    "    pooled_cs = {}\n",
    "    pooled_softmaxed = {}\n",
    "    out = {}\n",
    "    for node in net.module.root.nodes_with_children():\n",
    "        # this may or may not be cosine similarity based on UniConv2D or Conv2d\n",
    "        proto_features[node.name] = getattr(net.module, '_'+node.name+'_add_on')(features)\n",
    "        \n",
    "        \n",
    "        #calculating cosine similarity\n",
    "        prototypes = getattr(net.module, '_'+node.name+'_add_on')\n",
    "        proto_features_cs[node.name] = functional_UnitConv2D(features, prototypes.weight, prototypes.bias)\n",
    "\n",
    "        if net.module.args.softmax == 'y':\n",
    "            softmax_tau = 0.2\n",
    "            proto_features[node.name] = proto_features[node.name] / softmax_tau\n",
    "            proto_features_softmaxed[node.name] = net.module._softmax(proto_features[node.name])\n",
    "            proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "        elif net.module.args.gumbel_softmax == 'y':\n",
    "            proto_features_softmaxed[node.name] = net.module._gumbel_softmax(proto_features[node.name])\n",
    "            proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "\n",
    "        if net.module.args.multiply_cs_softmax == 'y':\n",
    "            proto_features[node.name] = proto_features_cs[node.name] * proto_features_softmaxed[node.name]\n",
    "        pooled[node.name] = net.module._pool(proto_features[node.name])\n",
    "        \n",
    "        # this could be softmax or cosine similarity\n",
    "        pooled_cs[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                     target=proto_features_cs[node.name])\n",
    "        \n",
    "        # only if the model uses softmax or gumbel softmax\n",
    "        if (net.module.args.softmax == 'y') or (net.module.args.gumbel_softmax == 'y'):\n",
    "            pooled_softmaxed[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                         target=proto_features_softmaxed[node.name])\n",
    "\n",
    "        if inference:\n",
    "            pooled[node.name] = torch.where(pooled[node.name] < 0.1, 0., pooled[node.name])  #during inference, ignore all prototypes that have 0.1 similarity or lower\n",
    "        out[node.name] = getattr(net.module, '_'+node.name+'_classification')(pooled[node.name]) #shape (bs*2, num_classes) # these are logits\n",
    "    \"\"\"\n",
    "    features -> Raw features generated by the backbone before the prototype layer\n",
    "    proto_features -> Output of prototype layer (UnitConv2D or Conv2D based on the network configuration used), and softmaxed\n",
    "    proto_features_cs -> Cosine similarity between features and prototypes\n",
    "    proto_features_softmaxed -> Same as proto_features\n",
    "    pooled -> max pooled on proto_features\n",
    "    pooled_cs -> cosine values corresponding to max indices in proto_features\n",
    "    \"\"\"\n",
    "    return features, proto_features_pre_softmax, proto_features, proto_features_cs, proto_features_softmaxed, pooled, pooled_cs, pooled_softmaxed, out\n",
    "\n",
    "find_non_descendants = True # True, False # param\n",
    "heatmap_type = 'pre_softmax' # 'pre_softmax', 'softmax'\n",
    "vizloader_name = 'projectloader' #'testloader' # 'projectloader'\n",
    "bbox_percentile = 97\n",
    "topk = 6 # param, args param\n",
    "save_images = True #True, False\n",
    "save_activation_as_npy_path = '_'.join(['activation_as_npy', vizloader_name]) # activation_as_npy, added for NUMPY SAVING\n",
    "if find_non_descendants and (save_activation_as_npy_path is not None):\n",
    "    save_activation_as_npy_path = save_activation_as_npy_path + '_non_desc'\n",
    "analysis_mode = True\n",
    "\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "font2 = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "font3 = ImageFont.truetype(\"arial.ttf\", 30)\n",
    "\n",
    "from datetime import datetime\n",
    "txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "txt_file.write('\\n')\n",
    "\n",
    "def write_num_proto_details(proto_mean_activations, node_name, net, threshold, txt_file, args):\n",
    "    \n",
    "    rand_input = torch.randn((1, 3, args.image_size, args.image_size))\n",
    "    with torch.no_grad():\n",
    "        *_, pooled, out = net(rand_input)\n",
    "    num_protos = pooled[node_name].shape[1]\n",
    "    used_protos = len(proto_mean_activations)\n",
    "    non_overspecific = 0\n",
    "    for p in proto_mean_activations:\n",
    "        logstr = '\\t'*2 + f'Proto:{p} '\n",
    "        protos_mean_for_all_leaf_descedants = []\n",
    "        for leaf_descendent in proto_mean_activations[p]:\n",
    "            mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "            protos_mean_for_all_leaf_descedants.append(mean_activation)\n",
    "            \n",
    "        if all([(mean_activation>0.2) for mean_activation in protos_mean_for_all_leaf_descedants]):\n",
    "            non_overspecific += 1\n",
    "            \n",
    "    txt_file.write(f\"Node:{node_name},Total:{num_protos},Used:{used_protos},Good:{non_overspecific},threshold={threshold}\\n\")\n",
    "\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "\n",
    "\n",
    "vizloader_dict = {'trainloader': trainloader,\n",
    "                 'projectloader': projectloader,\n",
    "                 'testloader': testloader,\n",
    "                 'test_projectloader': test_projectloader}\n",
    "vizloader_dict[vizloader_name] = unshuffle_dataloader(vizloader_dict[vizloader_name])\n",
    "\n",
    "\n",
    "if type(vizloader_dict[vizloader_name].dataset) == ImageFolder:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "else:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.dataset.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    \n",
    "#     if node.name == 'root':\n",
    "#         print('-'*25, 'Skipping root node', '-'*25)\n",
    "#         continue\n",
    "\n",
    "#     non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "#     if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "#         continue\n",
    "\n",
    "#     name2label = projectloader.dataset.class_to_idx # param\n",
    "#     label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(vizloader_dict[vizloader_name], node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    \n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        # change\n",
    "#         if not find_non_descendants: \n",
    "#             # do only when finding descendants\n",
    "#             if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "#                 continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = customForwardWithCSandSoftmax(net, xs, inference=False)\n",
    "            features, proto_features_pre_softmax, softmaxes, cosine_similarity, _, pooled, pooled_cs, pooled_softmaxed, out = model_output\n",
    "#             _, softmaxes, pooled, pooled_ip, pooled_softmax, _ = model_output # features, proto_features, pooled, pooled_cs, pooled_softmaxed, out\n",
    "#             model_output = net(xs, inference=False)\n",
    "#             if len(model_output) == 3:\n",
    "#                 softmaxes, pooled, _ = model_output\n",
    "#             elif len(model_output) == 4:\n",
    "#                 _, softmaxes, pooled, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0)\n",
    "            pooled_cs = pooled_cs[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "            cosine_similarity = cosine_similarity[node.name]\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # change\n",
    "#                 if (len(relevant_proto_class_names) == 1):# and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "#                     continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                \n",
    "                latent_activation_pre_softmax = proto_features_pre_softmax[node.name][:, p, :, :]\n",
    "                latent_activation_cs = cosine_similarity[:, p, :, :]\n",
    "                if not find_non_descendants:\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7] if analysis_mode else \\\n",
    "                                                label2name[orig_y.item()][4:]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), pooled_cs[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                                               latent_activation, latent_activation_cs, latent_activation_pre_softmax))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), pooled_cs[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                                            latent_activation, latent_activation_cs, latent_activation_pre_softmax))\n",
    "                else:\n",
    "                    if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7] if analysis_mode else \\\n",
    "                                                label2name[orig_y.item()][4:]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), pooled_cs[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                                               latent_activation, latent_activation_cs, latent_activation_pre_softmax))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), pooled_cs[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                                            latent_activation, latent_activation_cs, latent_activation_pre_softmax))\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "                \n",
    "    write_num_proto_details(proto_mean_activations, node.name, net, threshold=0.2, txt_file=txt_file, args=args)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for class_label in range(classification_weights.shape[0]):\n",
    "        child_name = (coarse_label2name[class_label])\n",
    "        print('Num protos for', child_name, torch.nonzero(classification_weights[class_label, :] > 1e-3).shape[0])\n",
    "        \n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            mean_activation_of_every_leaf = []\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "                mean_activation_of_every_leaf.append(mean_activation)\n",
    "            print(logstr)\n",
    "            \n",
    "            # # if the mean_activation is less for all leaf descendants skip the node\n",
    "            # if all([mean_act < 0.2 for mean_act in mean_activation_of_every_leaf]):\n",
    "            #     if find_non_descendants:\n",
    "            #         print('\\t'*2 + f'Not skipping proto {p} of {node.name} coz of find_non_descendants')\n",
    "            #     else:\n",
    "            #         print('\\t'*2 + f'Skipping proto {p} of {node.name}')\n",
    "            #         continue\n",
    "            \n",
    "            # have this for NON descendants\n",
    "            if len(proto_mean_activations[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images or save_activation_as_npy_path:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 if analysis_mode else 2 # 3x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 2)\n",
    "                    least_activation = min([round(activation, 2) for activation, *_ in proto_mean_activations[p][leaf_descendent]])\n",
    "                    most_activation = max([round(activation, 2) for activation, *_ in proto_mean_activations[p][leaf_descendent]])\n",
    "                    mean_cosine_similarity = round(np.mean([activation_inner_product for _, activation_inner_product, *_ in proto_mean_activations[p][leaf_descendent]]), 2)\n",
    "                    # modified for NUMPY SAVING\n",
    "                    for rank, ele in enumerate(heap):\n",
    "                        \n",
    "                        activation, activation_inner_product, img_to_open, \\\n",
    "                        (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                        latent_activation, latent_activation_cs, latent_activation_pre_softmax = ele\n",
    "                        \n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "#                         overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "#                         overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "#                         patches.append(overlayed_image)\n",
    "\n",
    "                        if heatmap_type == 'pre_softmax':\n",
    "                            overlayed_image_np = get_heatmap(latent_activation_pre_softmax, img_tensor)\n",
    "                        else:\n",
    "                            overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        if analysis_mode:\n",
    "                            overlayed_image_pil = Image.fromarray(overlayed_image_np)\n",
    "                            draw = D.Draw(overlayed_image_pil)\n",
    "                            text = f\"{round(activation, 2), round(activation_inner_product, 2)}\"\n",
    "    #                         text_width, text_height = draw.textsize(text, font2)\n",
    "                            bbox = draw.textbbox((0, 0), text, font2)\n",
    "                            text_width = bbox[2] - bbox[0]\n",
    "                            text_height = bbox[3] - bbox[1]\n",
    "                            x, y = 224 - text_width - 5, 5  # 10 pixels padding from right\n",
    "                            draw.text((x, y), text, font=font2, fill=(255, 255, 255))\n",
    "                            overlayed_image_np = np.array(overlayed_image_pil)\n",
    "                        \n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "\n",
    "                        # Commenting Bounding Boxes for now\n",
    "                        # if analysis_mode:\n",
    "                        #     upscaled_similarity = get_upscaled_activation_uninterpolated(latent_activation, image_size=(args.image_size, args.image_size))\n",
    "                        #     h_min, h_max, w_min, w_max = get_bb_gaussian_threshold(latent_activation, sigma=1.0, \\\n",
    "                        #                                                            percentile=bbox_percentile, extend_h=0, extend_w=0)\n",
    "                        #     bbox_coords = torch.tensor([[w_min, h_min, w_max, h_max]])\n",
    "                        #     overlayed_image = torchvision.utils.draw_bounding_boxes((overlayed_image * 255).type(torch.uint8), \\\n",
    "                        #                                                                bbox_coords, colors='red') / 255\n",
    "                        \n",
    "#                         plt_image = overlayed_bb_image.permute(1, 2, 0)# should be H, W, C with 0 to 1\n",
    "#                         plt.imshow(plt_image)\n",
    "#                         plt.show()\n",
    "#                         pdb.set_trace()\n",
    "                        patches.append(overlayed_image)\n",
    "                        # added for NUMPY SAVING\n",
    "                        if save_activation_as_npy_path:\n",
    "                            upscaled_similarity_interpolated = get_upscaled_activation_interpolated(latent_activation,\n",
    "                                                                                       image_size=(args.image_size, args.image_size))\n",
    "                            latent_activation_npy = latent_activation.squeeze().cpu().numpy()\n",
    "                            latent_activation_cs_npy = latent_activation_cs.squeeze().cpu().numpy()\n",
    "                            data = {'node_name': node.name,\n",
    "                                    'proto_num': p,\n",
    "                                    'child_name': child_classname,\n",
    "                                    'leaf_desc': leaf_descendent,\n",
    "                                     'rank': rank,\n",
    "                                     'img_path': img_to_open,\n",
    "                                     'img_filename': ntpath.basename(img_to_open),\n",
    "                                     'activation': latent_activation_npy,\n",
    "                                     'activation_cs': latent_activation_cs_npy,\n",
    "                                     'max_activation': activation,\n",
    "                                     'model_type': 'HPIPNET'}\n",
    "                            filename = str(rank)+ '-' + ntpath.basename(img_to_open) + '.npy'\n",
    "                            save_path = os.path.join(run_path, save_activation_as_npy_path, \\\n",
    "                                                     node.name, str(p), leaf_descendent,\n",
    "                                                     filename)\n",
    "                            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                            np.save(save_path, data, allow_pickle=True)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}' if analysis_mode else \\\n",
    "                                f'{leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((200, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font3)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "                \n",
    "                # weird thing padding should be zero for non descendants else it raises some error # change\n",
    "                if find_non_descendants or (len(patches) == topk): # (len(patches) == topk) means there is only one leaf descendant\n",
    "                    padding = 0\n",
    "                else:\n",
    "                    padding = 1\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=padding)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=padding)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid_right_descriptions, grid], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}' if analysis_mode else \\\n",
    "                            f'Parent node:{node.name}, Child node:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], 75), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((500, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([txttensor, grid], dim=1)\n",
    "                \n",
    "                if save_images:\n",
    "                    prefix = 'non_' if find_non_descendants else ''\n",
    "                    os.makedirs(os.path.join(run_path, prefix + f'descendent_specific_topk_heatmap_{vizloader_name}_{bbox_percentile}_ep={epoch}_analysis={analysis_mode}', node.name), exist_ok=True)\n",
    "                    torchvision.utils.save_image(grid, os.path.join(run_path, prefix + f'descendent_specific_topk_heatmap_{vizloader_name}_{bbox_percentile}_ep={epoch}_analysis={analysis_mode}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "txt_file.write('\\n')\n",
    "txt_file.close()\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "\tcub_052_Pied_billed_Grebe\n",
      "\tcub_053_Western_Grebe\n",
      "\tcub_050_Eared_Grebe\n",
      "\tcub_051_Horned_Grebe\n",
      "\tcub_004_Groove_billed_Ani\n",
      "\tcub_032_Mangrove_Cuckoo\n",
      "\tcub_033_Yellow_billed_Cuckoo\n",
      "\tcub_031_Black_billed_Cuckoo\n",
      "\tcub_086_Pacific_Loon\n",
      "\tcub_045_Northern_Fulmar\n",
      "\tcub_003_Sooty_Albatross\n",
      "\tcub_002_Laysan_Albatross\n",
      "\tcub_001_Black_footed_Albatross\n",
      "\tcub_101_White_Pelican\n",
      "\tcub_100_Brown_Pelican\n",
      "\tcub_023_Brandt_Cormorant\n",
      "\tcub_025_Pelagic_Cormorant\n",
      "\tcub_024_Red_faced_Cormorant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 844\n",
      "    Root location: /projects/ml4science/harishbabu/data/CUB_29_pipnet_224/dataset_segmented_imgnet_pt/test_crop\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "vizloader_name = 'testloader'\n",
    "vizloader_dict[vizloader_name] = unshuffle_dataloader(vizloader_dict[vizloader_name])\n",
    "print(vizloader_dict[vizloader_name].dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images using  NAIVE-HPIPNET with HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:08, 60.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:0 050:(0.5518) 051:(0.9456) 052:(0.7025) 053:(0.8337) \n",
      "\t\tProto:1 050:(0.6937) 051:(0.5367) 052:(0.3542) 053:(0.6313) \n",
      "\t\tProto:3 050:(0.4844) 051:(0.9281) 052:(0.726) 053:(0.9574) \n",
      "\t\tProto:4 050:(0.1962) 051:(0.3213) 052:(0.1935) 053:(0.6972) \n",
      "\t\tProto:8 050:(0.278) 051:(0.7743) 052:(0.6752) 053:(0.5223) \n",
      "\t\tProto:9 050:(0.8475) 051:(0.9772) 052:(0.9417) 053:(0.9023) \n",
      "\t Child: 004+086\n",
      "\t\tProto:10 001:(0.9984) 002:(0.9995) 003:(0.9906) 004:(0.9394) 023:(0.8774) 024:(0.9856) 025:(0.9731) 031:(0.9792) 032:(0.8464) 033:(0.9987) 045:(0.9874) 086:(0.9937) 100:(0.975) 101:(0.9749) \n",
      "\t\tProto:11 001:(0.2657) 002:(0.3227) 003:(0.3499) 004:(0.8971) 023:(0.8303) 024:(0.8436) 025:(0.9433) 031:(0.6574) 032:(0.8335) 033:(0.8053) 045:(0.7866) 086:(0.4094) 100:(0.3448) 101:(0.3689) \n",
      "\t\tProto:12 001:(0.9456) 002:(0.8183) 003:(0.9871) 004:(0.9165) 023:(0.9948) 024:(0.4263) 025:(0.9015) 031:(0.9895) 032:(0.879) 033:(0.8274) 045:(0.8713) 086:(0.9985) 100:(0.836) 101:(0.7469) \n",
      "\t\tProto:13 001:(0.9995) 002:(0.9995) 003:(0.9999) 004:(0.9889) 023:(0.9707) 024:(0.9916) 025:(0.9813) 031:(1.0) 032:(0.9981) 033:(0.9999) 045:(0.9991) 086:(0.9762) 100:(0.9979) 101:(0.999) \n",
      "\t\tProto:14 001:(0.9771) 002:(0.9975) 003:(0.9535) 004:(0.8368) 023:(0.8334) 024:(0.8254) 025:(0.8791) 031:(0.9949) 032:(0.9974) 033:(0.9966) 045:(0.8676) 086:(0.5621) 100:(0.9078) 101:(0.9876) \n",
      "\t\tProto:16 001:(0.7653) 002:(0.8634) 003:(0.8702) 004:(0.4893) 023:(0.3774) 024:(0.4247) 025:(0.5136) 031:(0.7858) 032:(0.619) 033:(0.69) 045:(0.8861) 086:(0.5258) 100:(0.7053) 101:(0.5441) \n",
      "\t\tProto:18 001:(0.2784) 002:(0.5613) 003:(0.563) 004:(0.5943) 023:(0.9239) 024:(0.5066) 025:(0.8347) 031:(0.9038) 032:(0.9514) 033:(0.8646) 045:(0.6336) 086:(0.8169) 100:(0.3434) 101:(0.1638) \n",
      "\t\tProto:19 001:(0.9643) 002:(0.9996) 003:(0.8501) 004:(0.913) 023:(0.8674) 024:(0.9987) 025:(0.7135) 031:(0.6058) 032:(0.2866) 033:(0.7271) 045:(0.9744) 086:(0.3553) 100:(1.0) 101:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 46.12it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "\t Child: cub_052_Pied_billed_Grebe\n",
      "\t\tProto:0 052:(0.999) \n",
      "\t\tProto:1 052:(0.9972) \n",
      "\t\tProto:3 052:(0.3696) \n",
      "\t\tProto:5 052:(0.9774) \n",
      "\t\tProto:8 052:(0.9965) \n",
      "\t\tProto:9 052:(0.9961) \n",
      "\t Child: 053+050\n",
      "\t\tProto:11 050:(0.9298) 051:(0.9366) 053:(0.9994) \n",
      "\t\tProto:12 050:(0.9476) 051:(0.9277) 053:(0.9714) \n",
      "\t\tProto:13 050:(0.9863) 051:(0.9944) 053:(0.977) \n",
      "\t\tProto:14 050:(0.8974) 051:(0.9807) 053:(0.9385) \n",
      "\t\tProto:15 050:(0.9845) 051:(0.996) 053:(0.9994) \n",
      "\t\tProto:16 050:(0.9553) 051:(0.9974) 053:(0.9958) \n",
      "\t\tProto:17 050:(0.8729) 051:(0.9412) 053:(0.9889) \n",
      "\t\tProto:18 050:(0.9847) 051:(0.999) 053:(0.988) \n",
      "\t\tProto:19 050:(0.9993) 051:(0.9958) 053:(0.9027) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:06, 60.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:2 004:(0.0658) 031:(0.9816) 032:(0.9939) 033:(0.9855) \n",
      "\t\tProto:3 004:(0.9992) 031:(0.9888) 032:(0.989) 033:(0.9955) \n",
      "\t\tProto:5 004:(0.9278) 031:(0.9208) 032:(0.9956) 033:(0.9993) \n",
      "\t\tProto:6 004:(0.9344) 031:(0.9995) 032:(0.9917) 033:(0.9996) \n",
      "\t\tProto:8 004:(0.9908) 031:(0.9023) 032:(0.9939) 033:(0.9426) \n",
      "\t Child: 086+045\n",
      "\t\tProto:10 001:(0.9809) 002:(0.8511) 003:(0.9238) 023:(0.9266) 024:(0.9324) 025:(0.7716) 045:(0.8939) 086:(0.9793) 100:(0.9356) 101:(0.9778) \n",
      "\t\tProto:11 001:(0.9594) 002:(0.8757) 003:(0.9845) 023:(0.9992) 024:(0.9999) 025:(0.9974) 045:(0.9701) 086:(0.999) 100:(0.9987) 101:(0.9836) \n",
      "\t\tProto:12 001:(0.9756) 002:(0.9476) 003:(0.7369) 023:(0.7323) 024:(0.9583) 025:(0.5397) 045:(0.4315) 086:(0.9007) 100:(0.9159) 101:(0.9293) \n",
      "\t\tProto:13 001:(0.9321) 002:(0.6039) 003:(0.7063) 023:(0.7847) 024:(0.6895) 025:(0.7372) 045:(0.527) 086:(0.914) 100:(0.825) 101:(0.5782) \n",
      "\t\tProto:14 001:(0.9983) 002:(0.9843) 003:(0.9958) 023:(0.9996) 024:(0.9997) 025:(0.9998) 045:(0.9797) 086:(0.9987) 100:(0.9999) 101:(0.9975) \n",
      "\t\tProto:15 001:(0.9963) 002:(0.9932) 003:(0.9888) 023:(0.8765) 024:(0.4234) 025:(0.8359) 045:(0.9602) 086:(0.856) 100:(0.8136) 101:(0.9244) \n",
      "\t\tProto:16 001:(0.4813) 002:(0.7098) 003:(0.7513) 023:(0.8736) 024:(0.6264) 025:(0.5651) 045:(0.6919) 086:(0.7478) 100:(0.8206) 101:(0.7926) \n",
      "\t\tProto:17 001:(0.9993) 002:(0.9998) 003:(0.9987) 023:(0.9978) 024:(0.9988) 025:(0.9419) 045:(0.998) 086:(0.9971) 100:(0.9964) 101:(0.9966) \n",
      "\t\tProto:18 001:(0.832) 002:(0.7624) 003:(0.6082) 023:(0.6697) 024:(0.9843) 025:(0.5924) 045:(0.6199) 086:(0.8606) 100:(0.9121) 101:(0.9716) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 41.80it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "\t Child: cub_053_Western_Grebe\n",
      "\t\tProto:0 053:(0.9993) \n",
      "\t\tProto:4 053:(0.9999) \n",
      "\t\tProto:5 053:(1.0) \n",
      "\t\tProto:7 053:(1.0) \n",
      "\t\tProto:8 053:(0.9997) \n",
      "\t\tProto:9 053:(0.9999) \n",
      "\t Child: 050+051\n",
      "\t\tProto:10 050:(0.9974) 051:(0.9893) \n",
      "\t\tProto:11 050:(0.9985) 051:(0.984) \n",
      "\t\tProto:13 050:(0.9834) 051:(0.9951) \n",
      "\t\tProto:14 050:(0.9971) 051:(0.9987) \n",
      "\t\tProto:15 050:(0.9283) 051:(0.9669) \n",
      "\t\tProto:16 050:(0.9704) 051:(0.9383) \n",
      "\t\tProto:17 050:(0.9951) 051:(0.998) \n",
      "\t\tProto:18 050:(0.8869) 051:(0.9863) \n",
      "\t\tProto:19 050:(0.9328) 051:(0.9962) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 44.99it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "\t Child: cub_004_Groove_billed_Ani\n",
      "\t\tProto:0 004:(0.9895) \n",
      "\t\tProto:3 004:(0.9988) \n",
      "\t\tProto:4 004:(0.9933) \n",
      "\t\tProto:5 004:(1.0) \n",
      "\t\tProto:6 004:(0.9998) \n",
      "\t Child: 032+033\n",
      "\t\tProto:10 031:(0.9961) 032:(0.9954) 033:(0.9981) \n",
      "\t\tProto:11 031:(0.999) 032:(0.9994) 033:(0.9958) \n",
      "\t\tProto:12 031:(0.9991) 032:(0.9678) 033:(0.9716) \n",
      "\t\tProto:13 031:(0.9943) 032:(0.9996) 033:(0.9996) \n",
      "\t\tProto:14 031:(0.9999) 032:(0.9995) 033:(0.9987) \n",
      "\t\tProto:15 031:(0.8629) 032:(0.9998) 033:(0.9999) \n",
      "\t\tProto:16 031:(0.9864) 032:(0.9998) 033:(0.7624) \n",
      "\t\tProto:17 031:(0.9742) 032:(0.9682) 033:(0.9252) \n",
      "\t\tProto:18 031:(0.9966) 032:(0.996) 033:(0.9996) \n",
      "\t\tProto:19 031:(0.9941) 032:(0.9809) 033:(0.9884) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:05, 58.02it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "\t Child: cub_086_Pacific_Loon\n",
      "\t\tProto:9 086:(0.9953) \n",
      "\t\tProto:2 086:(0.9992) \n",
      "\t\tProto:6 086:(0.9995) \n",
      "\t\tProto:7 086:(0.9994) \n",
      "\t Child: 045+101\n",
      "\t\tProto:10 001:(0.2124) 002:(0.7942) 003:(0.6234) 023:(0.9541) 024:(0.7813) 025:(0.8403) 045:(0.4974) 100:(0.7084) 101:(0.8462) \n",
      "\t\tProto:11 001:(0.9917) 002:(0.9887) 003:(0.9896) 023:(0.383) 024:(0.7232) 025:(0.6133) 045:(0.9261) 100:(0.9755) 101:(0.9674) \n",
      "\t\tProto:12 001:(0.9726) 002:(0.8995) 003:(0.9909) 023:(0.8758) 024:(0.9152) 025:(0.7397) 045:(0.9926) 100:(0.1204) 101:(0.9311) \n",
      "\t\tProto:13 001:(0.9974) 002:(0.8891) 003:(0.8062) 023:(0.9828) 024:(0.997) 025:(0.9934) 045:(0.9453) 100:(0.9881) 101:(0.9473) \n",
      "\t\tProto:14 001:(0.9989) 002:(0.9949) 003:(0.9812) 023:(0.9913) 024:(0.9889) 025:(0.9894) 045:(0.993) 100:(0.993) 101:(0.9566) \n",
      "\t\tProto:15 001:(0.6373) 002:(0.8878) 003:(0.9536) 023:(0.9634) 024:(0.8601) 025:(0.8425) 045:(0.716) 100:(0.9997) 101:(0.995) \n",
      "\t\tProto:16 001:(0.9354) 002:(0.9795) 003:(0.9138) 023:(0.9362) 024:(0.9994) 025:(0.817) 045:(0.7851) 100:(0.9744) 101:(0.9985) \n",
      "\t\tProto:17 001:(0.9817) 002:(0.7988) 003:(0.8608) 023:(0.9663) 024:(0.9663) 025:(0.9363) 045:(0.9376) 100:(0.9495) 101:(0.5728) \n",
      "\t\tProto:18 001:(0.8545) 002:(0.9621) 003:(0.9962) 023:(0.7574) 024:(0.9917) 025:(0.8994) 045:(0.7602) 100:(0.9963) 101:(0.9732) \n",
      "\t\tProto:19 001:(0.9975) 002:(0.9882) 003:(0.8094) 023:(0.9595) 024:(0.7599) 025:(0.7971) 045:(0.9976) 100:(0.4172) 101:(0.7417) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 33.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 050+051\n",
      "\t Child: cub_050_Eared_Grebe\n",
      "\t\tProto:0 050:(0.9931) \n",
      "\t\tProto:2 050:(1.0) \n",
      "\t\tProto:3 050:(0.9996) \n",
      "\t\tProto:4 050:(0.997) \n",
      "\t\tProto:7 050:(0.9995) \n",
      "\t\tProto:9 050:(0.9983) \n",
      "\t Child: cub_051_Horned_Grebe\n",
      "\t\tProto:11 051:(0.9966) \n",
      "\t\tProto:13 051:(0.9796) \n",
      "\t\tProto:15 051:(0.9996) \n",
      "\t\tProto:16 051:(0.9908) \n",
      "\t\tProto:17 051:(0.9977) \n",
      "\t\tProto:18 051:(0.8365) \n",
      "\t\tProto:19 051:(0.9329) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 41.17it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "\t Child: cub_032_Mangrove_Cuckoo\n",
      "\t\tProto:3 032:(0.999) \n",
      "\t\tProto:4 032:(0.9997) \n",
      "\t\tProto:5 032:(1.0) \n",
      "\t\tProto:6 032:(1.0) \n",
      "\t\tProto:7 032:(1.0) \n",
      "\t\tProto:8 032:(0.9997) \n",
      "\t Child: 033+031\n",
      "\t\tProto:10 031:(0.9987) 033:(0.9867) \n",
      "\t\tProto:11 031:(0.9943) 033:(0.9749) \n",
      "\t\tProto:12 031:(0.976) 033:(0.6806) \n",
      "\t\tProto:13 031:(0.9886) 033:(0.9105) \n",
      "\t\tProto:15 031:(0.9997) 033:(0.9988) \n",
      "\t\tProto:16 031:(0.9958) 033:(0.9916) \n",
      "\t\tProto:17 031:(0.9886) 033:(0.9814) \n",
      "\t\tProto:18 031:(0.9987) 033:(0.9966) \n",
      "\t\tProto:19 031:(0.9998) 033:(0.9997) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 59.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:2 001:(0.9343) 002:(0.961) 003:(0.9682) 045:(0.8507) \n",
      "\t\tProto:3 001:(0.8667) 002:(0.971) 003:(0.8624) 045:(0.9317) \n",
      "\t\tProto:6 001:(0.998) 002:(0.9601) 003:(0.9988) 045:(0.9968) \n",
      "\t\tProto:7 001:(0.9829) 002:(0.9852) 003:(0.9958) 045:(0.989) \n",
      "\t\tProto:9 001:(0.9998) 002:(0.9999) 003:(0.9996) 045:(0.9978) \n",
      "\t Child: 101+023\n",
      "\t\tProto:18 023:(0.993) 024:(0.9979) 025:(0.9916) 100:(0.9991) 101:(0.9998) \n",
      "\t\tProto:11 023:(0.9933) 024:(0.998) 025:(0.9901) 100:(0.6536) 101:(0.8352) \n",
      "\t\tProto:12 023:(0.9065) 024:(0.9533) 025:(0.9765) 100:(0.9633) 101:(0.7547) \n",
      "\t\tProto:14 023:(0.9992) 024:(0.9931) 025:(0.9968) 100:(0.9998) 101:(0.9992) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 35.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 033+031\n",
      "\t Child: cub_033_Yellow_billed_Cuckoo\n",
      "\t\tProto:1 033:(0.9999) \n",
      "\t\tProto:2 033:(1.0) \n",
      "\t\tProto:3 033:(0.9999) \n",
      "\t\tProto:4 033:(0.9995) \n",
      "\t\tProto:5 033:(0.9984) \n",
      "\t\tProto:6 033:(1.0) \n",
      "\t\tProto:9 033:(0.9999) \n",
      "\t Child: cub_031_Black_billed_Cuckoo\n",
      "\t\tProto:10 031:(0.9944) \n",
      "\t\tProto:11 031:(0.9843) \n",
      "\t\tProto:14 031:(0.9961) \n",
      "\t\tProto:15 031:(0.9994) \n",
      "\t\tProto:16 031:(0.9993) \n",
      "\t\tProto:18 031:(0.9991) \n",
      "\t\tProto:19 031:(0.8073) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 43.65it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "\t Child: cub_045_Northern_Fulmar\n",
      "\t\tProto:1 045:(0.9979) \n",
      "\t\tProto:3 045:(0.9987) \n",
      "\t\tProto:4 045:(0.9989) \n",
      "\t\tProto:6 045:(0.9992) \n",
      "\t\tProto:7 045:(0.998) \n",
      "\t\tProto:8 045:(0.9996) \n",
      "\t\tProto:9 045:(0.9967) \n",
      "\t Child: 003+002\n",
      "\t\tProto:10 001:(0.9094) 002:(0.925) 003:(0.6934) \n",
      "\t\tProto:11 001:(0.9937) 002:(0.9317) 003:(0.9684) \n",
      "\t\tProto:12 001:(0.9986) 002:(0.9992) 003:(0.9982) \n",
      "\t\tProto:13 001:(0.9426) 002:(0.9959) 003:(0.9366) \n",
      "\t\tProto:14 001:(0.9893) 002:(0.9985) 003:(0.9801) \n",
      "\t\tProto:15 001:(1.0) 002:(0.9998) 003:(0.9994) \n",
      "\t\tProto:16 001:(0.9955) 002:(0.9851) 003:(0.9904) \n",
      "\t\tProto:17 001:(0.9995) 002:(0.9999) 003:(0.999) \n",
      "\t\tProto:18 001:(0.9996) 002:(0.999) 003:(0.9944) \n",
      "\t\tProto:19 001:(0.9985) 002:(0.9953) 003:(0.9929) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 49.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:1 100:(0.9619) 101:(0.9977) \n",
      "\t\tProto:3 100:(0.9998) 101:(0.9995) \n",
      "\t\tProto:4 100:(0.9994) 101:(0.9998) \n",
      "\t\tProto:5 100:(0.9991) 101:(0.9994) \n",
      "\t\tProto:6 100:(0.9967) 101:(0.9966) \n",
      "\t\tProto:7 100:(0.9993) 101:(0.9999) \n",
      "\t\tProto:8 100:(0.9749) 101:(0.9823) \n",
      "\t\tProto:9 100:(0.9997) 101:(0.9997) \n",
      "\t Child: 023+025\n",
      "\t\tProto:10 023:(0.9986) 024:(0.9997) 025:(0.9962) \n",
      "\t\tProto:11 023:(0.9998) 024:(0.996) 025:(0.9509) \n",
      "\t\tProto:13 023:(0.9248) 024:(0.9975) 025:(0.9949) \n",
      "\t\tProto:14 023:(0.9968) 024:(0.9895) 025:(0.9994) \n",
      "\t\tProto:15 023:(0.9997) 024:(1.0) 025:(0.9997) \n",
      "\t\tProto:16 023:(0.9986) 024:(0.9997) 025:(0.9994) \n",
      "\t\tProto:19 023:(0.9989) 024:(0.9995) 025:(0.9993) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 40.05it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "\t Child: cub_003_Sooty_Albatross\n",
      "\t\tProto:3 003:(0.9999) \n",
      "\t\tProto:5 003:(0.9998) \n",
      "\t\tProto:6 003:(0.9997) \n",
      "\t\tProto:7 003:(0.9986) \n",
      "\t\tProto:8 003:(0.9955) \n",
      "\t\tProto:9 003:(0.9997) \n",
      "\t Child: 002+001\n",
      "\t\tProto:10 001:(0.9987) 002:(0.9986) \n",
      "\t\tProto:11 001:(0.8871) 002:(0.9943) \n",
      "\t\tProto:12 001:(0.998) 002:(0.9989) \n",
      "\t\tProto:13 001:(0.9979) 002:(0.9843) \n",
      "\t\tProto:14 001:(0.9964) 002:(0.9992) \n",
      "\t\tProto:15 001:(0.9964) 002:(0.9973) \n",
      "\t\tProto:16 001:(0.9902) 002:(0.9762) \n",
      "\t\tProto:17 001:(0.9993) 002:(0.9997) \n",
      "\t\tProto:18 001:(0.9937) 002:(0.9966) \n",
      "\t\tProto:19 001:(0.9994) 002:(0.9991) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 34.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+100\n",
      "\t Child: cub_101_White_Pelican\n",
      "\t\tProto:0 101:(1.0) \n",
      "\t\tProto:1 101:(0.999) \n",
      "\t\tProto:2 101:(0.998) \n",
      "\t\tProto:4 101:(0.9996) \n",
      "\t\tProto:5 101:(0.9984) \n",
      "\t\tProto:6 101:(0.9958) \n",
      "\t\tProto:8 101:(0.9937) \n",
      "\t\tProto:9 101:(0.9975) \n",
      "\t Child: cub_100_Brown_Pelican\n",
      "\t\tProto:10 100:(0.9946) \n",
      "\t\tProto:11 100:(0.9989) \n",
      "\t\tProto:12 100:(1.0) \n",
      "\t\tProto:13 100:(0.9999) \n",
      "\t\tProto:16 100:(0.9984) \n",
      "\t\tProto:17 100:(0.9997) \n",
      "\t\tProto:19 100:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 41.22it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "\t Child: cub_023_Brandt_Cormorant\n",
      "\t\tProto:0 023:(0.9999) \n",
      "\t\tProto:1 023:(0.9945) \n",
      "\t\tProto:2 023:(0.9976) \n",
      "\t\tProto:6 023:(0.9995) \n",
      "\t\tProto:8 023:(0.9999) \n",
      "\t Child: 025+024\n",
      "\t\tProto:10 024:(0.9988) 025:(0.9823) \n",
      "\t\tProto:11 024:(0.9988) 025:(0.9975) \n",
      "\t\tProto:12 024:(0.9972) 025:(0.9345) \n",
      "\t\tProto:13 024:(0.999) 025:(0.9949) \n",
      "\t\tProto:14 024:(0.9993) 025:(0.9853) \n",
      "\t\tProto:15 024:(1.0) 025:(0.9984) \n",
      "\t\tProto:16 024:(0.9985) 025:(0.9304) \n",
      "\t\tProto:17 024:(0.9581) 025:(0.998) \n",
      "\t\tProto:18 024:(0.9993) 025:(0.9921) \n",
      "\t\tProto:19 024:(0.9993) 025:(0.9523) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 37.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 002+001\n",
      "\t Child: cub_002_Laysan_Albatross\n",
      "\t\tProto:0 002:(1.0) \n",
      "\t\tProto:1 002:(0.9967) \n",
      "\t\tProto:2 002:(0.9965) \n",
      "\t\tProto:3 002:(0.9999) \n",
      "\t\tProto:6 002:(0.9928) \n",
      "\t\tProto:7 002:(0.9999) \n",
      "\t Child: cub_001_Black_footed_Albatross\n",
      "\t\tProto:10 001:(0.9999) \n",
      "\t\tProto:12 001:(0.9987) \n",
      "\t\tProto:13 001:(1.0) \n",
      "\t\tProto:15 001:(0.9895) \n",
      "\t\tProto:17 001:(0.9999) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 35.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 025+024\n",
      "\t Child: cub_025_Pelagic_Cormorant\n",
      "\t\tProto:1 025:(0.9993) \n",
      "\t\tProto:3 025:(0.9996) \n",
      "\t\tProto:4 025:(0.9999) \n",
      "\t\tProto:8 025:(0.9999) \n",
      "\t\tProto:9 025:(0.9997) \n",
      "\t Child: cub_024_Red_faced_Cormorant\n",
      "\t\tProto:10 024:(0.9997) \n",
      "\t\tProto:15 024:(0.9999) \n",
      "\t\tProto:16 024:(0.9997) \n",
      "\t\tProto:17 024:(0.9999) \n",
      "\t\tProto:18 024:(1.0) \n",
      "\t\tProto:19 024:(0.9993) \n",
      "Done !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "txt_file.write('\\n')\n",
    "\n",
    "vizloader_name = 'testloader' # projectloader\n",
    "find_non_descendants = False # True, False # param\n",
    "topk = 6\n",
    "save_images = False # True, False\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "save_activation_as_npy_path = None # 'activation_as_npy'\n",
    "if (save_activation_as_npy_path is not None):\n",
    "    save_activation_as_npy_path = '_'.join(['activation_as_npy', vizloader_name])  # activation_as_npy, added for NUMPY SAVING\n",
    "if find_non_descendants and (save_activation_as_npy_path is not None):\n",
    "    save_activation_as_npy_path = save_activation_as_npy_path + '_non_desc'\n",
    "plot_overspecificity_score = True\n",
    "    \n",
    "from datetime import datetime\n",
    "txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "txt_file.write('\\n')\n",
    "\n",
    "def write_num_proto_details(proto_mean_activations, node_name, net, threshold, txt_file, args):\n",
    "    \n",
    "    rand_input = torch.randn((1, 3, args.image_size, args.image_size))\n",
    "    with torch.no_grad():\n",
    "        *_, pooled, out = net(rand_input)\n",
    "    num_protos = pooled[node_name].shape[1]\n",
    "    used_protos = len(proto_mean_activations)\n",
    "    non_overspecific = 0\n",
    "    for p in proto_mean_activations:\n",
    "        logstr = '\\t'*2 + f'Proto:{p} '\n",
    "        protos_mean_for_all_leaf_descedants = []\n",
    "        for leaf_descendent in proto_mean_activations[p]:\n",
    "            mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "            protos_mean_for_all_leaf_descedants.append(mean_activation)\n",
    "            \n",
    "        if all([(mean_activation>0.2) for mean_activation in protos_mean_for_all_leaf_descedants]):\n",
    "            non_overspecific += 1\n",
    "            \n",
    "    txt_file.write(f\"Node:{node_name},Total:{num_protos},Used:{used_protos},Good:{non_overspecific},threshold={threshold}\\n\")\n",
    "\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "\n",
    "vizloader_dict = {'trainloader': trainloader,\n",
    "                 'projectloader': projectloader,\n",
    "                 'testloader': testloader,\n",
    "                 'test_projectloader': test_projectloader}\n",
    "vizloader_dict[vizloader_name] = unshuffle_dataloader(vizloader_dict[vizloader_name])\n",
    "\n",
    "\n",
    "if type(vizloader_dict[vizloader_name].dataset) == ImageFolder:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "else:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.dataset.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    \n",
    "overspecificity_score_and_proto_mask = []\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "#     non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "#     if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "#         continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "#         if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "#             continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = net(xs, inference=False)\n",
    "            if len(model_output) == 3:\n",
    "                softmaxes, pooled, _ = model_output\n",
    "            elif len(model_output) == 4:\n",
    "                _, softmaxes, pooled, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "#                 if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "#                     continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                \n",
    "                if not find_non_descendants:\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                else:\n",
    "                    if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    # write_num_proto_details(proto_mean_activations, node.name, net, threshold=0.2, txt_file=txt_file, args=args)\n",
    "\n",
    "    if plot_overspecificity_score:\n",
    "        for child_classname in class_and_prototypes:\n",
    "            for p in class_and_prototypes[child_classname]:\n",
    "                mean_activation_of_every_leaf = []\n",
    "                for leaf_descendent in proto_mean_activations[p]:\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    mean_activation_of_every_leaf.append(mean_activation)\n",
    "\n",
    "                overspecificity_score = 1\n",
    "                for mean_act in mean_activation_of_every_leaf:\n",
    "                    overspecificity_score *= mean_act * 1.0\n",
    "                proto_presence = getattr(net.module, '_'+node.name+'_proto_presence')\n",
    "                proto_presence = F.gumbel_softmax(proto_presence, tau=0.5, hard=True, dim=-1)\n",
    "                proto_mask = proto_presence[p, 1].item()\n",
    "                overspecificity_score_and_proto_mask.append((overspecificity_score, len(mean_activation_of_every_leaf), proto_mask))\n",
    "\n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            mean_activation_of_every_leaf = []\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "                mean_activation_of_every_leaf.append(mean_activation)\n",
    "            print(logstr)\n",
    "            \n",
    "            # # if the mean_activation is less for all leaf descendants skip the node\n",
    "            # if all([mean_act < 0.2 for mean_act in mean_activation_of_every_leaf]):\n",
    "            #     if find_non_descendants:\n",
    "            #         print('\\t'*2 + f'Not skipping proto {p} of {node.name} coz of find_non_descendants')\n",
    "            #     else:\n",
    "            #         print('\\t'*2 + f'Skipping proto {p} of {node.name}')\n",
    "            #         continue\n",
    "            \n",
    "            # have this for NON descendants\n",
    "            if len(proto_mean_activations[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images or save_activation_as_npy_path:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 # 3x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    for rank, ele in enumerate(heap):\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "                        patches.append(overlayed_image)\n",
    "                        \n",
    "                        # added for NUMPY SAVING\n",
    "                        \n",
    "                        if save_activation_as_npy_path:\n",
    "#                             upscaled_similarity_interpolated = get_upscaled_activation_interpolated(latent_activation,\n",
    "#                                                                                        image_size=(args.image_size, args.image_size))\n",
    "                            latent_activation_npy = latent_activation.squeeze().cpu().numpy()\n",
    "                            data = {'node_name': node.name,\n",
    "                                    'proto_num': p,\n",
    "                                    'child_name': child_classname,\n",
    "                                    'leaf_desc': leaf_descendent,\n",
    "                                     'rank': rank,\n",
    "                                     'img_path': img_to_open,\n",
    "                                     'img_filename': ntpath.basename(img_to_open),\n",
    "                                     'activation': latent_activation_npy,\n",
    "                                     'max_activation': activation,\n",
    "                                     'model_type': 'NAIVE-HPIPNET'}\n",
    "                            filename = str(rank)+ '-' + ntpath.basename(img_to_open) + '.npy'\n",
    "                            save_path = os.path.join(run_path, save_activation_as_npy_path, \\\n",
    "                                                     node.name, str(p), leaf_descendent,\n",
    "                                                     filename)\n",
    "                            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                            np.save(save_path, data, allow_pickle=True)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "                    \n",
    "                # weird thing padding should be zero for non descendants else it raises some error # change\n",
    "                if find_non_descendants or (len(patches) == topk): # (len(patches) == topk) means there is only one leaf descendant\n",
    "                    padding = 0\n",
    "                else:\n",
    "                    padding = 1\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=padding)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=padding)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "                \n",
    "                if save_images:\n",
    "                    prefix = 'non_' if find_non_descendants else ''\n",
    "                    os.makedirs(os.path.join(run_path, prefix+f'descendent_specific_topk_heatmap_ep={epoch}', node.name), exist_ok=True)\n",
    "                    torchvision.utils.save_image(grid, os.path.join(run_path, prefix+f'descendent_specific_topk_heatmap_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "txt_file.write('\\n')\n",
    "txt_file.close()\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example list of tuples\n",
    "data = overspecificity_score_and_proto_mask\n",
    "\n",
    "# Separate the data based on the second value\n",
    "x_0 = [x for x, y, z in data if z == 0]  # First values where the second value is 0\n",
    "x_1 = [x for x, y, z in data if z == 1]  # First values where the second value is 1\n",
    "\n",
    "# Create a dummy y-axis value since this is a one-dimensional scatter plot\n",
    "# y_0 = [y for x, y, z in data if z == 0]  # Dummy y values for blue points\n",
    "# y_1 = [y for x, y, z in data if z == 1]  # Dummy y values for red points\n",
    "\n",
    "# y_0 = [1]*len(x_0)\n",
    "# y_1 = [1.5]*len(x_1)\n",
    "\n",
    "y_0 = [1]*len(x_0)\n",
    "y_1 = [1]*len(x_1)\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(x_1, y_1, color='red', label='Value 1', s=4)   # Plot points with second value 1 in red\n",
    "plt.scatter(x_0, y_0, color='blue', label='Value 0', s=4)  # Plot points with second value 0 in blue\n",
    "\n",
    "\n",
    "# Additional plot formatting\n",
    "plt.xlabel('Overspecificity score')\n",
    "# plt.ylabel('Num descendants')  # Hide y-axis ticks since it's a one-dimensional plot\n",
    "plt.yticks([])\n",
    "# plt.legend(loc='best')\n",
    "# plt.title('One-dimensional Scatter Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(torch.tensor(2 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cos(torch.pi)\n",
    "torch.cos(torch.tensor(2 * torch.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9994999766349792\n",
      "1 0.9995477199554443\n",
      "2 0.9996727705001831\n",
      "3 0.9998272657394409\n",
      "4 0.9999522566795349\n",
      "5 1.0\n",
      "6 0.9999522566795349\n",
      "7 0.9998272657394409\n",
      "8 0.9996727705001831\n",
      "9 0.9995477199554443\n",
      "10 0.9994999766349792\n",
      "11 0.9995477199554443\n",
      "12 0.9996727705001831\n",
      "13 0.9998272657394409\n",
      "14 0.9999522566795349\n",
      "15 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "byol_tau_base = 0.9995\n",
    "byol_tau_max = 1.0\n",
    "# current_step = 50\n",
    "max_training_steps = 15\n",
    "cycle_steps = 5\n",
    "\n",
    "byol_tau_list = []\n",
    "for current_step in range(max_training_steps+1):\n",
    "#     byol_tau = byol_tau_max - (((byol_tau_max - byol_tau_base) * (torch.cos(torch.tensor((torch.pi * current_step)/max_training_steps)) + 1)) / 2)\n",
    "    byol_tau = byol_tau_max - (((byol_tau_max - byol_tau_base) * (torch.cos(torch.tensor((torch.pi * current_step)/cycle_steps)) + 1)) / 2)\n",
    "    print(current_step, byol_tau.item())\n",
    "    byol_tau_list.append(byol_tau)\n",
    "    \n",
    "plt.plot(byol_tau_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_max_value_correspondence(tensor1, tensor2):\n",
    "    # Find the index of the max value in tensor1\n",
    "    max_idx = torch.argmax(tensor1)\n",
    "\n",
    "    # Convert the index to 2D coordinates\n",
    "    H, W = tensor1.shape\n",
    "    max_coord = (max_idx // W, max_idx % W)\n",
    "\n",
    "    # Access the corresponding value in tensor2\n",
    "    return tensor2[max_coord]\n",
    "\n",
    "# Example tensors\n",
    "tensor1_example = torch.tensor([[1.1, 0.2, 0.3], [0.4, 0.8, 0.6], [0.5, 0.7, 0.9]])\n",
    "tensor2_example = torch.tensor([[False, True, True], [False, True, False], [True, False, True]])\n",
    "\n",
    "# Check if the value at the max value of tensor1 in tensor2 is True or False\n",
    "result = check_max_value_correspondence(tensor1_example, tensor2_example)\n",
    "result.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
