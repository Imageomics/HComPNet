{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/010-CUB-27-imgnet_OOD_cnext26_img=224_nprotos=20'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/031-CUB-18-imgnet_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/032-CUB-18-imgnet_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/035-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/043-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/036-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel_uniformity\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/041-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/042-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/044-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20-or-4per-desc_orth-on-rel\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/046-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=10per-desc_orth-on-rel\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/047-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=5per-desc_tanh-desc\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/048-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=5per-desc_tanh-desc_unit-sphere\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/051-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_tanh-desc_unit-sphere_AW=5-TW=2-UW=2-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/052-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=4per-desc_tanh-desc_unit-sphere_AW=5-TW=2-UW=2-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/055-CUB-18_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/056-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/057-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/058-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "\n",
    "# with unit sphere\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/059-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# unit sphere with softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/065-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# original hpipnet with 20 protos per node no KO, no OOD, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/062-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD\"\n",
    "\n",
    "# original hpipnet with 20 protos per node no KO, no OOD, WITH tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/063-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD_tanh-desc\"\n",
    "\n",
    "# with unit sphere but no AL+UNI\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/066-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_no-softmax_no-align_no-uni_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, with softmax, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/067-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, with softmax, no tanh-desc, INCORRECT\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/067-incorrect-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, no softmax, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/068-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 071 with bias\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/071-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_with-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 072 gumbel softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/072-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-gumbel-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 073 gumbel softmax, tau-1.0\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/073-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-gumbel-softmax-tau=1_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 075 068 with focal loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/075-068-with-focal_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_no-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 076 cs followed by softmax. Uses align_pf along with align+uni\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/076_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_align-pf-during-training_no-meanpool_no-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2-APW=5_batch=20\"\n",
    "\n",
    "# 074 multiply_cs_softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/074-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_multi-cs-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 077 unit sphere protopool with cosin no softmax constant 20 protos per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/077_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20-sphere-protopool_finetune=5_align-pf-during-training_no-meanpool_no-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 080 unit sphere protopool with cosin and softmax constant 20 protos per node (other details not sure)\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/080-CUB-18-imgnet_with-equalize-aug_cnext7_img=224_nprotos=20_unit-sphere-protopool_finetune=5_align-pf-during-training_no-meanpool_with-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_weighted-ce_batch=20\"\n",
    "\n",
    "# 082 unit sphere cs followed by softmax with minmazimize loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/082-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 083 unit sphere cs followed by softmax with minmazimize loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/083-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_no-align_no-uni_no-mm-loss_batch=48\"\n",
    "\n",
    "# 085 unit sphere cs followed by softmax-with-tau with minmazimize loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/085-notebook-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=12\"\n",
    "\n",
    "# 091 basic gaussian multiplier on stage 4\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/091-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_latent-dim=256_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 092 basic gaussian multiplier on stage 3, 4\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/092-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=3,4|1.0|50_img=224_latent-dim=256_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 093 128 dim linear\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/093-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_latent-dim=128_nprotos=20_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=1-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 094 128 dim linear\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/094-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_latent-dim=128_nprotos=20_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=1-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 095 ablation 091 without AL+UNI\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/095-091-woALUNI-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_no-AL_no-UNI_mm-loss_batch=48\"\n",
    "\n",
    "# 096 ablation 091 without AL+UNI\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/096-091-wfocal-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 097 - 091 with bg\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/097-091-wbg-CUB-18_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 0100 cub29 with 20 per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/100_CUB-29-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=20_unit-sphere-protopool_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 0101 baseline with 4 per desc per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/101-baseline-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_no-KO_no-OOD\"\n",
    "\n",
    "# 0103 091 with 20 per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/103-091-wProtoPool20PerNode_CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=20_unit-sphere-protopool_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_batch=48\"\n",
    "\n",
    "# 098 091 without AL + UNI\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/098-091-woALUNI_finetune=0_CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=4per-leaf-desc_unit-sphere_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48'\n",
    "\n",
    "# 0107 091 with 20 per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/107-baseline_LOU_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD\"\n",
    "\n",
    "# 109 flat structure 18 species - HPIPNet\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/109-FlatStructure180protos_CUB-18-imgnet-bg_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=180_unit-sphere-protopool_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_batch=48'\n",
    "\n",
    "# 110 flat structure 18 species - HPIPNet no AL+UNI\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/110-FlatStructure180protosNoALUNI_CUB-18-imgnet-bg_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=180_unit-sphere-protopool_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_batch=48'\n",
    "\n",
    "# 111 flat structure 18 species - Naive-HPIPNet\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/111-NaiveHPIPNetFlatStructure180-baseline_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=180_no-KO_no-OOD'\n",
    "\n",
    "# 112 flat structure 190 species - Naive-HPIPNet\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/112-NaiveHPIPNetFlatStructure_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD\"\n",
    "\n",
    "# 113 flat structure 190 species - Naive-HPIPNet no AL_PF+TANH\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/113-NaiveHPIPNetFlatStructureNoAlNoTanh_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD_no-AL_no-TANH\"\n",
    "\n",
    "# 116 BYOL Optimizer 2\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/116-HPIPNetBYOLOpt2_CUB-18-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=20_BYOL_no-KO_no-OOD_no-AL_no-TANH'\n",
    "\n",
    "# 118 Project dist with BYOL, HPIPNetBYOLOpt2ProtopoolProjDist\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/118-HPIPNetBYOLOpt2ProtopoolProjDist_CUB-18-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=20_BYOL_no-KO_no-OOD_no-AL_no-TANH\"\n",
    "\n",
    "# 126 BYOL with CL with ClusDesc only backpropagating CL\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/126-checkingBYOL05_bpOnlyCLNotClusDesc_with-CL-ClusDesc_byol=2'\n",
    "\n",
    "# 127 Just CL and ClusDesc, no BYOL\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/127-HPIPNetwCLwClusDesc_noBYOL_CUB-18-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=20'\n",
    "\n",
    "# 137 Naive HPIPNet frozen backbone\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/137-NaiveHPIPNetFrozenBackbone_cnext26_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# 138 Naive HPIPNet with TanhDesc loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/138-NaiveHPIPNetwithTanhDesc_cnext26_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# 142 ConciseProtoPNet\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/142-ConciseProtoPNet_cnext26_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# 148 ConciseProtoPNetNoProtoPoolWithKO=0.5WithTanhDesc\n",
    "run_path = \"/home/harishbabu/projects/PIPNet/runs/148-ConciseProtoPNetNoProtoPoolWithKO=0.5WithTanhDesc_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "try:\n",
    "    sys.path.remove('/home/harishbabu/projects/PIPNet')\n",
    "except:\n",
    "    pass\n",
    "sys.path.insert(0, os.path.join(run_path, 'source_clone'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/projects/PIPNet/runs/148-ConciseProtoPNetNoProtoPoolWithKO=0.5WithTanhDesc_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\n"
     ]
    }
   ],
   "source": [
    "print(run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import sys, os\n",
    "import random\n",
    "import numpy as np\n",
    "from shutil import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "# from skimage.filters import threshold_local, gaussian\n",
    "import ntpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/harishbabu/projects/PIPNet/runs/148-ConciseProtoPNetNoProtoPoolWithKO=0.5WithTanhDesc_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20/source_clone', '/home/harishbabu/.conda/envs/hpnet4/lib/python39.zip', '/home/harishbabu/.conda/envs/hpnet4/lib/python3.9', '/home/harishbabu/.conda/envs/hpnet4/lib/python3.9/lib-dynload', '', '/home/harishbabu/.conda/envs/hpnet4/lib/python3.9/site-packages']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/projects/PIPNet/runs/148-ConciseProtoPNetNoProtoPoolWithKO=0.5WithTanhDesc_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20/source_clone/util/node.py\n"
     ]
    }
   ],
   "source": [
    "# import pipnet.pipnet\n",
    "# from pipnet.pipnet import PIPNet, get_network\n",
    "# # from pipnet import pipnet\n",
    "# print(pipnet.__file__)\n",
    "from util import node\n",
    "print(node.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmaps showing where a prototype is found will not be generated because OpenCV is not installed.\n"
     ]
    }
   ],
   "source": [
    "from pipnet.pipnet import PIPNet, get_network\n",
    "from util.log import Log\n",
    "from util.args import get_args, save_args, get_optimizer_nn\n",
    "from util.data import get_dataloaders\n",
    "from util.func import init_weights_xavier\n",
    "from pipnet.train import train_pipnet, test_pipnet\n",
    "# from pipnet.test import eval_pipnet, get_thresholds, eval_ood\n",
    "from util.eval_cub_csv import eval_prototypes_cub_parts_csv, get_topk_cub, get_proto_patches_cub\n",
    "from util.vis_pipnet import visualize, visualize_topk\n",
    "from util.visualize_prediction import vis_pred, vis_pred_experiments\n",
    "from util.node import Node\n",
    "from util.phylo_utils import construct_phylo_tree, construct_discretized_phylo_tree\n",
    "from util.func import get_patch_size\n",
    "from util.data import ModifiedLabelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "def get_bb_gaussian_threshold(latent_activation, sigma=1.0, percentile=97, extend_h=0, extend_w=0):\n",
    "    # latent_activation -> []\n",
    "    upscaled_similarity = get_upscaled_activation_uninterpolated(latent_activation, \\\n",
    "                                                                 image_size=(args.image_size, args.image_size))\n",
    "    upscaled_similarity = minmaxscale(upscaled_similarity)\n",
    "    upscaled_similarity = gaussian(upscaled_similarity, sigma=sigma)\n",
    "    upscaled_similarity = threshold_local(upscaled_similarity, block_size=15, method='mean')\n",
    "    h_min, h_max, w_min, w_max = find_top_percentile_bbox(upscaled_similarity ,percentile=97)\n",
    "    h_min = max(0, h_min-extend_h)\n",
    "    h_max = min(upscaled_similarity.shape[0], h_max+extend_h)\n",
    "    w_min = max(0, w_min-extend_w)\n",
    "    w_max = min(upscaled_similarity.shape[1], w_max+extend_w)\n",
    "    return h_min, h_max, w_min, w_max\n",
    "\n",
    "\n",
    "def minmaxscale(tensor):\n",
    "    return (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def unshuffle_dataloader(dataloader):\n",
    "    if type(dataloader.dataset) == ImageFolder:\n",
    "        dataset = dataloader.dataset\n",
    "    else:\n",
    "        dataset = dataloader.dataset.dataset.dataset\n",
    "    new_dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=dataloader.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=dataloader.num_workers,\n",
    "        pin_memory=dataloader.pin_memory,\n",
    "        drop_last=dataloader.drop_last,\n",
    "        timeout=dataloader.timeout,\n",
    "        worker_init_fn=dataloader.worker_init_fn,\n",
    "        multiprocessing_context=dataloader.multiprocessing_context,\n",
    "        generator=dataloader.generator,\n",
    "        prefetch_factor=dataloader.prefetch_factor,\n",
    "        persistent_workers=dataloader.persistent_workers\n",
    "    )\n",
    "    return new_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- No discretization -------------------------\n"
     ]
    }
   ],
   "source": [
    "args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "args = pickle.load(args_file)\n",
    "\n",
    "if args.phylo_config:\n",
    "    phylo_config = OmegaConf.load(args.phylo_config)\n",
    "\n",
    "if args.phylo_config:\n",
    "    # construct the phylo tree\n",
    "    if phylo_config.phyloDistances_string == 'None':\n",
    "        if '031' in run_path: # this run uses a different phylogeny file that had an extra root node which is a mistake\n",
    "            root = construct_phylo_tree('/home/harishbabu/data/phlyogenyCUB/18Species-with-extra-root-node/1_tree-consensus-Hacket-18Species-modified_cub-names_v1.phy')\n",
    "        else:\n",
    "            root = construct_phylo_tree(phylo_config.phylogeny_path)\n",
    "        print('-'*25 + ' No discretization ' + '-'*25)\n",
    "    else:\n",
    "        root = construct_discretized_phylo_tree(phylo_config.phylogeny_path, phylo_config.phyloDistances_string)\n",
    "        print('-'*25 + ' Discretized ' + '-'*25)\n",
    "else:\n",
    "    # construct the tree (original hierarchy as described in the paper)\n",
    "    root = Node(\"root\")\n",
    "    root.add_children(['animal','vehicle','everyday_object','weapon','scuba_diver'])\n",
    "    root.add_children_to('animal',['non_primate','primate'])\n",
    "    root.add_children_to('non_primate',['African_elephant','giant_panda','lion'])\n",
    "    root.add_children_to('primate',['capuchin','gibbon','orangutan'])\n",
    "    root.add_children_to('vehicle',['ambulance','pickup','sports_car'])\n",
    "    root.add_children_to('everyday_object',['laptop','sandal','wine_bottle'])\n",
    "    root.add_children_to('weapon',['assault_rifle','rifle'])\n",
    "    # flat root\n",
    "    # root.add_children(['scuba_diver','African_elephant','giant_panda','lion','capuchin','gibbon','orangutan','ambulance','pickup','sports_car','laptop','sandal','wine_bottle','assault_rifle','rifle'])\n",
    "root.assign_all_descendents()\n",
    "\n",
    "exp_no = int(os.path.basename(run_path)[:3])\n",
    "\n",
    "if exp_no < 77:\n",
    "    if ('num_protos_per_descendant' in args) and (args.num_protos_per_descendant > 0):\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(args.num_protos_per_descendant)\n",
    "if exp_no == 77:\n",
    "    # update num of protos per node based on num_protos_per_descendant\n",
    "    if args.num_features == 0 and args.num_protos_per_descendant == 0:\n",
    "        raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "    for node in root.nodes_with_children():\n",
    "        node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                                            min_protos=args.num_features)\n",
    "else:\n",
    "    if ('num_protos_per_descendant' in args):\n",
    "        # update num of protos per node based on num_protos_per_descendant\n",
    "        if args.num_features == 0 and args.num_protos_per_descendant == 0:\n",
    "            raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                min_protos=args.num_features,\\\n",
    "                                split_protos=('protopool' in args) and (args.protopool == 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illegal option --\n",
      "Usage: /usr/bin/which [-a] args\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "CUB-18-imgnet-224\n"
     ]
    }
   ],
   "source": [
    "args.batch_size = 1\n",
    "\n",
    "print(args.batch_size)\n",
    "print(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: Transform2 disabled\n",
      "IMPORTANT: Transform2 disabled\n",
      "Dropping 0 samples from trainloader\n",
      "Dropping 0 samples from trainloader_normal\n",
      "Dropping 0 samples from trainloader_normal_augment\n",
      "Num classes (k) =  18 ['cub_001_Black_footed_Albatross', 'cub_002_Laysan_Albatross', 'cub_003_Sooty_Albatross', 'cub_004_Groove_billed_Ani', 'cub_023_Brandt_Cormorant'] etc.\n",
      "1 1\n",
      "Classes:  {'cub_001_Black_footed_Albatross': 0, 'cub_002_Laysan_Albatross': 1, 'cub_003_Sooty_Albatross': 2, 'cub_004_Groove_billed_Ani': 3, 'cub_023_Brandt_Cormorant': 4, 'cub_024_Red_faced_Cormorant': 5, 'cub_025_Pelagic_Cormorant': 6, 'cub_031_Black_billed_Cuckoo': 7, 'cub_032_Mangrove_Cuckoo': 8, 'cub_033_Yellow_billed_Cuckoo': 9, 'cub_045_Northern_Fulmar': 10, 'cub_050_Eared_Grebe': 11, 'cub_051_Horned_Grebe': 12, 'cub_052_Pied_billed_Grebe': 13, 'cub_053_Western_Grebe': 14, 'cub_086_Pacific_Loon': 15, 'cub_100_Brown_Pelican': 16, 'cub_101_White_Pelican': 17}\n",
      "Number of prototypes:  20\n",
      "----------Prototypes per descendant: 0----------\n",
      "Assigned 20 protos to node root\n",
      "Assigned 20 protos to node 052+053\n",
      "Assigned 20 protos to node 004+086\n",
      "Assigned 20 protos to node 053+050\n",
      "Assigned 20 protos to node 004+032\n",
      "Assigned 20 protos to node 086+045\n",
      "Assigned 20 protos to node 050+051\n",
      "Assigned 20 protos to node 032+033\n",
      "Assigned 20 protos to node 045+101\n",
      "Assigned 20 protos to node 033+031\n",
      "Assigned 20 protos to node 045+003\n",
      "Assigned 20 protos to node 101+023\n",
      "Assigned 20 protos to node 003+002\n",
      "Assigned 20 protos to node 101+100\n",
      "Assigned 20 protos to node 023+025\n",
      "Assigned 20 protos to node 002+001\n",
      "Assigned 20 protos to node 025+024\n",
      "Output shape:  torch.Size([1, 20, 13, 13])\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    device_ids = [torch.cuda.current_device()]\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    device_ids = []\n",
    "\n",
    "# args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "# args = pickle.load(args_file)\n",
    "\n",
    "# ckpt_file_name = 'net_overspecific_pruned_replaced_thresh=0.5_last'\n",
    "# ckpt_file_name = 'net_trained_30'\n",
    "# ckpt_file_name = 'net_trained_10'\n",
    "# ckpt_file_name = 'net_pretrained'\n",
    "ckpt_file_name = 'net_trained_last'\n",
    "epoch = ckpt_file_name.split('_')[-1]\n",
    "\n",
    "ckpt_path = os.path.join(run_path, 'checkpoints', ckpt_file_name)\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "if ckpt_file_name != 'net_trained_last':\n",
    "    print('\\n', (10*'-')+'WARNING: Not using the final trained model'+(10*'-'), '\\n')\n",
    "\n",
    "# Obtain the dataset and dataloaders\n",
    "trainloader, trainloader_pretraining, trainloader_normal, trainloader_normal_augment, projectloader, testloader, test_projectloader, classes = get_dataloaders(args, device)\n",
    "\n",
    "print(args.batch_size, trainloader.batch_size)\n",
    "\n",
    "if len(classes)<=20:\n",
    "    if args.validation_size == 0.:\n",
    "        print(\"Classes: \", testloader.dataset.class_to_idx, flush=True)\n",
    "    else:\n",
    "        print(\"Classes: \", str(classes), flush=True)\n",
    "\n",
    "# Create a convolutional network based on arguments and add 1x1 conv layer\n",
    "feature_net, add_on_layers, pool_layer, classification_layers, num_prototypes = get_network(len(classes), args, root=root)\n",
    "   \n",
    "# Create a PIP-Net\n",
    "net = PIPNet(num_classes=len(classes),\n",
    "                    num_prototypes=num_prototypes,\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "\n",
    "# Create a PIP-Net\n",
    "if ('byol' in args) and (args.byol == 'y'):\n",
    "    from pipnet.pipnet import PIPNetBYOL\n",
    "    net = PIPNetBYOL(num_classes=len(classes),\n",
    "                        num_prototypes=num_prototypes,\n",
    "                        feature_net = feature_net,\n",
    "                        args = args,\n",
    "                        add_on_layers = add_on_layers,\n",
    "                        pool_layer = pool_layer,\n",
    "                        classification_layers = classification_layers,\n",
    "                        num_parent_nodes = len(root.nodes_with_children()),\n",
    "                        root = root\n",
    "                        )\n",
    "else:\n",
    "    net = PIPNet(num_classes=len(classes),\n",
    "                    num_prototypes=num_prototypes,\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "        \n",
    "net = net.to(device=device)\n",
    "net = nn.DataParallel(net, device_ids = device_ids)    \n",
    "net.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "print(net.eval())\n",
    "criterion = nn.NLLLoss(reduction='mean').to(device)\n",
    "\n",
    "# Forward one batch through the backbone to get the latent output size\n",
    "with torch.no_grad():\n",
    "    xs1, _, _ = next(iter(trainloader))\n",
    "    xs1 = xs1.to(device)\n",
    "    _, proto_features, _, _ = net(xs1)\n",
    "    wshape = proto_features['root'].shape[-1]\n",
    "    args.wshape = wshape #needed for calculating image patch size\n",
    "    print(\"Output shape: \", proto_features['root'].shape, flush=True)\n",
    "    \n",
    "print(args.wshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.7\n",
      "2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.basic_cnext_gaussian_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/harishbabu/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/harishbabu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/harishbabu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/harishbabu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "# def count_parameters(model):\n",
    "#     \"\"\"\n",
    "#     Counts the number of trainable and non-trainable parameters in a model.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - model: The PyTorch model\n",
    "    \n",
    "#     Returns:\n",
    "#     - Tuple of (total_parameters, trainable_parameters)\n",
    "#     \"\"\"\n",
    "#     total_params = sum(p.numel() for p in model.parameters())\n",
    "#     trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "#     return total_params, trainable_params\n",
    "\n",
    "# count_parameters(net.module._net)\n",
    "\n",
    "dinov2_vits14_reg = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14_reg').cuda()\n",
    "\n",
    "dinov2_vits14_reg\n",
    "\n",
    "with torch.no_grad():\n",
    "    xs1, _, _ = next(iter(trainloader))\n",
    "    xs1 = xs1.to(device)\n",
    "    out = dinov2_vits14_reg(xs1)\n",
    "#     wshape = proto_features['root'].shape[-1]\n",
    "#     args.wshape = wshape #needed for calculating image patch size\n",
    "#     print(\"Output shape: \", proto_features['root'].shape, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images using either NAIVE-HPIPNET or UNIT-SPACE-PROTOPOOL with HEATMAP (CANON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:09, 57.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node root\n",
      "Num protos for 052+053 2\n",
      "Num protos for 004+086 2\n",
      "\t Child: 052+053\n",
      "\t\tProto:8 001:(0.6521) 002:(0.1829) 003:(0.1389) 004:(0.138) 023:(0.9219) 024:(0.3066) 025:(0.3828) 031:(0.7367) 032:(0.5336) 033:(0.4535) 045:(0.051) 086:(0.7017) 100:(0.1772) 101:(0.152) \n",
      "\t\tProto:4 001:(0.9945) 002:(0.997) 003:(0.9938) 004:(0.6667) 023:(0.9753) 024:(1.0) 025:(0.9884) 031:(0.9974) 032:(0.9246) 033:(0.8386) 045:(0.6352) 086:(0.9982) 100:(0.9922) 101:(0.9917) \n",
      "\t Child: 004+086\n",
      "\t\tProto:10 050:(0.9977) 051:(0.9872) 052:(0.9765) 053:(0.9134) \n",
      "\t\tProto:19 050:(1.0) 051:(1.0) 052:(1.0) 053:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 43.86it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "Num protos for cub_052_Pied_billed_Grebe 3\n",
      "Num protos for 053+050 3\n",
      "\t Child: cub_052_Pied_billed_Grebe\n",
      "\t\tProto:9 050:(0.7433) 051:(0.2557) 053:(0.0661) \n",
      "\t\tProto:3 050:(0.2038) 051:(0.115) 053:(0.0806) \n",
      "\t\tProto:4 050:(1.0) 051:(0.9996) 053:(0.7361) \n",
      "\t Child: 053+050\n",
      "\t\tProto:16 052:(0.0534) \n",
      "\t\tNot skipping proto 16 of 052+053 coz of find_non_descendants\n",
      "\t\tProto:19 052:(0.6232) \n",
      "\t\tProto:13 052:(0.4381) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:07, 57.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "Num protos for 004+032 1\n",
      "Num protos for 086+045 3\n",
      "\t Child: 004+032\n",
      "\t\tProto:3 001:(0.045) 002:(0.0423) 003:(0.0328) 023:(0.0233) 024:(0.0233) 025:(0.0324) 045:(0.0474) 086:(0.0566) 100:(0.0281) 101:(0.067) \n",
      "\t\tNot skipping proto 3 of 004+086 coz of find_non_descendants\n",
      "\t Child: 086+045\n",
      "\t\tProto:17 004:(1.0) 031:(1.0) 032:(1.0) 033:(1.0) \n",
      "\t\tProto:10 004:(1.0) 031:(1.0) 032:(1.0) 033:(1.0) \n",
      "\t\tProto:12 004:(0.3264) 031:(0.7429) 032:(0.2) 033:(0.0882) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 39.22it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "Num protos for cub_053_Western_Grebe 4\n",
      "Num protos for 050+051 4\n",
      "\t Child: cub_053_Western_Grebe\n",
      "\t\tProto:9 050:(0.0749) 051:(0.018) \n",
      "\t\tNot skipping proto 9 of 053+050 coz of find_non_descendants\n",
      "\t\tProto:3 050:(0.0867) 051:(0.2875) \n",
      "\t\tProto:6 050:(0.0273) 051:(0.0231) \n",
      "\t\tNot skipping proto 6 of 053+050 coz of find_non_descendants\n",
      "\t\tProto:7 050:(0.8867) 051:(0.7849) \n",
      "\t Child: 050+051\n",
      "\t\tProto:17 053:(1.0) \n",
      "\t\tProto:13 053:(1.0) \n",
      "\t\tProto:14 053:(0.0254) \n",
      "\t\tNot skipping proto 14 of 053+050 coz of find_non_descendants\n",
      "\t\tProto:15 053:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 43.76it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "Num protos for cub_004_Groove_billed_Ani 4\n",
      "Num protos for 032+033 3\n",
      "\t Child: cub_004_Groove_billed_Ani\n",
      "\t\tProto:2 031:(0.0206) 032:(0.0272) 033:(0.0247) \n",
      "\t\tNot skipping proto 2 of 004+032 coz of find_non_descendants\n",
      "\t\tProto:3 031:(0.162) 032:(0.0409) 033:(0.0375) \n",
      "\t\tNot skipping proto 3 of 004+032 coz of find_non_descendants\n",
      "\t\tProto:5 031:(0.0217) 032:(0.0481) 033:(0.0972) \n",
      "\t\tNot skipping proto 5 of 004+032 coz of find_non_descendants\n",
      "\t\tProto:6 031:(0.0936) 032:(0.0477) 033:(0.0213) \n",
      "\t\tNot skipping proto 6 of 004+032 coz of find_non_descendants\n",
      "\t Child: 032+033\n",
      "\t\tProto:10 004:(0.0486) \n",
      "\t\tNot skipping proto 10 of 004+032 coz of find_non_descendants\n",
      "\t\tProto:19 004:(0.9893) \n",
      "\t\tProto:12 004:(0.0167) \n",
      "\t\tNot skipping proto 12 of 004+032 coz of find_non_descendants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:05, 52.71it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "Num protos for cub_086_Pacific_Loon 3\n",
      "Num protos for 045+101 4\n",
      "\t Child: cub_086_Pacific_Loon\n",
      "\t\tProto:2 001:(0.1216) 002:(0.1516) 003:(0.1138) 023:(0.0682) 024:(0.0192) 025:(0.0913) 045:(0.0774) 100:(0.0213) 101:(0.1069) \n",
      "\t\tNot skipping proto 2 of 086+045 coz of find_non_descendants\n",
      "\t\tProto:5 001:(0.7779) 002:(0.5255) 003:(0.7132) 023:(0.866) 024:(0.2131) 025:(0.9262) 045:(0.4703) 100:(0.1099) 101:(0.2388) \n",
      "\t\tProto:7 001:(0.4674) 002:(0.2581) 003:(0.4281) 023:(0.4966) 024:(0.0982) 025:(0.4346) 045:(0.2383) 100:(0.1991) 101:(0.1169) \n",
      "\t Child: 045+101\n",
      "\t\tProto:10 086:(0.991) \n",
      "\t\tProto:11 086:(1.0) \n",
      "\t\tProto:13 086:(1.0) \n",
      "\t\tProto:14 086:(0.9915) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 34.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 050+051\n",
      "Num protos for cub_050_Eared_Grebe 4\n",
      "Num protos for cub_051_Horned_Grebe 4\n",
      "\t Child: cub_050_Eared_Grebe\n",
      "\t\tProto:0 051:(1.0) \n",
      "\t\tProto:8 051:(1.0) \n",
      "\t\tProto:4 051:(0.9223) \n",
      "\t\tProto:9 051:(0.9998) \n",
      "\t Child: cub_051_Horned_Grebe\n",
      "\t\tProto:19 050:(0.3065) \n",
      "\t\tProto:13 050:(0.9915) \n",
      "\t\tProto:14 050:(0.0347) \n",
      "\t\tNot skipping proto 14 of 050+051 coz of find_non_descendants\n",
      "\t\tProto:15 050:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 41.77it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "Num protos for cub_032_Mangrove_Cuckoo 2\n",
      "Num protos for 033+031 2\n",
      "\t Child: cub_032_Mangrove_Cuckoo\n",
      "\t\tProto:1 031:(0.3304) 033:(0.4868) \n",
      "\t\tProto:3 031:(0.9998) 033:(1.0) \n",
      "\t Child: 033+031\n",
      "\t\tProto:11 032:(1.0) \n",
      "\t\tProto:13 032:(0.2986) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:05, 53.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "Num protos for 045+003 2\n",
      "Num protos for 101+023 3\n",
      "\t Child: 045+003\n",
      "\t\tProto:1 023:(0.2325) 024:(0.1699) 025:(0.1899) 100:(0.3287) 101:(0.0957) \n",
      "\t\tProto:9 023:(0.0587) 024:(0.0915) 025:(0.344) 100:(0.2208) 101:(0.6275) \n",
      "\t Child: 101+023\n",
      "\t\tProto:16 001:(0.9587) 002:(0.9992) 003:(0.9733) 045:(0.5552) \n",
      "\t\tProto:18 001:(0.4483) 002:(0.207) 003:(0.0477) 045:(0.0417) \n",
      "\t\tProto:14 001:(0.5296) 002:(0.1997) 003:(0.3191) 045:(0.1205) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 35.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 033+031\n",
      "Num protos for cub_033_Yellow_billed_Cuckoo 1\n",
      "Num protos for cub_031_Black_billed_Cuckoo 4\n",
      "\t Child: cub_033_Yellow_billed_Cuckoo\n",
      "\t\tProto:1 031:(0.1646) \n",
      "\t\tNot skipping proto 1 of 033+031 coz of find_non_descendants\n",
      "\t Child: cub_031_Black_billed_Cuckoo\n",
      "\t\tProto:17 033:(0.8148) \n",
      "\t\tProto:18 033:(0.9689) \n",
      "\t\tProto:11 033:(0.3225) \n",
      "\t\tProto:13 033:(0.9973) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 44.22it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "Num protos for cub_045_Northern_Fulmar 3\n",
      "Num protos for 003+002 2\n",
      "\t Child: cub_045_Northern_Fulmar\n",
      "\t\tProto:8 001:(0.8035) 002:(1.0) 003:(0.3261) \n",
      "\t\tProto:9 001:(0.4164) 002:(0.2128) 003:(0.1892) \n",
      "\t\tProto:3 001:(0.0797) 002:(0.2652) 003:(0.2817) \n",
      "\t Child: 003+002\n",
      "\t\tProto:17 045:(0.8862) \n",
      "\t\tProto:15 045:(0.8434) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 48.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "Num protos for 101+100 3\n",
      "Num protos for 023+025 2\n",
      "\t Child: 101+100\n",
      "\t\tProto:2 023:(0.0249) 024:(0.0197) 025:(0.0188) \n",
      "\t\tNot skipping proto 2 of 101+023 coz of find_non_descendants\n",
      "\t\tProto:6 023:(0.031) 024:(0.022) 025:(0.0208) \n",
      "\t\tNot skipping proto 6 of 101+023 coz of find_non_descendants\n",
      "\t\tProto:7 023:(0.0409) 024:(0.0339) 025:(0.035) \n",
      "\t\tNot skipping proto 7 of 101+023 coz of find_non_descendants\n",
      "\t Child: 023+025\n",
      "\t\tProto:16 100:(0.183) 101:(0.0484) \n",
      "\t\tNot skipping proto 16 of 101+023 coz of find_non_descendants\n",
      "\t\tProto:12 100:(0.9564) 101:(0.584) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 42.02it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "Num protos for cub_003_Sooty_Albatross 2\n",
      "Num protos for 002+001 3\n",
      "\t Child: cub_003_Sooty_Albatross\n",
      "\t\tProto:1 001:(0.0446) 002:(0.0838) \n",
      "\t\tNot skipping proto 1 of 003+002 coz of find_non_descendants\n",
      "\t\tProto:4 001:(0.9988) 002:(0.9967) \n",
      "\t Child: 002+001\n",
      "\t\tProto:17 003:(0.9999) \n",
      "\t\tProto:13 003:(0.7063) \n",
      "\t\tProto:15 003:(0.4079) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 36.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+100\n",
      "Num protos for cub_101_White_Pelican 2\n",
      "Num protos for cub_100_Brown_Pelican 2\n",
      "\t Child: cub_101_White_Pelican\n",
      "\t\tProto:2 100:(0.6881) \n",
      "\t\tProto:6 100:(0.0452) \n",
      "\t\tNot skipping proto 6 of 101+100 coz of find_non_descendants\n",
      "\t Child: cub_100_Brown_Pelican\n",
      "\t\tProto:17 101:(0.7162) \n",
      "\t\tProto:13 101:(0.2292) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 42.57it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "Num protos for cub_023_Brandt_Cormorant 3\n",
      "Num protos for 025+024 3\n",
      "\t Child: cub_023_Brandt_Cormorant\n",
      "\t\tProto:9 024:(0.103) 025:(0.6508) \n",
      "\t\tProto:3 024:(0.035) 025:(0.9865) \n",
      "\t\tProto:7 024:(0.3924) 025:(0.9728) \n",
      "\t Child: 025+024\n",
      "\t\tProto:16 023:(0.8064) \n",
      "\t\tProto:17 023:(0.9999) \n",
      "\t\tProto:18 023:(0.9998) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 34.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 002+001\n",
      "Num protos for cub_002_Laysan_Albatross 3\n",
      "Num protos for cub_001_Black_footed_Albatross 3\n",
      "\t Child: cub_002_Laysan_Albatross\n",
      "\t\tProto:9 001:(0.2833) \n",
      "\t\tProto:2 001:(0.3572) \n",
      "\t\tProto:3 001:(0.0317) \n",
      "\t\tNot skipping proto 3 of 002+001 coz of find_non_descendants\n",
      "\t Child: cub_001_Black_footed_Albatross\n",
      "\t\tProto:17 002:(0.7671) \n",
      "\t\tProto:11 002:(0.9996) \n",
      "\t\tProto:15 002:(0.9997) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 35.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 025+024\n",
      "Num protos for cub_025_Pelagic_Cormorant 2\n",
      "Num protos for cub_024_Red_faced_Cormorant 2\n",
      "\t Child: cub_025_Pelagic_Cormorant\n",
      "\t\tProto:0 024:(0.9924) \n",
      "\t\tProto:1 024:(0.7525) \n",
      "\t Child: cub_024_Red_faced_Cormorant\n",
      "\t\tProto:18 025:(0.1881) \n",
      "\t\tNot skipping proto 18 of 025+024 coz of find_non_descendants\n",
      "\t\tProto:12 025:(0.3366) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "def find_top_percentile_bbox(image, percentile=95):\n",
    "    threshold = np.percentile(image.flatten(), percentile)\n",
    "    mask = image >= threshold\n",
    "    coords = np.argwhere(mask)\n",
    "    if coords.size == 0:\n",
    "        return None, None, None, None\n",
    "    h_min, w_min = coords.min(axis=0)\n",
    "    h_max, w_max = coords.max(axis=0)\n",
    "    h_min, h_max, w_min, w_max = map(int, [h_min, h_max, w_min, w_max])\n",
    "    return h_min, h_max, w_min, w_max\n",
    "\n",
    "def find_high_activation_crop(activation_map, percentile=95):\n",
    "    threshold = np.percentile(activation_map, percentile)\n",
    "    mask = np.ones(activation_map.shape)\n",
    "    mask[activation_map < threshold] = 0\n",
    "    lower_y, upper_y, lower_x, upper_x = 0, 0, 0, 0\n",
    "    for i in range(mask.shape[0]):\n",
    "        if np.amax(mask[i]) > 0.5:\n",
    "            lower_y = i\n",
    "            break\n",
    "    for i in reversed(range(mask.shape[0])):\n",
    "        if np.amax(mask[i]) > 0.5:\n",
    "            upper_y = i\n",
    "            break\n",
    "    for j in range(mask.shape[1]):\n",
    "        if np.amax(mask[:,j]) > 0.5:\n",
    "            lower_x = j\n",
    "            break\n",
    "    for j in reversed(range(mask.shape[1])):\n",
    "        if np.amax(mask[:,j]) > 0.5:\n",
    "            upper_x = j\n",
    "            break\n",
    "    return lower_y, upper_y+1, lower_x, upper_x+1\n",
    "\n",
    "def get_upscaled_activation_uninterpolated(latent_activation, image_size):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    min_image_a = image_a.min()\n",
    "    max_image_a = image_a.max()\n",
    "    image_a = (image_a - min_image_a) / (max_image_a - min_image_a)\n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((image_size[-1], \\\n",
    "                                                                                            image_size[-2]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    reshaped_image_a = (reshaped_image_a / 255).astype('float16')\n",
    "    reshaped_image_a = (reshaped_image_a * (max_image_a - min_image_a)) + min_image_a\n",
    "    return reshaped_image_a\n",
    "\n",
    "# added for NUMPY SAVING\n",
    "def get_upscaled_activation_interpolated(latent_activation, image_size):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    min_image_a = image_a.min()\n",
    "    max_image_a = image_a.max()\n",
    "    image_a = (image_a - min_image_a) / (max_image_a - min_image_a)\n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((image_size[-1], \\\n",
    "                                                                                            image_size[-2])))    \n",
    "    reshaped_image_a = (reshaped_image_a / 255).astype('float16')\n",
    "    reshaped_image_a = (reshaped_image_a * (max_image_a - min_image_a)) + min_image_a\n",
    "    return reshaped_image_a\n",
    "\n",
    "def functional_UnitConv2D(in_features, weight, bias, stride = 1, padding=0):\n",
    "    normalized_weight = F.normalize(weight.data, p=2, dim=(1, 2, 3)) # Normalize the kernels to unit vectors\n",
    "    normalized_input = F.normalize(in_features, p=2, dim=1) # Normalize the input to unit vectors\n",
    "    if bias is not None:\n",
    "        normalized_bias = F.normalize(bias.data, p=2, dim=0) # Normalize the kernels to unit vectors\n",
    "    else:\n",
    "        normalized_bias = None\n",
    "    return F.conv2d(normalized_input, normalized_weight, normalized_bias, stride=stride, padding=padding)\n",
    "\n",
    "def findCorrespondingToMax(base, target):\n",
    "    global args\n",
    "    output, indices = F.max_pool2d(base, kernel_size=(args.wshape, args.wshape), return_indices=True)# these are logits\n",
    "    tensor_flattened = target.view(target.shape[0], target.shape[1], -1)\n",
    "    indices_flattened = indices.view(target.shape[0], target.shape[1], -1)\n",
    "    corresponding_values_in_target = torch.gather(tensor_flattened, 2, indices_flattened)\n",
    "    corresponding_values_in_target = corresponding_values_in_target.view(target.shape[0],\\\n",
    "                                     target.shape[1], 1, 1)\n",
    "    pooled_target = corresponding_values_in_target\n",
    "    return pooled_target\n",
    "\n",
    "def customForwardWithCSandSoftmax(net, xs,  inference=False):\n",
    "    features = net.module._net(xs) \n",
    "    proto_features = {}\n",
    "    proto_features_cs = {}\n",
    "    proto_features_softmaxed = {}\n",
    "    proto_features_pre_softmax = {}\n",
    "    pooled = {}\n",
    "    pooled_cs = {}\n",
    "    pooled_softmaxed = {}\n",
    "    out = {}\n",
    "    for node in net.module.root.nodes_with_children():\n",
    "        # this may or may not be cosine similarity based on UniConv2D or Conv2d\n",
    "        proto_features[node.name] = getattr(net.module, '_'+node.name+'_add_on')(features)\n",
    "        proto_features_pre_softmax[node.name] = proto_features[node.name]\n",
    "        \n",
    "        #calculating cosine similarity\n",
    "        prototypes = getattr(net.module, '_'+node.name+'_add_on')\n",
    "        proto_features_cs[node.name] = functional_UnitConv2D(features, prototypes.weight, prototypes.bias)\n",
    "\n",
    "        if net.module.args.softmax.split('|')[0] == 'y':\n",
    "            if len(net.module.args.softmax.split('|')) > 1:\n",
    "                softmax_tau = int(net.module.args.softmax.split('|')[1])\n",
    "            else:\n",
    "                softmax_tau = 0.2\n",
    "            if ('y' in net.module.args.conc_log_ip):\n",
    "                # softmax over the channel instead of over the patch\n",
    "                B, C, H, W = proto_features[node.name].shape\n",
    "                proto_features[node.name] = proto_features[node.name].reshape(B, C, -1)\n",
    "                proto_features_softmaxed[node.name] = F.softmax(proto_features[node.name], dim=-1)\n",
    "                proto_features_softmaxed[node.name] = proto_features_softmaxed[node.name].reshape(B, C, H, W)\n",
    "                proto_features[node.name] = proto_features_softmaxed[node.name]\n",
    "            else:\n",
    "                proto_features[node.name] = proto_features[node.name] / softmax_tau\n",
    "                proto_features_softmaxed[node.name] = net.module._softmax(proto_features[node.name])\n",
    "                proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "                \n",
    "            # proto_features[node.name] = proto_features[node.name] / softmax_tau\n",
    "            # proto_features_softmaxed[node.name] = net.module._softmax(proto_features[node.name])\n",
    "            # proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "        elif net.module.args.gumbel_softmax == 'y':\n",
    "            proto_features_softmaxed[node.name] = net.module._gumbel_softmax(proto_features[node.name])\n",
    "            proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "\n",
    "        if net.module.args.multiply_cs_softmax == 'y':\n",
    "            proto_features[node.name] = proto_features_cs[node.name] * proto_features_softmaxed[node.name]\n",
    "        pooled[node.name] = net.module._pool(proto_features[node.name])\n",
    "        \n",
    "        # this could be softmax or cosine similarity\n",
    "        pooled_cs[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                     target=proto_features_cs[node.name])\n",
    "        \n",
    "        # only if the model uses softmax or gumbel softmax\n",
    "        if (net.module.args.softmax == 'y') or (net.module.args.gumbel_softmax == 'y'):\n",
    "            pooled_softmaxed[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                         target=proto_features_softmaxed[node.name])\n",
    "\n",
    "        if inference:\n",
    "            pooled[node.name] = torch.where(pooled[node.name] < 0.1, 0., pooled[node.name])  #during inference, ignore all prototypes that have 0.1 similarity or lower\n",
    "        out[node.name] = getattr(net.module, '_'+node.name+'_classification')(pooled[node.name]) #shape (bs*2, num_classes) # these are logits\n",
    "    \"\"\"\n",
    "    features -> Raw features generated by the backbone before the prototype layer\n",
    "    proto_features -> Output of prototype layer (UnitConv2D or Conv2D based on the network configuration used), and softmaxed\n",
    "    proto_features_cs -> Cosine similarity between features and prototypes\n",
    "    proto_features_softmaxed -> Same as proto_features\n",
    "    pooled -> max pooled on proto_features\n",
    "    pooled_cs -> cosine values corresponding to max indices in proto_features\n",
    "    \"\"\"\n",
    "    return features, proto_features_pre_softmax, proto_features, proto_features_cs, proto_features_softmaxed, pooled, pooled_cs, pooled_softmaxed, out\n",
    "#     return features, proto_features, pooled, pooled_cs, pooled_softmaxed, out\n",
    "\n",
    "def customForwardWithProjDistandSoftmax(net, xs,  inference=False):\n",
    "    features = net.module._net(xs) \n",
    "    proto_features = {}\n",
    "    proto_features_cs = {}\n",
    "    proto_features_softmaxed = {}\n",
    "    pooled = {}\n",
    "    pooled_cs = {}\n",
    "    pooled_softmaxed = {}\n",
    "    out = {}\n",
    "    for node in net.module.root.nodes_with_children():\n",
    "        # this may or may not be cosine similarity based on UniConv2D or Conv2d\n",
    "        proto_features[node.name] = getattr(net.module, '_'+node.name+'_add_on')(features)\n",
    "        \n",
    "        \n",
    "        #calculating cosine similarity\n",
    "        prototypes = getattr(net.module, '_'+node.name+'_add_on')\n",
    "        proto_features_cs[node.name] = functional_UnitConv2D(features, prototypes.weight, prototypes.bias)\n",
    "\n",
    "        if net.module.args.softmax == 'y':\n",
    "            softmax_tau = 0.2\n",
    "            proto_features[node.name] = proto_features[node.name] / softmax_tau\n",
    "            proto_features_softmaxed[node.name] = net.module._softmax(proto_features[node.name])\n",
    "            proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "        elif net.module.args.gumbel_softmax == 'y':\n",
    "            proto_features_softmaxed[node.name] = net.module._gumbel_softmax(proto_features[node.name])\n",
    "            proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "\n",
    "        if net.module.args.multiply_cs_softmax == 'y':\n",
    "            proto_features[node.name] = proto_features_cs[node.name] * proto_features_softmaxed[node.name]\n",
    "        pooled[node.name] = net.module._pool(proto_features[node.name])\n",
    "        \n",
    "        # this could be softmax or cosine similarity\n",
    "        pooled_cs[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                     target=proto_features_cs[node.name])\n",
    "        \n",
    "        # only if the model uses softmax or gumbel softmax\n",
    "        if (net.module.args.softmax == 'y') or (net.module.args.gumbel_softmax == 'y'):\n",
    "            pooled_softmaxed[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                         target=proto_features_softmaxed[node.name])\n",
    "\n",
    "        if inference:\n",
    "            pooled[node.name] = torch.where(pooled[node.name] < 0.1, 0., pooled[node.name])  #during inference, ignore all prototypes that have 0.1 similarity or lower\n",
    "        out[node.name] = getattr(net.module, '_'+node.name+'_classification')(pooled[node.name]) #shape (bs*2, num_classes) # these are logits\n",
    "    \"\"\"\n",
    "    features -> Raw features generated by the backbone before the prototype layer\n",
    "    proto_features -> Output of prototype layer (UnitConv2D or Conv2D based on the network configuration used), and softmaxed\n",
    "    proto_features_cs -> Cosine similarity between features and prototypes\n",
    "    proto_features_softmaxed -> Same as proto_features\n",
    "    pooled -> max pooled on proto_features\n",
    "    pooled_cs -> cosine values corresponding to max indices in proto_features\n",
    "    \"\"\"\n",
    "    return features, proto_features_pre_softmax, proto_features, proto_features_cs, proto_features_softmaxed, pooled, pooled_cs, pooled_softmaxed, out\n",
    "\n",
    "find_non_descendants = True # True, False # param\n",
    "heatmap_type = 'pre_softmax' # 'pre_softmax', 'softmax'\n",
    "vizloader_name = 'projectloader' #'testloader' # 'projectloader'\n",
    "bbox_percentile = 97\n",
    "topk = 6 # param, args param\n",
    "save_images = True #True, False\n",
    "save_activation_as_npy_path = '_'.join(['activation_as_npy', vizloader_name]) # activation_as_npy, added for NUMPY SAVING\n",
    "if find_non_descendants and (save_activation_as_npy_path is not None):\n",
    "    save_activation_as_npy_path = save_activation_as_npy_path + '_non_desc'\n",
    "analysis_mode = True\n",
    "\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "font2 = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "font3 = ImageFont.truetype(\"arial.ttf\", 30)\n",
    "\n",
    "from datetime import datetime\n",
    "txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "txt_file.write('\\n')\n",
    "\n",
    "def write_num_proto_details(proto_mean_activations, node_name, net, threshold, txt_file, args):\n",
    "    \n",
    "    rand_input = torch.randn((1, 3, args.image_size, args.image_size))\n",
    "    with torch.no_grad():\n",
    "        *_, pooled, out = net(rand_input)\n",
    "    num_protos = pooled[node_name].shape[1]\n",
    "    used_protos = len(proto_mean_activations)\n",
    "    non_overspecific = 0\n",
    "    for p in proto_mean_activations:\n",
    "        logstr = '\\t'*2 + f'Proto:{p} '\n",
    "        protos_mean_for_all_leaf_descedants = []\n",
    "        for leaf_descendent in proto_mean_activations[p]:\n",
    "            mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "            protos_mean_for_all_leaf_descedants.append(mean_activation)\n",
    "            \n",
    "        if all([(mean_activation>0.2) for mean_activation in protos_mean_for_all_leaf_descedants]):\n",
    "            non_overspecific += 1\n",
    "            \n",
    "    txt_file.write(f\"Node:{node_name},Total:{num_protos},Used:{used_protos},Good:{non_overspecific},threshold={threshold}\\n\")\n",
    "\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "\n",
    "\n",
    "vizloader_dict = {'trainloader': trainloader,\n",
    "                 'projectloader': projectloader,\n",
    "                 'testloader': testloader,\n",
    "                 'test_projectloader': test_projectloader}\n",
    "vizloader_dict[vizloader_name] = unshuffle_dataloader(vizloader_dict[vizloader_name])\n",
    "\n",
    "\n",
    "if type(vizloader_dict[vizloader_name].dataset) == ImageFolder:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "else:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.dataset.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    \n",
    "#     if node.name == 'root':\n",
    "#         print('-'*25, 'Skipping root node', '-'*25)\n",
    "#         continue\n",
    "\n",
    "#     non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "#     if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "#         continue\n",
    "\n",
    "#     name2label = projectloader.dataset.class_to_idx # param\n",
    "#     label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(vizloader_dict[vizloader_name], node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    \n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        # change\n",
    "#         if not find_non_descendants: \n",
    "#             # do only when finding descendants\n",
    "#             if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "#                 continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = customForwardWithCSandSoftmax(net, xs, inference=False)\n",
    "            features, proto_features_pre_softmax, softmaxes, cosine_similarity, _, pooled, pooled_cs, pooled_softmaxed, out = model_output\n",
    "#             _, softmaxes, pooled, pooled_ip, pooled_softmax, _ = model_output # features, proto_features, pooled, pooled_cs, pooled_softmaxed, out\n",
    "#             model_output = net(xs, inference=False)\n",
    "#             if len(model_output) == 3:\n",
    "#                 softmaxes, pooled, _ = model_output\n",
    "#             elif len(model_output) == 4:\n",
    "#                 _, softmaxes, pooled, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0)\n",
    "            pooled_cs = pooled_cs[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "            cosine_similarity = cosine_similarity[node.name]\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # change\n",
    "#                 if (len(relevant_proto_class_names) == 1):# and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "#                     continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                \n",
    "                latent_activation_pre_softmax = proto_features_pre_softmax[node.name][:, p, :, :]\n",
    "                latent_activation_cs = cosine_similarity[:, p, :, :]\n",
    "                if not find_non_descendants:\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7] if analysis_mode else \\\n",
    "                                                label2name[orig_y.item()][4:]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), pooled_cs[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                                               latent_activation, latent_activation_cs, latent_activation_pre_softmax))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), pooled_cs[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                                            latent_activation, latent_activation_cs, latent_activation_pre_softmax))\n",
    "                else:\n",
    "                    if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7] if analysis_mode else \\\n",
    "                                                label2name[orig_y.item()][4:]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), pooled_cs[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                                               latent_activation, latent_activation_cs, latent_activation_pre_softmax))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), pooled_cs[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                                            latent_activation, latent_activation_cs, latent_activation_pre_softmax))\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "                \n",
    "    write_num_proto_details(proto_mean_activations, node.name, net, threshold=0.2, txt_file=txt_file, args=args)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for class_label in range(classification_weights.shape[0]):\n",
    "        child_name = (coarse_label2name[class_label])\n",
    "        print('Num protos for', child_name, torch.nonzero(classification_weights[class_label, :] > 1e-3).shape[0])\n",
    "        \n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            mean_activation_of_every_leaf = []\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "                mean_activation_of_every_leaf.append(mean_activation)\n",
    "            print(logstr)\n",
    "            \n",
    "            # if the mean_activation is less for all leaf descendants skip the node\n",
    "            if all([mean_act < 0.2 for mean_act in mean_activation_of_every_leaf]):\n",
    "                if find_non_descendants:\n",
    "                    print('\\t'*2 + f'Not skipping proto {p} of {node.name} coz of find_non_descendants')\n",
    "                else:\n",
    "                    print('\\t'*2 + f'Skipping proto {p} of {node.name}')\n",
    "                    continue\n",
    "            \n",
    "            # have this for NON descendants\n",
    "            if len(proto_mean_activations[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images or save_activation_as_npy_path:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 if analysis_mode else 2 # 3x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 2)\n",
    "                    least_activation = min([round(activation, 2) for activation, *_ in proto_mean_activations[p][leaf_descendent]])\n",
    "                    most_activation = max([round(activation, 2) for activation, *_ in proto_mean_activations[p][leaf_descendent]])\n",
    "                    mean_cosine_similarity = round(np.mean([activation_inner_product for _, activation_inner_product, *_ in proto_mean_activations[p][leaf_descendent]]), 2)\n",
    "                    # modified for NUMPY SAVING\n",
    "                    for rank, ele in enumerate(heap):\n",
    "                        \n",
    "                        activation, activation_inner_product, img_to_open, \\\n",
    "                        (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                        latent_activation, latent_activation_cs, latent_activation_pre_softmax = ele\n",
    "                        \n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "#                         overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "#                         overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "#                         patches.append(overlayed_image)\n",
    "\n",
    "                        if heatmap_type == 'pre_softmax':\n",
    "                            overlayed_image_np = get_heatmap(latent_activation_pre_softmax, img_tensor)\n",
    "                        else:\n",
    "                            overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        if analysis_mode:\n",
    "                            overlayed_image_pil = Image.fromarray(overlayed_image_np)\n",
    "                            draw = D.Draw(overlayed_image_pil)\n",
    "                            text = f\"{round(activation, 2), round(activation_inner_product, 2)}\"\n",
    "    #                         text_width, text_height = draw.textsize(text, font2)\n",
    "                            bbox = draw.textbbox((0, 0), text, font2)\n",
    "                            text_width = bbox[2] - bbox[0]\n",
    "                            text_height = bbox[3] - bbox[1]\n",
    "                            x, y = 224 - text_width - 5, 5  # 10 pixels padding from right\n",
    "                            draw.text((x, y), text, font=font2, fill=(255, 255, 255))\n",
    "                            overlayed_image_np = np.array(overlayed_image_pil)\n",
    "                        \n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "\n",
    "                        # Commenting Bounding Boxes for now\n",
    "                        # if analysis_mode:\n",
    "                        #     upscaled_similarity = get_upscaled_activation_uninterpolated(latent_activation, image_size=(args.image_size, args.image_size))\n",
    "                        #     h_min, h_max, w_min, w_max = get_bb_gaussian_threshold(latent_activation, sigma=1.0, \\\n",
    "                        #                                                            percentile=bbox_percentile, extend_h=0, extend_w=0)\n",
    "                        #     bbox_coords = torch.tensor([[w_min, h_min, w_max, h_max]])\n",
    "                        #     overlayed_image = torchvision.utils.draw_bounding_boxes((overlayed_image * 255).type(torch.uint8), \\\n",
    "                        #                                                                bbox_coords, colors='red') / 255\n",
    "                        \n",
    "#                         plt_image = overlayed_bb_image.permute(1, 2, 0)# should be H, W, C with 0 to 1\n",
    "#                         plt.imshow(plt_image)\n",
    "#                         plt.show()\n",
    "#                         pdb.set_trace()\n",
    "                        patches.append(overlayed_image)\n",
    "                        # added for NUMPY SAVING\n",
    "                        if save_activation_as_npy_path:\n",
    "                            upscaled_similarity_interpolated = get_upscaled_activation_interpolated(latent_activation,\n",
    "                                                                                       image_size=(args.image_size, args.image_size))\n",
    "                            latent_activation_npy = latent_activation.squeeze().cpu().numpy()\n",
    "                            latent_activation_cs_npy = latent_activation_cs.squeeze().cpu().numpy()\n",
    "                            data = {'node_name': node.name,\n",
    "                                    'proto_num': p,\n",
    "                                    'child_name': child_classname,\n",
    "                                    'leaf_desc': leaf_descendent,\n",
    "                                     'rank': rank,\n",
    "                                     'img_path': img_to_open,\n",
    "                                     'img_filename': ntpath.basename(img_to_open),\n",
    "                                     'activation': latent_activation_npy,\n",
    "                                     'activation_cs': latent_activation_cs_npy,\n",
    "                                     'max_activation': activation,\n",
    "                                     'model_type': 'HPIPNET'}\n",
    "                            filename = str(rank)+ '-' + ntpath.basename(img_to_open) + '.npy'\n",
    "                            save_path = os.path.join(run_path, save_activation_as_npy_path, \\\n",
    "                                                     node.name, str(p), leaf_descendent,\n",
    "                                                     filename)\n",
    "                            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                            np.save(save_path, data, allow_pickle=True)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}' if analysis_mode else \\\n",
    "                                f'{leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((200, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font3)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "                \n",
    "                # weird thing padding should be zero for non descendants else it raises some error # change\n",
    "                if find_non_descendants or (len(patches) == topk): # (len(patches) == topk) means there is only one leaf descendant\n",
    "                    padding = 0\n",
    "                else:\n",
    "                    padding = 1\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=padding)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=padding)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid_right_descriptions, grid], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}' if analysis_mode else \\\n",
    "                            f'Parent node:{node.name}, Child node:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], 75), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((500, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([txttensor, grid], dim=1)\n",
    "                \n",
    "                if save_images:\n",
    "                    prefix = 'non_' if find_non_descendants else ''\n",
    "                    os.makedirs(os.path.join(run_path, prefix + f'descendent_specific_topk_heatmap_{vizloader_name}_{bbox_percentile}_ep={epoch}_analysis={analysis_mode}', node.name), exist_ok=True)\n",
    "                    torchvision.utils.save_image(grid, os.path.join(run_path, prefix + f'descendent_specific_topk_heatmap_{vizloader_name}_{bbox_percentile}_ep={epoch}_analysis={analysis_mode}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "txt_file.write('\\n')\n",
    "txt_file.close()\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "\tcub_052_Pied_billed_Grebe\n",
      "\tcub_053_Western_Grebe\n",
      "\tcub_050_Eared_Grebe\n",
      "\tcub_051_Horned_Grebe\n",
      "\tcub_004_Groove_billed_Ani\n",
      "\tcub_032_Mangrove_Cuckoo\n",
      "\tcub_033_Yellow_billed_Cuckoo\n",
      "\tcub_031_Black_billed_Cuckoo\n",
      "\tcub_086_Pacific_Loon\n",
      "\tcub_045_Northern_Fulmar\n",
      "\tcub_003_Sooty_Albatross\n",
      "\tcub_002_Laysan_Albatross\n",
      "\tcub_001_Black_footed_Albatross\n",
      "\tcub_101_White_Pelican\n",
      "\tcub_100_Brown_Pelican\n",
      "\tcub_023_Brandt_Cormorant\n",
      "\tcub_025_Pelagic_Cormorant\n",
      "\tcub_024_Red_faced_Cormorant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 844\n",
      "    Root location: /projects/ml4science/harishbabu/data/CUB_29_pipnet_224/dataset_segmented_imgnet_pt/test_crop\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "vizloader_name = 'testloader'\n",
    "vizloader_dict[vizloader_name] = unshuffle_dataloader(vizloader_dict[vizloader_name])\n",
    "print(vizloader_dict[vizloader_name].dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images using  NAIVE-HPIPNET with HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 5695/5695 [14:28<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node root\n",
      "\t Child: cub_104_American_Pipit, cub_093_Clark_Nutcracker\n",
      "\t\tProto:16 093:(0.9982) 104:(0.9913) \n",
      "\t Child: cub_142_Black_Tern, cub_025_Pelagic_Cormorant\n",
      "\t\tProto:17 025:(0.9915) 142:(1.0) \n",
      "\t Child: cub_197_Marsh_Wren\n",
      "\t\tProto:18 197:(0.9999) \n",
      "\t\tProto:551 197:(0.9973) \n",
      "\t Child: cub_037_Acadian_Flycatcher, cub_102_Western_Wood_Pewee, cub_041_Scissor_tailed_Flycatcher\n",
      "\t\tProto:19 037:(0.9942) 041:(1.0) 102:(0.9971) \n",
      "\t Child: cub_114_Black_throated_Sparrow\n",
      "\t\tProto:152 114:(1.0) \n",
      "\t\tProto:22 114:(1.0) \n",
      "\t Child: cub_018_Spotted_Catbird, cub_083_White_breasted_Kingfisher, cub_067_Anna_Hummingbird, cub_070_Green_Violetear\n",
      "\t\tProto:24 018:(0.9998) 067:(0.1902) 070:(1.0) 083:(1.0) \n",
      "\t Child: cub_009_Brewer_Blackbird, cub_162_Canada_Warbler, cub_057_Rose_breasted_Grosbeak, cub_151_Black_capped_Vireo, cub_156_White_eyed_Vireo, cub_152_Blue_headed_Vireo, cub_006_Least_Auklet, cub_007_Parakeet_Auklet, cub_005_Crested_Auklet, cub_008_Rhinoceros_Auklet, cub_058_Pigeon_Guillemot, cub_089_Hooded_Merganser\n",
      "\t\tProto:26 005:(1.0) 006:(1.0) 007:(1.0) 008:(1.0) 009:(0.0004) 057:(1.0) 058:(1.0) 089:(1.0) 151:(0.7178) 152:(1.0) 156:(1.0) 162:(1.0) \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 36] File name too long: '/home/harishbabu/projects/PIPNet/runs/113-NaiveHPIPNetFlatStructureNoAlNoTanh_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD_no-AL_no-TANH/descendent_specific_topk_heatmap_ep=last/root/cub_009_Brewer_Blackbird, cub_162_Canada_Warbler, cub_057_Rose_breasted_Grosbeak, cub_151_Black_capped_Vireo, cub_156_White_eyed_Vireo, cub_152_Blue_headed_Vireo, cub_006_Least_Auklet, cub_007_Parakeet_Auklet, cub_005_Crested_Auklet, cub_008_Rhinoceros_Auklet, cub_058_Pigeon_Guillemot, cub_089_Hooded_Merganser-p26.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 285\u001b[0m\n\u001b[1;32m    283\u001b[0m                     prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnon_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m find_non_descendants \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    284\u001b[0m                     os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_path, prefix\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescendent_specific_topk_heatmap_ep=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, node\u001b[38;5;241m.\u001b[39mname), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 285\u001b[0m                     \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdescendent_specific_topk_heatmap_ep=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchild_classname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-p\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mp\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m txt_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    288\u001b[0m txt_file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.conda/envs/hpnet3/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/utils.py:150\u001b[0m, in \u001b[0;36msave_image\u001b[0;34m(tensor, fp, format, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m ndarr \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mmul(\u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39madd_(\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    149\u001b[0m im \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(ndarr)\n\u001b[0;32m--> 150\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/PIL/Image.py:2435\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2433\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2434\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2435\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2438\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 36] File name too long: '/home/harishbabu/projects/PIPNet/runs/113-NaiveHPIPNetFlatStructureNoAlNoTanh_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD_no-AL_no-TANH/descendent_specific_topk_heatmap_ep=last/root/cub_009_Brewer_Blackbird, cub_162_Canada_Warbler, cub_057_Rose_breasted_Grosbeak, cub_151_Black_capped_Vireo, cub_156_White_eyed_Vireo, cub_152_Blue_headed_Vireo, cub_006_Least_Auklet, cub_007_Parakeet_Auklet, cub_005_Crested_Auklet, cub_008_Rhinoceros_Auklet, cub_058_Pigeon_Guillemot, cub_089_Hooded_Merganser-p26.png'"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "txt_file.write('\\n')\n",
    "\n",
    "vizloader_name = 'testloader' # projectloader\n",
    "find_non_descendants = True # True, False # param\n",
    "topk = 6\n",
    "save_images = True # True, False\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "save_activation_as_npy_path = 'activation_as_npy'\n",
    "save_activation_as_npy_path = '_'.join(['activation_as_npy', vizloader_name])  # activation_as_npy, added for NUMPY SAVING\n",
    "if find_non_descendants and (save_activation_as_npy_path is not None):\n",
    "    save_activation_as_npy_path = save_activation_as_npy_path + '_non_desc'\n",
    "    \n",
    "from datetime import datetime\n",
    "txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "txt_file.write('\\n')\n",
    "\n",
    "def write_num_proto_details(proto_mean_activations, node_name, net, threshold, txt_file, args):\n",
    "    \n",
    "    rand_input = torch.randn((1, 3, args.image_size, args.image_size))\n",
    "    with torch.no_grad():\n",
    "        *_, pooled, out = net(rand_input)\n",
    "    num_protos = pooled[node_name].shape[1]\n",
    "    used_protos = len(proto_mean_activations)\n",
    "    non_overspecific = 0\n",
    "    for p in proto_mean_activations:\n",
    "        logstr = '\\t'*2 + f'Proto:{p} '\n",
    "        protos_mean_for_all_leaf_descedants = []\n",
    "        for leaf_descendent in proto_mean_activations[p]:\n",
    "            mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "            protos_mean_for_all_leaf_descedants.append(mean_activation)\n",
    "            \n",
    "        if all([(mean_activation>0.2) for mean_activation in protos_mean_for_all_leaf_descedants]):\n",
    "            non_overspecific += 1\n",
    "            \n",
    "    txt_file.write(f\"Node:{node_name},Total:{num_protos},Used:{used_protos},Good:{non_overspecific},threshold={threshold}\\n\")\n",
    "\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "\n",
    "vizloader_dict = {'trainloader': trainloader,\n",
    "                 'projectloader': projectloader,\n",
    "                 'testloader': testloader,\n",
    "                 'test_projectloader': test_projectloader}\n",
    "vizloader_dict[vizloader_name] = unshuffle_dataloader(vizloader_dict[vizloader_name])\n",
    "\n",
    "\n",
    "if type(vizloader_dict[vizloader_name].dataset) == ImageFolder:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "else:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.dataset.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "#     non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "#     if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "#         continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "#         if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "#             continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = net(xs, inference=False)\n",
    "            if len(model_output) == 3:\n",
    "                softmaxes, pooled, _ = model_output\n",
    "            elif len(model_output) == 4:\n",
    "                _, softmaxes, pooled, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "#                 if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "#                     continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                \n",
    "                if not find_non_descendants:\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                else:\n",
    "                    if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    write_num_proto_details(proto_mean_activations, node.name, net, threshold=0.2, txt_file=txt_file, args=args)\n",
    "\n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            mean_activation_of_every_leaf = []\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "                mean_activation_of_every_leaf.append(mean_activation)\n",
    "            print(logstr)\n",
    "            \n",
    "            # if the mean_activation is less for all leaf descendants skip the node\n",
    "            if all([mean_act < 0.2 for mean_act in mean_activation_of_every_leaf]):\n",
    "                print(f'Skipping proto {p} of {node.name}')\n",
    "                continue\n",
    "            \n",
    "            # have this for NON descendants\n",
    "            if len(proto_mean_activations[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images or save_activation_as_npy_path:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 # 3x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    for rank, ele in enumerate(heap):\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "                        patches.append(overlayed_image)\n",
    "                        \n",
    "                        # added for NUMPY SAVING\n",
    "                        \n",
    "                        if save_activation_as_npy_path:\n",
    "#                             upscaled_similarity_interpolated = get_upscaled_activation_interpolated(latent_activation,\n",
    "#                                                                                        image_size=(args.image_size, args.image_size))\n",
    "                            latent_activation_npy = latent_activation.squeeze().cpu().numpy()\n",
    "                            data = {'node_name': node.name,\n",
    "                                    'proto_num': p,\n",
    "                                    'child_name': child_classname,\n",
    "                                    'leaf_desc': leaf_descendent,\n",
    "                                     'rank': rank,\n",
    "                                     'img_path': img_to_open,\n",
    "                                     'img_filename': ntpath.basename(img_to_open),\n",
    "                                     'activation': latent_activation_npy,\n",
    "                                     'max_activation': activation,\n",
    "                                     'model_type': 'NAIVE-HPIPNET'}\n",
    "                            filename = str(rank)+ '-' + ntpath.basename(img_to_open) + '.npy'\n",
    "                            save_path = os.path.join(run_path, save_activation_as_npy_path, \\\n",
    "                                                     node.name, str(p), leaf_descendent,\n",
    "                                                     filename)\n",
    "                            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                            np.save(save_path, data, allow_pickle=True)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "                    \n",
    "                # weird thing padding should be zero for non descendants else it raises some error # change\n",
    "                if find_non_descendants or (len(patches) == topk): # (len(patches) == topk) means there is only one leaf descendant\n",
    "                    padding = 0\n",
    "                else:\n",
    "                    padding = 1\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=padding)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=padding)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "                \n",
    "                if save_images:\n",
    "                    prefix = 'non_' if find_non_descendants else ''\n",
    "                    os.makedirs(os.path.join(run_path, prefix+f'descendent_specific_topk_heatmap_ep={epoch}', node.name), exist_ok=True)\n",
    "                    torchvision.utils.save_image(grid, os.path.join(run_path, prefix+f'descendent_specific_topk_heatmap_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "txt_file.write('\\n')\n",
    "txt_file.close()\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(torch.tensor(2 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cos(torch.pi)\n",
    "torch.cos(torch.tensor(2 * torch.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9994999766349792\n",
      "1 0.9995477199554443\n",
      "2 0.9996727705001831\n",
      "3 0.9998272657394409\n",
      "4 0.9999522566795349\n",
      "5 1.0\n",
      "6 0.9999522566795349\n",
      "7 0.9998272657394409\n",
      "8 0.9996727705001831\n",
      "9 0.9995477199554443\n",
      "10 0.9994999766349792\n",
      "11 0.9995477199554443\n",
      "12 0.9996727705001831\n",
      "13 0.9998272657394409\n",
      "14 0.9999522566795349\n",
      "15 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "byol_tau_base = 0.9995\n",
    "byol_tau_max = 1.0\n",
    "# current_step = 50\n",
    "max_training_steps = 15\n",
    "cycle_steps = 5\n",
    "\n",
    "byol_tau_list = []\n",
    "for current_step in range(max_training_steps+1):\n",
    "#     byol_tau = byol_tau_max - (((byol_tau_max - byol_tau_base) * (torch.cos(torch.tensor((torch.pi * current_step)/max_training_steps)) + 1)) / 2)\n",
    "    byol_tau = byol_tau_max - (((byol_tau_max - byol_tau_base) * (torch.cos(torch.tensor((torch.pi * current_step)/cycle_steps)) + 1)) / 2)\n",
    "    print(current_step, byol_tau.item())\n",
    "    byol_tau_list.append(byol_tau)\n",
    "    \n",
    "plt.plot(byol_tau_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_max_value_correspondence(tensor1, tensor2):\n",
    "    # Find the index of the max value in tensor1\n",
    "    max_idx = torch.argmax(tensor1)\n",
    "\n",
    "    # Convert the index to 2D coordinates\n",
    "    H, W = tensor1.shape\n",
    "    max_coord = (max_idx // W, max_idx % W)\n",
    "\n",
    "    # Access the corresponding value in tensor2\n",
    "    return tensor2[max_coord]\n",
    "\n",
    "# Example tensors\n",
    "tensor1_example = torch.tensor([[1.1, 0.2, 0.3], [0.4, 0.8, 0.6], [0.5, 0.7, 0.9]])\n",
    "tensor2_example = torch.tensor([[False, True, True], [False, True, False], [True, False, True]])\n",
    "\n",
    "# Check if the value at the max value of tensor1 in tensor2 is True or False\n",
    "result = check_max_value_correspondence(tensor1_example, tensor2_example)\n",
    "result.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
