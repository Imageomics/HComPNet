{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/010-CUB-27-imgnet_OOD_cnext26_img=224_nprotos=20'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/031-CUB-18-imgnet_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/032-CUB-18-imgnet_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/035-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/043-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/036-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel_uniformity\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/041-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/042-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/044-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20-or-4per-desc_orth-on-rel\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/046-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=10per-desc_orth-on-rel\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/047-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=5per-desc_tanh-desc\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/048-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=5per-desc_tanh-desc_unit-sphere\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/051-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_tanh-desc_unit-sphere_AW=5-TW=2-UW=2-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/052-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=4per-desc_tanh-desc_unit-sphere_AW=5-TW=2-UW=2-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/055-CUB-18_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/056-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/057-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/058-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "\n",
    "# with unit sphere\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/059-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# unit sphere with softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/065-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# original hpipnet with 20 protos per node no KO, no OOD, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/062-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD\"\n",
    "\n",
    "# original hpipnet with 20 protos per node no KO, no OOD, WITH tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/063-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD_tanh-desc\"\n",
    "\n",
    "# with unit sphere but no AL+UNI\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/066-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_no-softmax_no-align_no-uni_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, with softmax, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/067-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, with softmax, no tanh-desc, INCORRECT\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/067-incorrect-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, no softmax, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/068-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 071 with bias\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/071-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_with-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 072 gumbel softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/072-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-gumbel-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 073 gumbel softmax, tau-1.0\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/073-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-gumbel-softmax-tau=1_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 075 068 with focal loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/075-068-with-focal_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_no-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 076 cs followed by softmax. Uses align_pf along with align+uni\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/076_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_align-pf-during-training_no-meanpool_no-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2-APW=5_batch=20\"\n",
    "\n",
    "# 074 multiply_cs_softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/074-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_multi-cs-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 077 unit sphere protopool with cosin no softmax constant 20 protos per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/077_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20-sphere-protopool_finetune=5_align-pf-during-training_no-meanpool_no-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 080 unit sphere protopool with cosin and softmax constant 20 protos per node (other details not sure)\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/080-CUB-18-imgnet_with-equalize-aug_cnext7_img=224_nprotos=20_unit-sphere-protopool_finetune=5_align-pf-during-training_no-meanpool_with-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_weighted-ce_batch=20\"\n",
    "\n",
    "# 082 unit sphere cs followed by softmax with minmazimize loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/082-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 083 unit sphere cs followed by softmax with minmazimize loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/083-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_no-align_no-uni_no-mm-loss_batch=48\"\n",
    "\n",
    "# 085 unit sphere cs followed by softmax-with-tau with minmazimize loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/085-notebook-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=12\"\n",
    "\n",
    "# 091 basic gaussian multiplier on stage 4\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/091-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_latent-dim=256_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 092 basic gaussian multiplier on stage 3, 4\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/092-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=3,4|1.0|50_img=224_latent-dim=256_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 093 128 dim linear\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/093-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_latent-dim=128_nprotos=20_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=1-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 094 128 dim linear\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/094-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_latent-dim=128_nprotos=20_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=1-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 095 ablation 091 without AL+UNI\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/095-091-woALUNI-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_no-AL_no-UNI_mm-loss_batch=48\"\n",
    "\n",
    "# 096 ablation 091 without AL+UNI\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/096-091-wfocal-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 097 - 091 with bg\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/097-091-wbg-CUB-18_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 0100 cub29 with 20 per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/100_CUB-29-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=20_unit-sphere-protopool_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 0101 baseline with 4 per desc per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/101-baseline-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_no-KO_no-OOD\"\n",
    "\n",
    "# 0103 091 with 20 per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/103-091-wProtoPool20PerNode_CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=20_unit-sphere-protopool_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_batch=48\"\n",
    "\n",
    "# 098 091 without AL + UNI\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/098-091-woALUNI_finetune=0_CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=4per-leaf-desc_unit-sphere_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48'\n",
    "\n",
    "# 0107 091 with 20 per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/107-baseline_LOU_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD\"\n",
    "\n",
    "# 109 flat structure 18 species - HPIPNet\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/109-FlatStructure180protos_CUB-18-imgnet-bg_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=180_unit-sphere-protopool_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_batch=48'\n",
    "\n",
    "# 110 flat structure 18 species - HPIPNet no AL+UNI\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/110-FlatStructure180protosNoALUNI_CUB-18-imgnet-bg_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_nprotos=180_unit-sphere-protopool_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_batch=48'\n",
    "\n",
    "# 111 flat structure 18 species - Naive-HPIPNet\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/111-NaiveHPIPNetFlatStructure180-baseline_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=180_no-KO_no-OOD'\n",
    "\n",
    "# 112 flat structure 190 species - Naive-HPIPNet\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/112-NaiveHPIPNetFlatStructure_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD\"\n",
    "\n",
    "# 113 flat structure 190 species - Naive-HPIPNet no AL_PF+TANH\n",
    "run_path = \"/home/harishbabu/projects/PIPNet/runs/113-NaiveHPIPNetFlatStructureNoAlNoTanh_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD_no-AL_no-TANH\"\n",
    "\n",
    "try:\n",
    "    sys.path.remove('/home/harishbabu/projects/PIPNet')\n",
    "except:\n",
    "    pass\n",
    "sys.path.insert(0, os.path.join(run_path, 'source_clone'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/projects/PIPNet/runs/113-NaiveHPIPNetFlatStructureNoAlNoTanh_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD_no-AL_no-TANH\n"
     ]
    }
   ],
   "source": [
    "print(run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/harishbabu/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import sys, os\n",
    "import random\n",
    "import numpy as np\n",
    "from shutil import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.filters import threshold_local, gaussian\n",
    "import ntpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/harishbabu/projects/PIPNet/runs/113-NaiveHPIPNetFlatStructureNoAlNoTanh_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD_no-AL_no-TANH/source_clone', '/home/harishbabu/.conda/envs/hpnet3/lib/python38.zip', '/home/harishbabu/.conda/envs/hpnet3/lib/python3.8', '/home/harishbabu/.conda/envs/hpnet3/lib/python3.8/lib-dynload', '', '/home/harishbabu/.local/lib/python3.8/site-packages', '/home/harishbabu/.conda/envs/hpnet3/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipnet.pipnet import PIPNet, get_network\n",
    "from util.log import Log\n",
    "from util.args import get_args, save_args, get_optimizer_nn\n",
    "from util.data import get_dataloaders\n",
    "from util.func import init_weights_xavier\n",
    "from pipnet.train import train_pipnet, test_pipnet\n",
    "# from pipnet.test import eval_pipnet, get_thresholds, eval_ood\n",
    "from util.eval_cub_csv import eval_prototypes_cub_parts_csv, get_topk_cub, get_proto_patches_cub\n",
    "from util.vis_pipnet import visualize, visualize_topk\n",
    "from util.visualize_prediction import vis_pred, vis_pred_experiments\n",
    "from util.node import Node\n",
    "from util.phylo_utils import construct_phylo_tree, construct_discretized_phylo_tree\n",
    "from util.func import get_patch_size\n",
    "from util.data import ModifiedLabelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/projects/PIPNet/runs/113-NaiveHPIPNetFlatStructureNoAlNoTanh_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD_no-AL_no-TANH/source_clone/pipnet/pipnet.py\n",
      "/home/harishbabu/projects/PIPNet/runs/113-NaiveHPIPNetFlatStructureNoAlNoTanh_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD_no-AL_no-TANH/source_clone/util/node.py\n"
     ]
    }
   ],
   "source": [
    "from pipnet import pipnet\n",
    "print(pipnet.__file__)\n",
    "from util import node\n",
    "print(node.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "def get_bb_gaussian_threshold(latent_activation, sigma=1.0, percentile=97, extend_h=0, extend_w=0):\n",
    "    # latent_activation -> []\n",
    "    upscaled_similarity = get_upscaled_activation_uninterpolated(latent_activation, \\\n",
    "                                                                 image_size=(args.image_size, args.image_size))\n",
    "    upscaled_similarity = minmaxscale(upscaled_similarity)\n",
    "    upscaled_similarity = gaussian(upscaled_similarity, sigma=sigma)\n",
    "    upscaled_similarity = threshold_local(upscaled_similarity, block_size=15, method='mean')\n",
    "    h_min, h_max, w_min, w_max = find_top_percentile_bbox(upscaled_similarity ,percentile=97)\n",
    "    h_min = max(0, h_min-extend_h)\n",
    "    h_max = min(upscaled_similarity.shape[0], h_max+extend_h)\n",
    "    w_min = max(0, w_min-extend_w)\n",
    "    w_max = min(upscaled_similarity.shape[1], w_max+extend_w)\n",
    "    return h_min, h_max, w_min, w_max\n",
    "\n",
    "\n",
    "def minmaxscale(tensor):\n",
    "    return (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def unshuffle_dataloader(dataloader):\n",
    "    if type(dataloader.dataset) == ImageFolder:\n",
    "        dataset = dataloader.dataset\n",
    "    else:\n",
    "        dataset = dataloader.dataset.dataset.dataset\n",
    "    new_dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=dataloader.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=dataloader.num_workers,\n",
    "        pin_memory=dataloader.pin_memory,\n",
    "        drop_last=dataloader.drop_last,\n",
    "        timeout=dataloader.timeout,\n",
    "        worker_init_fn=dataloader.worker_init_fn,\n",
    "        multiprocessing_context=dataloader.multiprocessing_context,\n",
    "        generator=dataloader.generator,\n",
    "        prefetch_factor=dataloader.prefetch_factor,\n",
    "        persistent_workers=dataloader.persistent_workers\n",
    "    )\n",
    "    return new_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- No discretization -------------------------\n"
     ]
    }
   ],
   "source": [
    "args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "args = pickle.load(args_file)\n",
    "\n",
    "if args.phylo_config:\n",
    "    phylo_config = OmegaConf.load(args.phylo_config)\n",
    "\n",
    "if args.phylo_config:\n",
    "    # construct the phylo tree\n",
    "    if phylo_config.phyloDistances_string == 'None':\n",
    "        if '031' in run_path: # this run uses a different phylogeny file that had an extra root node which is a mistake\n",
    "            root = construct_phylo_tree('/home/harishbabu/data/phlyogenyCUB/18Species-with-extra-root-node/1_tree-consensus-Hacket-18Species-modified_cub-names_v1.phy')\n",
    "        else:\n",
    "            root = construct_phylo_tree(phylo_config.phylogeny_path)\n",
    "        print('-'*25 + ' No discretization ' + '-'*25)\n",
    "    else:\n",
    "        root = construct_discretized_phylo_tree(phylo_config.phylogeny_path, phylo_config.phyloDistances_string)\n",
    "        print('-'*25 + ' Discretized ' + '-'*25)\n",
    "else:\n",
    "    # construct the tree (original hierarchy as described in the paper)\n",
    "    root = Node(\"root\")\n",
    "    root.add_children(['animal','vehicle','everyday_object','weapon','scuba_diver'])\n",
    "    root.add_children_to('animal',['non_primate','primate'])\n",
    "    root.add_children_to('non_primate',['African_elephant','giant_panda','lion'])\n",
    "    root.add_children_to('primate',['capuchin','gibbon','orangutan'])\n",
    "    root.add_children_to('vehicle',['ambulance','pickup','sports_car'])\n",
    "    root.add_children_to('everyday_object',['laptop','sandal','wine_bottle'])\n",
    "    root.add_children_to('weapon',['assault_rifle','rifle'])\n",
    "    # flat root\n",
    "    # root.add_children(['scuba_diver','African_elephant','giant_panda','lion','capuchin','gibbon','orangutan','ambulance','pickup','sports_car','laptop','sandal','wine_bottle','assault_rifle','rifle'])\n",
    "root.assign_all_descendents()\n",
    "\n",
    "exp_no = int(os.path.basename(run_path)[:3])\n",
    "\n",
    "if exp_no < 77:\n",
    "    if ('num_protos_per_descendant' in args) and (args.num_protos_per_descendant > 0):\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(args.num_protos_per_descendant)\n",
    "if exp_no == 77:\n",
    "    # update num of protos per node based on num_protos_per_descendant\n",
    "    if args.num_features == 0 and args.num_protos_per_descendant == 0:\n",
    "        raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "    for node in root.nodes_with_children():\n",
    "        node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                                            min_protos=args.num_features)\n",
    "else:\n",
    "    if ('num_protos_per_descendant' in args):\n",
    "        # update num of protos per node based on num_protos_per_descendant\n",
    "        if args.num_features == 0 and args.num_protos_per_descendant == 0:\n",
    "            raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                min_protos=args.num_features,\\\n",
    "                                split_protos=('protopool' in args) and (args.protopool == 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "CUB-190-imgnet-224\n"
     ]
    }
   ],
   "source": [
    "args.batch_size = 1\n",
    "\n",
    "print(args.batch_size)\n",
    "print(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 samples from trainloader\n",
      "Dropping 0 samples from trainloader_normal\n",
      "Dropping 0 samples from trainloader_normal_augment\n",
      "Num classes (k) =  190 ['cub_001_Black_footed_Albatross', 'cub_002_Laysan_Albatross', 'cub_003_Sooty_Albatross', 'cub_004_Groove_billed_Ani', 'cub_005_Crested_Auklet'] etc.\n",
      "1 1\n",
      "Number of prototypes:  768\n",
      "----------Prototypes per descendant: 0----------\n",
      "Assigned 768 protos to node root\n",
      "DataParallel(\n",
      "  (module): PIPNet(\n",
      "    (_net): ConvNeXt(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "          (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "          )\n",
      "          (1): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
      "          )\n",
      "          (2): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
      "          )\n",
      "          (1): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
      "          )\n",
      "          (2): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
      "          )\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(1, 1))\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
      "          )\n",
      "          (1): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
      "          )\n",
      "          (2): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
      "          )\n",
      "          (3): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
      "          )\n",
      "          (4): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
      "          )\n",
      "          (5): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
      "          )\n",
      "          (6): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
      "          )\n",
      "          (7): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
      "          )\n",
      "          (8): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
      "          )\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(1, 1))\n",
      "        )\n",
      "        (7): Sequential(\n",
      "          (0): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
      "          )\n",
      "          (1): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
      "          )\n",
      "          (2): CNBlock(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "              (1): Permute()\n",
      "              (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "              (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (4): GELU(approximate='none')\n",
      "              (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (6): Permute()\n",
      "            )\n",
      "            (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (avgpool): Identity()\n",
      "      (classifier): Identity()\n",
      "    )\n",
      "    (_root_add_on): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (_pool): Sequential(\n",
      "      (0): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "      (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (_root_classification): NonNegLinear()\n",
      "    (_softmax): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    device_ids = [torch.cuda.current_device()]\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    device_ids = []\n",
    "\n",
    "# args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "# args = pickle.load(args_file)\n",
    "\n",
    "# ckpt_file_name = 'net_overspecific_pruned_replaced_thresh=0.5_last'\n",
    "ckpt_file_name = 'net_trained_last'\n",
    "# ckpt_file_name = 'net_trained_10'\n",
    "# ckpt_file_name = 'net_pretrained'\n",
    "epoch = ckpt_file_name.split('_')[-1]\n",
    "\n",
    "ckpt_path = os.path.join(run_path, 'checkpoints', ckpt_file_name)\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "if ckpt_file_name != 'net_trained_last':\n",
    "    print('\\n', (10*'-')+'WARNING: Not using the final trained model'+(10*'-'), '\\n')\n",
    "\n",
    "# Obtain the dataset and dataloaders\n",
    "trainloader, trainloader_pretraining, trainloader_normal, trainloader_normal_augment, projectloader, testloader, test_projectloader, classes = get_dataloaders(args, device)\n",
    "\n",
    "print(args.batch_size, trainloader.batch_size)\n",
    "\n",
    "if len(classes)<=20:\n",
    "    if args.validation_size == 0.:\n",
    "        print(\"Classes: \", testloader.dataset.class_to_idx, flush=True)\n",
    "    else:\n",
    "        print(\"Classes: \", str(classes), flush=True)\n",
    "\n",
    "# Create a convolutional network based on arguments and add 1x1 conv layer\n",
    "feature_net, add_on_layers, pool_layer, classification_layers, num_prototypes = get_network(len(classes), args, root=root)\n",
    "   \n",
    "# Create a PIP-Net\n",
    "net = PIPNet(num_classes=len(classes),\n",
    "                    num_prototypes=num_prototypes,\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "net = net.to(device=device)\n",
    "net = nn.DataParallel(net, device_ids = device_ids)    \n",
    "net.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "print(net.eval())\n",
    "criterion = nn.NLLLoss(reduction='mean').to(device)\n",
    "\n",
    "# Forward one batch through the backbone to get the latent output size\n",
    "# with torch.no_grad():\n",
    "#     xs1, _, _ = next(iter(trainloader))\n",
    "#     xs1 = xs1.to(device)\n",
    "#     proto_features, _, _ = net(xs1)\n",
    "#     wshape = proto_features['root'].shape[-1]\n",
    "#     args.wshape = wshape #needed for calculating image patch size\n",
    "#     print(\"Output shape: \", proto_features['root'].shape, flush=True)\n",
    "    \n",
    "args.wshape = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.7\n",
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4|1.0|50'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.basic_cnext_gaussian_multiplier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images using either NAIVE-HPIPNET or UNIT-SPACE-PROTOPOOL with HEATMAP (CANON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:11, 46.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node root\n",
      "Num protos for 052+053 5\n",
      "Num protos for 004+086 3\n",
      "\t Child: 052+053\n",
      "\t\tProto:3 001:(0.3831) 002:(0.3817) 003:(0.385) 004:(0.3812) 023:(0.3842) 024:(0.3822) 025:(0.3838) 031:(0.382) 032:(0.3851) 033:(0.385) 045:(0.3818) 086:(0.3856) 100:(0.3784) 101:(0.3828) \n",
      "\t\tProto:6 001:(0.1076) 002:(0.0817) 003:(0.0816) 004:(0.081) 023:(0.2333) 024:(0.0759) 025:(0.0824) 031:(0.0776) 032:(0.0732) 033:(0.0779) 045:(0.0744) 086:(0.1286) 100:(0.159) 101:(0.0766) \n",
      "\t\tProto:8 001:(0.3181) 002:(0.3224) 003:(0.2913) 004:(0.3304) 023:(0.3065) 024:(0.2972) 025:(0.3311) 031:(0.3093) 032:(0.3302) 033:(0.3266) 045:(0.3273) 086:(0.3256) 100:(0.3253) 101:(0.3046) \n",
      "\t\tProto:11 001:(0.0913) 002:(0.0881) 003:(0.0825) 004:(0.0801) 023:(0.1031) 024:(0.082) 025:(0.0808) 031:(0.0909) 032:(0.108) 033:(0.0779) 045:(0.0883) 086:(0.0917) 100:(0.084) 101:(0.0827) \n",
      "\t\tSkipping proto 11 of root\n",
      "\t\tProto:17 001:(0.0827) 002:(0.0822) 003:(0.0808) 004:(0.0858) 023:(0.0814) 024:(0.0803) 025:(0.0813) 031:(0.0829) 032:(0.0817) 033:(0.0806) 045:(0.0797) 086:(0.0837) 100:(0.0829) 101:(0.0795) \n",
      "\t\tSkipping proto 17 of root\n",
      "\t Child: 004+086\n",
      "\t\tProto:4 050:(0.0976) 051:(0.1153) 052:(0.2537) 053:(0.1037) \n",
      "\t\tProto:5 050:(0.0783) 051:(0.173) 052:(0.1682) 053:(0.1241) \n",
      "\t\tSkipping proto 5 of root\n",
      "\t\tProto:7 050:(0.083) 051:(0.1) 052:(0.293) 053:(0.0755) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 36.18it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "Num protos for cub_052_Pied_billed_Grebe 4\n",
      "Num protos for 053+050 2\n",
      "\t Child: cub_052_Pied_billed_Grebe\n",
      "\t\tProto:16 050:(0.0747) 051:(0.0751) 053:(0.0746) \n",
      "\t\tSkipping proto 16 of 052+053\n",
      "\t\tProto:19 050:(0.0816) 051:(0.0779) 053:(0.0721) \n",
      "\t\tSkipping proto 19 of 052+053\n",
      "\t\tProto:5 050:(0.0793) 051:(0.0818) 053:(0.0778) \n",
      "\t\tSkipping proto 5 of 052+053\n",
      "\t\tProto:7 050:(0.1321) 051:(0.1626) 053:(0.069) \n",
      "\t\tSkipping proto 7 of 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:12 052:(0.0747) \n",
      "\t\tSkipping proto 12 of 052+053\n",
      "\t\tProto:6 052:(0.0821) \n",
      "\t\tSkipping proto 6 of 052+053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:08, 48.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "Num protos for 004+032 1\n",
      "Num protos for 086+045 3\n",
      "\t Child: 004+032\n",
      "\t\tProto:0 001:(0.0747) 002:(0.0786) 003:(0.0801) 023:(0.0767) 024:(0.0737) 025:(0.0768) 045:(0.0755) 086:(0.0763) 100:(0.0829) 101:(0.0812) \n",
      "\t\tSkipping proto 0 of 004+086\n",
      "\t Child: 086+045\n",
      "\t\tProto:8 004:(0.0703) 031:(0.0724) 032:(0.0745) 033:(0.0728) \n",
      "\t\tSkipping proto 8 of 004+086\n",
      "\t\tProto:18 004:(0.0722) 031:(0.0747) 032:(0.075) 033:(0.0743) \n",
      "\t\tSkipping proto 18 of 004+086\n",
      "\t\tProto:19 004:(0.0686) 031:(0.0726) 032:(0.0713) 033:(0.0707) \n",
      "\t\tSkipping proto 19 of 004+086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 36.26it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "Num protos for cub_053_Western_Grebe 6\n",
      "Num protos for 050+051 3\n",
      "\t Child: cub_053_Western_Grebe\n",
      "\t\tProto:5 050:(0.0982) 051:(0.0974) \n",
      "\t\tSkipping proto 5 of 053+050\n",
      "\t\tProto:9 050:(0.0757) 051:(0.0787) \n",
      "\t\tSkipping proto 9 of 053+050\n",
      "\t\tProto:12 050:(0.0722) 051:(0.071) \n",
      "\t\tSkipping proto 12 of 053+050\n",
      "\t\tProto:14 050:(0.0793) 051:(0.0793) \n",
      "\t\tSkipping proto 14 of 053+050\n",
      "\t\tProto:15 050:(0.0784) 051:(0.0825) \n",
      "\t\tSkipping proto 15 of 053+050\n",
      "\t\tProto:19 050:(0.0755) 051:(0.0763) \n",
      "\t\tSkipping proto 19 of 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:10 053:(0.0738) \n",
      "\t\tSkipping proto 10 of 053+050\n",
      "\t\tProto:18 053:(0.0813) \n",
      "\t\tSkipping proto 18 of 053+050\n",
      "\t\tProto:7 053:(0.0699) \n",
      "\t\tSkipping proto 7 of 053+050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 37.28it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "Num protos for cub_004_Groove_billed_Ani 2\n",
      "Num protos for 032+033 2\n",
      "\t Child: cub_004_Groove_billed_Ani\n",
      "\t\tProto:19 031:(0.0684) 032:(0.0674) 033:(0.0692) \n",
      "\t\tSkipping proto 19 of 004+032\n",
      "\t\tProto:3 031:(0.0764) 032:(0.0747) 033:(0.0757) \n",
      "\t\tSkipping proto 3 of 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:13 004:(0.0695) \n",
      "\t\tSkipping proto 13 of 004+032\n",
      "\t\tProto:5 004:(0.0715) \n",
      "\t\tSkipping proto 5 of 004+032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:06, 47.55it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "Num protos for cub_086_Pacific_Loon 0\n",
      "Num protos for 045+101 1\n",
      "\t Child: 045+101\n",
      "\t\tProto:16 086:(0.0689) \n",
      "\t\tSkipping proto 16 of 086+045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 30.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 050+051\n",
      "Num protos for cub_050_Eared_Grebe 1\n",
      "Num protos for cub_051_Horned_Grebe 3\n",
      "\t Child: cub_051_Horned_Grebe\n",
      "\t\tProto:17 050:(0.177) \n",
      "\t\tSkipping proto 17 of 050+051\n",
      "\t\tProto:12 050:(0.0796) \n",
      "\t\tSkipping proto 12 of 050+051\n",
      "\t\tProto:6 050:(0.2951) \n",
      "\t Child: cub_050_Eared_Grebe\n",
      "\t\tProto:14 051:(0.4636) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 33.42it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "Num protos for cub_032_Mangrove_Cuckoo 6\n",
      "Num protos for 033+031 2\n",
      "\t Child: cub_032_Mangrove_Cuckoo\n",
      "\t\tProto:0 031:(0.0749) 033:(0.074) \n",
      "\t\tSkipping proto 0 of 032+033\n",
      "\t\tProto:6 031:(0.0829) 033:(0.0804) \n",
      "\t\tSkipping proto 6 of 032+033\n",
      "\t\tProto:8 031:(0.0776) 033:(0.0731) \n",
      "\t\tSkipping proto 8 of 032+033\n",
      "\t\tProto:9 031:(0.0875) 033:(0.0875) \n",
      "\t\tSkipping proto 9 of 032+033\n",
      "\t\tProto:11 031:(0.0845) 033:(0.0861) \n",
      "\t\tSkipping proto 11 of 032+033\n",
      "\t\tProto:18 031:(0.0765) 033:(0.0778) \n",
      "\t\tSkipping proto 18 of 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:2 032:(0.0726) \n",
      "\t\tSkipping proto 2 of 032+033\n",
      "\t\tProto:4 032:(0.0818) \n",
      "\t\tSkipping proto 4 of 032+033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:06, 44.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "Num protos for 045+003 1\n",
      "Num protos for 101+023 1\n",
      "\t Child: 045+003\n",
      "\t\tProto:0 023:(0.1126) 024:(0.0746) 025:(0.2177) 100:(0.1794) 101:(0.094) \n",
      "\t Child: 101+023\n",
      "\t\tProto:12 001:(0.0723) 002:(0.0671) 003:(0.0921) 045:(0.0818) \n",
      "\t\tSkipping proto 12 of 045+101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 30.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 033+031\n",
      "Num protos for cub_033_Yellow_billed_Cuckoo 2\n",
      "Num protos for cub_031_Black_billed_Cuckoo 3\n",
      "\t Child: cub_033_Yellow_billed_Cuckoo\n",
      "\t\tProto:4 031:(0.159) \n",
      "\t\tSkipping proto 4 of 033+031\n",
      "\t\tProto:7 031:(0.0859) \n",
      "\t\tSkipping proto 7 of 033+031\n",
      "\t Child: cub_031_Black_billed_Cuckoo\n",
      "\t\tProto:18 033:(0.069) \n",
      "\t\tSkipping proto 18 of 033+031\n",
      "\t\tProto:12 033:(0.0792) \n",
      "\t\tSkipping proto 12 of 033+031\n",
      "\t\tProto:14 033:(0.0725) \n",
      "\t\tSkipping proto 14 of 033+031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 35.36it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "Num protos for cub_045_Northern_Fulmar 16\n",
      "Num protos for 003+002 2\n",
      "\t Child: 003+002\n",
      "\t\tProto:0 045:(0.0681) \n",
      "\t\tSkipping proto 0 of 045+003\n",
      "\t\tProto:5 045:(0.0701) \n",
      "\t\tSkipping proto 5 of 045+003\n",
      "\t Child: cub_045_Northern_Fulmar\n",
      "\t\tProto:1 001:(0.1821) 002:(0.3188) 003:(0.3733) \n",
      "\t\tProto:2 001:(0.0798) 002:(0.0807) 003:(0.0802) \n",
      "\t\tSkipping proto 2 of 045+003\n",
      "\t\tProto:3 001:(0.0927) 002:(0.0909) 003:(0.0961) \n",
      "\t\tSkipping proto 3 of 045+003\n",
      "\t\tProto:4 001:(0.0782) 002:(0.0817) 003:(0.0825) \n",
      "\t\tSkipping proto 4 of 045+003\n",
      "\t\tProto:6 001:(0.0939) 002:(0.0941) 003:(0.0943) \n",
      "\t\tSkipping proto 6 of 045+003\n",
      "\t\tProto:7 001:(0.0968) 002:(0.096) 003:(0.1096) \n",
      "\t\tSkipping proto 7 of 045+003\n",
      "\t\tProto:8 001:(0.0782) 002:(0.0772) 003:(0.076) \n",
      "\t\tSkipping proto 8 of 045+003\n",
      "\t\tProto:9 001:(0.1086) 002:(0.1075) 003:(0.1094) \n",
      "\t\tSkipping proto 9 of 045+003\n",
      "\t\tProto:10 001:(0.089) 002:(0.0929) 003:(0.0877) \n",
      "\t\tSkipping proto 10 of 045+003\n",
      "\t\tProto:11 001:(0.0758) 002:(0.0875) 003:(0.0874) \n",
      "\t\tSkipping proto 11 of 045+003\n",
      "\t\tProto:13 001:(0.0953) 002:(0.0965) 003:(0.098) \n",
      "\t\tSkipping proto 13 of 045+003\n",
      "\t\tProto:14 001:(0.0989) 002:(0.1003) 003:(0.099) \n",
      "\t\tSkipping proto 14 of 045+003\n",
      "\t\tProto:15 001:(0.0908) 002:(0.1365) 003:(0.0836) \n",
      "\t\tSkipping proto 15 of 045+003\n",
      "\t\tProto:16 001:(0.1837) 002:(0.1599) 003:(0.1591) \n",
      "\t\tSkipping proto 16 of 045+003\n",
      "\t\tProto:17 001:(0.0803) 002:(0.083) 003:(0.0808) \n",
      "\t\tSkipping proto 17 of 045+003\n",
      "\t\tProto:18 001:(0.0852) 002:(0.0782) 003:(0.0831) \n",
      "\t\tSkipping proto 18 of 045+003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 41.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "Num protos for 101+100 1\n",
      "Num protos for 023+025 2\n",
      "\t Child: 101+100\n",
      "\t\tProto:1 023:(0.0692) 024:(0.0795) 025:(0.0706) \n",
      "\t\tSkipping proto 1 of 101+023\n",
      "\t Child: 023+025\n",
      "\t\tProto:2 100:(0.0689) 101:(0.0715) \n",
      "\t\tSkipping proto 2 of 101+023\n",
      "\t\tProto:19 100:(0.1862) 101:(0.0695) \n",
      "\t\tSkipping proto 19 of 101+023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 35.03it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "Num protos for cub_003_Sooty_Albatross 15\n",
      "Num protos for 002+001 2\n",
      "\t Child: cub_003_Sooty_Albatross\n",
      "\t\tProto:0 001:(0.0828) 002:(0.0811) \n",
      "\t\tSkipping proto 0 of 003+002\n",
      "\t\tProto:3 001:(0.0836) 002:(0.0785) \n",
      "\t\tSkipping proto 3 of 003+002\n",
      "\t\tProto:4 001:(0.0918) 002:(0.0912) \n",
      "\t\tSkipping proto 4 of 003+002\n",
      "\t\tProto:5 001:(0.0787) 002:(0.0797) \n",
      "\t\tSkipping proto 5 of 003+002\n",
      "\t\tProto:6 001:(0.0918) 002:(0.0893) \n",
      "\t\tSkipping proto 6 of 003+002\n",
      "\t\tProto:7 001:(0.0841) 002:(0.0844) \n",
      "\t\tSkipping proto 7 of 003+002\n",
      "\t\tProto:9 001:(0.0831) 002:(0.0836) \n",
      "\t\tSkipping proto 9 of 003+002\n",
      "\t\tProto:11 001:(0.0767) 002:(0.0777) \n",
      "\t\tSkipping proto 11 of 003+002\n",
      "\t\tProto:12 001:(0.0772) 002:(0.0773) \n",
      "\t\tSkipping proto 12 of 003+002\n",
      "\t\tProto:13 001:(0.2091) 002:(0.2201) \n",
      "\t\tProto:14 001:(0.1577) 002:(0.2323) \n",
      "\t\tProto:15 001:(0.0788) 002:(0.0771) \n",
      "\t\tSkipping proto 15 of 003+002\n",
      "\t\tProto:16 001:(0.1132) 002:(0.1174) \n",
      "\t\tSkipping proto 16 of 003+002\n",
      "\t\tProto:18 001:(0.0941) 002:(0.1071) \n",
      "\t\tSkipping proto 18 of 003+002\n",
      "\t\tProto:19 001:(0.1851) 002:(0.2215) \n",
      "\t Child: 002+001\n",
      "\t\tProto:1 003:(0.0731) \n",
      "\t\tSkipping proto 1 of 003+002\n",
      "\t\tProto:10 003:(0.2577) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 30.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+100\n",
      "Num protos for cub_101_White_Pelican 4\n",
      "Num protos for cub_100_Brown_Pelican 3\n",
      "\t Child: cub_101_White_Pelican\n",
      "\t\tProto:0 100:(0.0753) \n",
      "\t\tSkipping proto 0 of 101+100\n",
      "\t\tProto:9 100:(0.0847) \n",
      "\t\tSkipping proto 9 of 101+100\n",
      "\t\tProto:18 100:(0.2242) \n",
      "\t\tProto:16 100:(0.078) \n",
      "\t\tSkipping proto 16 of 101+100\n",
      "\t Child: cub_100_Brown_Pelican\n",
      "\t\tProto:10 101:(0.0772) \n",
      "\t\tSkipping proto 10 of 101+100\n",
      "\t\tProto:4 101:(0.0772) \n",
      "\t\tSkipping proto 4 of 101+100\n",
      "\t\tProto:14 101:(0.0702) \n",
      "\t\tSkipping proto 14 of 101+100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 33.80it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "Num protos for cub_023_Brandt_Cormorant 16\n",
      "Num protos for 025+024 3\n",
      "\t Child: cub_023_Brandt_Cormorant\n",
      "\t\tProto:0 024:(0.1754) 025:(0.0857) \n",
      "\t\tSkipping proto 0 of 023+025\n",
      "\t\tProto:2 024:(0.084) 025:(0.0871) \n",
      "\t\tSkipping proto 2 of 023+025\n",
      "\t\tProto:4 024:(0.09) 025:(0.0913) \n",
      "\t\tSkipping proto 4 of 023+025\n",
      "\t\tProto:5 024:(0.0796) 025:(0.0863) \n",
      "\t\tSkipping proto 5 of 023+025\n",
      "\t\tProto:6 024:(0.0743) 025:(0.0745) \n",
      "\t\tSkipping proto 6 of 023+025\n",
      "\t\tProto:7 024:(0.0861) 025:(0.0878) \n",
      "\t\tSkipping proto 7 of 023+025\n",
      "\t\tProto:8 024:(0.0749) 025:(0.0736) \n",
      "\t\tSkipping proto 8 of 023+025\n",
      "\t\tProto:9 024:(0.0841) 025:(0.0842) \n",
      "\t\tSkipping proto 9 of 023+025\n",
      "\t\tProto:10 024:(0.0816) 025:(0.082) \n",
      "\t\tSkipping proto 10 of 023+025\n",
      "\t\tProto:11 024:(0.0775) 025:(0.08) \n",
      "\t\tSkipping proto 11 of 023+025\n",
      "\t\tProto:12 024:(0.0774) 025:(0.0801) \n",
      "\t\tSkipping proto 12 of 023+025\n",
      "\t\tProto:13 024:(0.0763) 025:(0.0792) \n",
      "\t\tSkipping proto 13 of 023+025\n",
      "\t\tProto:14 024:(0.0756) 025:(0.0747) \n",
      "\t\tSkipping proto 14 of 023+025\n",
      "\t\tProto:16 024:(0.0829) 025:(0.0856) \n",
      "\t\tSkipping proto 16 of 023+025\n",
      "\t\tProto:17 024:(0.0765) 025:(0.0767) \n",
      "\t\tSkipping proto 17 of 023+025\n",
      "\t\tProto:19 024:(0.1403) 025:(0.4924) \n",
      "\t Child: 025+024\n",
      "\t\tProto:1 023:(0.6573) \n",
      "\t\tProto:18 023:(0.1449) \n",
      "\t\tSkipping proto 18 of 023+025\n",
      "\t\tProto:15 023:(0.2111) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:02<00:00, 28.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 002+001\n",
      "Num protos for cub_002_Laysan_Albatross 1\n",
      "Num protos for cub_001_Black_footed_Albatross 2\n",
      "\t Child: cub_002_Laysan_Albatross\n",
      "\t\tProto:4 001:(0.0697) \n",
      "\t\tSkipping proto 4 of 002+001\n",
      "\t Child: cub_001_Black_footed_Albatross\n",
      "\t\tProto:18 002:(0.073) \n",
      "\t\tSkipping proto 18 of 002+001\n",
      "\t\tProto:15 002:(0.0733) \n",
      "\t\tSkipping proto 15 of 002+001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 30.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 025+024\n",
      "Num protos for cub_025_Pelagic_Cormorant 2\n",
      "Num protos for cub_024_Red_faced_Cormorant 1\n",
      "\t Child: cub_024_Red_faced_Cormorant\n",
      "\t\tProto:2 025:(0.073) \n",
      "\t\tSkipping proto 2 of 025+024\n",
      "\t Child: cub_025_Pelagic_Cormorant\n",
      "\t\tProto:8 024:(0.0744) \n",
      "\t\tSkipping proto 8 of 025+024\n",
      "\t\tProto:12 024:(0.4363) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "def find_top_percentile_bbox(image, percentile=95):\n",
    "    threshold = np.percentile(image.flatten(), percentile)\n",
    "    mask = image >= threshold\n",
    "    coords = np.argwhere(mask)\n",
    "    if coords.size == 0:\n",
    "        return None, None, None, None\n",
    "    h_min, w_min = coords.min(axis=0)\n",
    "    h_max, w_max = coords.max(axis=0)\n",
    "    h_min, h_max, w_min, w_max = map(int, [h_min, h_max, w_min, w_max])\n",
    "    return h_min, h_max, w_min, w_max\n",
    "\n",
    "def find_high_activation_crop(activation_map, percentile=95):\n",
    "    threshold = np.percentile(activation_map, percentile)\n",
    "    mask = np.ones(activation_map.shape)\n",
    "    mask[activation_map < threshold] = 0\n",
    "    lower_y, upper_y, lower_x, upper_x = 0, 0, 0, 0\n",
    "    for i in range(mask.shape[0]):\n",
    "        if np.amax(mask[i]) > 0.5:\n",
    "            lower_y = i\n",
    "            break\n",
    "    for i in reversed(range(mask.shape[0])):\n",
    "        if np.amax(mask[i]) > 0.5:\n",
    "            upper_y = i\n",
    "            break\n",
    "    for j in range(mask.shape[1]):\n",
    "        if np.amax(mask[:,j]) > 0.5:\n",
    "            lower_x = j\n",
    "            break\n",
    "    for j in reversed(range(mask.shape[1])):\n",
    "        if np.amax(mask[:,j]) > 0.5:\n",
    "            upper_x = j\n",
    "            break\n",
    "    return lower_y, upper_y+1, lower_x, upper_x+1\n",
    "\n",
    "def get_upscaled_activation_uninterpolated(latent_activation, image_size):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    min_image_a = image_a.min()\n",
    "    max_image_a = image_a.max()\n",
    "    image_a = (image_a - min_image_a) / (max_image_a - min_image_a)\n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((image_size[-1], \\\n",
    "                                                                                            image_size[-2]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    reshaped_image_a = (reshaped_image_a / 255).astype('float16')\n",
    "    reshaped_image_a = (reshaped_image_a * (max_image_a - min_image_a)) + min_image_a\n",
    "    return reshaped_image_a\n",
    "\n",
    "# added for NUMPY SAVING\n",
    "def get_upscaled_activation_interpolated(latent_activation, image_size):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    min_image_a = image_a.min()\n",
    "    max_image_a = image_a.max()\n",
    "    image_a = (image_a - min_image_a) / (max_image_a - min_image_a)\n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((image_size[-1], \\\n",
    "                                                                                            image_size[-2])))    \n",
    "    reshaped_image_a = (reshaped_image_a / 255).astype('float16')\n",
    "    reshaped_image_a = (reshaped_image_a * (max_image_a - min_image_a)) + min_image_a\n",
    "    return reshaped_image_a\n",
    "\n",
    "def functional_UnitConv2D(in_features, weight, bias, stride = 1, padding=0):\n",
    "    normalized_weight = F.normalize(weight.data, p=2, dim=(1, 2, 3)) # Normalize the kernels to unit vectors\n",
    "    normalized_input = F.normalize(in_features, p=2, dim=1) # Normalize the input to unit vectors\n",
    "    if bias is not None:\n",
    "        normalized_bias = F.normalize(bias.data, p=2, dim=0) # Normalize the kernels to unit vectors\n",
    "    else:\n",
    "        normalized_bias = None\n",
    "    return F.conv2d(normalized_input, normalized_weight, normalized_bias, stride=stride, padding=padding)\n",
    "\n",
    "def findCorrespondingToMax(base, target):\n",
    "    output, indices = F.max_pool2d(base, kernel_size=(26, 26), return_indices=True)# these are logits\n",
    "    tensor_flattened = target.view(target.shape[0], target.shape[1], -1)\n",
    "    indices_flattened = indices.view(target.shape[0], target.shape[1], -1)\n",
    "    corresponding_values_in_target = torch.gather(tensor_flattened, 2, indices_flattened)\n",
    "    corresponding_values_in_target = corresponding_values_in_target.view(target.shape[0],\\\n",
    "                                     target.shape[1], 1, 1)\n",
    "    pooled_target = corresponding_values_in_target\n",
    "    return pooled_target\n",
    "\n",
    "def customForwardWithCSandSoftmax(net, xs,  inference=False):\n",
    "    features = net.module._net(xs) \n",
    "    proto_features = {}\n",
    "    proto_features_cs = {}\n",
    "    proto_features_softmaxed = {}\n",
    "    pooled = {}\n",
    "    pooled_cs = {}\n",
    "    pooled_softmaxed = {}\n",
    "    out = {}\n",
    "    for node in net.module.root.nodes_with_children():\n",
    "        # this may or may not be cosine similarity based on UniConv2D or Conv2d\n",
    "        proto_features[node.name] = getattr(net.module, '_'+node.name+'_add_on')(features)\n",
    "        \n",
    "        #calculating cosine similarity\n",
    "        prototypes = getattr(net.module, '_'+node.name+'_add_on')\n",
    "        proto_features_cs[node.name] = functional_UnitConv2D(features, prototypes.weight, prototypes.bias)\n",
    "\n",
    "        if net.module.args.softmax == 'y':\n",
    "            softmax_tau = 0.2\n",
    "            proto_features[node.name] = proto_features[node.name] / softmax_tau\n",
    "            proto_features_softmaxed[node.name] = net.module._softmax(proto_features[node.name])\n",
    "            proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "        elif net.module.args.gumbel_softmax == 'y':\n",
    "            proto_features_softmaxed[node.name] = net.module._gumbel_softmax(proto_features[node.name])\n",
    "            proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "\n",
    "        if net.module.args.multiply_cs_softmax == 'y':\n",
    "            proto_features[node.name] = proto_features_cs[node.name] * proto_features_softmaxed[node.name]\n",
    "        pooled[node.name] = net.module._pool(proto_features[node.name])\n",
    "        \n",
    "        # this could be softmax or cosine similarity\n",
    "        pooled_cs[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                     target=proto_features_cs[node.name])\n",
    "        \n",
    "        # only if the model uses softmax or gumbel softmax\n",
    "        if (net.module.args.softmax == 'y') or (net.module.args.gumbel_softmax == 'y'):\n",
    "            pooled_softmaxed[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                         target=proto_features_softmaxed[node.name])\n",
    "\n",
    "        if inference:\n",
    "            pooled[node.name] = torch.where(pooled[node.name] < 0.1, 0., pooled[node.name])  #during inference, ignore all prototypes that have 0.1 similarity or lower\n",
    "        out[node.name] = getattr(net.module, '_'+node.name+'_classification')(pooled[node.name]) #shape (bs*2, num_classes) # these are logits\n",
    "    \"\"\"\n",
    "    features -> Raw features generated by the backbone before the prototype layer\n",
    "    proto_features -> Output of prototype layer (UnitConv2D or Conv2D based on the network configuration used), and softmaxed\n",
    "    proto_features_cs -> Cosine similarity between features and prototypes\n",
    "    proto_features_softmaxed -> Same as proto_features\n",
    "    pooled -> max pooled on proto_features\n",
    "    pooled_cs -> cosine values corresponding to max indices in proto_features\n",
    "    \"\"\"\n",
    "    return features, proto_features, proto_features_cs, proto_features_softmaxed, pooled, pooled_cs, pooled_softmaxed, out\n",
    "#     return features, proto_features, pooled, pooled_cs, pooled_softmaxed, out\n",
    "\n",
    "find_non_descendants = True # True, False # param\n",
    "vizloader_name = 'projectloader'\n",
    "bbox_percentile = 97\n",
    "topk = 6 # param, args param\n",
    "save_images = False #True\n",
    "save_activation_as_npy_path = '_'.join(['activation_as_npy', vizloader_name]) # activation_as_npy, added for NUMPY SAVING\n",
    "if find_non_descendants and (save_activation_as_npy_path is not None):\n",
    "    save_activation_as_npy_path = save_activation_as_npy_path + '_non_desc'\n",
    "analysis_mode = True\n",
    "\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "font2 = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "font3 = ImageFont.truetype(\"arial.ttf\", 30)\n",
    "\n",
    "from datetime import datetime\n",
    "txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "txt_file.write('\\n')\n",
    "\n",
    "def write_num_proto_details(proto_mean_activations, node_name, net, threshold, txt_file, args):\n",
    "    \n",
    "    rand_input = torch.randn((1, 3, args.image_size, args.image_size))\n",
    "    with torch.no_grad():\n",
    "        *_, pooled, out = net(rand_input)\n",
    "    num_protos = pooled[node_name].shape[1]\n",
    "    used_protos = len(proto_mean_activations)\n",
    "    non_overspecific = 0\n",
    "    for p in proto_mean_activations:\n",
    "        logstr = '\\t'*2 + f'Proto:{p} '\n",
    "        protos_mean_for_all_leaf_descedants = []\n",
    "        for leaf_descendent in proto_mean_activations[p]:\n",
    "            mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "            protos_mean_for_all_leaf_descedants.append(mean_activation)\n",
    "            \n",
    "        if all([(mean_activation>0.2) for mean_activation in protos_mean_for_all_leaf_descedants]):\n",
    "            non_overspecific += 1\n",
    "            \n",
    "    txt_file.write(f\"Node:{node_name},Total:{num_protos},Used:{used_protos},Good:{non_overspecific},threshold={threshold}\\n\")\n",
    "\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "\n",
    "\n",
    "vizloader_dict = {'trainloader': trainloader,\n",
    "                 'projectloader': projectloader,\n",
    "                 'testloader': testloader,\n",
    "                 'test_projectloader': test_projectloader}\n",
    "vizloader_dict[vizloader_name] = unshuffle_dataloader(vizloader_dict[vizloader_name])\n",
    "\n",
    "\n",
    "if type(vizloader_dict[vizloader_name].dataset) == ImageFolder:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "else:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.dataset.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    \n",
    "#     if node.name == 'root':\n",
    "#         print('-'*25, 'Skipping root node', '-'*25)\n",
    "#         continue\n",
    "\n",
    "#     non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "#     if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "#         continue\n",
    "\n",
    "#     name2label = projectloader.dataset.class_to_idx # param\n",
    "#     label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(vizloader_dict[vizloader_name], node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    \n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        # change\n",
    "#         if not find_non_descendants: \n",
    "#             # do only when finding descendants\n",
    "#             if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "#                 continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = customForwardWithCSandSoftmax(net, xs, inference=False)\n",
    "            features, softmaxes, cosine_similarity, _, pooled, pooled_cs, pooled_softmaxed, out = model_output\n",
    "#             _, softmaxes, pooled, pooled_ip, pooled_softmax, _ = model_output # features, proto_features, pooled, pooled_cs, pooled_softmaxed, out\n",
    "#             model_output = net(xs, inference=False)\n",
    "#             if len(model_output) == 3:\n",
    "#                 softmaxes, pooled, _ = model_output\n",
    "#             elif len(model_output) == 4:\n",
    "#                 _, softmaxes, pooled, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0)\n",
    "            pooled_cs = pooled_cs[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "            cosine_similarity = cosine_similarity[node.name]\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # change\n",
    "#                 if (len(relevant_proto_class_names) == 1):# and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "#                     continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                latent_activation_cs = cosine_similarity[:, p, :, :]\n",
    "                if not find_non_descendants:\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7] if analysis_mode else \\\n",
    "                                                label2name[orig_y.item()][4:]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), pooled_cs[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                                               latent_activation, latent_activation_cs))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), pooled_cs[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                                            latent_activation, latent_activation_cs))\n",
    "                else:\n",
    "                    if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7] if analysis_mode else \\\n",
    "                                                label2name[orig_y.item()][4:]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), pooled_cs[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                                               latent_activation, latent_activation_cs))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), pooled_cs[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                                            latent_activation, latent_activation_cs))\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "                \n",
    "    write_num_proto_details(proto_mean_activations, node.name, net, threshold=0.2, txt_file=txt_file, args=args)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for class_label in range(classification_weights.shape[0]):\n",
    "        child_name = (coarse_label2name[class_label])\n",
    "        print('Num protos for', child_name, torch.nonzero(classification_weights[class_label, :] > 1e-3).shape[0])\n",
    "        \n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            mean_activation_of_every_leaf = []\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "                mean_activation_of_every_leaf.append(mean_activation)\n",
    "            print(logstr)\n",
    "            \n",
    "            # if the mean_activation is less for all leaf descendants skip the node\n",
    "            if all([mean_act < 0.2 for mean_act in mean_activation_of_every_leaf]):\n",
    "                print('\\t'*2 + f'Skipping proto {p} of {node.name}')\n",
    "                continue\n",
    "            \n",
    "            # have this for NON descendants\n",
    "            if len(proto_mean_activations[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images or save_activation_as_npy_path:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 if analysis_mode else 2 # 3x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 2)\n",
    "                    least_activation = min([round(activation, 2) for activation, *_ in proto_mean_activations[p][leaf_descendent]])\n",
    "                    most_activation = max([round(activation, 2) for activation, *_ in proto_mean_activations[p][leaf_descendent]])\n",
    "                    mean_cosine_similarity = round(np.mean([activation_inner_product for _, activation_inner_product, *_ in proto_mean_activations[p][leaf_descendent]]), 2)\n",
    "                    # modified for NUMPY SAVING\n",
    "                    for rank, ele in enumerate(heap):\n",
    "                        \n",
    "                        activation, activation_inner_product, img_to_open, \\\n",
    "                        (h_coor_min, h_coor_max, w_coor_min, w_coor_max), \\\n",
    "                        latent_activation, latent_activation_cs = ele\n",
    "                        \n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "#                         overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "#                         overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "#                         patches.append(overlayed_image)\n",
    "                        \n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        if analysis_mode:\n",
    "                            overlayed_image_pil = Image.fromarray(overlayed_image_np)\n",
    "                            draw = D.Draw(overlayed_image_pil)\n",
    "                            text = f\"{round(activation, 2), round(activation_inner_product, 2)}\"\n",
    "    #                         text_width, text_height = draw.textsize(text, font2)\n",
    "                            bbox = draw.textbbox((0, 0), text, font2)\n",
    "                            text_width = bbox[2] - bbox[0]\n",
    "                            text_height = bbox[3] - bbox[1]\n",
    "                            x, y = 224 - text_width - 5, 5  # 10 pixels padding from right\n",
    "                            draw.text((x, y), text, font=font2, fill=(255, 255, 255))\n",
    "                            overlayed_image_np = np.array(overlayed_image_pil)\n",
    "                        \n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "                        \n",
    "                        if analysis_mode:\n",
    "                            upscaled_similarity = get_upscaled_activation_uninterpolated(latent_activation, image_size=(args.image_size, args.image_size))\n",
    "                            h_min, h_max, w_min, w_max = get_bb_gaussian_threshold(latent_activation, sigma=1.0, \\\n",
    "                                                                                   percentile=bbox_percentile, extend_h=0, extend_w=0)\n",
    "                            bbox_coords = torch.tensor([[w_min, h_min, w_max, h_max]])\n",
    "                            overlayed_image = torchvision.utils.draw_bounding_boxes((overlayed_image * 255).type(torch.uint8), \\\n",
    "                                                                                       bbox_coords, colors='red') / 255\n",
    "                        \n",
    "#                         plt_image = overlayed_bb_image.permute(1, 2, 0)# should be H, W, C with 0 to 1\n",
    "#                         plt.imshow(plt_image)\n",
    "#                         plt.show()\n",
    "#                         pdb.set_trace()\n",
    "                        patches.append(overlayed_image)\n",
    "                        # added for NUMPY SAVING\n",
    "                        if save_activation_as_npy_path:\n",
    "                            upscaled_similarity_interpolated = get_upscaled_activation_interpolated(latent_activation,\n",
    "                                                                                       image_size=(args.image_size, args.image_size))\n",
    "                            latent_activation_npy = latent_activation.squeeze().cpu().numpy()\n",
    "                            latent_activation_cs_npy = latent_activation_cs.squeeze().cpu().numpy()\n",
    "                            data = {'node_name': node.name,\n",
    "                                    'proto_num': p,\n",
    "                                    'child_name': child_classname,\n",
    "                                    'leaf_desc': leaf_descendent,\n",
    "                                     'rank': rank,\n",
    "                                     'img_path': img_to_open,\n",
    "                                     'img_filename': ntpath.basename(img_to_open),\n",
    "                                     'activation': latent_activation_npy,\n",
    "                                     'activation_cs': latent_activation_cs_npy,\n",
    "                                     'max_activation': activation,\n",
    "                                     'model_type': 'HPIPNET'}\n",
    "                            filename = str(rank)+ '-' + ntpath.basename(img_to_open) + '.npy'\n",
    "                            save_path = os.path.join(run_path, save_activation_as_npy_path, \\\n",
    "                                                     node.name, str(p), leaf_descendent,\n",
    "                                                     filename)\n",
    "                            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                            np.save(save_path, data, allow_pickle=True)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}' if analysis_mode else \\\n",
    "                                f'{leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((200, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font3)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "                \n",
    "                # weird thing padding should be zero for non descendants else it raises some error # change\n",
    "                if find_non_descendants or (len(patches) == topk): # (len(patches) == topk) means there is only one leaf descendant\n",
    "                    padding = 0\n",
    "                else:\n",
    "                    padding = 1\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=padding)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=padding)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid_right_descriptions, grid], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}' if analysis_mode else \\\n",
    "                            f'Parent node:{node.name}, Child node:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], 75), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((500, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([txttensor, grid], dim=1)\n",
    "                \n",
    "                if save_images:\n",
    "                    prefix = 'non_' if find_non_descendants else ''\n",
    "                    os.makedirs(os.path.join(run_path, prefix + f'descendent_specific_topk_heatmap_{vizloader_name}_{bbox_percentile}_ep={epoch}_analysis={analysis_mode}', node.name), exist_ok=True)\n",
    "                    torchvision.utils.save_image(grid, os.path.join(run_path, prefix + f'descendent_specific_topk_heatmap_{vizloader_name}_{bbox_percentile}_ep={epoch}_analysis={analysis_mode}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "txt_file.write('\\n')\n",
    "txt_file.close()\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "\tcub_052_Pied_billed_Grebe\n",
      "\tcub_053_Western_Grebe\n",
      "\tcub_050_Eared_Grebe\n",
      "\tcub_051_Horned_Grebe\n",
      "\tcub_004_Groove_billed_Ani\n",
      "\tcub_032_Mangrove_Cuckoo\n",
      "\tcub_033_Yellow_billed_Cuckoo\n",
      "\tcub_031_Black_billed_Cuckoo\n",
      "\tcub_086_Pacific_Loon\n",
      "\tcub_045_Northern_Fulmar\n",
      "\tcub_003_Sooty_Albatross\n",
      "\tcub_002_Laysan_Albatross\n",
      "\tcub_001_Black_footed_Albatross\n",
      "\tcub_101_White_Pelican\n",
      "\tcub_100_Brown_Pelican\n",
      "\tcub_023_Brandt_Cormorant\n",
      "\tcub_025_Pelagic_Cormorant\n",
      "\tcub_024_Red_faced_Cormorant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 844\n",
      "    Root location: /projects/ml4science/harishbabu/data/CUB_29_pipnet_224/dataset_segmented_imgnet_pt/test_crop\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "vizloader_name = 'testloader'\n",
    "vizloader_dict[vizloader_name] = unshuffle_dataloader(vizloader_dict[vizloader_name])\n",
    "print(vizloader_dict[vizloader_name].dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images using  NAIVE-HPIPNET with HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 5695/5695 [14:28<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node root\n",
      "\t Child: cub_104_American_Pipit, cub_093_Clark_Nutcracker\n",
      "\t\tProto:16 093:(0.9982) 104:(0.9913) \n",
      "\t Child: cub_142_Black_Tern, cub_025_Pelagic_Cormorant\n",
      "\t\tProto:17 025:(0.9915) 142:(1.0) \n",
      "\t Child: cub_197_Marsh_Wren\n",
      "\t\tProto:18 197:(0.9999) \n",
      "\t\tProto:551 197:(0.9973) \n",
      "\t Child: cub_037_Acadian_Flycatcher, cub_102_Western_Wood_Pewee, cub_041_Scissor_tailed_Flycatcher\n",
      "\t\tProto:19 037:(0.9942) 041:(1.0) 102:(0.9971) \n",
      "\t Child: cub_114_Black_throated_Sparrow\n",
      "\t\tProto:152 114:(1.0) \n",
      "\t\tProto:22 114:(1.0) \n",
      "\t Child: cub_018_Spotted_Catbird, cub_083_White_breasted_Kingfisher, cub_067_Anna_Hummingbird, cub_070_Green_Violetear\n",
      "\t\tProto:24 018:(0.9998) 067:(0.1902) 070:(1.0) 083:(1.0) \n",
      "\t Child: cub_009_Brewer_Blackbird, cub_162_Canada_Warbler, cub_057_Rose_breasted_Grosbeak, cub_151_Black_capped_Vireo, cub_156_White_eyed_Vireo, cub_152_Blue_headed_Vireo, cub_006_Least_Auklet, cub_007_Parakeet_Auklet, cub_005_Crested_Auklet, cub_008_Rhinoceros_Auklet, cub_058_Pigeon_Guillemot, cub_089_Hooded_Merganser\n",
      "\t\tProto:26 005:(1.0) 006:(1.0) 007:(1.0) 008:(1.0) 009:(0.0004) 057:(1.0) 058:(1.0) 089:(1.0) 151:(0.7178) 152:(1.0) 156:(1.0) 162:(1.0) \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 36] File name too long: '/home/harishbabu/projects/PIPNet/runs/113-NaiveHPIPNetFlatStructureNoAlNoTanh_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD_no-AL_no-TANH/descendent_specific_topk_heatmap_ep=last/root/cub_009_Brewer_Blackbird, cub_162_Canada_Warbler, cub_057_Rose_breasted_Grosbeak, cub_151_Black_capped_Vireo, cub_156_White_eyed_Vireo, cub_152_Blue_headed_Vireo, cub_006_Least_Auklet, cub_007_Parakeet_Auklet, cub_005_Crested_Auklet, cub_008_Rhinoceros_Auklet, cub_058_Pigeon_Guillemot, cub_089_Hooded_Merganser-p26.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 285\u001b[0m\n\u001b[1;32m    283\u001b[0m                     prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnon_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m find_non_descendants \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    284\u001b[0m                     os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_path, prefix\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescendent_specific_topk_heatmap_ep=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, node\u001b[38;5;241m.\u001b[39mname), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 285\u001b[0m                     \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdescendent_specific_topk_heatmap_ep=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchild_classname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-p\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mp\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m txt_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    288\u001b[0m txt_file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.conda/envs/hpnet3/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/utils.py:150\u001b[0m, in \u001b[0;36msave_image\u001b[0;34m(tensor, fp, format, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m ndarr \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mmul(\u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39madd_(\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    149\u001b[0m im \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(ndarr)\n\u001b[0;32m--> 150\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/PIL/Image.py:2435\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2433\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2434\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2435\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2438\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 36] File name too long: '/home/harishbabu/projects/PIPNet/runs/113-NaiveHPIPNetFlatStructureNoAlNoTanh_CUB-190-imgnet-224_with-equalize-aug_cnext26_img=224_nprotos=768_no-KO_no-OOD_no-AL_no-TANH/descendent_specific_topk_heatmap_ep=last/root/cub_009_Brewer_Blackbird, cub_162_Canada_Warbler, cub_057_Rose_breasted_Grosbeak, cub_151_Black_capped_Vireo, cub_156_White_eyed_Vireo, cub_152_Blue_headed_Vireo, cub_006_Least_Auklet, cub_007_Parakeet_Auklet, cub_005_Crested_Auklet, cub_008_Rhinoceros_Auklet, cub_058_Pigeon_Guillemot, cub_089_Hooded_Merganser-p26.png'"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "txt_file.write('\\n')\n",
    "\n",
    "vizloader_name = 'testloader' # projectloader\n",
    "find_non_descendants = False # True, False # param\n",
    "topk = 6\n",
    "save_images = True # True, False\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "save_activation_as_npy_path = 'activation_as_npy'\n",
    "save_activation_as_npy_path = '_'.join(['activation_as_npy', vizloader_name])  # activation_as_npy, added for NUMPY SAVING\n",
    "\n",
    "from datetime import datetime\n",
    "txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "txt_file.write('\\n')\n",
    "\n",
    "def write_num_proto_details(proto_mean_activations, node_name, net, threshold, txt_file, args):\n",
    "    \n",
    "    rand_input = torch.randn((1, 3, args.image_size, args.image_size))\n",
    "    with torch.no_grad():\n",
    "        *_, pooled, out = net(rand_input)\n",
    "    num_protos = pooled[node_name].shape[1]\n",
    "    used_protos = len(proto_mean_activations)\n",
    "    non_overspecific = 0\n",
    "    for p in proto_mean_activations:\n",
    "        logstr = '\\t'*2 + f'Proto:{p} '\n",
    "        protos_mean_for_all_leaf_descedants = []\n",
    "        for leaf_descendent in proto_mean_activations[p]:\n",
    "            mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "            protos_mean_for_all_leaf_descedants.append(mean_activation)\n",
    "            \n",
    "        if all([(mean_activation>0.2) for mean_activation in protos_mean_for_all_leaf_descedants]):\n",
    "            non_overspecific += 1\n",
    "            \n",
    "    txt_file.write(f\"Node:{node_name},Total:{num_protos},Used:{used_protos},Good:{non_overspecific},threshold={threshold}\\n\")\n",
    "\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "\n",
    "vizloader_dict = {'trainloader': trainloader,\n",
    "                 'projectloader': projectloader,\n",
    "                 'testloader': testloader,\n",
    "                 'test_projectloader': test_projectloader}\n",
    "vizloader_dict[vizloader_name] = unshuffle_dataloader(vizloader_dict[vizloader_name])\n",
    "\n",
    "\n",
    "if type(vizloader_dict[vizloader_name].dataset) == ImageFolder:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "else:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.dataset.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "#     non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "#     if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "#         continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "#         if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "#             continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = net(xs, inference=False)\n",
    "            if len(model_output) == 3:\n",
    "                softmaxes, pooled, _ = model_output\n",
    "            elif len(model_output) == 4:\n",
    "                _, softmaxes, pooled, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "#                 if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "#                     continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                \n",
    "                if not find_non_descendants:\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                else:\n",
    "                    if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    write_num_proto_details(proto_mean_activations, node.name, net, threshold=0.2, txt_file=txt_file, args=args)\n",
    "\n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            mean_activation_of_every_leaf = []\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "                mean_activation_of_every_leaf.append(mean_activation)\n",
    "            print(logstr)\n",
    "            \n",
    "            # if the mean_activation is less for all leaf descendants skip the node\n",
    "            if all([mean_act < 0.2 for mean_act in mean_activation_of_every_leaf]):\n",
    "                print(f'Skipping proto {p} of {node.name}')\n",
    "                continue\n",
    "            \n",
    "            # have this for NON descendants\n",
    "            if len(proto_mean_activations[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images or save_activation_as_npy_path:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 # 3x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    for rank, ele in enumerate(heap):\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "                        patches.append(overlayed_image)\n",
    "                        \n",
    "                        # added for NUMPY SAVING\n",
    "                        \n",
    "                        if save_activation_as_npy_path:\n",
    "#                             upscaled_similarity_interpolated = get_upscaled_activation_interpolated(latent_activation,\n",
    "#                                                                                        image_size=(args.image_size, args.image_size))\n",
    "                            latent_activation_npy = latent_activation.squeeze().cpu().numpy()\n",
    "                            data = {'node_name': node.name,\n",
    "                                    'proto_num': p,\n",
    "                                    'child_name': child_classname,\n",
    "                                    'leaf_desc': leaf_descendent,\n",
    "                                     'rank': rank,\n",
    "                                     'img_path': img_to_open,\n",
    "                                     'img_filename': ntpath.basename(img_to_open),\n",
    "                                     'activation': latent_activation_npy,\n",
    "                                     'max_activation': activation,\n",
    "                                     'model_type': 'NAIVE-HPIPNET'}\n",
    "                            filename = str(rank)+ '-' + ntpath.basename(img_to_open) + '.npy'\n",
    "                            save_path = os.path.join(run_path, save_activation_as_npy_path, \\\n",
    "                                                     node.name, str(p), leaf_descendent,\n",
    "                                                     filename)\n",
    "                            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                            np.save(save_path, data, allow_pickle=True)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "                    \n",
    "                # weird thing padding should be zero for non descendants else it raises some error # change\n",
    "                if find_non_descendants or (len(patches) == topk): # (len(patches) == topk) means there is only one leaf descendant\n",
    "                    padding = 0\n",
    "                else:\n",
    "                    padding = 1\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=padding)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=padding)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "                \n",
    "                if save_images:\n",
    "                    prefix = 'non_' if find_non_descendants else ''\n",
    "                    os.makedirs(os.path.join(run_path, prefix+f'descendent_specific_topk_heatmap_ep={epoch}', node.name), exist_ok=True)\n",
    "                    torchvision.utils.save_image(grid, os.path.join(run_path, prefix+f'descendent_specific_topk_heatmap_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "txt_file.write('\\n')\n",
    "txt_file.close()\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(torch.tensor(2 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cos(torch.pi)\n",
    "torch.cos(torch.tensor(2 * torch.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9995)\n",
      "tensor(0.9995)\n",
      "tensor(0.9995)\n",
      "tensor(0.9995)\n",
      "tensor(0.9995)\n",
      "tensor(0.9995)\n",
      "tensor(0.9995)\n",
      "tensor(0.9995)\n",
      "tensor(0.9995)\n",
      "tensor(0.9995)\n",
      "tensor(0.9995)\n",
      "tensor(0.9996)\n",
      "tensor(0.9996)\n",
      "tensor(0.9996)\n",
      "tensor(0.9996)\n",
      "tensor(0.9996)\n",
      "tensor(0.9996)\n",
      "tensor(0.9996)\n",
      "tensor(0.9996)\n",
      "tensor(0.9997)\n",
      "tensor(0.9997)\n",
      "tensor(0.9997)\n",
      "tensor(0.9997)\n",
      "tensor(0.9997)\n",
      "tensor(0.9997)\n",
      "tensor(0.9998)\n",
      "tensor(0.9998)\n",
      "tensor(0.9998)\n",
      "tensor(0.9998)\n",
      "tensor(0.9998)\n",
      "tensor(0.9998)\n",
      "tensor(0.9998)\n",
      "tensor(0.9999)\n",
      "tensor(0.9999)\n",
      "tensor(0.9999)\n",
      "tensor(0.9999)\n",
      "tensor(0.9999)\n",
      "tensor(0.9999)\n",
      "tensor(0.9999)\n",
      "tensor(0.9999)\n",
      "tensor(1.0000)\n",
      "tensor(1.0000)\n",
      "tensor(1.0000)\n",
      "tensor(1.0000)\n",
      "tensor(1.0000)\n",
      "tensor(1.0000)\n",
      "tensor(1.0000)\n",
      "tensor(1.0000)\n",
      "tensor(1.0000)\n",
      "tensor(1.0000)\n",
      "tensor(1.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "byol_tau_base = 0.9995\n",
    "current_step = 50\n",
    "max_training_steps = 50\n",
    "\n",
    "byol_tau_list = []\n",
    "for current_step in range(max_training_steps+1):\n",
    "    byol_tau = 1 - (((1 - byol_tau_base) * (torch.cos(torch.tensor((torch.pi * current_step)/max_training_steps)) + 1)) / 2)\n",
    "    print(byol_tau)\n",
    "    byol_tau_list.append(byol_tau)\n",
    "    \n",
    "plt.plot(byol_tau_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
