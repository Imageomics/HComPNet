{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e062bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/home/harishbabu/.conda/envs/hpnet1/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from pipnet.pipnet import PIPNet, get_network\n",
    "from util.data import get_dataloaders\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "from util.vis_pipnet import visualize, visualize_topk\n",
    "from util.func import get_patch_size\n",
    "from util.eval_cub_csv import get_topk_cub\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "from pipnet.train import test_pipnet, train_pipnet\n",
    "from omegaconf import OmegaConf\n",
    "from util.phylo_utils import construct_phylo_tree, construct_discretized_phylo_tree\n",
    "from util.args import get_args, save_args, get_optimizer_nn\n",
    "import wandb\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "import pdb\n",
    "import math\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a352f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/004-CUB-27-imgnet_cnext26_img=224_nprotos=200'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/005-CUB-27-imgnet_cnext26_img=224_nprotos=50'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/007-CUB-27-imgnet_cnext26_img=224_nprotos=50'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/009-CUB-27-imgnet_cnext26_img=224_nprotos=50'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/010-CUB-27-imgnet_OOD_cnext26_img=224_nprotos=20'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/012-CUB-27-imgnet_OOD_cnext26_img=224_nprotos=20'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/013-CUB-27-imgnet_OOD_cnext26_img=224_nprotos=20'\n",
    "run_path = '/home/harishbabu/projects/PIPNet/runs/018-CUB-27-imgnet_cnext26_img=224_nprotos=20'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    device_ids = [torch.cuda.current_device()]\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    device_ids = []\n",
    "\n",
    "args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "args = pickle.load(args_file)\n",
    "args.OOD_dataset = 'CUB-163-OOD-imgnet-224'\n",
    "\n",
    "ckpt_epoch = 10\n",
    "\n",
    "ckpt_path = os.path.join(run_path, 'checkpoints', 'net_trained_'+str(ckpt_epoch))\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d485a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- No discretization -------------------------\n",
      "root\n",
      "\t016+181\n",
      "\t\tcub_016_Painted_Bunting\n",
      "\t\t181+097\n",
      "\t\t\t181+161\n",
      "\t\t\t\tcub_181_Worm_eating_Warbler\n",
      "\t\t\t\t161+165\n",
      "\t\t\t\t\tcub_161_Blue_winged_Warbler\n",
      "\t\t\t\t\tcub_165_Chestnut_sided_Warbler\n",
      "\t\t\t097+122\n",
      "\t\t\t\t097+011\n",
      "\t\t\t\t\tcub_097_Orchard_Oriole\n",
      "\t\t\t\t\tcub_011_Rusty_Blackbird\n",
      "\t\t\t\t122+113\n",
      "\t\t\t\t\tcub_122_Harris_Sparrow\n",
      "\t\t\t\t\tcub_113_Baird_Sparrow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args.phylo_config = './configs/cub08_phylogeny.yaml'\n",
    "if args.phylo_config:\n",
    "    phylo_config = OmegaConf.load(args.phylo_config)\n",
    "\n",
    "if args.phylo_config:\n",
    "    # construct the phylo tree\n",
    "    if phylo_config.phyloDistances_string == 'None':\n",
    "        root = construct_phylo_tree(phylo_config.phylogeny_path)\n",
    "        print('-'*25 + ' No discretization ' + '-'*25)\n",
    "    else:\n",
    "        root = construct_discretized_phylo_tree(phylo_config.phylogeny_path, phylo_config.phyloDistances_string)\n",
    "        print('-'*25 + ' Discretized ' + '-'*25)\n",
    "else:\n",
    "    # construct the tree (original hierarchy as described in the paper)\n",
    "    root = Node(\"root\")\n",
    "    root.add_children(['animal','vehicle','everyday_object','weapon','scuba_diver'])\n",
    "    root.add_children_to('animal',['non_primate','primate'])\n",
    "    root.add_children_to('non_primate',['African_elephant','giant_panda','lion'])\n",
    "    root.add_children_to('primate',['capuchin','gibbon','orangutan'])\n",
    "    root.add_children_to('vehicle',['ambulance','pickup','sports_car'])\n",
    "    root.add_children_to('everyday_object',['laptop','sandal','wine_bottle'])\n",
    "    root.add_children_to('weapon',['assault_rifle','rifle'])\n",
    "    # flat root\n",
    "    # root.add_children(['scuba_diver','African_elephant','giant_panda','lion','capuchin','gibbon','orangutan','ambulance','pickup','sports_car','laptop','sandal','wine_bottle','assault_rifle','rifle'])\n",
    "root.assign_all_descendents()\n",
    "\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c03e618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes (k) =  27 ['cub_001_Black_footed_Albatross', 'cub_011_Rusty_Blackbird', 'cub_016_Painted_Bunting', 'cub_019_Gray_Catbird', 'cub_030_Fish_Crow'] etc.\n",
      "Dropping 21 samples from trainloader_pretraining\n",
      "Num classes (k) =  163 ['cub_002_Laysan_Albatross', 'cub_003_Sooty_Albatross', 'cub_004_Groove_billed_Ani', 'cub_005_Crested_Auklet', 'cub_006_Least_Auklet'] etc.\n"
     ]
    }
   ],
   "source": [
    "trainloader, trainloader_pretraining, trainloader_normal, trainloader_normal_augment, projectloader, testloader, test_projectloader, classes = get_dataloaders(args, device, OOD=False)\n",
    "trainloader_OOD, trainloader_pretraining_OOD, trainloader_normal_OOD, trainloader_normal_augment_OOD, projectloader_OOD, testloader_OOD, test_projectloader_OOD, _ = get_dataloaders(args, device, OOD=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62775d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prototypes:  20\n"
     ]
    }
   ],
   "source": [
    "# Create a convolutional network based on arguments and add 1x1 conv layer\n",
    "feature_net, add_on_layers, pool_layer, classification_layers, num_prototypes = get_network(len(classes), args, root=root)\n",
    "   \n",
    "# Create a PIP-Net\n",
    "net = PIPNet(num_classes=len(classes),\n",
    "                    num_prototypes=num_prototypes,\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "net = net.to(device=device)\n",
    "net = nn.DataParallel(net, device_ids = device_ids)    \n",
    "net.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "criterion = nn.NLLLoss(reduction='mean').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "125ad6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([64, 20, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        xs1, _, _ = next(iter(trainloader))\n",
    "        xs1 = xs1.to(device)\n",
    "        proto_features, _, _ = net(xs1)\n",
    "        wshape = proto_features['root'].shape[-1]\n",
    "        args.wshape = wshape #needed for calculating image patch size\n",
    "        print(\"Output shape: \", proto_features['root'].shape, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1acc4ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_001+033_classification weights:  tensor([1.2527, 0.5492, 0.6577, 0.5446, 0.6620, 1.0300, 0.8236, 0.8055, 0.8551,\n",
      "        0.7457, 0.9521, 0.8871, 0.5308, 0.6835, 1.0988, 0.9804, 0.5986, 2.0822,\n",
      "        0.2149, 0.8755, 1.7046, 0.6834, 1.1044, 0.7179, 0.4011, 2.3770, 0.7406,\n",
      "        0.7218, 0.7058, 0.8697, 0.6373, 0.6767, 0.9792, 0.8126, 0.2888, 0.7840,\n",
      "        0.8037], device='cuda:0') torch.Size([37])\n",
      "_001+052_classification weights:  tensor([0.9740, 0.5849, 1.0898, 2.3066, 1.1345, 1.0837, 1.2009, 0.1623, 0.9263,\n",
      "        1.4857, 0.7822, 0.8057, 1.0692, 0.5540, 0.9848, 1.2713, 0.9706, 0.7821,\n",
      "        1.0589, 0.5269, 1.7319, 1.0501, 0.5331, 0.6632, 0.5687, 0.8421, 1.5807,\n",
      "        0.4428, 0.1836, 0.7065, 0.9953, 0.5378, 1.1638, 0.4059, 0.3501, 0.7237,\n",
      "        0.7092, 0.6144], device='cuda:0') torch.Size([38])\n",
      "_011+097_classification weights:  tensor([1.0461, 0.8292, 0.6568, 0.1928, 1.4023, 0.7130, 0.6120, 0.5622, 0.5374,\n",
      "        0.4139, 0.8673, 0.8223, 0.4411, 0.6061, 1.2021, 0.8795, 0.8331, 1.6902,\n",
      "        2.3013, 0.6795, 0.9811, 0.9448, 1.5628, 0.1903, 0.8434, 0.8314, 1.0644,\n",
      "        1.1155, 1.1115, 0.6383, 0.6105, 1.1007, 0.6065, 0.4924, 0.8296, 0.9400,\n",
      "        1.8075, 0.0447], device='cuda:0') torch.Size([38])\n",
      "_030+156_classification weights:  tensor([0.6708, 1.3900, 0.9685, 0.2996, 0.5297, 0.6385, 0.6094, 0.3432, 0.5325,\n",
      "        0.4945, 0.5557, 0.2497, 0.5590, 0.6517, 0.5749, 1.7242, 0.4268, 0.0927,\n",
      "        2.5802, 0.1386, 0.2022, 0.0680, 2.9404, 0.3141, 0.2110, 1.0822, 2.8216,\n",
      "        0.0259, 2.4097], device='cuda:0') torch.Size([29])\n",
      "_037+077_classification weights:  tensor([0.7106, 0.5534, 0.8043, 0.4858, 0.5602, 0.6897, 0.4388, 0.5744, 0.8770,\n",
      "        0.2883, 1.8141, 1.1973, 0.7195, 0.9911, 0.5229, 2.8934, 0.4840, 0.9362,\n",
      "        0.6542, 0.7538, 0.7950, 2.2046, 0.6123, 1.0807, 0.7782, 0.6095, 1.0897,\n",
      "        0.8861, 0.8025, 1.4212, 0.2735, 0.7862, 0.3175, 0.7960, 1.0330, 0.7796,\n",
      "        0.6972], device='cuda:0') torch.Size([37])\n",
      "_060+071_classification weights:  tensor([1.3098, 0.6551, 1.0506, 0.7872, 1.1126, 0.7893, 1.5608, 1.1974, 1.0722,\n",
      "        0.7913, 0.8911, 0.7836, 0.9021, 1.2276, 1.2937, 1.2901, 0.6448, 0.8021,\n",
      "        2.4405, 0.9646, 0.5301, 1.0450, 0.5492, 0.8197, 0.5421, 1.0612, 0.5010,\n",
      "        0.4991, 0.5905, 1.1796, 0.7411, 1.0072, 0.7406, 0.2088, 0.5286, 0.2799,\n",
      "        0.9401, 0.9950, 0.8114], device='cuda:0') torch.Size([39])\n",
      "_060+143_classification weights:  tensor([0.5749, 0.3163, 0.8634, 0.7789, 0.4627, 0.8081, 0.5865, 0.8838, 0.4880,\n",
      "        0.5885, 0.4439, 2.1296, 1.0415, 1.5247, 1.3630, 0.9957, 0.6228, 0.1684,\n",
      "        0.6451, 1.5650, 0.8772, 1.0755, 0.7221, 1.1594, 1.1699, 0.8178, 1.0203,\n",
      "        0.7946, 1.2028, 1.1138, 1.0310, 0.3681, 0.1559, 0.2395, 0.7238, 1.2480,\n",
      "        1.4322, 1.2848, 0.1505], device='cuda:0') torch.Size([39])\n",
      "_113+001+068_classification weights:  tensor([1.1037, 1.3107, 1.0415, 3.0896, 1.6234, 1.3495, 1.1504, 1.0987, 1.0852,\n",
      "        1.4461, 1.2136, 1.7609, 1.2187, 1.1794, 1.1487, 1.3870, 1.1440, 0.9329,\n",
      "        1.1911, 0.7725, 0.2730, 0.7342, 0.5201, 3.0975, 0.8785, 0.2910, 0.6049,\n",
      "        0.7116, 0.3173, 0.4185, 0.2581, 0.4627, 0.5972, 0.4909, 0.5074, 0.4692,\n",
      "        0.1262, 0.3034, 0.4671, 0.1420, 0.5496, 0.2581, 0.4217, 0.2131, 0.3035,\n",
      "        0.5029, 0.5580, 0.3987], device='cuda:0') torch.Size([48])\n",
      "_113+011_classification weights:  tensor([0.8941, 0.6597, 0.8776, 0.8597, 0.9045, 0.4617, 1.1731, 1.2706, 1.1817,\n",
      "        1.2313, 0.7514, 0.6601, 0.9250, 1.2453, 0.0232, 0.4605, 0.7111, 1.3203,\n",
      "        0.4339, 0.7220, 0.7830, 0.6753, 0.6565, 1.2299, 0.4535, 0.2257, 0.5846,\n",
      "        0.4747, 0.8381, 0.6659, 1.7316, 0.5549, 0.1139, 1.8133, 1.3261, 1.1263,\n",
      "        1.8338, 0.1607], device='cuda:0') torch.Size([38])\n",
      "_113+016_classification weights:  tensor([1.1533, 1.5747, 1.1524, 1.2486, 1.1364, 1.2790, 1.2255, 1.3265, 1.6664,\n",
      "        1.3809, 1.3192, 1.2601, 1.2252, 1.2934, 0.9947, 1.2920, 1.0429, 1.3229,\n",
      "        1.8844, 0.5396, 1.9255, 0.3958, 0.2544, 0.4228, 0.1453, 0.3093, 0.4295,\n",
      "        0.2507, 0.5594, 0.2547, 0.2648, 0.5164, 0.5086, 0.5507, 0.4721, 0.6424,\n",
      "        0.5205], device='cuda:0') torch.Size([37])\n",
      "_113+030_classification weights:  tensor([1.0378, 1.2643, 0.8669, 1.6716, 1.3849, 1.4314, 1.0826, 1.0265, 1.4195,\n",
      "        1.4936, 1.4138, 1.2973, 1.3341, 1.1600, 1.2257, 2.1880, 1.4208, 1.6916,\n",
      "        1.2028, 0.8418, 0.8896, 0.4944, 1.0369, 0.5009, 0.4295, 0.4080, 0.6632,\n",
      "        0.4756, 0.2635, 0.4035, 0.1224, 0.4914, 0.2256, 0.4860, 0.4179, 0.4920,\n",
      "        0.3245, 0.6499, 0.6380], device='cuda:0') torch.Size([39])\n",
      "_113+034_classification weights:  tensor([0.3291, 1.3928, 0.3215, 0.8288, 1.2061, 0.8388, 1.6994, 0.5690, 1.4288,\n",
      "        0.7543, 0.3908, 1.1583, 1.5372, 1.0345, 1.7363, 1.0950, 3.2445, 1.7435,\n",
      "        1.0830, 0.2655, 0.3437, 0.2857, 0.0452, 0.2349, 2.3524, 0.5575, 2.3030,\n",
      "        0.4465, 0.4101], device='cuda:0') torch.Size([29])\n",
      "_113+037_classification weights:  tensor([1.0991e+00, 1.1814e+00, 3.6329e-01, 1.3277e+00, 2.0477e+00, 1.4270e+00,\n",
      "        1.4324e+00, 1.4547e+00, 1.5969e+00, 5.1823e-01, 1.4607e+00, 1.1918e+00,\n",
      "        1.3414e+00, 1.3882e+00, 8.6289e-01, 8.1775e-01, 1.5414e+00, 9.1688e-01,\n",
      "        1.4326e+00, 1.4198e+00, 7.3559e-01, 4.2908e-01, 1.7796e+00, 3.5299e-01,\n",
      "        2.7448e-01, 2.6368e-01, 3.8574e-01, 3.1580e-01, 1.0471e+00, 1.5148e-01,\n",
      "        4.8296e-01, 4.0593e-01, 2.4027e-01, 4.8460e-01, 1.0556e+00, 1.5994e-03,\n",
      "        3.9887e-01, 9.3105e-02, 2.4639e-01], device='cuda:0') torch.Size([39])\n",
      "_113+060_classification weights:  tensor([1.0775, 1.6351, 1.2652, 2.4204, 0.3122, 1.1298, 1.4180, 1.0426, 1.1349,\n",
      "        1.2120, 0.9395, 0.8564, 0.3925, 1.1299, 2.9033, 1.2233, 3.0973, 1.2149,\n",
      "        0.5712, 1.3486, 0.4717, 0.3908, 0.8941, 0.6849, 0.3647, 0.5827, 0.4972,\n",
      "        0.5918, 0.7404, 0.8330, 0.1341, 0.4533, 0.5349, 0.3420, 0.7377, 0.1749],\n",
      "       device='cuda:0') torch.Size([36])\n",
      "_113+085_classification weights:  tensor([1.4472, 1.0155, 1.6218, 1.1272, 1.5374, 1.3435, 1.6115, 1.6270, 1.0375,\n",
      "        1.0458, 2.8850, 1.1812, 1.2770, 1.3074, 1.4320, 1.6061, 1.5656, 1.2178,\n",
      "        1.5566, 0.3404, 0.2529, 0.0628, 0.4592, 0.1963, 0.2203, 2.4219, 0.5597,\n",
      "        0.4156, 0.3085, 0.2166, 0.5473, 0.2778, 0.2348, 0.4198, 0.2925],\n",
      "       device='cuda:0') torch.Size([35])\n",
      "_113+118_classification weights:  tensor([1.3196, 1.2552, 1.2300, 1.2333, 1.4552, 0.9338, 1.3009, 1.0733, 2.0644,\n",
      "        1.0718, 1.5769, 1.1982, 1.4603, 1.1757, 1.7228, 0.9512, 1.1561, 0.7869,\n",
      "        1.7295, 1.9009, 0.3933, 0.4285, 0.2545, 0.2937, 0.0915, 0.8065, 0.3218,\n",
      "        0.6605, 0.4387, 0.1372, 0.5100, 0.3570, 0.0847, 0.2438, 0.6723, 0.5563,\n",
      "        0.9914, 0.0488], device='cuda:0') torch.Size([38])\n",
      "_113+122_classification weights:  tensor([0.7073, 0.7291, 0.5253, 0.4856, 1.1650, 1.1239, 1.1454, 1.9077, 1.0374,\n",
      "        0.5149, 0.8973, 1.1787, 0.5750, 0.9866, 0.7005, 0.5988, 1.3350, 0.6734,\n",
      "        0.7236, 0.4459, 0.7788, 0.8239, 0.9121, 0.1777, 0.5323, 0.5766, 0.7669,\n",
      "        0.8994, 2.7542, 0.7978, 0.4448, 0.8279, 0.6396, 0.6365, 0.7749, 0.0673,\n",
      "        1.0956, 0.6301], device='cuda:0') torch.Size([38])\n",
      "_113+165_classification weights:  tensor([0.6018, 0.9161, 0.6872, 0.6385, 2.0814, 0.4883, 0.9675, 0.5985, 0.8637,\n",
      "        0.9720, 0.3418, 1.4415, 0.9682, 1.4931, 1.5824, 0.5971, 0.6127, 0.7504,\n",
      "        0.7823, 0.7270, 0.3291, 3.0591, 0.5463, 0.7416, 0.2332, 0.5810, 0.5397,\n",
      "        0.6042, 0.9831, 0.3110, 1.9342, 0.2603, 0.8580, 0.2830, 0.6272],\n",
      "       device='cuda:0') torch.Size([35])\n",
      "_113+187_classification weights:  tensor([0.9526, 0.9201, 2.3846, 0.6644, 1.7418, 1.1532, 1.7135, 1.0692, 0.2177,\n",
      "        0.9369, 1.0263, 1.4288, 3.4070, 1.0123, 0.7827, 1.2606, 1.2263, 1.0422,\n",
      "        1.0407, 1.2071, 0.5083, 0.4635, 0.8918, 0.3792, 0.4948, 0.7163, 0.1582,\n",
      "        0.4001, 0.1761, 0.4853, 0.1934, 0.2985, 0.3551, 0.4987, 0.6705, 0.4971],\n",
      "       device='cuda:0') torch.Size([36])\n",
      "_113+194_classification weights:  tensor([0.4053, 1.0135, 1.1219, 1.5547, 1.2273, 1.5432, 0.0893, 1.1178, 1.2850,\n",
      "        1.4577, 1.0017, 0.6406, 1.2012, 1.1697, 1.4124, 1.1464, 1.1343, 1.1459,\n",
      "        1.7849, 0.9790, 1.4807, 0.6259, 0.5520, 0.4239, 0.2717, 0.0981, 1.2982,\n",
      "        0.5399, 0.3935, 0.3864, 0.6497, 1.1762, 0.4870, 0.4935, 0.3780, 0.2908,\n",
      "        0.4164, 0.3820, 0.5400], device='cuda:0') torch.Size([39])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_165+161_classification weights:  tensor([1.0083, 1.0126, 0.8060, 0.6430, 0.8119, 1.4438, 0.9061, 0.7766, 1.4878,\n",
      "        0.2954, 1.3330, 0.7098, 1.0528, 0.5782, 0.2641, 0.7989, 1.1762, 0.9185,\n",
      "        0.8117, 0.7630, 0.7129, 0.8642, 0.9697, 0.7509, 0.3542, 0.6390, 0.9533,\n",
      "        0.2624, 1.2297, 0.3526, 0.9480, 0.6770, 1.0599, 1.2184, 0.8308, 0.5280,\n",
      "        0.3890, 2.3402, 0.8102], device='cuda:0') torch.Size([39])\n",
      "_165+181_classification weights:  tensor([0.9386, 1.1016, 1.0464, 0.9703, 1.1304, 0.9817, 1.0875, 1.0224, 0.8527,\n",
      "        1.1275, 0.8968, 1.0555, 1.2416, 0.8093, 0.9245, 1.1461, 1.0536, 1.0085,\n",
      "        0.2914, 0.3324, 0.5007, 0.4102, 0.4447, 0.4389, 0.7309, 2.8073, 0.4853,\n",
      "        0.4585, 0.6047, 0.2998, 0.5373, 0.6694, 0.1323, 0.7068, 0.9621, 0.4383,\n",
      "        0.5932, 0.4226, 1.4222], device='cuda:0') torch.Size([39])\n",
      "_187+079_classification weights:  tensor([1.0967, 0.5341, 0.8547, 0.9251, 1.4282, 0.8067, 0.8161, 0.8277, 0.4337,\n",
      "        0.6162, 0.5845, 0.7878, 0.6150, 1.2744, 1.2385, 1.0043, 1.0183, 0.7405,\n",
      "        0.7216, 0.9455, 0.7913, 1.2189, 0.7734, 0.7129, 0.4654, 0.7990, 1.0925,\n",
      "        0.5338, 1.4200, 1.2404, 1.1395, 1.2139, 0.8876, 0.6854, 0.5621, 0.7969,\n",
      "        0.4957, 1.0025, 1.0244, 0.6649], device='cuda:0') torch.Size([40])\n",
      "_194+019_classification weights:  tensor([0.6403, 0.8336, 0.6728, 0.8575, 1.0607, 1.4172, 1.0355, 0.7811, 0.5943,\n",
      "        0.9166, 1.0699, 0.9915, 0.6731, 0.9528, 1.0824, 0.8119, 0.6403, 0.5211,\n",
      "        0.4315, 0.4768, 1.0165, 0.7182, 0.6373, 0.0585, 0.3741, 0.6552, 1.0712,\n",
      "        0.4108, 0.2798, 0.6782, 2.3781, 0.9498, 0.5078, 0.4607, 0.6496, 2.2721,\n",
      "        0.7139, 1.1420], device='cuda:0') torch.Size([38])\n",
      "_root_classification weights:  tensor([1.3406, 1.5084, 1.5369, 1.7779, 1.0611, 1.5716, 1.7511, 1.1916, 1.2251,\n",
      "        1.1208, 1.4876, 1.2096, 2.7023, 1.5304, 1.4494, 1.4633, 1.6576, 1.8022,\n",
      "        1.3166, 2.2953, 0.4959, 0.3788, 0.5978, 0.4731, 0.2904, 0.5647, 0.4735,\n",
      "        0.4778, 0.1446], device='cuda:0') torch.Size([29])\n"
     ]
    }
   ],
   "source": [
    "# SET SMALL WEIGHTS TO ZERO\n",
    "with torch.no_grad():\n",
    "    torch.set_printoptions(profile=\"full\")\n",
    "    for attr in dir(net.module):\n",
    "        if attr.endswith('_classification'):\n",
    "            getattr(net.module, attr).weight.copy_(torch.clamp(getattr(net.module, attr).weight.data - 0.001, min=0.)) \n",
    "            print(f\"{attr} weights: \", getattr(net.module, attr).weight[getattr(net.module, attr).weight.nonzero(as_tuple=True)], \\\n",
    "                  (getattr(net.module, attr).weight[getattr(net.module, attr).weight.nonzero(as_tuple=True)]).shape, flush=True)\n",
    "            if args.bias:\n",
    "                print(f\"{attr} bias: \", getattr(net.module, attr).bias, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f42be8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing prototypes for topk of node root ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 810it [00:13, 61.88it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 810it [00:02, 299.58it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node root [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 14, 15, 16, 17, 18] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+001+068 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 780it [00:12, 63.79it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 780it [00:02, 269.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+001+068 [0, 1, 2, 4, 5, 7, 9, 11, 14, 15, 17, 18, 19] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+060 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 660it [00:11, 59.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 660it [00:02, 240.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+060 [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 13, 15, 19] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 001+052 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 36.83it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 90it [00:04, 21.89it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 001+052 [] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+187 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 570it [00:09, 57.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 570it [00:03, 182.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+187 [1, 3, 5, 7, 10, 11, 15, 16, 17, 18, 19] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 060+071 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 36.71it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 90it [00:03, 25.57it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 060+071 [0, 7, 13, 14] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 001+033 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:02<00:00, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 100% 60/60 [00:03<00:00, 18.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 001+033 [1, 8, 9, 11, 13, 14, 17] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+037 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 510it [00:08, 58.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 510it [00:04, 112.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+037 [] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 187+079 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:02<00:00, 28.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 100% 60/60 [00:03<00:00, 16.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 187+079 [7, 12, 16] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 060+143 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:02<00:00, 29.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 100% 60/60 [00:03<00:00, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 060+143 [1, 17] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+030 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 450it [00:07, 56.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 450it [00:03, 113.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+030 [1, 6, 13, 18] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 037+077 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:02<00:00, 29.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 100% 60/60 [00:04<00:00, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 037+077 [] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+085 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 390it [00:06, 56.91it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 390it [00:03, 105.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+085 [3, 6, 10, 13, 14, 18] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 030+156 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:02<00:00, 29.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 100% 60/60 [00:03<00:00, 15.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 030+156 [16] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+194 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 360it [00:06, 56.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 360it [00:03, 96.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+194 [1, 3, 4, 7, 12] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+118 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:05, 52.70it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 300it [00:03, 80.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+118 [3, 9, 11, 13] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 194+019 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:02<00:00, 29.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 100% 60/60 [00:03<00:00, 16.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 194+019 [2, 8, 19] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+034 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:05, 52.82it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 270it [00:03, 68.79it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+034 [4, 12, 15, 17] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+016 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 240it [00:04, 49.32it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 240it [00:03, 77.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+016 [0, 3, 4, 7, 10, 11, 13, 14, 18] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+165 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 210it [00:04, 50.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 210it [00:03, 52.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+165 [10, 19] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+011 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 41.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 120it [00:03, 35.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+011 [6, 8, 9, 11, 16, 19] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 165+181 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 35.93it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 90it [00:03, 25.79it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 165+181 [8, 9, 13, 14] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 113+122 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:02<00:00, 29.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 100% 60/60 [00:03<00:00, 19.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 113+122 [1, 5, 6, 8, 11, 12, 18] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 011+097 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:02<00:00, 28.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 100% 60/60 [00:03<00:00, 16.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 011+097 [0, 1, 8, 10] are set to zero because it is never detected with similarity>0.1 in the training set\n",
      "Visualizing prototypes for topk of node 165+161 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:02<00:00, 27.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 prototypes do not have any similarity score > 0.1. Will be ignored in visualisation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizing topk: 100% 60/60 [00:03<00:00, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of prototypes of node 165+161 [7] are set to zero because it is never detected with similarity>0.1 in the training set\n"
     ]
    }
   ],
   "source": [
    "for node in root.nodes_with_children():\n",
    "    topks = visualize_topk(net, projectloader, node.num_children(), device, f'visualised_prototypes_topk_ep={ckpt_epoch}/{node.name}', args, node=node, wandb_logging=False)\n",
    "    # set weights of prototypes that are never really found in projection set to 0\n",
    "    set_to_zero = []\n",
    "    classification_layer = getattr(net.module, '_'+node.name+'_classification')\n",
    "    if topks:\n",
    "        for prot in topks.keys():\n",
    "            found = False\n",
    "            for (i_id, score) in topks[prot]:\n",
    "                if score > 0.1:\n",
    "                    found = True\n",
    "            if not found:\n",
    "                torch.nn.init.zeros_(classification_layer.weight[:,prot])\n",
    "                set_to_zero.append(prot)\n",
    "        print(f\"Weights of prototypes of node {node.name}\", set_to_zero, \"are set to zero because it is never detected with similarity>0.1 in the training set\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952aa1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
