{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c818ec1-bbb5-40d9-8489-0138316e194a",
   "metadata": {},
   "source": [
    "Supposed to be the cleaned version of v2. v2 works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ba329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import sys, os\n",
    "import random\n",
    "import numpy as np\n",
    "from shutil import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "# from skimage.filters import threshold_local, gaussian\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443ab7d-e26b-4010-8fac-54619a466af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7743f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 154 18 species Naive hpipnet with mask\n",
    "# run_path = \"runs/154-PruningNaiveHPIPNet_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/162-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/163-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.2MinCont=0.1_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/164-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/165-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=2.0MinCont=0.1_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/166-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=2.0MinCont=0.1_cnext26_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/167-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext26_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/168-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext26_CUB-29-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/169-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=2.0MinCont=0.1_cnext26_CUB-29-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/170-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60MinCont=0.1_cnext26_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/171-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60MinCont=0.1_cnext26_CUB-29-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/172-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.1MinCont=0.1_cnext26_CUB-29-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/173-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.1MinCont=0.1_cnext26_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/176-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=2.0MinCont=0.1_cnext26_CUB-190-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/178-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/179-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/180-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=2.0MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/181-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=2.0MinCont=0.1_cnext26_CUB-190-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/182-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.1MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/183-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/184-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/192-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=85Cl=4.0NoTanhDescMinCont=0.5_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/202-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=60Cl=2.0TanhDesc=0.05MinCont=0.1_cnext13_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "\n",
    "# run_path = \"runs/211-178cloneWithGeoMeanOvsp-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=60Cl=2.0TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "\n",
    "# run_path = \"runs/216-178like-cnext26_PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=60Cl=2.0TanhDesc=1.0MinCont=0.1_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "\n",
    "# run_path = \"runs/215-178like-cnext26_PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=60Cl=2.0TanhDesc=0.5MinCont=0.1_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "\n",
    "# run_path = \"runs/214-178like-cnext26_PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=60Cl=2.0TanhDesc=0.1MinCont=0.1_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "\n",
    "# run_path = \"runs/213-178like-cnext26_PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=60Cl=2.0TanhDesc=0.05MinCont=0.1_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "\n",
    "run_path = \"runs/217-178like-cnext26_PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=60Cl=2.0TanhDesc=2.0MinCont=0.1_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "\n",
    "try:\n",
    "    sys.path.remove(os.path.join(os.getcwd(), 'projects', 'PIPNet'))\n",
    "except:\n",
    "    pass\n",
    "sys.path.insert(0, os.path.join(run_path, 'source_clone'))\n",
    "\n",
    "print(run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f39153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipnet.pipnet import PIPNet, get_network\n",
    "from util.log import Log\n",
    "from util.args import get_args, save_args, get_optimizer_nn\n",
    "from util.data import get_dataloaders\n",
    "from util.func import init_weights_xavier\n",
    "from pipnet.train import train_pipnet, test_pipnet\n",
    "# from pipnet.test import eval_pipnet, get_thresholds, eval_ood\n",
    "from util.eval_cub_csv import eval_prototypes_cub_parts_csv, get_topk_cub, get_proto_patches_cub\n",
    "from util.vis_pipnet import visualize, visualize_topk\n",
    "from util.visualize_prediction import vis_pred, vis_pred_experiments\n",
    "from util.node import Node\n",
    "from util.phylo_utils import construct_phylo_tree, construct_discretized_phylo_tree\n",
    "from util.func import get_patch_size\n",
    "from util.data import ModifiedLabelLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba5e1c",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "args = pickle.load(args_file)\n",
    "\n",
    "if args.phylo_config:\n",
    "    phylo_config = OmegaConf.load(args.phylo_config)\n",
    "\n",
    "if args.phylo_config:\n",
    "    # construct the phylo tree\n",
    "    if phylo_config.phyloDistances_string == 'None':\n",
    "        if '031' in run_path: # this run uses a different phylogeny file that had an extra root node which is a mistake\n",
    "            root = construct_phylo_tree('data/phlyogenyCUB/18Species-with-extra-root-node/1_tree-consensus-Hacket-18Species-modified_cub-names_v1.phy')\n",
    "        else:\n",
    "            root = construct_phylo_tree(phylo_config.phylogeny_path)\n",
    "        print('-'*25 + ' No discretization ' + '-'*25)\n",
    "    else:\n",
    "        root = construct_discretized_phylo_tree(phylo_config.phylogeny_path, phylo_config.phyloDistances_string)\n",
    "        print('-'*25 + ' Discretized ' + '-'*25)\n",
    "else:\n",
    "    # construct the tree (original hierarchy as described in the paper)\n",
    "    root = Node(\"root\")\n",
    "    root.add_children(['animal','vehicle','everyday_object','weapon','scuba_diver'])\n",
    "    root.add_children_to('animal',['non_primate','primate'])\n",
    "    root.add_children_to('non_primate',['African_elephant','giant_panda','lion'])\n",
    "    root.add_children_to('primate',['capuchin','gibbon','orangutan'])\n",
    "    root.add_children_to('vehicle',['ambulance','pickup','sports_car'])\n",
    "    root.add_children_to('everyday_object',['laptop','sandal','wine_bottle'])\n",
    "    root.add_children_to('weapon',['assault_rifle','rifle'])\n",
    "    # flat root\n",
    "    # root.add_children(['scuba_diver','African_elephant','giant_panda','lion','capuchin','gibbon','orangutan','ambulance','pickup','sports_car','laptop','sandal','wine_bottle','assault_rifle','rifle'])\n",
    "root.assign_all_descendents()\n",
    "\n",
    "exp_no = int(os.path.basename(run_path)[:3])\n",
    "\n",
    "if exp_no < 77:\n",
    "    if ('num_protos_per_descendant' in args) and (args.num_protos_per_descendant > 0):\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(args.num_protos_per_descendant)\n",
    "if exp_no == 77:\n",
    "    # update num of protos per node based on num_protos_per_descendant\n",
    "    if args.num_features == 0 and args.num_protos_per_descendant == 0:\n",
    "        raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "    for node in root.nodes_with_children():\n",
    "        node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                                            min_protos=args.num_features)\n",
    "else:\n",
    "    if ('num_protos_per_child' in args) and ('num_protos_per_descendant' in args):\n",
    "        if args.num_features == 0 and args.num_protos_per_descendant == 0 and args.num_protos_per_child == 0:\n",
    "            raise Exception('Either of num_features or num_protos_per_descendant or num_protos_per_child must be greater than zero')\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                num_protos_per_child=args.num_protos_per_child,\\\n",
    "                                min_protos=args.num_features,\\\n",
    "                                split_protos=('protopool' in args) and (args.protopool == 'n'))\n",
    "    elif ('num_protos_per_descendant' in args):\n",
    "        # update num of protos per node based on num_protos_per_descendant\n",
    "        if args.num_features == 0 and args.num_protos_per_descendant == 0 and args.num_protos_per_child == 0:\n",
    "            raise Exception('Either of num_features or num_protos_per_descendant or num_protos_per_child must be greater than zero')\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                min_protos=args.num_features,\\\n",
    "                                split_protos=('protopool' in args) and (args.protopool == 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    device_ids = [torch.cuda.current_device()]\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    device_ids = []\n",
    "\n",
    "# args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "# args = pickle.load(args_file)\n",
    "\n",
    "# ckpt_file_name = 'net_overspecific_pruned_replaced_thresh=0.5_last'\n",
    "ckpt_file_name = 'net_trained_last'\n",
    "# ckpt_file_name = 'net_trained_10'\n",
    "# ckpt_file_name = 'net_pretrained'\n",
    "epoch = ckpt_file_name.split('_')[-1]\n",
    "\n",
    "ckpt_path = os.path.join(run_path, 'checkpoints', ckpt_file_name)\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "if ckpt_file_name != 'net_trained_last':\n",
    "    print('\\n', (10*'-')+'WARNING: Not using the final trained model'+(10*'-'), '\\n')\n",
    "\n",
    "# Obtain the dataset and dataloaders\n",
    "trainloader, trainloader_pretraining, trainloader_normal, trainloader_normal_augment, projectloader, testloader, test_projectloader, classes = get_dataloaders(args, device)\n",
    "\n",
    "print(args.batch_size, trainloader.batch_size)\n",
    "\n",
    "if len(classes)<=20:\n",
    "    if args.validation_size == 0.:\n",
    "        print(\"Classes: \", testloader.dataset.class_to_idx, flush=True)\n",
    "    else:\n",
    "        print(\"Classes: \", str(classes), flush=True)\n",
    "\n",
    "# Create a convolutional network based on arguments and add 1x1 conv layer\n",
    "feature_net, add_on_layers, pool_layer, classification_layers = get_network(len(classes), args, root=root)\n",
    "   \n",
    "# Create a PIP-Net\n",
    "net = PIPNet(num_classes=len(classes),\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "net = net.to(device=device)\n",
    "net = nn.DataParallel(net, device_ids = device_ids)    \n",
    "net.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "# print(net.eval())\n",
    "criterion = nn.NLLLoss(reduction='mean').to(device)\n",
    "\n",
    "# Forward one batch through the backbone to get the latent output size\n",
    "with torch.no_grad():\n",
    "    xs1, _, _ = next(iter(trainloader))\n",
    "    xs1 = xs1.to(device)\n",
    "    _, proto_features, _, _ = net(xs1)\n",
    "    wshape = proto_features['root'].shape[-1]\n",
    "    args.wshape = wshape #needed for calculating image patch size\n",
    "    print(\"Output shape: \", proto_features['root'].shape, flush=True)\n",
    "    \n",
    "print(args.wshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd56802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from util.func import get_patch_size\n",
    "import csv\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "\n",
    "\n",
    "def get_topk_cub_nodewise(net, root, projectloader, k, epoch, device, args):   \n",
    "\n",
    "    list_csvfile_topk = []\n",
    "    list_node_wise_df = []\n",
    "    dict_node_wise_df = {}\n",
    "\n",
    "    if isinstance(projectloader.sampler, torch.utils.data.RandomSampler):\n",
    "        raise Exception('Dataset should not be in shuffle')\n",
    "    # Make sure the model is in evaluation mode\n",
    "    net.eval()\n",
    "    \n",
    "    # IMPORTANT: dataloader should NOT be in shuffle, because imgs will not be shuffled, indexing wont be right\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    # Show progress on progress bar\n",
    "    project_iter = tqdm(enumerate(projectloader),\n",
    "                        total=len(projectloader),\n",
    "                        desc='Collecting top-k Prototypes CUB parts',\n",
    "                        mininterval=50.,\n",
    "                        ncols=0)\n",
    "    imgs = projectloader.dataset.imgs\n",
    "\n",
    "    patchsize, skip = get_patch_size(args)\n",
    "\n",
    "    scores_per_prototype = dict() # maps node.name -> proto_idx -> leaf_name -> list(topk)\n",
    "    for node in root.nodes_with_children():\n",
    "        scores_per_prototype[node.name] = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "        # Iterate through the projection set\n",
    "    for i, (xs, orig_y) in project_iter:\n",
    "        xs= xs.to(device)\n",
    "\n",
    "        # coarse_label = ys.item()\n",
    "        leaf_label = orig_y.item()\n",
    "        leaf_name = label2name[leaf_label]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Use the model to classify this batch of input data\n",
    "            _, pfs_dict, pooled_dict, _ = net(xs)\n",
    "\n",
    "            for node in root.nodes_with_children():\n",
    "\n",
    "                if leaf_name not in node.leaf_descendents:\n",
    "                    continue\n",
    "\n",
    "                classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "\n",
    "                child_name = node.closest_descendent_for(leaf_name).name\n",
    "                coarse_label = node.children_to_labels[child_name]\n",
    "                coarse_label2name = {label: name for name, label in node.children_to_labels.items()}\n",
    "                \n",
    "                pfs = pfs_dict[node.name]\n",
    "                pooled = pooled_dict[node.name]\n",
    "                pooled = pooled.squeeze(0) \n",
    "                pfs = pfs.squeeze(0) \n",
    "                for p in range(pooled.shape[0]):\n",
    "\n",
    "                    if (classification_weights[coarse_label, p].item() > 1e-3):\n",
    "                        scores_per_prototype[node.name][p][leaf_label].append((i, pooled[p].item(), pfs[p,:,:]))\n",
    "    \n",
    "    csvfolderpath = os.path.join(args.log_dir, f'node_wise_top{k}')\n",
    "    os.makedirs(csvfolderpath, exist_ok=True)\n",
    "\n",
    "    for node in root.nodes_with_children():\n",
    "        proto_img_coordinates = []\n",
    "        proto_img_coordinates_df = []\n",
    "        csvfilepath = os.path.join(csvfolderpath, f'{node.name}_prototypes_top{k}_{str(epoch)}.csv')\n",
    "        print('csv filepath:', csvfilepath)\n",
    "        too_small = set()\n",
    "        protoype_iter = tqdm(enumerate(scores_per_prototype[node.name].keys()), total=len(list(scores_per_prototype[node.name].keys())),mininterval=5.,ncols=0,desc='Collecting top-k patch coordinates CUB')\n",
    "        with open(csvfilepath, \"w\", newline='') as csvfile:\n",
    "            print(\"Writing CSV file with top k image patches..\", flush=True)\n",
    "            writer = csv.writer(csvfile, delimiter=',')\n",
    "            writer.writerow([\"node\", \"child\", \"leaf\", \"prototype\", \\\n",
    "                             \"img name\", \"h_min_224\", \"h_max_224\", \\\n",
    "                             \"w_min_224\", \"w_max_224\", \"scores\"])\n",
    "            for _, prototype in protoype_iter:\n",
    "                for leaf_label in scores_per_prototype[node.name][prototype]:\n",
    "                    leaf_descendent_name = label2name[leaf_label]\n",
    "                    child_name = node.closest_descendent_for(leaf_descendent_name).name\n",
    "                    leaf_descendent_name = leaf_descendent_name[4:7] # taking only the number from class name\n",
    "                    df = pd.DataFrame(scores_per_prototype[node.name][prototype][leaf_label], columns=['img_id', 'scores', 'latent_activation'])\n",
    "                    topk = df.nlargest(k, 'scores')\n",
    "                    for index, row in topk.iterrows():\n",
    "                        imgid = int(row['img_id'])\n",
    "                        imgname = imgs[imgid][0]\n",
    "                        with torch.no_grad():\n",
    "                            if row['scores'] < 0.1:\n",
    "                                too_small.add(p)\n",
    "                                \n",
    "                            location_h, location_h_idx = torch.max(row['latent_activation'], dim=0)\n",
    "                            _, location_w_idx = torch.max(location_h, dim=0)\n",
    "                            location = (location_h_idx[location_w_idx].item(), location_w_idx.item())\n",
    "                            h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, row['latent_activation'].unsqueeze(0).shape, \\\n",
    "                                                                                                 patchsize, skip, location[0], location[1])\n",
    "                            \n",
    "                            proto_img_coordinates.append([node.name, child_name, leaf_descendent_name, \\\n",
    "                                                          prototype, imgname, h_coor_min, h_coor_max, \\\n",
    "                                                          w_coor_min, w_coor_max, row['scores']])\n",
    "                            proto_img_coordinates_df.append([node.name, child_name, leaf_descendent_name, \\\n",
    "                                                          prototype, imgname, h_coor_min, h_coor_max, \\\n",
    "                                                          w_coor_min, w_coor_max, row['scores'], row['latent_activation']])\n",
    "                # write intermediate results in case of large dataset\n",
    "                if len(proto_img_coordinates) > 10000:\n",
    "                    writer.writerows(proto_img_coordinates)\n",
    "                    proto_img_coordinates = []\n",
    "            print(\"Warning: image patches included in topk, but similarity < 0.1! This might unfairly reduce the purity metric because prototype has less than k similar image patches. You could consider reducing k for prototypes\", too_small, flush=True)\n",
    "    \n",
    "            writer.writerows(proto_img_coordinates) \n",
    "        # do something about this\n",
    "        df = pd.DataFrame(proto_img_coordinates_df, columns=[\"node\", \"child\", \"leaf\", \"prototype\", \\\n",
    "                                                         \"img name\", \"h_min_224\", \"h_max_224\", \\\n",
    "                                                         \"w_min_224\", \"w_max_224\", \"scores\", 'latent_activation'])\n",
    "        list_csvfile_topk.append(csvfilepath)\n",
    "        list_node_wise_df.append(df)\n",
    "        dict_node_wise_df[node.name] = df\n",
    "    # return df\n",
    "    return list_csvfile_topk, list_node_wise_df, dict_node_wise_df\n",
    "\n",
    "def eval_prototypes_cub_parts_csv_nodewise_maxmin(node, csvfile, parts_loc_path, parts_name_path, imgs_id_path, epoch, args, desc_threshold=0, log=None):\n",
    "    patchsize, _ = get_patch_size(args)\n",
    "    imgresize = float(args.image_size)\n",
    "    path_to_id = dict()\n",
    "    id_to_path = dict()\n",
    "    with open(imgs_id_path) as f:\n",
    "        for line in f:\n",
    "            id, path = line.split('\\n')[0].split(' ')\n",
    "            path_to_id[path]=id\n",
    "            id_to_path[id]=path\n",
    "\n",
    "    img_to_part_xy_vis = dict()\n",
    "    with open(parts_loc_path) as f:\n",
    "        for line in f:\n",
    "            img, partid, x, y, vis = line.split('\\n')[0].split(' ')\n",
    "            vis = str(int(float(vis)))\n",
    "            x =float(x)\n",
    "            y =float(y)\n",
    "            if x > 1.06 or y > 1.05:\n",
    "                raise Exception('Provide normalized coordinated for part loc')\n",
    "            if img not in img_to_part_xy_vis.keys():\n",
    "                img_to_part_xy_vis[img]=dict()\n",
    "            if vis == '1':\n",
    "                img_to_part_xy_vis[img][partid]=(x,y)\n",
    "\n",
    "    parts_id_to_name = dict()\n",
    "    parts_name_to_id = dict()\n",
    "    with open (parts_name_path) as f:\n",
    "        for line in f:\n",
    "            id, name = line.split('\\n')[0].split(' ',1)\n",
    "            parts_id_to_name[id]=name\n",
    "            parts_name_to_id[name]=id\n",
    "#     print(parts_id_to_name)\n",
    "\n",
    "    # merge left and right cub parts\n",
    "    duplicate_part_ids = []\n",
    "    with open (parts_name_path) as f:\n",
    "        for line in f:\n",
    "            id, name = line.split('\\n')[0].split(' ',1)\n",
    "            if 'left' in name:\n",
    "                new_name = name.replace('left', 'right')\n",
    "                \n",
    "                duplicate_part_ids.append((id, parts_name_to_id[new_name]))\n",
    "           \n",
    "    proto_parts_presences = dict()\n",
    "    child_name_to_protos = defaultdict(set)\n",
    "    \n",
    "    with open (csvfile, newline='') as f:\n",
    "        filereader = csv.reader(f, delimiter=',')\n",
    "        next(filereader) #skip header\n",
    "        for (node_name, child_name, leaf_descendant_name, prototype, imgname, h_min_224, h_max_224, w_min_224, w_max_224, scores) in filereader:\n",
    "            child_name_to_protos[child_name].add(prototype)\n",
    "            \n",
    "            if prototype not in proto_parts_presences.keys():\n",
    "                proto_parts_presences[prototype]=dict()\n",
    "            if leaf_descendant_name not in proto_parts_presences[prototype].keys():\n",
    "                proto_parts_presences[prototype][leaf_descendant_name]=dict()\n",
    "            p = prototype\n",
    "            img = Image.open(imgname)\n",
    "            imgname = imgname.replace('\\\\', '/')\n",
    "            imgnamec, imgnamef = imgname.split('/')[-2:]\n",
    "            if 'normal_' in imgnamef:\n",
    "                imgnamef = imgnamef.split('normal_')[-1]\n",
    "            imgname = imgnamec+'/'+imgnamef\n",
    "            img_id = path_to_id[imgname]\n",
    "            img_orig_width, img_orig_height = img.size\n",
    "            h_min_224, h_max_224, w_min_224, w_max_224 = float(h_min_224), float(h_max_224), float(w_min_224), float(w_max_224)\n",
    "            \n",
    "            \n",
    "            diffh = h_max_224 - h_min_224\n",
    "            diffw = w_max_224 - w_min_224\n",
    "            if diffh > patchsize: #patch size too big, we take the center. otherwise the bigger the patch, the higher the purity.\n",
    "                correction = diffh-patchsize\n",
    "                h_min_224 = h_min_224 + correction//2.\n",
    "                h_max_224 = h_max_224 - correction//2.\n",
    "            if diffw > patchsize:\n",
    "                correction = diffw-patchsize\n",
    "                w_min_224 = w_min_224 + correction//2.\n",
    "                w_max_224 = w_max_224 - correction//2.\n",
    "\n",
    "            normalized_h_min = (h_min_224/imgresize) \n",
    "            normalized_h_max = (h_max_224/imgresize) \n",
    "            normalized_w_min = (w_min_224/imgresize) \n",
    "            normalized_w_max = (w_max_224/imgresize) \n",
    "                        \n",
    "            part_dict_img = img_to_part_xy_vis[img_id]\n",
    "            for part in part_dict_img.keys():\n",
    "                x,y = part_dict_img[part]                \n",
    "                part_in_patch = 0 \n",
    "                if y >= normalized_h_min and y <= normalized_h_max:\n",
    "                    if x >= normalized_w_min and x <= normalized_w_max:\n",
    "                        part_in_patch = 1\n",
    "                if part not in proto_parts_presences[p][leaf_descendant_name].keys():\n",
    "                    proto_parts_presences[p][leaf_descendant_name][part]=[]\n",
    "                    \n",
    "                proto_parts_presences[p][leaf_descendant_name][part].append(part_in_patch)\n",
    "            \n",
    "            for pair in duplicate_part_ids:\n",
    "                if pair[0] in part_dict_img.keys():\n",
    "                    if pair[1] in part_dict_img.keys():\n",
    "                        presence0 = proto_parts_presences[p][leaf_descendant_name][pair[0]][-1]\n",
    "                        presence1 = proto_parts_presences[p][leaf_descendant_name][pair[1]][-1]\n",
    "                        if presence0 > presence1: \n",
    "                            proto_parts_presences[p][leaf_descendant_name][pair[1]][-1] = presence0\n",
    "\n",
    "                        del proto_parts_presences[p][leaf_descendant_name][pair[0]]\n",
    "                    else:\n",
    "\n",
    "                        if pair[1] not in proto_parts_presences[p][leaf_descendant_name].keys():\n",
    "                            proto_parts_presences[p][leaf_descendant_name][pair[1]]=[]\n",
    "                        proto_parts_presences[p][leaf_descendant_name][pair[1]].append(proto_parts_presences[p][leaf_descendant_name][pair[0]][-1])\n",
    "                        del proto_parts_presences[p][leaf_descendant_name][pair[0]]\n",
    "                        \n",
    "    print(\"Number of prototypes in parts_presences: \", len(proto_parts_presences.keys()), flush=True)\n",
    "    \n",
    "    prototypes_part_related = 0\n",
    "    max_presence_purity = dict()\n",
    "    max_presence_purity_part = dict()\n",
    "    max_presence_purity_sum = dict()\n",
    "\n",
    "    most_often_present_purity = dict()\n",
    "    part_most_present = dict()\n",
    "\n",
    "    # for each of a proto taking the least occurence with respect to topk from each descendant\n",
    "    proto_parts_presences_copy = dict()\n",
    "    for proto in proto_parts_presences.keys():\n",
    "        proto_parts_presences_copy[proto] = dict()\n",
    "        for part in part_dict_img.keys():\n",
    "            proto_parts_presences_copy[proto][part] = None\n",
    "            for leaf_descendant_name in proto_parts_presences[proto].keys():\n",
    "\n",
    "                # to avoid the keyvalue error\n",
    "                if part not in proto_parts_presences[proto][leaf_descendant_name]:\n",
    "                    continue\n",
    "                \n",
    "                if proto_parts_presences_copy[proto][part] is None:\n",
    "                    proto_parts_presences_copy[proto][part] = proto_parts_presences[proto][leaf_descendant_name][part]\n",
    "                else:\n",
    "                    if np.array(proto_parts_presences_copy[proto][part]).sum() > np.array(proto_parts_presences[proto][leaf_descendant_name][part]).sum():\n",
    "                        proto_parts_presences_copy[proto][part] = proto_parts_presences[proto][leaf_descendant_name][part]\n",
    "            if proto_parts_presences_copy[proto][part] is None:\n",
    "                # meaning the part did not occur in any of the descendant\n",
    "                del proto_parts_presences_copy[proto][part]\n",
    "    proto_parts_presences = proto_parts_presences_copy\n",
    "    \n",
    "    for proto in proto_parts_presences.keys():\n",
    "        \n",
    "        max_presence_purity[proto]= 0.\n",
    "        part_most_present[proto] = ('0',0)\n",
    "        most_often_present_purity[proto] = 0.\n",
    "\n",
    "        # CUB parts 7,8 and 9 are  duplicate (right and left). additional check that these should not occur (already fixed earlier in this function)\n",
    "        if ('7' in proto_parts_presences[proto].keys() or '8' in proto_parts_presences[proto].keys() or '9' in proto_parts_presences[proto].keys()):\n",
    "            print(\"unused part in keys! \", proto, proto_parts_presences[proto].keys(), proto_parts_presences[proto], flush=True)\n",
    "            raise ValueError()\n",
    "        \n",
    "        for part in proto_parts_presences[proto].keys():\n",
    "            presence_purity = np.mean(proto_parts_presences[proto][part])\n",
    "            sum_occurs = np.array(proto_parts_presences[proto][part]).sum()\n",
    "        \n",
    "            # evaluate whether the purity of this prototype for this part is higher than for other parts\n",
    "            if presence_purity > max_presence_purity[proto]:\n",
    "                max_presence_purity[proto]=presence_purity\n",
    "                max_presence_purity_part[proto]=parts_id_to_name[part]\n",
    "                max_presence_purity_sum[proto] = sum_occurs\n",
    "            elif presence_purity == max_presence_purity[proto]:\n",
    "                if presence_purity == 0.:\n",
    "                    max_presence_purity[proto]=presence_purity\n",
    "                    max_presence_purity_part[proto]=parts_id_to_name[part]\n",
    "                    max_presence_purity_sum[proto] = sum_occurs\n",
    "                elif sum_occurs > max_presence_purity_sum[proto]:\n",
    "                    max_presence_purity[proto]=presence_purity\n",
    "                    max_presence_purity_part[proto]=parts_id_to_name[part]\n",
    "                    max_presence_purity_sum[proto] = sum_occurs\n",
    "        \n",
    "            if sum_occurs > part_most_present[proto][1]:\n",
    "                part_most_present[proto] = (part, sum_occurs)\n",
    "                most_often_present_purity[proto]=presence_purity         \n",
    "        if max_presence_purity[proto] > 0.5:\n",
    "            prototypes_part_related += 1 \n",
    "        \n",
    "            \n",
    "    print(f\"Part-related (purity>0.5): {prototypes_part_related}\", flush=True)\n",
    "    purity_of_child = {}\n",
    "    for child_name in child_name_to_protos:\n",
    "        purity_of_child[child_name] = np.mean([max_presence_purity[p] for p in child_name_to_protos[child_name]])\n",
    "        std = np.std([max_presence_purity[p] for p in child_name_to_protos[child_name]])\n",
    "        num_descendants = node.get_node(child_name).num_leaf_descendents()\n",
    "        print('Node:', node.name, '| Child:', child_name, '| Purity:', purity_of_child[child_name], '| Num desc:', num_descendants, '| Num protos:', len(child_name_to_protos[child_name]))\n",
    "        for p in child_name_to_protos[child_name]:\n",
    "            print('\\tProto:', p, max_presence_purity[p])\n",
    "\n",
    "    if log:\n",
    "        log.log_values('log_epoch_overview', \"p_cub_\"+str(epoch), \"mean purity (averaged over all prototypes, corresponding to purest part)\", \"std purity\", \"mean purity (averaged over all prototypes, corresponding to part with most often overlap)\", \"std purity\", \"# prototypes in csv\", \"#part-related prototypes (purity > 0.5)\",\"\",\"\")\n",
    "\n",
    "        log.log_values('log_epoch_overview', \"p_cub_\"+str(epoch), np.mean(list(max_presence_purity.values())), np.std(list(max_presence_purity.values())), np.mean(list(most_often_present_purity.values())), np.std(list(most_often_present_purity.values())), len(list(proto_parts_presences.keys())), prototypes_part_related, \"\", \"\")\n",
    "\n",
    "    overall_node_purity = np.mean([max_presence_purity[p] for child_name in child_name_to_protos for p in child_name_to_protos[child_name]])\n",
    "    return overall_node_purity, max_presence_purity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca970c1c-3abd-4443-9970-306dbcc7e988",
   "metadata": {},
   "source": [
    "# Find subtree root - only for finding does not affect the run, use the value found here in the visualization block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c2d072-ddc6-46f6-afa6-bac63733f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_descendents = set(['cub_052_Pied_billed_Grebe', 'cub_004_Groove_billed_Ani'])\n",
    "subtree_root = root\n",
    "for node in root.nodes_with_children():\n",
    "    if leaf_descendents.issubset(node.leaf_descendents) and (len(node.leaf_descendents) < len(subtree_root.leaf_descendents)):\n",
    "        subtree_root = node\n",
    "# root.get_node('053+004')\n",
    "print(subtree_root.name)\n",
    "# 024+051 for CUB-18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ed5a9-8381-4ab7-b990-df38778cbb13",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb500e-3df6-4be0-ab4d-c10dda5bd067",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK = 10\n",
    "maindataloader = testloader # projectloader, trainloader_normal, trainloader_normal_augment, projectloader, testloader, test_projectloader\n",
    "subtree_root = root#.get_node('024+051')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad862fe-d979-43a3-b5ec-035e17a8cd9d",
   "metadata": {},
   "source": [
    "# For PIPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d685874-b788-4686-ad9a-17329ea92f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    projectset_img0_path = maindataloader.dataset.samples[0][0]\n",
    "except:\n",
    "    projectset_img0_path = maindataloader.dataset.dataset.samples[0][0]\n",
    "\n",
    "parts_name_path = 'data/CUB_200_2011/parts/parts.txt'\n",
    "imgs_id_path = 'data/CUB_200_2011/images_cub.txt'\n",
    "print(projectset_img0_path)\n",
    "# print(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab565e-c0c5-440a-a64e-3eece22651cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_meta_file_base_path = os.path.dirname(os.path.dirname(projectset_img0_path))\n",
    "image_meta_filepath = os.path.join(image_meta_file_base_path, 'image_meta_file.json')\n",
    "\n",
    "import json\n",
    "\n",
    "with open(image_meta_filepath, 'r') as file:\n",
    "    image_meta = json.load(file)\n",
    "    \n",
    "print(image_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098d6fa-e4cb-47e4-b591-1472c0557daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'data/CUB_200_2011/'  # part locs are loaded from here\n",
    "\n",
    "if image_meta['cropped'] and image_meta['padded']:\n",
    "    part_locs_file = os.path.join(dataset_path, 'parts', 'part_locs_normalized_after_cropped_after_padded.txt') \n",
    "    print('*-'*40)\n",
    "    print('\\t\\t\\tIMPORTANT: Using CROPPED and PADDED part locations')\n",
    "    print('*-'*40)\n",
    "elif not image_meta['cropped'] and image_meta['padded']:\n",
    "    part_locs_file = os.path.join(dataset_path, 'parts', 'part_locs_normalized_after_padded.txt') \n",
    "    print('*-'*40)\n",
    "    print('\\t\\t\\tIMPORTANT: Using NOT CROPPED and PADDED part locations')\n",
    "    print('*-'*40)\n",
    "elif image_meta['cropped'] and not image_meta['padded']:\n",
    "    part_locs_file = os.path.join(dataset_path, 'parts', 'part_locs_normalized_after_cropped.txt') \n",
    "    print('*-'*40)\n",
    "    print('\\t\\t\\tIMPORTANT: Using CROPPED and NOT PADDED part locations')\n",
    "    print('*-'*40)\n",
    "elif not image_meta['cropped'] and not image_meta['padded']:\n",
    "    part_locs_file = os.path.join(dataset_path, 'parts', 'part_locs_normalized.txt') \n",
    "    print('*-'*40)\n",
    "    print('\\t\\t\\tIMPORTANT: Using NOT CROPPED and NOT PADDED part locations')\n",
    "    print('*-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf78fa1-0739-4899-ac15-51cac061fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ntpath\n",
    "NUM_PARTS = 15\n",
    "images_file = os.path.join(dataset_path, 'images_cub.txt')\n",
    "\n",
    "# Read the image index to filename mapping\n",
    "img_filename_to_index = {} # image filename to image index\n",
    "with open(images_file, 'r') as file:\n",
    "    for line in file:\n",
    "        index, filename = line.strip().split()\n",
    "        img_filename = ntpath.basename(filename)\n",
    "        img_filename_to_index[img_filename] = int(index)\n",
    "\n",
    "# Load part locations\n",
    "image_part_locs = defaultdict(list)\n",
    "with open(part_locs_file, 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split()\n",
    "        image_index, part_id, x, y, visible = int(parts[0]), int(parts[1]), float(parts[2]), float(parts[3]), bool(float(parts[4]))\n",
    "        image_part_locs[image_index].append((part_id, x, y, visible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9de0b3e-0902-4c5c-83d1-627b182edbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unshuffle_dataloader(dataloader, batch_size=1):\n",
    "    if type(dataloader.dataset) == ImageFolder:\n",
    "        dataset = dataloader.dataset\n",
    "    else:\n",
    "        dataset = dataloader.dataset.dataset#.dataset\n",
    "    new_dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=dataloader.num_workers,\n",
    "        pin_memory=dataloader.pin_memory,\n",
    "        drop_last=dataloader.drop_last,\n",
    "        timeout=dataloader.timeout,\n",
    "        worker_init_fn=dataloader.worker_init_fn,\n",
    "        multiprocessing_context=dataloader.multiprocessing_context,\n",
    "        generator=dataloader.generator,\n",
    "        prefetch_factor=dataloader.prefetch_factor,\n",
    "        persistent_workers=dataloader.persistent_workers\n",
    "    )\n",
    "    return new_dataloader\n",
    "\n",
    "maindataloader = unshuffle_dataloader(maindataloader, batch_size=1)\n",
    "print(maindataloader.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39585984-4500-4303-bfcd-0fc75bf7f93d",
   "metadata": {},
   "source": [
    "# Calculate part purity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a628a-3588-470d-b55e-806922591d0c",
   "metadata": {},
   "source": [
    "## Create the CSV file with info about the Top-K image patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32827f87-d87a-4aff-aaf4-d398974ef4e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_ = time.time()\n",
    "list_csvfile_topk, list_node_wise_df, dict_node_wise_df = get_topk_cub_nodewise(net, root, maindataloader, \\\n",
    "                                                                                 TOPK, str(epoch), device, args)\n",
    "print('Elapsed', time.time() - start_, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad18956-a4eb-4264-b3f5-dcfcaea65a68",
   "metadata": {},
   "source": [
    "## Calculate part purity from the created CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03591379-002b-4f60-b622-e599c67087b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_wise_purity = []\n",
    "node_wise_purity_of_unmasked = []\n",
    "node_wise_purity_of_masked = []\n",
    "for csvfile_topk, node in zip(list_csvfile_topk, root.nodes_with_children()):\n",
    "\n",
    "    if node.name not in subtree_root.descendents:\n",
    "        print('Skipping node', node.name)\n",
    "        continue\n",
    "        \n",
    "    node_purity, max_presence_purity = eval_prototypes_cub_parts_csv_nodewise_maxmin(node, csvfile_topk, part_locs_file, parts_name_path, \\\n",
    "                              imgs_id_path, 'projectloader_topk_'+str(epoch), args, desc_threshold=0.2)\n",
    "    node_wise_purity.append(node_purity)\n",
    "    proto_presence = getattr(net.module, '_'+node.name+'_proto_presence')\n",
    "    node_wise_purity_of_unmasked.append(np.mean([max_presence_purity[p] for p in max_presence_purity if (proto_presence[int(p), 0] < proto_presence[int(p), 1])]))\n",
    "    node_wise_purity_of_masked.append(np.mean([max_presence_purity[p] for p in max_presence_purity if (proto_presence[int(p), 0] > proto_presence[int(p), 1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364390d0-62f7-4a6a-880e-1290302d98a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before masking')\n",
    "print(np.mean(node_wise_purity))\n",
    "print(np.std(node_wise_purity))\n",
    "print(np.nanmean(node_wise_purity))\n",
    "print(np.nanstd(node_wise_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9b1664-25c9-4a4d-ba3c-2f90baff26c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After masking (of unmasked protos)')\n",
    "print(np.mean(node_wise_purity_of_unmasked))\n",
    "print(np.std(node_wise_purity_of_unmasked))\n",
    "print(np.nanmean(node_wise_purity_of_unmasked))\n",
    "print(np.nanstd(node_wise_purity_of_unmasked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71c786-5576-463c-9369-08aee15d14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Of masked protos')\n",
    "print(np.mean(node_wise_purity_of_masked))\n",
    "print(np.std(node_wise_purity_of_masked))\n",
    "print(np.nanmean(node_wise_purity_of_masked))\n",
    "print(np.nanstd(node_wise_purity_of_masked))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006c62c-793f-4250-a08f-73e6296e3264",
   "metadata": {},
   "source": [
    "# Ratio of good protos / Total protos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42fb9b-b99c-4800-a94b-8b5d8893a01d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "total_relevant_protos = 0.\n",
    "total_good_protos = 0.\n",
    "\n",
    "with torch.no_grad():\n",
    "    for node in root.nodes_with_children():\n",
    "        label_to_children = {v: k for k, v in node.children_to_labels.items()}\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "        proto_presence = getattr(net.module, '_'+node.name+'_proto_presence')\n",
    "        proto_presence = F.gumbel_softmax(proto_presence, tau=0.5, hard=True, dim=-1)\n",
    "        masked_classification_weights = proto_presence[:, 1].unsqueeze(0) * classification_weights\n",
    "        all_protos_masked = False\n",
    "        for class_idx in range(masked_classification_weights.shape[0]):\n",
    "            # print(node.name, label_to_children[class_idx], 'relevant:', (classification_weights[class_idx, :] > 1e-3).sum().item(), \\\n",
    "            #       'Good ones:', (masked_classification_weights[class_idx, :] > 1e-3).sum().item(), \\\n",
    "            #       'Good proto idxs:', torch.nonzero(masked_classification_weights[class_idx, :] > 1e-3).reshape(-1))\n",
    "            print(node.name, label_to_children[class_idx], 'Good/Total:', f'{(masked_classification_weights[class_idx, :] > 1e-3).sum().item()}/{(classification_weights[class_idx, :] > 1e-3).sum().item()}', \\\n",
    "                 'Good proto idxs:', torch.nonzero(masked_classification_weights[class_idx, :] > 1e-3).reshape(-1))\n",
    "            total_relevant_protos += (classification_weights[class_idx, :] > 1e-3).sum().item()\n",
    "            total_good_protos += (masked_classification_weights[class_idx, :] > 1e-3).sum().item()\n",
    "\n",
    "print('Total protos:', total_relevant_protos, 'Total good protos:', total_good_protos, 'Ratio:', total_good_protos/total_relevant_protos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e596e3-663a-493a-af21-c92bf10f2ec5",
   "metadata": {},
   "source": [
    "# Visualizing part locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3cc23-6f4b-4f3f-9c33-9e6f5d4623b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# proto_parts_presences['17']\n",
    "\n",
    "import pandas as pd\n",
    "# df = pd.read_csv(list_csvfile_topk[0])\n",
    "# df = pd.read_csv('runs/154-PruningNaiveHPIPNet_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20/node_wise_top10/004+032_prototypes_top10_projectloader_last.csv')\n",
    "df = pd.read_csv('runs/154-PruningNaiveHPIPNet_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20/node_wise_top10/root_prototypes_top10_projectloader_last.csv')\n",
    "print(list_csvfile_topk[0])\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec32e6-d9af-4978-8111-07769caf6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_node_wise_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d4e80-4b4a-4b6d-b842-516de8a9607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "part_color_map = {\n",
    "    1: 'red',\n",
    "    2: 'blue',\n",
    "    3: 'green',\n",
    "    4: 'yellow',\n",
    "    5: 'orange',\n",
    "    6: 'purple',\n",
    "    7: 'pink',\n",
    "    8: 'brown',\n",
    "    9: 'black',\n",
    "    10: 'white',\n",
    "    11: 'gray',\n",
    "    12: 'cyan',\n",
    "    13: 'magenta',\n",
    "    14: 'lime',\n",
    "    15: 'navy'\n",
    "}\n",
    "\n",
    "# Function to draw parts on an image\n",
    "def draw_parts(img, part_locs):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    img_width, img_height = img.size\n",
    "    for part_id, x_norm, y_norm, visible in part_locs:\n",
    "        if visible:\n",
    "            x = int(x_norm * img_width)\n",
    "            y = int(y_norm * img_height)\n",
    "            draw.ellipse((x - 2, y - 2, x + 2, y + 2), outline=\"red\", fill=part_color_map[part_id])\n",
    "    return img\n",
    "\n",
    "def add_heatmap(latent_activation, input_image, only_peak=False, interpolate=True):\n",
    "    \"\"\"\n",
    "    latent_activation -> np array of shape (H, W)\n",
    "    input_image -> PIL image of size (H, W)\n",
    "    \"\"\"\n",
    "    image_a = latent_activation#.cpu().numpy()\n",
    "    # image_a[image_a != image_a.max()] = 0\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "    \n",
    "    input_image = np.array(input_image)\n",
    "    image_b = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "\n",
    "    if interpolate:\n",
    "        reshaped_image_a = np.array(Image.fromarray((image_a * 255).astype('uint8'))\\\n",
    "                                    .resize((input_image.shape[0], input_image.shape[1])))\n",
    "    else:\n",
    "        reshaped_image_a = np.array(Image.fromarray((image_a * 255).astype('uint8'))\\\n",
    "                                    .resize((input_image.shape[0], input_image.shape[1]), resample=Image.NEAREST))\n",
    "\n",
    "    reshaped_image_a[reshaped_image_a != reshaped_image_a.max()] = 0\n",
    "    \n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "#     pdb.set_trace()\n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.7)\n",
    "    \n",
    "    return result_image\n",
    "\n",
    "# Function to display images in a Jupyter notebook\n",
    "def display_images(images, titles=None, bboxes=None):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, img in enumerate(images, 1):\n",
    "        plt.subplot(4, 5, i)\n",
    "        plt.imshow(img)\n",
    "\n",
    "        if bboxes:\n",
    "            h_min_224, h_max_224, w_min_224, w_max_224 = bboxes[i-1]\n",
    "            rect = patches.Rectangle((w_min_224, h_min_224), w_max_224 - w_min_224, h_max_224 - h_min_224,\n",
    "                                 linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax = plt.gca()\n",
    "            ax.add_patch(rect)\n",
    "        if titles:\n",
    "            plt.title(titles[i-1])\n",
    "        # plt.axis('off')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "# Randomly sample 10 images\n",
    "# sampled_images = random.sample((dict_node_wise_df['052+053'][(dict_node_wise_df['052+053']['prototype'] == 12) & (dict_node_wise_df['052+053']['leaf'] == '050')][[\"node\", \"prototype\", 'img name', 'scores', 'h_min_224', 'h_max_224', 'w_min_224', 'w_max_224', 'latent_activation']].values).tolist(), 10)\n",
    "sampled_images = random.sample((dict_node_wise_df['054+016'][[\"node\", \"prototype\", 'img name', 'scores', 'h_min_224', 'h_max_224', 'w_min_224', 'w_max_224', 'latent_activation']].values).tolist(), 10)\n",
    "sampled_images = sorted(sampled_images, key=lambda x: x[3])[::-1]\n",
    "# sampled_images = random.sample((df[(df['prototype'] == 10) & (df['leaf'] == '001')][[\"node\", \"prototype\", 'img name', 'scores', 'h_min_224', 'h_max_224', 'w_min_224', 'w_max_224', 'latent_activation']].values).tolist(), 10)\n",
    "# sampled_images = random.sample((df[df['max_part_activation'] > 0.7][['img_filename', 'img_path', 'activation']].values).tolist(), 1)\n",
    "# sampled_images = random.sample((df[['img_filename', 'img_path', 'activation']].values).tolist(), 1)\n",
    "# print(sampled_images)\n",
    "\n",
    "\n",
    "# Draw parts or heatmap on the images\n",
    "sampled_images_with_parts = []\n",
    "sampled_images_bboxes = []\n",
    "sampled_images_titles = []\n",
    "for node_name, prototype_idx, img_path, score, h_min_224, h_max_224, w_min_224, w_max_224, latent_activation in sampled_images:\n",
    "    # image_path = os.path.join(img_path)\n",
    "    img_filename = ntpath.basename(img_path)\n",
    "    img_index = img_filename_to_index[img_filename]\n",
    "    image = Image.open(img_path)\n",
    "    # pdb.set_trace()\n",
    "    image = add_heatmap(latent_activation.clone().detach().cpu().numpy(), image, only_peak=True, interpolate=False)\n",
    "    image = draw_parts(image, image_part_locs[img_index])\n",
    "    sampled_images_with_parts.append(image)\n",
    "    sampled_images_bboxes.append((h_min_224, h_max_224, w_min_224, w_max_224))\n",
    "    sampled_images_titles.append(f'{round(score)}, N:{node_name}, P:{prototype_idx}')\n",
    "\n",
    "\n",
    "# # Randomly sample 10 images\n",
    "# sampled_images = random.sample((df[[\"node\", \"prototype\", 'img name', 'scores', 'h_min_224', 'h_max_224', 'w_min_224', 'w_max_224']].values).tolist(), 10)\n",
    "# # sampled_images = random.sample((df[(df['prototype'] == 10) & (df['leaf'] == '001')][[\"node\", \"prototype\", 'img name', 'scores', 'h_min_224', 'h_max_224', 'w_min_224', 'w_max_224']].values).tolist(), 10)\n",
    "# # sampled_images = random.sample((df[df['max_part_activation'] > 0.7][['img_filename', 'img_path', 'activation']].values).tolist(), 1)\n",
    "# # sampled_images = random.sample((df[['img_filename', 'img_path', 'activation']].values).tolist(), 1)\n",
    "# # print(sampled_images)\n",
    "\n",
    "\n",
    "# # Draw parts or heatmap on the images\n",
    "# sampled_images_with_parts = []\n",
    "# sampled_images_bboxes = []\n",
    "# sampled_images_titles = []\n",
    "# for node_name, prototype_idx, img_path, score, h_min_224, h_max_224, w_min_224, w_max_224 in sampled_images:\n",
    "#     # image_path = os.path.join(img_path)\n",
    "#     img_filename = ntpath.basename(img_path)\n",
    "#     img_index = img_filename_to_index[img_filename]\n",
    "#     image = Image.open(img_path)\n",
    "#     # pdb.set_trace()\n",
    "#     # image = add_heatmap(latent_activation.clone().detach().cpu().numpy(), image)\n",
    "#     image = draw_parts(image, image_part_locs[img_index])\n",
    "#     sampled_images_with_parts.append(image)\n",
    "#     sampled_images_bboxes.append((h_min_224, h_max_224, w_min_224, w_max_224))\n",
    "#     sampled_images_titles.append(f'{round(score)}, N:{node_name}, P:{prototype_idx}')\n",
    "\n",
    "# Display the images with parts\n",
    "display_images(sampled_images_with_parts, titles=sampled_images_titles, bboxes=sampled_images_bboxes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8c199e-bea2-4e43-bb7f-3475c18758cb",
   "metadata": {},
   "source": [
    "# HPnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67194e-fe61-4472-86e0-3b613f4d02b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_path = \"HPnet_lambda/saved_models/024_vgg19-14_cub18-224-prop-resized_10protos_kaiming-normal_batch=80_push-every=5_joint-eps=50_with-pretraining_CEDA=True\"\n",
    "run_path = \"HPnet_lambda/saved_models/029_vgg19-7_cub190-224-prop-resized_10protos_kaiming-normal_batch=80_push-every=5_joint-eps=50_with-pretraining_CEDA=True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a5484-11e8-400d-9925-ccaee79e9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_folder_path = os.path.join(run_path, 'node_wise_top10')\n",
    "sample_csv_file = os.listdir(csv_folder_path)[0]\n",
    "sample_image_path = pd.read_csv(os.path.join(csv_folder_path, sample_csv_file))['img name'][0]\n",
    "print(sample_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4fc469-3df3-4607-963c-a6f37b652bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_name_path = 'data/CUB_200_2011/parts/parts.txt'\n",
    "imgs_id_path = 'data/CUB_200_2011/images_cub.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e38a0e8-414e-4bbf-b896-9636bf01c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_meta_file_base_path = os.path.dirname(os.path.dirname(sample_image_path))\n",
    "image_meta_filepath = os.path.join(image_meta_file_base_path, 'image_meta_file.json')\n",
    "\n",
    "import json\n",
    "\n",
    "with open(image_meta_filepath, 'r') as file:\n",
    "    image_meta = json.load(file)    \n",
    "print(image_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b79ff-cacf-4261-9018-fbaa70edd78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'data/CUB_200_2011/'  # part locs are loaded from here\n",
    "\n",
    "if image_meta['cropped'] and image_meta['padded']:\n",
    "    part_locs_file = os.path.join(dataset_path, 'parts', 'part_locs_normalized_after_cropped_after_padded.txt') \n",
    "    print('*-'*40)\n",
    "    print('\\t\\t\\tIMPORTANT: Using CROPPED and PADDED part locations')\n",
    "    print('*-'*40)\n",
    "elif not image_meta['cropped'] and image_meta['padded']:\n",
    "    part_locs_file = os.path.join(dataset_path, 'parts', 'part_locs_normalized_after_padded.txt') \n",
    "    print('*-'*40)\n",
    "    print('\\t\\t\\tIMPORTANT: Using NOT CROPPED and PADDED part locations')\n",
    "    print('*-'*40)\n",
    "elif image_meta['cropped'] and not image_meta['padded']:\n",
    "    part_locs_file = os.path.join(dataset_path, 'parts', 'part_locs_normalized_after_cropped.txt') \n",
    "    print('*-'*40)\n",
    "    print('\\t\\t\\tIMPORTANT: Using CROPPED and NOT PADDED part locations')\n",
    "    print('*-'*40)\n",
    "elif not image_meta['cropped'] and not image_meta['padded']:\n",
    "    part_locs_file = os.path.join(dataset_path, 'parts', 'part_locs_normalized.txt') \n",
    "    print('*-'*40)\n",
    "    print('\\t\\t\\tIMPORTANT: Using NOT CROPPED and NOT PADDED part locations')\n",
    "    print('*-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3079f58-6bab-4828-a0bb-679166af0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ntpath\n",
    "from collections import defaultdict\n",
    "\n",
    "NUM_PARTS = 15\n",
    "images_file = os.path.join(dataset_path, 'images_cub.txt')\n",
    "\n",
    "# Read the image index to filename mapping\n",
    "img_filename_to_index = {} # image filename to image index\n",
    "with open(images_file, 'r') as file:\n",
    "    for line in file:\n",
    "        index, filename = line.strip().split()\n",
    "        img_filename = ntpath.basename(filename)\n",
    "        img_filename_to_index[img_filename] = int(index)\n",
    "\n",
    "# Load part locations\n",
    "image_part_locs = defaultdict(list)\n",
    "with open(part_locs_file, 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split()\n",
    "        image_index, part_id, x, y, visible = int(parts[0]), int(parts[1]), float(parts[2]), float(parts[3]), bool(float(parts[4]))\n",
    "        image_part_locs[image_index].append((part_id, x, y, visible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c771d3-e385-4811-989a-7f1aaae9ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unshuffle_dataloader(dataloader):\n",
    "#     if type(dataloader.dataset) == ImageFolder:\n",
    "#         dataset = dataloader.dataset\n",
    "#     else:\n",
    "#         dataset = dataloader.dataset.dataset.dataset\n",
    "#     new_dataloader = DataLoader(\n",
    "#         dataset=dataset,\n",
    "#         batch_size=dataloader.batch_size,\n",
    "#         shuffle=False,\n",
    "#         num_workers=dataloader.num_workers,\n",
    "#         pin_memory=dataloader.pin_memory,\n",
    "#         drop_last=dataloader.drop_last,\n",
    "#         timeout=dataloader.timeout,\n",
    "#         worker_init_fn=dataloader.worker_init_fn,\n",
    "#         multiprocessing_context=dataloader.multiprocessing_context,\n",
    "#         generator=dataloader.generator,\n",
    "#         prefetch_factor=dataloader.prefetch_factor,'\n",
    "#         persistent_workers=dataloader.persistent_workers\n",
    "#     )\n",
    "#     return new_dataloader\n",
    "\n",
    "# projectloader = unshuffle_dataloader(projectloader)\n",
    "# print(projectloader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c67f8a-0863-41f1-80e1-7897b1277c0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_csvfile_topk = []\n",
    "list_node_wise_df = []\n",
    "dict_node_wise_df = {}\n",
    "\n",
    "node_wise_purity = []\n",
    "for csvfile_topk in os.listdir(csv_folder_path):\n",
    "    node_name = csvfile_topk.split('_')[0]\n",
    "    node = root.get_node(node_name)\n",
    "    csvfile_topk = os.path.join(csv_folder_path, csvfile_topk)\n",
    "    list_csvfile_topk.append(csvfile_topk)\n",
    "    dict_node_wise_df[node.name] = pd.read_csv(csvfile_topk)\n",
    "    # node_purity = eval_prototypes_cub_parts_csv_nodewise(node, csvfile_topk, part_locs_file, parts_name_path, \\\n",
    "    #                           imgs_id_path, 'projectloader_topk_'+str(epoch), args, desc_threshold=0.2)\n",
    "    node_purity, max_presence_purity  = eval_prototypes_cub_parts_csv_nodewise_maxmin(node, csvfile_topk, part_locs_file, parts_name_path, \\\n",
    "                              imgs_id_path, 'projectloader_topk_'+str(epoch), args, desc_threshold=0.2)\n",
    "    node_wise_purity.append(node_purity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1babdc11-0117-42b0-876b-fdd533614a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(node_wise_purity))\n",
    "print(np.nanstd(node_wise_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e9d92-5d33-40d6-89ec-21b5ce32c115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
