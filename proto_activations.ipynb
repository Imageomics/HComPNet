{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import sys, os\n",
    "import random\n",
    "import numpy as np\n",
    "from shutil import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/010-CUB-27-imgnet_OOD_cnext26_img=224_nprotos=20'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/031-CUB-18-imgnet_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/032-CUB-18-imgnet_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/035-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/043-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/036-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel_uniformity\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/041-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/042-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/044-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20-or-4per-desc_orth-on-rel\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/046-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=10per-desc_orth-on-rel\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/047-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=5per-desc_tanh-desc\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/048-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=5per-desc_tanh-desc_unit-sphere\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/051-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_tanh-desc_unit-sphere_AW=5-TW=2-UW=2-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/052-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=4per-desc_tanh-desc_unit-sphere_AW=5-TW=2-UW=2-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/055-CUB-18_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/056-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/057-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/058-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "\n",
    "# with unit sphere\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/059-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# unit sphere with softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/065-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# original hpipnet with 20 protos per node no KO, no OOD, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/062-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD\"\n",
    "\n",
    "# original hpipnet with 20 protos per node no KO, no OOD, WITH tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/063-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD_tanh-desc\"\n",
    "\n",
    "# with unit sphere but no AL+UNI\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/066-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_no-softmax_no-align_no-uni_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, with softmax, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/067-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, with softmax, no tanh-desc, INCORRECT\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/067-incorrect-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, no softmax, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/068-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 071 with bias\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/071-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_with-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 072 gumbel softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/072-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-gumbel-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 073 gumbel softmax, tau-1.0\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/073-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-gumbel-softmax-tau=1_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 075 068 with focal loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/075-068-with-focal_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_no-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 076 cs followed by softmax. Uses align_pf along with align+uni\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/076_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_align-pf-during-training_no-meanpool_no-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2-APW=5_batch=20\"\n",
    "\n",
    "# 074 multiply_cs_softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/074-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_multi-cs-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 077 unit sphere protopool with cosin no softmax constant 20 protos per node\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/077_CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20-sphere-protopool_finetune=5_align-pf-during-training_no-meanpool_no-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 082 unit sphere cs followed by softmax with minmazimize loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/082-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 083 unit sphere cs followed by softmax with minmazimize loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/083-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_no-align_no-uni_no-mm-loss_batch=48\"\n",
    "\n",
    "# 085 unit sphere cs followed by softmax-with-tau with minmazimize loss\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/085-notebook-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=12\"\n",
    "\n",
    "# 091 basic gaussian multiplier on stage 4\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/091-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_latent-dim=256_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 092 basic gaussian multiplier on stage 3, 4\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/092-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=3,4|1.0|50_img=224_latent-dim=256_nprotos=4per-leaf-desc_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=3-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 093 128 dim linear\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/093-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_latent-dim=128_nprotos=20_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=1-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "# 094 128 dim linear\n",
    "run_path = \"/home/harishbabu/projects/PIPNet/runs/094-CUB-18-imgnet_with-equalize-aug_cnext26_BGM=4|1.0|50_img=224_latent-dim=128_nprotos=20_unit-sphere_finetune=5_no-meanpool_with-softmax-tau=0.2_no-addon-bias_AW=3-TW=2-MMW=2-UW=1-CW=2_mm-loss_batch=48\"\n",
    "\n",
    "try:\n",
    "    sys.path.remove('/home/harishbabu/projects/PIPNet')\n",
    "except:\n",
    "    pass\n",
    "sys.path.insert(0, os.path.join(run_path, 'source_clone'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmaps showing where a prototype is found will not be generated because OpenCV is not installed.\n"
     ]
    }
   ],
   "source": [
    "from pipnet.pipnet import PIPNet, get_network\n",
    "from util.log import Log\n",
    "from util.args import get_args, save_args, get_optimizer_nn\n",
    "from util.data import get_dataloaders\n",
    "from util.func import init_weights_xavier\n",
    "from pipnet.train import train_pipnet, test_pipnet\n",
    "# from pipnet.test import eval_pipnet, get_thresholds, eval_ood\n",
    "from util.eval_cub_csv import eval_prototypes_cub_parts_csv, get_topk_cub, get_proto_patches_cub\n",
    "from util.vis_pipnet import visualize, visualize_topk\n",
    "from util.visualize_prediction import vis_pred, vis_pred_experiments\n",
    "from util.node import Node\n",
    "from util.phylo_utils import construct_phylo_tree, construct_discretized_phylo_tree\n",
    "from util.func import get_patch_size\n",
    "from util.data import ModifiedLabelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- No discretization -------------------------\n"
     ]
    }
   ],
   "source": [
    "args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "args = pickle.load(args_file)\n",
    "\n",
    "if args.phylo_config:\n",
    "    phylo_config = OmegaConf.load(args.phylo_config)\n",
    "\n",
    "if args.phylo_config:\n",
    "    # construct the phylo tree\n",
    "    if phylo_config.phyloDistances_string == 'None':\n",
    "        if '031' in run_path: # this run uses a different phylogeny file that had an extra root node which is a mistake\n",
    "            root = construct_phylo_tree('/home/harishbabu/data/phlyogenyCUB/18Species-with-extra-root-node/1_tree-consensus-Hacket-18Species-modified_cub-names_v1.phy')\n",
    "        else:\n",
    "            root = construct_phylo_tree(phylo_config.phylogeny_path)\n",
    "        print('-'*25 + ' No discretization ' + '-'*25)\n",
    "    else:\n",
    "        root = construct_discretized_phylo_tree(phylo_config.phylogeny_path, phylo_config.phyloDistances_string)\n",
    "        print('-'*25 + ' Discretized ' + '-'*25)\n",
    "else:\n",
    "    # construct the tree (original hierarchy as described in the paper)\n",
    "    root = Node(\"root\")\n",
    "    root.add_children(['animal','vehicle','everyday_object','weapon','scuba_diver'])\n",
    "    root.add_children_to('animal',['non_primate','primate'])\n",
    "    root.add_children_to('non_primate',['African_elephant','giant_panda','lion'])\n",
    "    root.add_children_to('primate',['capuchin','gibbon','orangutan'])\n",
    "    root.add_children_to('vehicle',['ambulance','pickup','sports_car'])\n",
    "    root.add_children_to('everyday_object',['laptop','sandal','wine_bottle'])\n",
    "    root.add_children_to('weapon',['assault_rifle','rifle'])\n",
    "    # flat root\n",
    "    # root.add_children(['scuba_diver','African_elephant','giant_panda','lion','capuchin','gibbon','orangutan','ambulance','pickup','sports_car','laptop','sandal','wine_bottle','assault_rifle','rifle'])\n",
    "root.assign_all_descendents()\n",
    "\n",
    "exp_no = int(os.path.basename(run_path)[:3])\n",
    "\n",
    "if exp_no < 77:\n",
    "    if ('num_protos_per_descendant' in args) and (args.num_protos_per_descendant > 0):\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(args.num_protos_per_descendant)\n",
    "else:\n",
    "    # update num of protos per node based on num_protos_per_descendant\n",
    "    if args.num_features == 0 and args.num_protos_per_descendant == 0:\n",
    "        raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "    for node in root.nodes_with_children():\n",
    "        node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                            min_protos=args.num_features,\\\n",
    "                            split_protos=('protopool' in args) and (args.protopool == 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "args.batch_size = 1\n",
    "\n",
    "print(args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 samples from trainloader\n",
      "Dropping 0 samples from trainloader_normal\n",
      "Dropping 0 samples from trainloader_normal_augment\n",
      "Num classes (k) =  18 ['cub_001_Black_footed_Albatross', 'cub_002_Laysan_Albatross', 'cub_003_Sooty_Albatross', 'cub_004_Groove_billed_Ani', 'cub_023_Brandt_Cormorant'] etc.\n",
      "1 1\n",
      "Classes:  {'cub_001_Black_footed_Albatross': 0, 'cub_002_Laysan_Albatross': 1, 'cub_003_Sooty_Albatross': 2, 'cub_004_Groove_billed_Ani': 3, 'cub_023_Brandt_Cormorant': 4, 'cub_024_Red_faced_Cormorant': 5, 'cub_025_Pelagic_Cormorant': 6, 'cub_031_Black_billed_Cuckoo': 7, 'cub_032_Mangrove_Cuckoo': 8, 'cub_033_Yellow_billed_Cuckoo': 9, 'cub_045_Northern_Fulmar': 10, 'cub_050_Eared_Grebe': 11, 'cub_051_Horned_Grebe': 12, 'cub_052_Pied_billed_Grebe': 13, 'cub_053_Western_Grebe': 14, 'cub_086_Pacific_Loon': 15, 'cub_100_Brown_Pelican': 16, 'cub_101_White_Pelican': 17}\n",
      "stage 4\n",
      "Added reducer stage4_reducer_0_conv 768 to 384\n",
      "Added reducer stage4_reducer_0_gelu\n",
      "Added reducer stage4_reducer_1_conv 384 to 128\n",
      "Added reducer stage4_reducer_1_gelu\n",
      "Number of prototypes:  20\n",
      "----------Prototypes per descendant: 0----------\n",
      "Assigned 20 protos to node root\n",
      "Assigned 20 protos to node 052+053\n",
      "Assigned 20 protos to node 004+086\n",
      "Assigned 20 protos to node 053+050\n",
      "Assigned 20 protos to node 004+032\n",
      "Assigned 20 protos to node 086+045\n",
      "Assigned 20 protos to node 050+051\n",
      "Assigned 20 protos to node 032+033\n",
      "Assigned 20 protos to node 045+101\n",
      "Assigned 20 protos to node 033+031\n",
      "Assigned 20 protos to node 045+003\n",
      "Assigned 20 protos to node 101+023\n",
      "Assigned 20 protos to node 003+002\n",
      "Assigned 20 protos to node 101+100\n",
      "Assigned 20 protos to node 023+025\n",
      "Assigned 20 protos to node 002+001\n",
      "Assigned 20 protos to node 025+024\n",
      "DataParallel(\n",
      "  (module): PIPNet(\n",
      "    (_net): Sequential(\n",
      "      (backbone): ConvNeXt(\n",
      "        (features): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "            (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "            )\n",
      "            (1): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
      "            )\n",
      "            (2): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
      "            )\n",
      "            (1): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
      "            )\n",
      "            (2): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
      "            )\n",
      "          )\n",
      "          (4): Sequential(\n",
      "            (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "            (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(1, 1))\n",
      "          )\n",
      "          (5): Sequential(\n",
      "            (0): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
      "            )\n",
      "            (1): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
      "            )\n",
      "            (2): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
      "            )\n",
      "            (3): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
      "            )\n",
      "            (4): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
      "            )\n",
      "            (5): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
      "            )\n",
      "            (6): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
      "            )\n",
      "            (7): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
      "            )\n",
      "            (8): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
      "            )\n",
      "          )\n",
      "          (6): Sequential(\n",
      "            (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(1, 1))\n",
      "          )\n",
      "          (7): Sequential(\n",
      "            (0): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): BasicGaussianMultiplierConv2D(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
      "            )\n",
      "            (1): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): BasicGaussianMultiplierConv2D(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
      "            )\n",
      "            (2): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): BasicGaussianMultiplierConv2D(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (avgpool): Identity()\n",
      "        (classifier): Identity()\n",
      "      )\n",
      "      (stage4_reducer_0_conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (stage4_reducer_0_gelu): GELU(approximate='none')\n",
      "      (stage4_reducer_1_conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (stage4_reducer_1_gelu): GELU(approximate='none')\n",
      "    )\n",
      "    (_root_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_052+053_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_004+086_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_053+050_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_004+032_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_086+045_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_050+051_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_032+033_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_045+101_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_033+031_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_045+003_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_101+023_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_003+002_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_101+100_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_023+025_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_002+001_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_025+024_add_on): UnitConv2D(128, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (_pool): Sequential(\n",
      "      (0): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "      (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (_avg_pool): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (_root_classification): NonNegLinear()\n",
      "    (_052+053_classification): NonNegLinear()\n",
      "    (_004+086_classification): NonNegLinear()\n",
      "    (_053+050_classification): NonNegLinear()\n",
      "    (_004+032_classification): NonNegLinear()\n",
      "    (_086+045_classification): NonNegLinear()\n",
      "    (_050+051_classification): NonNegLinear()\n",
      "    (_032+033_classification): NonNegLinear()\n",
      "    (_045+101_classification): NonNegLinear()\n",
      "    (_033+031_classification): NonNegLinear()\n",
      "    (_045+003_classification): NonNegLinear()\n",
      "    (_101+023_classification): NonNegLinear()\n",
      "    (_003+002_classification): NonNegLinear()\n",
      "    (_101+100_classification): NonNegLinear()\n",
      "    (_023+025_classification): NonNegLinear()\n",
      "    (_002+001_classification): NonNegLinear()\n",
      "    (_025+024_classification): NonNegLinear()\n",
      "    (_softmax): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    device_ids = [torch.cuda.current_device()]\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    device_ids = []\n",
    "\n",
    "# args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "# args = pickle.load(args_file)\n",
    "\n",
    "# ckpt_file_name = 'net_overspecific_pruned_replaced_thresh=0.5_last'\n",
    "ckpt_file_name = 'net_trained_last'\n",
    "# ckpt_file_name = 'net_trained_10'\n",
    "# ckpt_file_name = 'net_pretrained'\n",
    "epoch = ckpt_file_name.split('_')[-1]\n",
    "\n",
    "ckpt_path = os.path.join(run_path, 'checkpoints', ckpt_file_name)\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "if ckpt_file_name != 'net_trained_last':\n",
    "    print('\\n', (10*'-')+'WARNING: Not using the final trained model'+(10*'-'), '\\n')\n",
    "\n",
    "# Obtain the dataset and dataloaders\n",
    "trainloader, trainloader_pretraining, trainloader_normal, trainloader_normal_augment, projectloader, testloader, test_projectloader, classes = get_dataloaders(args, device)\n",
    "\n",
    "print(args.batch_size, trainloader.batch_size)\n",
    "\n",
    "if len(classes)<=20:\n",
    "    if args.validation_size == 0.:\n",
    "        print(\"Classes: \", testloader.dataset.class_to_idx, flush=True)\n",
    "    else:\n",
    "        print(\"Classes: \", str(classes), flush=True)\n",
    "\n",
    "# Create a convolutional network based on arguments and add 1x1 conv layer\n",
    "feature_net, add_on_layers, pool_layer, classification_layers, num_prototypes = get_network(len(classes), args, root=root)\n",
    "   \n",
    "# Create a PIP-Net\n",
    "net = PIPNet(num_classes=len(classes),\n",
    "                    num_prototypes=num_prototypes,\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "net = net.to(device=device)\n",
    "net = nn.DataParallel(net, device_ids = device_ids)    \n",
    "net.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "print(net.eval())\n",
    "criterion = nn.NLLLoss(reduction='mean').to(device)\n",
    "\n",
    "# Forward one batch through the backbone to get the latent output size\n",
    "# with torch.no_grad():\n",
    "#     xs1, _, _ = next(iter(trainloader))\n",
    "#     xs1 = xs1.to(device)\n",
    "#     proto_features, _, _ = net(xs1)\n",
    "#     wshape = proto_features['root'].shape[-1]\n",
    "#     args.wshape = wshape #needed for calculating image patch size\n",
    "#     print(\"Output shape: \", proto_features['root'].shape, flush=True)\n",
    "    \n",
    "args.wshape = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4|1.0|50'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.basic_cnext_gaussian_multiplier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on Grand children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:14, 37.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "052+004\n",
      "\t 052+053\n",
      "\t\tProto:0 053+051:0.42/90 cub_052_Pied_billed_Grebe:0.0/30 \n",
      "\t\tProto:36 053+051:0.08/90 cub_052_Pied_billed_Grebe:0.29/30 \n",
      "\t\tProto:5 053+051:0.17/90 cub_052_Pied_billed_Grebe:0.16/30 \n",
      "\t\tProto:43 053+051:0.32/90 cub_052_Pied_billed_Grebe:0.37/30 \n",
      "\t\tProto:13 053+051:0.38/90 cub_052_Pied_billed_Grebe:0.49/30 \n",
      "\t\tProto:46 053+051:0.47/90 cub_052_Pied_billed_Grebe:0.01/30 \n",
      "\t\tProto:16 053+051:0.46/90 cub_052_Pied_billed_Grebe:0.0/30 \n",
      "\t\tProto:17 053+051:0.34/90 cub_052_Pied_billed_Grebe:0.03/30 \n",
      "\t\tProto:23 053+051:0.03/90 cub_052_Pied_billed_Grebe:0.46/30 \n",
      "\t\tProto:31 053+051:0.2/90 cub_052_Pied_billed_Grebe:0.06/30 \n",
      "\t 004+086\n",
      "\t\tProto:2 086+045:0.18/300 004+032:0.12/120 \n",
      "\t\tProto:3 086+045:0.19/300 004+032:0.16/120 \n",
      "\t\tProto:4 086+045:0.32/300 004+032:0.18/120 \n",
      "\t\tProto:7 086+045:0.19/300 004+032:0.35/120 \n",
      "\t\tProto:8 086+045:0.12/300 004+032:0.24/120 \n",
      "\t\tProto:10 086+045:0.0/300 004+032:0.51/120 \n",
      "\t\tProto:11 086+045:0.27/300 004+032:0.06/120 \n",
      "\t\tProto:12 086+045:0.03/300 004+032:0.35/120 \n",
      "\t\tProto:14 086+045:0.31/300 004+032:0.01/120 \n",
      "\t\tProto:15 086+045:0.07/300 004+032:0.03/120 \n",
      "\t\tProto:18 086+045:0.13/300 004+032:0.18/120 \n",
      "\t\tProto:19 086+045:0.26/300 004+032:0.03/120 \n",
      "\t\tProto:22 086+045:0.09/300 004+032:0.16/120 \n",
      "\t\tProto:24 086+045:0.11/300 004+032:0.14/120 \n",
      "\t\tProto:26 086+045:0.13/300 004+032:0.32/120 \n",
      "\t\tProto:27 086+045:0.21/300 004+032:0.38/120 \n",
      "\t\tProto:28 086+045:0.03/300 004+032:0.13/120 \n",
      "\t\tProto:30 086+045:0.12/300 004+032:0.17/120 \n",
      "\t\tProto:32 086+045:0.22/300 004+032:0.13/120 \n",
      "\t\tProto:33 086+045:0.25/300 004+032:0.04/120 \n",
      "\t\tProto:34 086+045:0.16/300 004+032:0.11/120 \n",
      "\t\tProto:35 086+045:0.11/300 004+032:0.13/120 \n",
      "\t\tProto:37 086+045:0.23/300 004+032:0.01/120 \n",
      "\t\tProto:39 086+045:0.32/300 004+032:0.01/120 \n",
      "\t\tProto:40 086+045:0.11/300 004+032:0.16/120 \n",
      "\t\tProto:41 086+045:0.11/300 004+032:0.17/120 \n",
      "\t\tProto:44 086+045:0.01/300 004+032:0.55/120 \n",
      "\t\tProto:47 086+045:0.13/300 004+032:0.09/120 \n",
      "\t\tProto:48 086+045:0.12/300 004+032:0.18/120 \n",
      "\t\tProto:49 086+045:0.06/300 004+032:0.22/120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 36.07it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "052+053\n",
      "\t 053+051\n",
      "\t\tProto:2 051+050:0.49/60 cub_053_Western_Grebe:0.06/30 \n",
      "\t\tProto:4 051+050:0.26/60 cub_053_Western_Grebe:0.39/30 \n",
      "\t\tProto:5 051+050:0.11/60 cub_053_Western_Grebe:0.1/30 \n",
      "\t\tProto:6 051+050:0.38/60 cub_053_Western_Grebe:0.72/30 \n",
      "\t\tProto:7 051+050:0.17/60 cub_053_Western_Grebe:0.63/30 \n",
      "\t\tProto:9 051+050:0.42/60 cub_053_Western_Grebe:0.83/30 \n",
      "\t\tProto:10 051+050:0.14/60 cub_053_Western_Grebe:0.74/30 \n",
      "\t\tProto:11 051+050:0.69/60 cub_053_Western_Grebe:0.67/30 \n",
      "\t\tProto:15 051+050:0.4/60 cub_053_Western_Grebe:0.9/30 \n",
      "\t\tProto:16 051+050:0.52/60 cub_053_Western_Grebe:0.43/30 \n",
      "\t\tProto:17 051+050:0.74/60 cub_053_Western_Grebe:0.46/30 \n",
      "\t\tProto:18 051+050:0.47/60 cub_053_Western_Grebe:0.24/30 \n",
      "\t\tProto:20 051+050:0.18/60 cub_053_Western_Grebe:0.62/30 \n",
      "\t\tProto:21 051+050:0.19/60 cub_053_Western_Grebe:0.26/30 \n",
      "\t\tProto:22 051+050:0.35/60 cub_053_Western_Grebe:0.07/30 \n",
      "\t\tProto:23 051+050:0.31/60 cub_053_Western_Grebe:0.01/30 \n",
      "\t\tProto:24 051+050:0.41/60 cub_053_Western_Grebe:0.58/30 \n",
      "\t\tProto:26 051+050:0.32/60 cub_053_Western_Grebe:0.41/30 \n",
      "\t\tProto:27 051+050:0.37/60 cub_053_Western_Grebe:0.53/30 \n",
      "\t\tProto:34 051+050:0.46/60 cub_053_Western_Grebe:0.2/30 \n",
      "\t\tProto:36 051+050:0.47/60 cub_053_Western_Grebe:0.83/30 \n",
      "\t\tProto:38 051+050:0.12/60 cub_053_Western_Grebe:0.76/30 \n",
      "\t\tProto:39 051+050:0.56/60 cub_053_Western_Grebe:0.08/30 \n",
      "\t\tProto:43 051+050:0.44/60 cub_053_Western_Grebe:0.19/30 \n",
      "\t\tProto:45 051+050:0.68/60 cub_053_Western_Grebe:0.6/30 \n",
      "\t\tProto:46 051+050:0.67/60 cub_053_Western_Grebe:0.03/30 \n",
      "\t\tProto:48 051+050:0.28/60 cub_053_Western_Grebe:0.0/30 \n",
      "\t\tProto:49 051+050:0.34/60 cub_053_Western_Grebe:0.0/30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:11, 36.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004+086\n",
      "\t 086+045\n",
      "\t\tProto:1 045+100:0.18/270 cub_086_Pacific_Loon:0.48/30 \n",
      "\t\tProto:4 045+100:0.4/270 cub_086_Pacific_Loon:0.33/30 \n",
      "\t\tProto:5 045+100:0.13/270 cub_086_Pacific_Loon:0.0/30 \n",
      "\t\tProto:10 045+100:0.46/270 cub_086_Pacific_Loon:0.53/30 \n",
      "\t\tProto:11 045+100:0.31/270 cub_086_Pacific_Loon:0.01/30 \n",
      "\t\tProto:13 045+100:0.31/270 cub_086_Pacific_Loon:0.0/30 \n",
      "\t\tProto:14 045+100:0.16/270 cub_086_Pacific_Loon:0.27/30 \n",
      "\t\tProto:17 045+100:0.45/270 cub_086_Pacific_Loon:0.08/30 \n",
      "\t\tProto:19 045+100:0.24/270 cub_086_Pacific_Loon:0.0/30 \n",
      "\t\tProto:21 045+100:0.12/270 cub_086_Pacific_Loon:0.25/30 \n",
      "\t\tProto:28 045+100:0.23/270 cub_086_Pacific_Loon:0.35/30 \n",
      "\t\tProto:29 045+100:0.15/270 cub_086_Pacific_Loon:0.28/30 \n",
      "\t\tProto:32 045+100:0.32/270 cub_086_Pacific_Loon:0.6/30 \n",
      "\t\tProto:38 045+100:0.21/270 cub_086_Pacific_Loon:0.01/30 \n",
      "\t\tProto:39 045+100:0.29/270 cub_086_Pacific_Loon:0.03/30 \n",
      "\t\tProto:40 045+100:0.16/270 cub_086_Pacific_Loon:0.2/30 \n",
      "\t\tProto:41 045+100:0.15/270 cub_086_Pacific_Loon:0.28/30 \n",
      "\t\tProto:42 045+100:0.2/270 cub_086_Pacific_Loon:0.11/30 \n",
      "\t\tProto:43 045+100:0.22/270 cub_086_Pacific_Loon:0.07/30 \n",
      "\t\tProto:45 045+100:0.19/270 cub_086_Pacific_Loon:0.54/30 \n",
      "\t\tProto:46 045+100:0.16/270 cub_086_Pacific_Loon:0.01/30 \n",
      "\t\tProto:48 045+100:0.15/270 cub_086_Pacific_Loon:0.38/30 \n",
      "\t\tProto:49 045+100:0.11/270 cub_086_Pacific_Loon:0.06/30 \n",
      "\t 004+032\n",
      "\t\tProto:33 cub_004_Groove_billed_Ani:0.0/30 032+031:0.34/90 \n",
      "\t\tProto:35 cub_004_Groove_billed_Ani:0.0/30 032+031:0.41/90 \n",
      "\t\tProto:36 cub_004_Groove_billed_Ani:0.53/30 032+031:0.03/90 \n",
      "\t\tProto:6 cub_004_Groove_billed_Ani:0.25/30 032+031:0.21/90 \n",
      "\t\tProto:7 cub_004_Groove_billed_Ani:0.0/30 032+031:0.47/90 \n",
      "\t\tProto:8 cub_004_Groove_billed_Ani:0.0/30 032+031:0.72/90 \n",
      "\t\tProto:9 cub_004_Groove_billed_Ani:0.63/30 032+031:0.68/90 \n",
      "\t\tProto:12 cub_004_Groove_billed_Ani:0.0/30 032+031:0.28/90 \n",
      "\t\tProto:15 cub_004_Groove_billed_Ani:0.32/30 032+031:0.31/90 \n",
      "\t\tProto:22 cub_004_Groove_billed_Ani:0.24/30 032+031:0.37/90 \n",
      "\t\tProto:23 cub_004_Groove_billed_Ani:0.12/30 032+031:0.19/90 \n",
      "\t\tProto:24 cub_004_Groove_billed_Ani:0.2/30 032+031:0.66/90 \n",
      "\t\tProto:25 cub_004_Groove_billed_Ani:0.11/30 032+031:0.18/90 \n",
      "\t\tProto:27 cub_004_Groove_billed_Ani:0.19/30 032+031:0.39/90 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 35.97it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "053+051\n",
      "\t 051+050\n",
      "\t\tProto:3 cub_050_Eared_Grebe:0.21/30 cub_051_Horned_Grebe:0.4/30 \n",
      "\t\tProto:5 cub_050_Eared_Grebe:0.05/30 cub_051_Horned_Grebe:0.2/30 \n",
      "\t\tProto:8 cub_050_Eared_Grebe:0.11/30 cub_051_Horned_Grebe:0.23/30 \n",
      "\t\tProto:9 cub_050_Eared_Grebe:0.57/30 cub_051_Horned_Grebe:0.6/30 \n",
      "\t\tProto:10 cub_050_Eared_Grebe:0.46/30 cub_051_Horned_Grebe:0.62/30 \n",
      "\t\tProto:11 cub_050_Eared_Grebe:0.41/30 cub_051_Horned_Grebe:0.5/30 \n",
      "\t\tProto:12 cub_050_Eared_Grebe:0.74/30 cub_051_Horned_Grebe:0.73/30 \n",
      "\t\tProto:13 cub_050_Eared_Grebe:0.58/30 cub_051_Horned_Grebe:0.58/30 \n",
      "\t\tProto:16 cub_050_Eared_Grebe:0.55/30 cub_051_Horned_Grebe:0.39/30 \n",
      "\t\tProto:17 cub_050_Eared_Grebe:0.5/30 cub_051_Horned_Grebe:0.63/30 \n",
      "\t\tProto:18 cub_050_Eared_Grebe:0.22/30 cub_051_Horned_Grebe:0.45/30 \n",
      "\t\tProto:20 cub_050_Eared_Grebe:0.16/30 cub_051_Horned_Grebe:0.3/30 \n",
      "\t\tProto:25 cub_050_Eared_Grebe:0.27/30 cub_051_Horned_Grebe:0.47/30 \n",
      "\t\tProto:32 cub_050_Eared_Grebe:0.33/30 cub_051_Horned_Grebe:0.34/30 \n",
      "\t\tProto:36 cub_050_Eared_Grebe:0.44/30 cub_051_Horned_Grebe:0.5/30 \n",
      "\t\tProto:38 cub_050_Eared_Grebe:0.31/30 cub_051_Horned_Grebe:0.51/30 \n",
      "\t\tProto:42 cub_050_Eared_Grebe:0.41/30 cub_051_Horned_Grebe:0.38/30 \n",
      "\t\tProto:43 cub_050_Eared_Grebe:0.35/30 cub_051_Horned_Grebe:0.37/30 \n",
      "\t\tProto:45 cub_050_Eared_Grebe:0.22/30 cub_051_Horned_Grebe:0.48/30 \n",
      "\t\tProto:47 cub_050_Eared_Grebe:0.53/30 cub_051_Horned_Grebe:0.57/30 \n",
      "\t\tProto:48 cub_050_Eared_Grebe:0.25/30 cub_051_Horned_Grebe:0.33/30 \n",
      "\t\tProto:49 cub_050_Eared_Grebe:0.54/30 cub_051_Horned_Grebe:0.61/30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 38.02it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004+032\n",
      "\t 032+031\n",
      "\t\tProto:0 031+033:0.2/60 cub_032_Mangrove_Cuckoo:0.69/30 \n",
      "\t\tProto:1 031+033:0.62/60 cub_032_Mangrove_Cuckoo:0.51/30 \n",
      "\t\tProto:4 031+033:0.5/60 cub_032_Mangrove_Cuckoo:0.13/30 \n",
      "\t\tProto:5 031+033:0.56/60 cub_032_Mangrove_Cuckoo:0.57/30 \n",
      "\t\tProto:6 031+033:0.52/60 cub_032_Mangrove_Cuckoo:0.39/30 \n",
      "\t\tProto:7 031+033:0.31/60 cub_032_Mangrove_Cuckoo:0.35/30 \n",
      "\t\tProto:9 031+033:0.6/60 cub_032_Mangrove_Cuckoo:0.4/30 \n",
      "\t\tProto:12 031+033:0.64/60 cub_032_Mangrove_Cuckoo:0.61/30 \n",
      "\t\tProto:16 031+033:0.35/60 cub_032_Mangrove_Cuckoo:0.72/30 \n",
      "\t\tProto:17 031+033:0.32/60 cub_032_Mangrove_Cuckoo:0.23/30 \n",
      "\t\tProto:18 031+033:0.58/60 cub_032_Mangrove_Cuckoo:0.14/30 \n",
      "\t\tProto:19 031+033:0.36/60 cub_032_Mangrove_Cuckoo:0.41/30 \n",
      "\t\tProto:20 031+033:0.48/60 cub_032_Mangrove_Cuckoo:0.37/30 \n",
      "\t\tProto:22 031+033:0.54/60 cub_032_Mangrove_Cuckoo:0.22/30 \n",
      "\t\tProto:27 031+033:0.42/60 cub_032_Mangrove_Cuckoo:0.44/30 \n",
      "\t\tProto:30 031+033:0.07/60 cub_032_Mangrove_Cuckoo:0.14/30 \n",
      "\t\tProto:31 031+033:0.31/60 cub_032_Mangrove_Cuckoo:0.37/30 \n",
      "\t\tProto:32 031+033:0.68/60 cub_032_Mangrove_Cuckoo:0.39/30 \n",
      "\t\tProto:36 031+033:0.37/60 cub_032_Mangrove_Cuckoo:0.07/30 \n",
      "\t\tProto:37 031+033:0.38/60 cub_032_Mangrove_Cuckoo:0.25/30 \n",
      "\t\tProto:38 031+033:0.46/60 cub_032_Mangrove_Cuckoo:0.47/30 \n",
      "\t\tProto:40 031+033:0.47/60 cub_032_Mangrove_Cuckoo:0.47/30 \n",
      "\t\tProto:45 031+033:0.32/60 cub_032_Mangrove_Cuckoo:0.45/30 \n",
      "\t\tProto:49 031+033:0.38/60 cub_032_Mangrove_Cuckoo:0.36/30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:08, 37.36it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "086+045\n",
      "\t 045+100\n",
      "\t\tProto:2 045+003:0.02/120 100+023:0.37/150 \n",
      "\t\tProto:3 045+003:0.07/120 100+023:0.27/150 \n",
      "\t\tProto:5 045+003:0.24/120 100+023:0.12/150 \n",
      "\t\tProto:6 045+003:0.14/120 100+023:0.25/150 \n",
      "\t\tProto:7 045+003:0.05/120 100+023:0.16/150 \n",
      "\t\tProto:9 045+003:0.15/120 100+023:0.14/150 \n",
      "\t\tProto:10 045+003:0.14/120 100+023:0.18/150 \n",
      "\t\tProto:11 045+003:0.22/120 100+023:0.13/150 \n",
      "\t\tProto:12 045+003:0.1/120 100+023:0.24/150 \n",
      "\t\tProto:14 045+003:0.22/120 100+023:0.1/150 \n",
      "\t\tProto:17 045+003:0.15/120 100+023:0.09/150 \n",
      "\t\tProto:18 045+003:0.22/120 100+023:0.17/150 \n",
      "\t\tProto:19 045+003:0.19/120 100+023:0.22/150 \n",
      "\t\tProto:20 045+003:0.47/120 100+023:0.01/150 \n",
      "\t\tProto:21 045+003:0.47/120 100+023:0.02/150 \n",
      "\t\tProto:23 045+003:0.05/120 100+023:0.14/150 \n",
      "\t\tProto:24 045+003:0.23/120 100+023:0.15/150 \n",
      "\t\tProto:25 045+003:0.1/120 100+023:0.16/150 \n",
      "\t\tProto:26 045+003:0.05/120 100+023:0.26/150 \n",
      "\t\tProto:27 045+003:0.16/120 100+023:0.14/150 \n",
      "\t\tProto:29 045+003:0.14/120 100+023:0.34/150 \n",
      "\t\tProto:30 045+003:0.07/120 100+023:0.34/150 \n",
      "\t\tProto:31 045+003:0.37/120 100+023:0.02/150 \n",
      "\t\tProto:32 045+003:0.22/120 100+023:0.05/150 \n",
      "\t\tProto:33 045+003:0.01/120 100+023:0.28/150 \n",
      "\t\tProto:34 045+003:0.03/120 100+023:0.35/150 \n",
      "\t\tProto:35 045+003:0.17/120 100+023:0.29/150 \n",
      "\t\tProto:36 045+003:0.31/120 100+023:0.12/150 \n",
      "\t\tProto:41 045+003:0.1/120 100+023:0.19/150 \n",
      "\t\tProto:42 045+003:0.18/120 100+023:0.15/150 \n",
      "\t\tProto:43 045+003:0.12/120 100+023:0.19/150 \n",
      "\t\tProto:44 045+003:0.17/120 100+023:0.3/150 \n",
      "\t\tProto:45 045+003:0.24/120 100+023:0.12/150 \n",
      "\t\tProto:46 045+003:0.27/120 100+023:0.11/150 \n",
      "\t\tProto:47 045+003:0.2/120 100+023:0.06/150 \n",
      "\t\tProto:48 045+003:0.26/120 100+023:0.24/150 \n",
      "\t\tProto:49 045+003:0.11/120 100+023:0.27/150 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 36.15it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "032+031\n",
      "\t 031+033\n",
      "\t\tProto:1 cub_031_Black_billed_Cuckoo:0.28/30 cub_033_Yellow_billed_Cuckoo:0.44/30 \n",
      "\t\tProto:33 cub_031_Black_billed_Cuckoo:0.39/30 cub_033_Yellow_billed_Cuckoo:0.7/30 \n",
      "\t\tProto:35 cub_031_Black_billed_Cuckoo:0.67/30 cub_033_Yellow_billed_Cuckoo:0.51/30 \n",
      "\t\tProto:4 cub_031_Black_billed_Cuckoo:0.85/30 cub_033_Yellow_billed_Cuckoo:0.3/30 \n",
      "\t\tProto:36 cub_031_Black_billed_Cuckoo:0.67/30 cub_033_Yellow_billed_Cuckoo:0.48/30 \n",
      "\t\tProto:37 cub_031_Black_billed_Cuckoo:0.39/30 cub_033_Yellow_billed_Cuckoo:0.35/30 \n",
      "\t\tProto:43 cub_031_Black_billed_Cuckoo:0.64/30 cub_033_Yellow_billed_Cuckoo:0.39/30 \n",
      "\t\tProto:13 cub_031_Black_billed_Cuckoo:0.55/30 cub_033_Yellow_billed_Cuckoo:0.44/30 \n",
      "\t\tProto:14 cub_031_Black_billed_Cuckoo:0.8/30 cub_033_Yellow_billed_Cuckoo:0.54/30 \n",
      "\t\tProto:15 cub_031_Black_billed_Cuckoo:0.59/30 cub_033_Yellow_billed_Cuckoo:0.46/30 \n",
      "\t\tProto:46 cub_031_Black_billed_Cuckoo:0.61/30 cub_033_Yellow_billed_Cuckoo:0.43/30 \n",
      "\t\tProto:47 cub_031_Black_billed_Cuckoo:0.36/30 cub_033_Yellow_billed_Cuckoo:0.24/30 \n",
      "\t\tProto:24 cub_031_Black_billed_Cuckoo:0.73/30 cub_033_Yellow_billed_Cuckoo:0.33/30 \n",
      "\t\tProto:28 cub_031_Black_billed_Cuckoo:0.68/30 cub_033_Yellow_billed_Cuckoo:0.63/30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:07, 35.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "045+100\n",
      "\t 100+023\n",
      "\t\tProto:32 023+024:0.1/90 100+101:0.6/60 \n",
      "\t\tProto:2 023+024:0.56/90 100+101:0.03/60 \n",
      "\t\tProto:35 023+024:0.03/90 100+101:0.81/60 \n",
      "\t\tProto:6 023+024:0.22/90 100+101:0.4/60 \n",
      "\t\tProto:7 023+024:0.68/90 100+101:0.01/60 \n",
      "\t\tProto:8 023+024:0.36/90 100+101:0.01/60 \n",
      "\t\tProto:40 023+024:0.49/90 100+101:0.21/60 \n",
      "\t\tProto:41 023+024:0.21/90 100+101:0.3/60 \n",
      "\t\tProto:11 023+024:0.29/90 100+101:0.14/60 \n",
      "\t\tProto:44 023+024:0.49/90 100+101:0.0/60 \n",
      "\t\tProto:14 023+024:0.25/90 100+101:0.05/60 \n",
      "\t\tProto:46 023+024:0.3/90 100+101:0.18/60 \n",
      "\t\tProto:19 023+024:0.26/90 100+101:0.19/60 \n",
      "\t\tProto:22 023+024:0.4/90 100+101:0.57/60 \n",
      "\t\tProto:25 023+024:0.42/90 100+101:0.03/60 \n",
      "\t\tProto:27 023+024:0.38/90 100+101:0.68/60 \n",
      "\t 045+003\n",
      "\t\tProto:33 003+001:0.25/90 cub_045_Northern_Fulmar:0.46/30 \n",
      "\t\tProto:34 003+001:0.13/90 cub_045_Northern_Fulmar:0.27/30 \n",
      "\t\tProto:3 003+001:0.23/90 cub_045_Northern_Fulmar:0.47/30 \n",
      "\t\tProto:36 003+001:0.5/90 cub_045_Northern_Fulmar:0.53/30 \n",
      "\t\tProto:5 003+001:0.39/90 cub_045_Northern_Fulmar:0.51/30 \n",
      "\t\tProto:37 003+001:0.2/90 cub_045_Northern_Fulmar:0.15/30 \n",
      "\t\tProto:39 003+001:0.42/90 cub_045_Northern_Fulmar:0.57/30 \n",
      "\t\tProto:9 003+001:0.69/90 cub_045_Northern_Fulmar:0.47/30 \n",
      "\t\tProto:10 003+001:0.43/90 cub_045_Northern_Fulmar:0.34/30 \n",
      "\t\tProto:13 003+001:0.42/90 cub_045_Northern_Fulmar:0.28/30 \n",
      "\t\tProto:16 003+001:0.6/90 cub_045_Northern_Fulmar:0.49/30 \n",
      "\t\tProto:49 003+001:0.45/90 cub_045_Northern_Fulmar:0.05/30 \n",
      "\t\tProto:18 003+001:0.17/90 cub_045_Northern_Fulmar:0.22/30 \n",
      "\t\tProto:24 003+001:0.41/90 cub_045_Northern_Fulmar:0.37/30 \n",
      "\t\tProto:28 003+001:0.52/90 cub_045_Northern_Fulmar:0.1/30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 36.57it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "045+003\n",
      "\t 003+001\n",
      "\t\tProto:0 001+002:0.57/60 cub_003_Sooty_Albatross:0.4/30 \n",
      "\t\tProto:1 001+002:0.7/60 cub_003_Sooty_Albatross:0.24/30 \n",
      "\t\tProto:6 001+002:0.25/60 cub_003_Sooty_Albatross:0.73/30 \n",
      "\t\tProto:8 001+002:0.31/60 cub_003_Sooty_Albatross:0.46/30 \n",
      "\t\tProto:10 001+002:0.62/60 cub_003_Sooty_Albatross:0.38/30 \n",
      "\t\tProto:13 001+002:0.37/60 cub_003_Sooty_Albatross:0.51/30 \n",
      "\t\tProto:14 001+002:0.34/60 cub_003_Sooty_Albatross:0.49/30 \n",
      "\t\tProto:17 001+002:0.58/60 cub_003_Sooty_Albatross:0.35/30 \n",
      "\t\tProto:21 001+002:0.32/60 cub_003_Sooty_Albatross:0.67/30 \n",
      "\t\tProto:24 001+002:0.31/60 cub_003_Sooty_Albatross:0.51/30 \n",
      "\t\tProto:27 001+002:0.52/60 cub_003_Sooty_Albatross:0.34/30 \n",
      "\t\tProto:28 001+002:0.65/60 cub_003_Sooty_Albatross:0.3/30 \n",
      "\t\tProto:29 001+002:0.4/60 cub_003_Sooty_Albatross:0.17/30 \n",
      "\t\tProto:30 001+002:0.71/60 cub_003_Sooty_Albatross:0.41/30 \n",
      "\t\tProto:31 001+002:0.49/60 cub_003_Sooty_Albatross:0.28/30 \n",
      "\t\tProto:37 001+002:0.43/60 cub_003_Sooty_Albatross:0.32/30 \n",
      "\t\tProto:40 001+002:0.48/60 cub_003_Sooty_Albatross:0.34/30 \n",
      "\t\tProto:41 001+002:0.61/60 cub_003_Sooty_Albatross:0.2/30 \n",
      "\t\tProto:46 001+002:0.48/60 cub_003_Sooty_Albatross:0.15/30 \n",
      "\t\tProto:47 001+002:0.44/60 cub_003_Sooty_Albatross:0.14/30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:04, 32.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100+023\n",
      "\t 023+024\n",
      "\t\tProto:0 cub_023_Brandt_Cormorant:0.11/30 024+025:0.62/60 \n",
      "\t\tProto:2 cub_023_Brandt_Cormorant:0.56/30 024+025:0.55/60 \n",
      "\t\tProto:3 cub_023_Brandt_Cormorant:0.51/30 024+025:0.62/60 \n",
      "\t\tProto:4 cub_023_Brandt_Cormorant:0.5/30 024+025:0.58/60 \n",
      "\t\tProto:35 cub_023_Brandt_Cormorant:0.27/30 024+025:0.66/60 \n",
      "\t\tProto:7 cub_023_Brandt_Cormorant:0.56/30 024+025:0.71/60 \n",
      "\t\tProto:41 cub_023_Brandt_Cormorant:0.47/30 024+025:0.57/60 \n",
      "\t\tProto:42 cub_023_Brandt_Cormorant:0.13/30 024+025:0.54/60 \n",
      "\t\tProto:43 cub_023_Brandt_Cormorant:0.47/30 024+025:0.52/60 \n",
      "\t\tProto:12 cub_023_Brandt_Cormorant:0.32/30 024+025:0.32/60 \n",
      "\t\tProto:46 cub_023_Brandt_Cormorant:0.39/30 024+025:0.54/60 \n",
      "\t\tProto:16 cub_023_Brandt_Cormorant:0.51/30 024+025:0.53/60 \n",
      "\t\tProto:48 cub_023_Brandt_Cormorant:0.4/30 024+025:0.46/60 \n",
      "\t\tProto:18 cub_023_Brandt_Cormorant:0.27/30 024+025:0.31/60 \n",
      "\t\tProto:20 cub_023_Brandt_Cormorant:0.56/30 024+025:0.49/60 \n",
      "\t\tProto:24 cub_023_Brandt_Cormorant:0.67/30 024+025:0.4/60 \n",
      "\t\tProto:28 cub_023_Brandt_Cormorant:0.3/30 024+025:0.48/60 \n",
      "\t\tProto:31 cub_023_Brandt_Cormorant:0.7/30 024+025:0.5/60 \n",
      "\t 100+101\n",
      "\t\tProto:1 cub_100_Brown_Pelican:0.6/30 cub_101_White_Pelican:0.5/30 \n",
      "\t\tProto:33 cub_100_Brown_Pelican:0.49/30 cub_101_White_Pelican:0.43/30 \n",
      "\t\tProto:36 cub_100_Brown_Pelican:0.78/30 cub_101_White_Pelican:0.53/30 \n",
      "\t\tProto:6 cub_100_Brown_Pelican:0.53/30 cub_101_White_Pelican:0.51/30 \n",
      "\t\tProto:8 cub_100_Brown_Pelican:0.82/30 cub_101_White_Pelican:0.75/30 \n",
      "\t\tProto:40 cub_100_Brown_Pelican:0.53/30 cub_101_White_Pelican:0.71/30 \n",
      "\t\tProto:10 cub_100_Brown_Pelican:0.63/30 cub_101_White_Pelican:0.59/30 \n",
      "\t\tProto:13 cub_100_Brown_Pelican:0.9/30 cub_101_White_Pelican:0.77/30 \n",
      "\t\tProto:45 cub_100_Brown_Pelican:0.54/30 cub_101_White_Pelican:0.68/30 \n",
      "\t\tProto:15 cub_100_Brown_Pelican:0.43/30 cub_101_White_Pelican:0.56/30 \n",
      "\t\tProto:26 cub_100_Brown_Pelican:0.53/30 cub_101_White_Pelican:0.72/30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 37.36it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003+001\n",
      "\t 001+002\n",
      "\t\tProto:0 cub_001_Black_footed_Albatross:0.71/30 cub_002_Laysan_Albatross:0.68/30 \n",
      "\t\tProto:33 cub_001_Black_footed_Albatross:0.55/30 cub_002_Laysan_Albatross:0.42/30 \n",
      "\t\tProto:3 cub_001_Black_footed_Albatross:0.46/30 cub_002_Laysan_Albatross:0.54/30 \n",
      "\t\tProto:36 cub_001_Black_footed_Albatross:0.66/30 cub_002_Laysan_Albatross:0.43/30 \n",
      "\t\tProto:6 cub_001_Black_footed_Albatross:0.47/30 cub_002_Laysan_Albatross:0.52/30 \n",
      "\t\tProto:7 cub_001_Black_footed_Albatross:0.46/30 cub_002_Laysan_Albatross:0.63/30 \n",
      "\t\tProto:40 cub_001_Black_footed_Albatross:0.37/30 cub_002_Laysan_Albatross:0.63/30 \n",
      "\t\tProto:9 cub_001_Black_footed_Albatross:0.57/30 cub_002_Laysan_Albatross:0.65/30 \n",
      "\t\tProto:42 cub_001_Black_footed_Albatross:0.68/30 cub_002_Laysan_Albatross:0.46/30 \n",
      "\t\tProto:12 cub_001_Black_footed_Albatross:0.76/30 cub_002_Laysan_Albatross:0.78/30 \n",
      "\t\tProto:17 cub_001_Black_footed_Albatross:0.8/30 cub_002_Laysan_Albatross:0.57/30 \n",
      "\t\tProto:24 cub_001_Black_footed_Albatross:0.64/30 cub_002_Laysan_Albatross:0.56/30 \n",
      "\t\tProto:25 cub_001_Black_footed_Albatross:0.47/30 cub_002_Laysan_Albatross:0.4/30 \n",
      "\t\tProto:30 cub_001_Black_footed_Albatross:0.54/30 cub_002_Laysan_Albatross:0.58/30 \n",
      "\t\tProto:31 cub_001_Black_footed_Albatross:0.65/30 cub_002_Laysan_Albatross:0.72/30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 36.45it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "023+024\n",
      "\t 024+025\n",
      "\t\tProto:33 cub_024_Red_faced_Cormorant:0.64/30 cub_025_Pelagic_Cormorant:0.31/30 \n",
      "\t\tProto:35 cub_024_Red_faced_Cormorant:0.32/30 cub_025_Pelagic_Cormorant:0.48/30 \n",
      "\t\tProto:37 cub_024_Red_faced_Cormorant:0.67/30 cub_025_Pelagic_Cormorant:0.52/30 \n",
      "\t\tProto:38 cub_024_Red_faced_Cormorant:0.69/30 cub_025_Pelagic_Cormorant:0.41/30 \n",
      "\t\tProto:7 cub_024_Red_faced_Cormorant:0.84/30 cub_025_Pelagic_Cormorant:0.32/30 \n",
      "\t\tProto:9 cub_024_Red_faced_Cormorant:0.85/30 cub_025_Pelagic_Cormorant:0.15/30 \n",
      "\t\tProto:10 cub_024_Red_faced_Cormorant:0.48/30 cub_025_Pelagic_Cormorant:0.44/30 \n",
      "\t\tProto:12 cub_024_Red_faced_Cormorant:0.84/30 cub_025_Pelagic_Cormorant:0.5/30 \n",
      "\t\tProto:13 cub_024_Red_faced_Cormorant:0.48/30 cub_025_Pelagic_Cormorant:0.26/30 \n",
      "\t\tProto:14 cub_024_Red_faced_Cormorant:0.45/30 cub_025_Pelagic_Cormorant:0.55/30 \n",
      "\t\tProto:47 cub_024_Red_faced_Cormorant:0.5/30 cub_025_Pelagic_Cormorant:0.32/30 \n",
      "\t\tProto:18 cub_024_Red_faced_Cormorant:0.76/30 cub_025_Pelagic_Cormorant:0.26/30 \n",
      "\t\tProto:26 cub_024_Red_faced_Cormorant:0.44/30 cub_025_Pelagic_Cormorant:0.54/30 \n",
      "\t\tProto:27 cub_024_Red_faced_Cormorant:0.36/30 cub_025_Pelagic_Cormorant:0.28/30 \n",
      "\t\tProto:31 cub_024_Red_faced_Cormorant:0.55/30 cub_025_Pelagic_Cormorant:0.18/30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on Grand children\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import pdb\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    if node.name == 'root':\n",
    "        continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    \n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> (mean_activation, num_images)\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: [0, 0]))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pfs, pooled, _ = net(xs, inference=True)\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            pfs = pfs[node.name].squeeze(0)\n",
    "\n",
    "            \n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    grand_child = child_node.closest_descendent_for(label2name[orig_y.item()])\n",
    "                    proto_mean_activations[p][grand_child.name][0] = ((proto_mean_activations[p][grand_child.name][0] * \\\n",
    "                                                                      proto_mean_activations[p][grand_child.name][1]) + pooled[p]) / (proto_mean_activations[p][grand_child.name][1] + 1)\n",
    "                    proto_mean_activations[p][grand_child.name][1] += 1\n",
    "\n",
    "                if (len(relevant_proto_class_names) > 1) and (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    if child_node.is_leaf():\n",
    "                        proto_mean_activations[p][child_node.name][0] = ((proto_mean_activations[p][child_node.name][0] * \\\n",
    "                                                                            proto_mean_activations[p][child_node.name][1]) + pooled[p]) / (proto_mean_activations[p][child_node.name][1] + 1)\n",
    "                        proto_mean_activations[p][child_node.name][1] += 1\n",
    "                    else:\n",
    "                        grand_child = child_node.closest_descendent_for(label2name[orig_y.item()])\n",
    "                        proto_mean_activations[p][grand_child.name][0] = ((proto_mean_activations[p][grand_child.name][0] * \\\n",
    "                                                                            proto_mean_activations[p][grand_child.name][1]) + pooled[p]) / (proto_mean_activations[p][grand_child.name][1] + 1)\n",
    "                        proto_mean_activations[p][grand_child.name][1] += 1\n",
    "                \n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "            # class_and_prototypes = defaultdict(list)\n",
    "            # for p in range(pooled.shape[0]):\n",
    "            #     class_and_prototypes[', '.join(list(proto_mean_activations[p].keys()))].append(p)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for grand_child_name in proto_mean_activations[p]:\n",
    "                mean_activation = round(proto_mean_activations[p][grand_child_name][0].item(), 2)\n",
    "                num_images = proto_mean_activations[p][grand_child_name][1]\n",
    "                logstr += f'{grand_child_name}:{mean_activation}/{num_images} '\n",
    "            print(logstr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - all image-activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:14, 37.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+004\n",
      "\t Child: 052+053\n",
      "\t\tProto:0 050:(0.23) 051:(0.57) 052:(0.0) 053:(0.45) \n",
      "\t\tProto:36 050:(0.16) 051:(0.15) 052:(0.31) 053:(0.0) \n",
      "\t\tProto:5 050:(0.12) 051:(0.4) 052:(0.14) 053:(0.0) \n",
      "\t\tProto:43 050:(0.2) 051:(0.52) 052:(0.35) 053:(0.18) \n",
      "\t\tProto:13 050:(0.36) 051:(0.46) 052:(0.54) 053:(0.3) \n",
      "\t\tProto:46 050:(0.43) 051:(0.46) 052:(0.02) 053:(0.49) \n",
      "\t\tProto:16 050:(0.17) 051:(0.52) 052:(0.0) 053:(0.64) \n",
      "\t\tProto:17 050:(0.12) 051:(0.44) 052:(0.03) 053:(0.48) \n",
      "\t\tProto:23 050:(0.01) 051:(0.04) 052:(0.42) 053:(0.06) \n",
      "\t\tProto:31 050:(0.16) 051:(0.38) 052:(0.06) 053:(0.0) \n",
      "\t Child: 004+086\n",
      "\t\tProto:2 001:(0.15) 002:(0.27) 003:(0.23) 004:(0.23) 023:(0.16) 024:(0.18) 025:(0.34) 031:(0.13) 032:(0.07) 033:(0.06) 045:(0.11) 086:(0.12) 100:(0.11) 101:(0.11) \n",
      "\t\tProto:3 001:(0.2) 002:(0.47) 003:(0.64) 004:(0.03) 023:(0.0) 024:(0.01) 025:(0.03) 031:(0.34) 032:(0.07) 033:(0.28) 045:(0.43) 086:(0.01) 100:(0.03) 101:(0.09) \n",
      "\t\tProto:4 001:(0.66) 002:(0.03) 003:(0.31) 004:(0.03) 023:(0.56) 024:(0.13) 025:(0.48) 031:(0.54) 032:(0.0) 033:(0.12) 045:(0.08) 086:(0.69) 100:(0.19) 101:(0.02) \n",
      "\t\tProto:7 001:(0.36) 002:(0.18) 003:(0.3) 004:(0.34) 023:(0.24) 024:(0.04) 025:(0.28) 031:(0.23) 032:(0.49) 033:(0.36) 045:(0.25) 086:(0.15) 100:(0.0) 101:(0.02) \n",
      "\t\tProto:8 001:(0.01) 002:(0.0) 003:(0.01) 004:(0.0) 023:(0.57) 024:(0.0) 025:(0.11) 031:(0.06) 032:(0.66) 033:(0.29) 045:(0.01) 086:(0.41) 100:(0.0) 101:(0.0) \n",
      "\t\tProto:10 001:(0.0) 002:(0.0) 003:(0.0) 004:(0.0) 023:(0.01) 024:(0.0) 025:(0.0) 031:(0.68) 032:(0.76) 033:(0.61) 045:(0.0) 086:(0.04) 100:(0.0) 101:(0.0) \n",
      "\t\tProto:11 001:(0.88) 002:(0.58) 003:(0.25) 004:(0.0) 023:(0.05) 024:(0.15) 025:(0.14) 031:(0.19) 032:(0.0) 033:(0.07) 045:(0.22) 086:(0.15) 100:(0.15) 101:(0.05) \n",
      "\t\tProto:12 001:(0.12) 002:(0.05) 003:(0.0) 004:(0.0) 023:(0.0) 024:(0.0) 025:(0.02) 031:(0.63) 032:(0.3) 033:(0.41) 045:(0.0) 086:(0.06) 100:(0.0) 101:(0.0) \n",
      "\t\tProto:14 001:(0.41) 002:(0.6) 003:(0.44) 004:(0.01) 023:(0.02) 024:(0.0) 025:(0.05) 031:(0.01) 032:(0.0) 033:(0.03) 045:(0.08) 086:(0.07) 100:(0.76) 101:(0.65) \n",
      "\t\tProto:15 001:(0.15) 002:(0.17) 003:(0.15) 004:(0.03) 023:(0.06) 024:(0.0) 025:(0.01) 031:(0.0) 032:(0.06) 033:(0.01) 045:(0.03) 086:(0.02) 100:(0.02) 101:(0.03) \n",
      "\t\tProto:18 001:(0.54) 002:(0.03) 003:(0.1) 004:(0.0) 023:(0.04) 024:(0.0) 025:(0.01) 031:(0.5) 032:(0.0) 033:(0.22) 045:(0.05) 086:(0.41) 100:(0.0) 101:(0.0) \n",
      "\t\tProto:19 001:(0.0) 002:(0.33) 003:(0.0) 004:(0.04) 023:(0.04) 024:(0.92) 025:(0.04) 031:(0.0) 032:(0.03) 033:(0.02) 045:(0.4) 086:(0.0) 100:(0.17) 101:(0.67) \n",
      "\t\tProto:22 001:(0.03) 002:(0.01) 003:(0.03) 004:(0.32) 023:(0.02) 024:(0.3) 025:(0.39) 031:(0.23) 032:(0.07) 033:(0.08) 045:(0.02) 086:(0.0) 100:(0.03) 101:(0.01) \n",
      "\t\tProto:24 001:(0.11) 002:(0.08) 003:(0.09) 004:(0.07) 023:(0.01) 024:(0.02) 025:(0.04) 031:(0.25) 032:(0.13) 033:(0.15) 045:(0.53) 086:(0.01) 100:(0.02) 101:(0.08) \n",
      "\t\tProto:26 001:(0.15) 002:(0.11) 003:(0.12) 004:(0.22) 023:(0.29) 024:(0.2) 025:(0.09) 031:(0.51) 032:(0.21) 033:(0.33) 045:(0.04) 086:(0.01) 100:(0.1) 101:(0.08) \n",
      "\t\tProto:27 001:(0.07) 002:(0.15) 003:(0.03) 004:(0.0) 023:(0.45) 024:(0.44) 025:(0.41) 031:(0.22) 032:(0.52) 033:(0.84) 045:(0.04) 086:(0.35) 100:(0.0) 101:(0.07) \n",
      "\t\tProto:28 001:(0.01) 002:(0.01) 003:(0.01) 004:(0.13) 023:(0.01) 024:(0.05) 025:(0.01) 031:(0.0) 032:(0.36) 033:(0.04) 045:(0.08) 086:(0.03) 100:(0.01) 101:(0.06) \n",
      "\t\tProto:30 001:(0.05) 002:(0.09) 003:(0.17) 004:(0.08) 023:(0.07) 024:(0.05) 025:(0.02) 031:(0.31) 032:(0.16) 033:(0.1) 045:(0.03) 086:(0.0) 100:(0.37) 101:(0.17) \n",
      "\t\tProto:32 001:(0.0) 002:(0.02) 003:(0.01) 004:(0.48) 023:(0.57) 024:(0.89) 025:(0.65) 031:(0.0) 032:(0.0) 033:(0.0) 045:(0.0) 086:(0.17) 100:(0.0) 101:(0.0) \n",
      "\t\tProto:33 001:(0.07) 002:(0.52) 003:(0.08) 004:(0.0) 023:(0.05) 024:(0.1) 025:(0.0) 031:(0.03) 032:(0.08) 033:(0.1) 045:(0.13) 086:(0.05) 100:(0.72) 101:(0.81) \n",
      "\t\tProto:34 001:(0.03) 002:(0.02) 003:(0.38) 004:(0.25) 023:(0.25) 024:(0.03) 025:(0.48) 031:(0.12) 032:(0.03) 033:(0.02) 045:(0.05) 086:(0.29) 100:(0.06) 101:(0.0) \n",
      "\t\tProto:35 001:(0.06) 002:(0.09) 003:(0.25) 004:(0.44) 023:(0.04) 024:(0.0) 025:(0.01) 031:(0.07) 032:(0.0) 033:(0.01) 045:(0.45) 086:(0.18) 100:(0.0) 101:(0.03) \n",
      "\t\tProto:37 001:(0.29) 002:(0.53) 003:(0.06) 004:(0.0) 023:(0.0) 024:(0.05) 025:(0.0) 031:(0.03) 032:(0.0) 033:(0.03) 045:(0.02) 086:(0.0) 100:(0.7) 101:(0.79) \n",
      "\t\tProto:39 001:(0.77) 002:(0.79) 003:(0.11) 004:(0.0) 023:(0.01) 024:(0.07) 025:(0.01) 031:(0.01) 032:(0.0) 033:(0.05) 045:(0.16) 086:(0.05) 100:(0.68) 101:(0.66) \n",
      "\t\tProto:40 001:(0.03) 002:(0.05) 003:(0.1) 004:(0.54) 023:(0.04) 024:(0.31) 025:(0.09) 031:(0.0) 032:(0.0) 033:(0.0) 045:(0.48) 086:(0.07) 100:(0.05) 101:(0.04) \n",
      "\t\tProto:41 001:(0.04) 002:(0.02) 003:(0.17) 004:(0.37) 023:(0.14) 024:(0.22) 025:(0.3) 031:(0.09) 032:(0.16) 033:(0.11) 045:(0.01) 086:(0.02) 100:(0.18) 101:(0.08) \n",
      "\t\tProto:44 001:(0.0) 002:(0.03) 003:(0.0) 004:(0.0) 023:(0.0) 024:(0.0) 025:(0.0) 031:(0.72) 032:(0.64) 033:(0.83) 045:(0.02) 086:(0.01) 100:(0.0) 101:(0.0) \n",
      "\t\tProto:47 001:(0.05) 002:(0.05) 003:(0.14) 004:(0.11) 023:(0.31) 024:(0.09) 025:(0.08) 031:(0.1) 032:(0.11) 033:(0.06) 045:(0.02) 086:(0.17) 100:(0.24) 101:(0.01) \n",
      "\t\tProto:48 001:(0.0) 002:(0.01) 003:(0.0) 004:(0.0) 023:(0.09) 024:(0.84) 025:(0.26) 031:(0.01) 032:(0.28) 033:(0.52) 045:(0.0) 086:(0.01) 100:(0.0) 101:(0.02) \n",
      "\t\tProto:49 001:(0.05) 002:(0.33) 003:(0.0) 004:(0.01) 023:(0.0) 024:(0.0) 025:(0.0) 031:(0.61) 032:(0.0) 033:(0.25) 045:(0.16) 086:(0.01) 100:(0.0) 101:(0.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 35.92it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "\t Child: 053+051\n",
      "\t\tProto:2 050:(0.5) 051:(0.54) 053:(0.04) \n",
      "\t\tProto:4 050:(0.17) 051:(0.33) 053:(0.36) \n",
      "\t\tProto:5 050:(0.08) 051:(0.12) 053:(0.1) \n",
      "\t\tProto:6 050:(0.35) 051:(0.34) 053:(0.7) \n",
      "\t\tProto:7 050:(0.01) 051:(0.31) 053:(0.66) \n",
      "\t\tProto:9 050:(0.38) 051:(0.44) 053:(0.81) \n",
      "\t\tProto:10 050:(0.12) 051:(0.21) 053:(0.68) \n",
      "\t\tProto:11 050:(0.68) 051:(0.71) 053:(0.62) \n",
      "\t\tProto:15 050:(0.49) 051:(0.3) 053:(0.87) \n",
      "\t\tProto:16 050:(0.52) 051:(0.54) 053:(0.36) \n",
      "\t\tProto:17 050:(0.72) 051:(0.8) 053:(0.38) \n",
      "\t\tProto:18 050:(0.39) 051:(0.47) 053:(0.22) \n",
      "\t\tProto:20 050:(0.01) 051:(0.35) 053:(0.57) \n",
      "\t\tProto:21 050:(0.23) 051:(0.16) 053:(0.22) \n",
      "\t\tProto:22 050:(0.36) 051:(0.4) 053:(0.08) \n",
      "\t\tProto:23 050:(0.18) 051:(0.41) 053:(0.01) \n",
      "\t\tProto:24 050:(0.4) 051:(0.44) 053:(0.55) \n",
      "\t\tProto:26 050:(0.31) 051:(0.39) 053:(0.45) \n",
      "\t\tProto:27 050:(0.35) 051:(0.46) 053:(0.5) \n",
      "\t\tProto:34 050:(0.43) 051:(0.47) 053:(0.18) \n",
      "\t\tProto:36 050:(0.5) 051:(0.44) 053:(0.77) \n",
      "\t\tProto:38 050:(0.01) 051:(0.24) 053:(0.69) \n",
      "\t\tProto:39 050:(0.46) 051:(0.6) 053:(0.1) \n",
      "\t\tProto:43 050:(0.41) 051:(0.45) 053:(0.19) \n",
      "\t\tProto:45 050:(0.66) 051:(0.7) 053:(0.58) \n",
      "\t\tProto:46 050:(0.65) 051:(0.62) 053:(0.04) \n",
      "\t\tProto:48 050:(0.2) 051:(0.38) 053:(0.0) \n",
      "\t\tProto:49 050:(0.32) 051:(0.39) 053:(0.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:11, 37.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 086+045\n",
      "\t\tProto:1 001:(0.0) 002:(0.0) 003:(0.05) 023:(0.59) 024:(0.12) 025:(0.47) 045:(0.0) 086:(0.51) 100:(0.26) 101:(0.02) \n",
      "\t\tProto:4 001:(0.49) 002:(0.65) 003:(0.23) 023:(0.15) 024:(0.74) 025:(0.23) 045:(0.04) 086:(0.31) 100:(0.49) 101:(0.71) \n",
      "\t\tProto:5 001:(0.04) 002:(0.0) 003:(0.14) 023:(0.11) 024:(0.59) 025:(0.18) 045:(0.0) 086:(0.0) 100:(0.05) 101:(0.0) \n",
      "\t\tProto:10 001:(0.49) 002:(0.68) 003:(0.25) 023:(0.39) 024:(0.56) 025:(0.32) 045:(0.01) 086:(0.41) 100:(0.64) 101:(0.6) \n",
      "\t\tProto:11 001:(0.3) 002:(0.66) 003:(0.3) 023:(0.08) 024:(0.12) 025:(0.15) 045:(0.36) 086:(0.01) 100:(0.07) 101:(0.59) \n",
      "\t\tProto:13 001:(0.06) 002:(0.55) 003:(0.06) 023:(0.02) 024:(0.38) 025:(0.0) 045:(0.28) 086:(0.0) 100:(0.66) 101:(0.75) \n",
      "\t\tProto:14 001:(0.24) 002:(0.13) 003:(0.33) 023:(0.3) 024:(0.15) 025:(0.19) 045:(0.03) 086:(0.32) 100:(0.0) 101:(0.0) \n",
      "\t\tProto:17 001:(0.17) 002:(0.69) 003:(0.11) 023:(0.17) 024:(0.84) 025:(0.21) 045:(0.48) 086:(0.08) 100:(0.81) 101:(0.66) \n",
      "\t\tProto:19 001:(0.7) 002:(0.4) 003:(0.39) 023:(0.03) 024:(0.0) 025:(0.05) 045:(0.61) 086:(0.03) 100:(0.0) 101:(0.0) \n",
      "\t\tProto:21 001:(0.03) 002:(0.03) 003:(0.52) 023:(0.1) 024:(0.05) 025:(0.19) 045:(0.07) 086:(0.26) 100:(0.01) 101:(0.03) \n",
      "\t\tProto:28 001:(0.3) 002:(0.03) 003:(0.13) 023:(0.38) 024:(0.71) 025:(0.5) 045:(0.01) 086:(0.35) 100:(0.01) 101:(0.0) \n",
      "\t\tProto:29 001:(0.15) 002:(0.06) 003:(0.33) 023:(0.15) 024:(0.11) 025:(0.32) 045:(0.13) 086:(0.29) 100:(0.03) 101:(0.0) \n",
      "\t\tProto:32 001:(0.27) 002:(0.13) 003:(0.27) 023:(0.51) 024:(0.46) 025:(0.5) 045:(0.27) 086:(0.6) 100:(0.36) 101:(0.32) \n",
      "\t\tProto:38 001:(0.16) 002:(0.5) 003:(0.55) 023:(0.0) 024:(0.0) 025:(0.0) 045:(0.58) 086:(0.0) 100:(0.0) 101:(0.0) \n",
      "\t\tProto:39 001:(0.0) 002:(0.12) 003:(0.29) 023:(0.34) 024:(0.92) 025:(0.37) 045:(0.0) 086:(0.05) 100:(0.25) 101:(0.23) \n",
      "\t\tProto:40 001:(0.11) 002:(0.34) 003:(0.13) 023:(0.03) 024:(0.02) 025:(0.06) 045:(0.34) 086:(0.2) 100:(0.08) 101:(0.17) \n",
      "\t\tProto:41 001:(0.86) 002:(0.15) 003:(0.1) 023:(0.14) 024:(0.01) 025:(0.06) 045:(0.02) 086:(0.27) 100:(0.08) 101:(0.0) \n",
      "\t\tProto:42 001:(0.25) 002:(0.11) 003:(0.16) 023:(0.16) 024:(0.45) 025:(0.23) 045:(0.2) 086:(0.19) 100:(0.01) 101:(0.2) \n",
      "\t\tProto:43 001:(0.05) 002:(0.34) 003:(0.07) 023:(0.02) 024:(0.04) 025:(0.01) 045:(0.13) 086:(0.08) 100:(0.62) 101:(0.69) \n",
      "\t\tProto:45 001:(0.16) 002:(0.16) 003:(0.18) 023:(0.66) 024:(0.06) 025:(0.31) 045:(0.11) 086:(0.55) 100:(0.03) 101:(0.03) \n",
      "\t\tProto:46 001:(0.0) 002:(0.56) 003:(0.0) 023:(0.0) 024:(0.0) 025:(0.0) 045:(0.34) 086:(0.0) 100:(0.12) 101:(0.34) \n",
      "\t\tProto:48 001:(0.16) 002:(0.04) 003:(0.53) 023:(0.09) 024:(0.0) 025:(0.0) 045:(0.37) 086:(0.36) 100:(0.02) 101:(0.01) \n",
      "\t\tProto:49 001:(0.08) 002:(0.05) 003:(0.07) 023:(0.13) 024:(0.1) 025:(0.19) 045:(0.16) 086:(0.06) 100:(0.1) 101:(0.14) \n",
      "\t Child: 004+032\n",
      "\t\tProto:33 004:(0.0) 031:(0.75) 032:(0.0) 033:(0.27) \n",
      "\t\tProto:35 004:(0.0) 031:(0.02) 032:(0.74) 033:(0.48) \n",
      "\t\tProto:36 004:(0.54) 031:(0.03) 032:(0.03) 033:(0.06) \n",
      "\t\tProto:6 004:(0.24) 031:(0.28) 032:(0.19) 033:(0.21) \n",
      "\t\tProto:7 004:(0.0) 031:(0.03) 032:(0.63) 033:(0.78) \n",
      "\t\tProto:8 004:(0.0) 031:(0.88) 032:(0.58) 033:(0.73) \n",
      "\t\tProto:9 004:(0.56) 031:(0.67) 032:(0.74) 033:(0.6) \n",
      "\t\tProto:12 004:(0.0) 031:(0.63) 032:(0.0) 033:(0.18) \n",
      "\t\tProto:15 004:(0.34) 031:(0.29) 032:(0.24) 033:(0.48) \n",
      "\t\tProto:22 004:(0.27) 031:(0.3) 032:(0.49) 033:(0.3) \n",
      "\t\tProto:23 004:(0.12) 031:(0.22) 032:(0.2) 033:(0.13) \n",
      "\t\tProto:24 004:(0.29) 031:(0.77) 032:(0.49) 033:(0.76) \n",
      "\t\tProto:25 004:(0.13) 031:(0.02) 032:(0.17) 033:(0.38) \n",
      "\t\tProto:27 004:(0.23) 031:(0.02) 032:(0.46) 033:(0.73) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 37.27it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+051\n",
      "\t Child: 051+050\n",
      "\t\tProto:3 050:(0.19) 051:(0.38) \n",
      "\t\tProto:5 050:(0.06) 051:(0.22) \n",
      "\t\tProto:8 050:(0.09) 051:(0.25) \n",
      "\t\tProto:9 050:(0.55) 051:(0.62) \n",
      "\t\tProto:10 050:(0.46) 051:(0.59) \n",
      "\t\tProto:11 050:(0.38) 051:(0.49) \n",
      "\t\tProto:12 050:(0.73) 051:(0.73) \n",
      "\t\tProto:13 050:(0.59) 051:(0.58) \n",
      "\t\tProto:16 050:(0.56) 051:(0.35) \n",
      "\t\tProto:17 050:(0.46) 051:(0.61) \n",
      "\t\tProto:18 050:(0.28) 051:(0.45) \n",
      "\t\tProto:20 050:(0.17) 051:(0.28) \n",
      "\t\tProto:25 050:(0.26) 051:(0.46) \n",
      "\t\tProto:32 050:(0.32) 051:(0.32) \n",
      "\t\tProto:36 050:(0.39) 051:(0.48) \n",
      "\t\tProto:38 050:(0.37) 051:(0.47) \n",
      "\t\tProto:42 050:(0.39) 051:(0.35) \n",
      "\t\tProto:43 050:(0.36) 051:(0.41) \n",
      "\t\tProto:45 050:(0.2) 051:(0.45) \n",
      "\t\tProto:47 050:(0.51) 051:(0.62) \n",
      "\t\tProto:48 050:(0.29) 051:(0.34) \n",
      "\t\tProto:49 050:(0.57) 051:(0.64) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 35.69it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "\t Child: 032+031\n",
      "\t\tProto:0 031:(0.28) 032:(0.65) 033:(0.22) \n",
      "\t\tProto:1 031:(0.77) 032:(0.49) 033:(0.52) \n",
      "\t\tProto:4 031:(0.48) 032:(0.13) 033:(0.54) \n",
      "\t\tProto:5 031:(0.36) 032:(0.49) 033:(0.75) \n",
      "\t\tProto:6 031:(0.52) 032:(0.38) 033:(0.5) \n",
      "\t\tProto:7 031:(0.0) 032:(0.36) 033:(0.67) \n",
      "\t\tProto:9 031:(0.61) 032:(0.4) 033:(0.62) \n",
      "\t\tProto:12 031:(0.34) 032:(0.59) 033:(0.82) \n",
      "\t\tProto:16 031:(0.21) 032:(0.72) 033:(0.54) \n",
      "\t\tProto:17 031:(0.38) 032:(0.23) 033:(0.24) \n",
      "\t\tProto:18 031:(0.69) 032:(0.16) 033:(0.52) \n",
      "\t\tProto:19 031:(0.43) 032:(0.4) 033:(0.3) \n",
      "\t\tProto:20 031:(0.44) 032:(0.36) 033:(0.46) \n",
      "\t\tProto:22 031:(0.65) 032:(0.23) 033:(0.46) \n",
      "\t\tProto:27 031:(0.39) 032:(0.41) 033:(0.4) \n",
      "\t\tProto:30 031:(0.13) 032:(0.12) 033:(0.09) \n",
      "\t\tProto:31 031:(0.2) 032:(0.34) 033:(0.4) \n",
      "\t\tProto:32 031:(0.73) 032:(0.39) 033:(0.63) \n",
      "\t\tProto:36 031:(0.46) 032:(0.08) 033:(0.35) \n",
      "\t\tProto:37 031:(0.12) 032:(0.27) 033:(0.63) \n",
      "\t\tProto:38 031:(0.42) 032:(0.51) 033:(0.46) \n",
      "\t\tProto:40 031:(0.88) 032:(0.43) 033:(0.07) \n",
      "\t\tProto:45 031:(0.01) 032:(0.42) 033:(0.65) \n",
      "\t\tProto:49 031:(0.31) 032:(0.34) 033:(0.41) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:07, 37.71it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "\t Child: 045+100\n",
      "\t\tProto:2 001:(0.02) 002:(0.03) 003:(0.02) 023:(0.71) 024:(0.73) 025:(0.37) 045:(0.0) 100:(0.02) 101:(0.02) \n",
      "\t\tProto:3 001:(0.12) 002:(0.08) 003:(0.08) 023:(0.11) 024:(0.84) 025:(0.27) 045:(0.04) 100:(0.01) 101:(0.05) \n",
      "\t\tProto:5 001:(0.17) 002:(0.24) 003:(0.09) 023:(0.04) 024:(0.22) 025:(0.21) 045:(0.43) 100:(0.02) 101:(0.12) \n",
      "\t\tProto:6 001:(0.18) 002:(0.32) 003:(0.1) 023:(0.0) 024:(0.01) 025:(0.01) 045:(0.04) 100:(0.87) 101:(0.4) \n",
      "\t\tProto:7 001:(0.04) 002:(0.02) 003:(0.03) 023:(0.1) 024:(0.28) 025:(0.3) 045:(0.09) 100:(0.12) 101:(0.06) \n",
      "\t\tProto:9 001:(0.22) 002:(0.26) 003:(0.17) 023:(0.11) 024:(0.06) 025:(0.09) 045:(0.02) 100:(0.25) 101:(0.28) \n",
      "\t\tProto:10 001:(0.22) 002:(0.16) 003:(0.18) 023:(0.09) 024:(0.33) 025:(0.42) 045:(0.04) 100:(0.01) 101:(0.03) \n",
      "\t\tProto:11 001:(0.02) 002:(0.4) 003:(0.0) 023:(0.02) 024:(0.22) 025:(0.0) 045:(0.42) 100:(0.01) 101:(0.48) \n",
      "\t\tProto:12 001:(0.06) 002:(0.21) 003:(0.12) 023:(0.0) 024:(0.08) 025:(0.03) 045:(0.02) 100:(0.55) 101:(0.56) \n",
      "\t\tProto:14 001:(0.2) 002:(0.24) 003:(0.25) 023:(0.2) 024:(0.13) 025:(0.13) 045:(0.1) 100:(0.05) 101:(0.0) \n",
      "\t\tProto:17 001:(0.27) 002:(0.06) 003:(0.09) 023:(0.24) 024:(0.07) 025:(0.08) 045:(0.23) 100:(0.07) 101:(0.04) \n",
      "\t\tProto:18 001:(0.47) 002:(0.12) 003:(0.27) 023:(0.19) 024:(0.18) 025:(0.4) 045:(0.08) 100:(0.01) 101:(0.01) \n",
      "\t\tProto:19 001:(0.31) 002:(0.22) 003:(0.14) 023:(0.19) 024:(0.19) 025:(0.24) 045:(0.16) 100:(0.4) 101:(0.07) \n",
      "\t\tProto:20 001:(0.08) 002:(0.6) 003:(0.61) 023:(0.0) 024:(0.01) 025:(0.01) 045:(0.6) 100:(0.0) 101:(0.05) \n",
      "\t\tProto:21 001:(0.71) 002:(0.27) 003:(0.46) 023:(0.03) 024:(0.0) 025:(0.08) 045:(0.39) 100:(0.0) 101:(0.0) \n",
      "\t\tProto:23 001:(0.09) 002:(0.02) 003:(0.05) 023:(0.19) 024:(0.1) 025:(0.11) 045:(0.06) 100:(0.2) 101:(0.07) \n",
      "\t\tProto:24 001:(0.34) 002:(0.3) 003:(0.21) 023:(0.34) 024:(0.16) 025:(0.16) 045:(0.06) 100:(0.1) 101:(0.0) \n",
      "\t\tProto:25 001:(0.07) 002:(0.08) 003:(0.14) 023:(0.01) 024:(0.69) 025:(0.08) 045:(0.11) 100:(0.03) 101:(0.0) \n",
      "\t\tProto:26 001:(0.04) 002:(0.05) 003:(0.03) 023:(0.03) 024:(0.84) 025:(0.06) 045:(0.09) 100:(0.1) 101:(0.32) \n",
      "\t\tProto:27 001:(0.26) 002:(0.15) 003:(0.19) 023:(0.18) 024:(0.12) 025:(0.15) 045:(0.05) 100:(0.17) 101:(0.05) \n",
      "\t\tProto:29 001:(0.09) 002:(0.42) 003:(0.01) 023:(0.12) 024:(0.62) 025:(0.17) 045:(0.04) 100:(0.06) 101:(0.6) \n",
      "\t\tProto:30 001:(0.07) 002:(0.01) 003:(0.15) 023:(0.41) 024:(0.65) 025:(0.59) 045:(0.02) 100:(0.0) 101:(0.01) \n",
      "\t\tProto:31 001:(0.61) 002:(0.31) 003:(0.11) 023:(0.04) 024:(0.04) 025:(0.01) 045:(0.39) 100:(0.03) 101:(0.01) \n",
      "\t\tProto:32 001:(0.22) 002:(0.07) 003:(0.49) 023:(0.16) 024:(0.03) 025:(0.01) 045:(0.03) 100:(0.07) 101:(0.0) \n",
      "\t\tProto:33 001:(0.01) 002:(0.01) 003:(0.02) 023:(0.57) 024:(0.09) 025:(0.58) 045:(0.01) 100:(0.09) 101:(0.01) \n",
      "\t\tProto:34 001:(0.01) 002:(0.04) 003:(0.04) 023:(0.51) 024:(0.53) 025:(0.57) 045:(0.0) 100:(0.01) 101:(0.0) \n",
      "\t\tProto:35 001:(0.55) 002:(0.02) 003:(0.07) 023:(0.37) 024:(0.2) 025:(0.55) 045:(0.0) 100:(0.24) 101:(0.08) \n",
      "\t\tProto:36 001:(0.26) 002:(0.2) 003:(0.55) 023:(0.04) 024:(0.03) 025:(0.01) 045:(0.3) 100:(0.35) 101:(0.14) \n",
      "\t\tProto:41 001:(0.06) 002:(0.1) 003:(0.16) 023:(0.03) 024:(0.06) 025:(0.04) 045:(0.07) 100:(0.4) 101:(0.41) \n",
      "\t\tProto:42 001:(0.24) 002:(0.4) 003:(0.01) 023:(0.0) 024:(0.0) 025:(0.0) 045:(0.07) 100:(0.26) 101:(0.46) \n",
      "\t\tProto:43 001:(0.17) 002:(0.11) 003:(0.07) 023:(0.56) 024:(0.02) 025:(0.34) 045:(0.13) 100:(0.04) 101:(0.01) \n",
      "\t\tProto:44 001:(0.08) 002:(0.47) 003:(0.01) 023:(0.01) 024:(0.72) 025:(0.01) 045:(0.14) 100:(0.29) 101:(0.51) \n",
      "\t\tProto:45 001:(0.36) 002:(0.16) 003:(0.23) 023:(0.06) 024:(0.04) 025:(0.12) 045:(0.11) 100:(0.25) 101:(0.12) \n",
      "\t\tProto:46 001:(0.01) 002:(0.49) 003:(0.02) 023:(0.0) 024:(0.0) 025:(0.0) 045:(0.58) 100:(0.15) 101:(0.4) \n",
      "\t\tProto:47 001:(0.05) 002:(0.05) 003:(0.11) 023:(0.0) 024:(0.08) 025:(0.11) 045:(0.54) 100:(0.03) 101:(0.07) \n",
      "\t\tProto:48 001:(0.58) 002:(0.3) 003:(0.05) 023:(0.01) 024:(0.0) 025:(0.02) 045:(0.06) 100:(0.83) 101:(0.31) \n",
      "\t\tProto:49 001:(0.14) 002:(0.25) 003:(0.04) 023:(0.0) 024:(0.04) 025:(0.0) 045:(0.01) 100:(0.73) 101:(0.56) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 36.41it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+031\n",
      "\t Child: 031+033\n",
      "\t\tProto:1 031:(0.33) 033:(0.48) \n",
      "\t\tProto:33 031:(0.47) 033:(0.71) \n",
      "\t\tProto:35 031:(0.67) 033:(0.54) \n",
      "\t\tProto:4 031:(0.85) 033:(0.32) \n",
      "\t\tProto:36 031:(0.75) 033:(0.53) \n",
      "\t\tProto:37 031:(0.37) 033:(0.37) \n",
      "\t\tProto:43 031:(0.69) 033:(0.4) \n",
      "\t\tProto:13 031:(0.61) 033:(0.43) \n",
      "\t\tProto:14 031:(0.85) 033:(0.57) \n",
      "\t\tProto:15 031:(0.63) 033:(0.42) \n",
      "\t\tProto:46 031:(0.62) 033:(0.48) \n",
      "\t\tProto:47 031:(0.39) 033:(0.25) \n",
      "\t\tProto:24 031:(0.79) 033:(0.31) \n",
      "\t\tProto:28 031:(0.74) 033:(0.64) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:07, 35.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+100\n",
      "\t Child: 100+023\n",
      "\t\tProto:32 023:(0.01) 024:(0.16) 025:(0.08) 100:(0.63) 101:(0.6) \n",
      "\t\tProto:2 023:(0.4) 024:(0.83) 025:(0.43) 100:(0.02) 101:(0.04) \n",
      "\t\tProto:35 023:(0.03) 024:(0.0) 025:(0.05) 100:(0.85) 101:(0.81) \n",
      "\t\tProto:6 023:(0.0) 024:(0.69) 025:(0.02) 100:(0.44) 101:(0.4) \n",
      "\t\tProto:7 023:(0.67) 024:(0.74) 025:(0.64) 100:(0.01) 101:(0.02) \n",
      "\t\tProto:8 023:(0.31) 024:(0.41) 025:(0.35) 100:(0.06) 101:(0.0) \n",
      "\t\tProto:40 023:(0.24) 024:(0.77) 025:(0.5) 100:(0.2) 101:(0.17) \n",
      "\t\tProto:41 023:(0.0) 024:(0.57) 025:(0.08) 100:(0.09) 101:(0.5) \n",
      "\t\tProto:11 023:(0.04) 024:(0.81) 025:(0.0) 100:(0.08) 101:(0.17) \n",
      "\t\tProto:44 023:(0.61) 024:(0.63) 025:(0.2) 100:(0.02) 101:(0.0) \n",
      "\t\tProto:14 023:(0.45) 024:(0.18) 025:(0.11) 100:(0.12) 101:(0.0) \n",
      "\t\tProto:46 023:(0.45) 024:(0.04) 025:(0.46) 100:(0.4) 101:(0.03) \n",
      "\t\tProto:19 023:(0.01) 024:(0.73) 025:(0.04) 100:(0.07) 101:(0.31) \n",
      "\t\tProto:22 023:(0.47) 024:(0.24) 025:(0.52) 100:(0.42) 101:(0.72) \n",
      "\t\tProto:25 023:(0.18) 024:(0.38) 025:(0.7) 100:(0.01) 101:(0.03) \n",
      "\t\tProto:27 023:(0.58) 024:(0.18) 025:(0.34) 100:(0.71) 101:(0.7) \n",
      "\t Child: 045+003\n",
      "\t\tProto:33 001:(0.21) 002:(0.42) 003:(0.27) 045:(0.56) \n",
      "\t\tProto:34 001:(0.09) 002:(0.27) 003:(0.02) 045:(0.28) \n",
      "\t\tProto:3 001:(0.39) 002:(0.16) 003:(0.19) 045:(0.43) \n",
      "\t\tProto:36 001:(0.53) 002:(0.36) 003:(0.66) 045:(0.49) \n",
      "\t\tProto:5 001:(0.27) 002:(0.23) 003:(0.62) 045:(0.61) \n",
      "\t\tProto:37 001:(0.12) 002:(0.29) 003:(0.23) 045:(0.18) \n",
      "\t\tProto:39 001:(0.5) 002:(0.64) 003:(0.12) 045:(0.64) \n",
      "\t\tProto:9 001:(0.57) 002:(0.66) 003:(0.82) 045:(0.48) \n",
      "\t\tProto:10 001:(0.62) 002:(0.32) 003:(0.35) 045:(0.4) \n",
      "\t\tProto:13 001:(0.4) 002:(0.51) 003:(0.28) 045:(0.32) \n",
      "\t\tProto:16 001:(0.71) 002:(0.73) 003:(0.38) 045:(0.5) \n",
      "\t\tProto:49 001:(0.57) 002:(0.24) 003:(0.51) 045:(0.06) \n",
      "\t\tProto:18 001:(0.15) 002:(0.16) 003:(0.21) 045:(0.23) \n",
      "\t\tProto:24 001:(0.63) 002:(0.55) 003:(0.1) 045:(0.37) \n",
      "\t\tProto:28 001:(0.66) 002:(0.72) 003:(0.18) 045:(0.12) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 37.70it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "\t Child: 003+001\n",
      "\t\tProto:0 001:(0.64) 002:(0.51) 003:(0.45) \n",
      "\t\tProto:1 001:(0.73) 002:(0.6) 003:(0.29) \n",
      "\t\tProto:6 001:(0.18) 002:(0.23) 003:(0.81) \n",
      "\t\tProto:8 001:(0.39) 002:(0.29) 003:(0.44) \n",
      "\t\tProto:10 001:(0.53) 002:(0.6) 003:(0.34) \n",
      "\t\tProto:13 001:(0.35) 002:(0.32) 003:(0.55) \n",
      "\t\tProto:14 001:(0.45) 002:(0.18) 003:(0.44) \n",
      "\t\tProto:17 001:(0.62) 002:(0.55) 003:(0.33) \n",
      "\t\tProto:21 001:(0.12) 002:(0.59) 003:(0.67) \n",
      "\t\tProto:24 001:(0.25) 002:(0.34) 003:(0.46) \n",
      "\t\tProto:27 001:(0.57) 002:(0.49) 003:(0.33) \n",
      "\t\tProto:28 001:(0.46) 002:(0.75) 003:(0.34) \n",
      "\t\tProto:29 001:(0.36) 002:(0.36) 003:(0.2) \n",
      "\t\tProto:30 001:(0.77) 002:(0.62) 003:(0.34) \n",
      "\t\tProto:31 001:(0.42) 002:(0.52) 003:(0.27) \n",
      "\t\tProto:37 001:(0.38) 002:(0.45) 003:(0.34) \n",
      "\t\tProto:40 001:(0.45) 002:(0.55) 003:(0.33) \n",
      "\t\tProto:41 001:(0.3) 002:(0.83) 003:(0.22) \n",
      "\t\tProto:46 001:(0.43) 002:(0.54) 003:(0.13) \n",
      "\t\tProto:47 001:(0.71) 002:(0.16) 003:(0.13) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:04, 33.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 100+023\n",
      "\t Child: 023+024\n",
      "\t\tProto:0 023:(0.09) 024:(0.8) 025:(0.35) \n",
      "\t\tProto:2 023:(0.54) 024:(0.54) 025:(0.56) \n",
      "\t\tProto:3 023:(0.49) 024:(0.67) 025:(0.6) \n",
      "\t\tProto:4 023:(0.47) 024:(0.52) 025:(0.6) \n",
      "\t\tProto:35 023:(0.29) 024:(0.8) 025:(0.49) \n",
      "\t\tProto:7 023:(0.58) 024:(0.9) 025:(0.56) \n",
      "\t\tProto:41 023:(0.44) 024:(0.62) 025:(0.49) \n",
      "\t\tProto:42 023:(0.13) 024:(0.51) 025:(0.55) \n",
      "\t\tProto:43 023:(0.46) 024:(0.47) 025:(0.53) \n",
      "\t\tProto:12 023:(0.32) 024:(0.58) 025:(0.07) \n",
      "\t\tProto:46 023:(0.37) 024:(0.6) 025:(0.5) \n",
      "\t\tProto:16 023:(0.48) 024:(0.83) 025:(0.27) \n",
      "\t\tProto:48 023:(0.43) 024:(0.36) 025:(0.58) \n",
      "\t\tProto:18 023:(0.24) 024:(0.43) 025:(0.21) \n",
      "\t\tProto:20 023:(0.56) 024:(0.37) 025:(0.61) \n",
      "\t\tProto:24 023:(0.64) 024:(0.37) 025:(0.47) \n",
      "\t\tProto:28 023:(0.3) 024:(0.65) 025:(0.32) \n",
      "\t\tProto:31 023:(0.67) 024:(0.73) 025:(0.3) \n",
      "\t Child: 100+101\n",
      "\t\tProto:1 100:(0.57) 101:(0.49) \n",
      "\t\tProto:33 100:(0.47) 101:(0.51) \n",
      "\t\tProto:36 100:(0.78) 101:(0.6) \n",
      "\t\tProto:6 100:(0.56) 101:(0.54) \n",
      "\t\tProto:8 100:(0.81) 101:(0.75) \n",
      "\t\tProto:40 100:(0.55) 101:(0.72) \n",
      "\t\tProto:10 100:(0.67) 101:(0.66) \n",
      "\t\tProto:13 100:(0.88) 101:(0.81) \n",
      "\t\tProto:45 100:(0.56) 101:(0.71) \n",
      "\t\tProto:15 100:(0.47) 101:(0.64) \n",
      "\t\tProto:26 100:(0.58) 101:(0.75) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 38.94it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+001\n",
      "\t Child: 001+002\n",
      "\t\tProto:0 001:(0.71) 002:(0.65) \n",
      "\t\tProto:33 001:(0.56) 002:(0.48) \n",
      "\t\tProto:3 001:(0.46) 002:(0.59) \n",
      "\t\tProto:36 001:(0.66) 002:(0.42) \n",
      "\t\tProto:6 001:(0.5) 002:(0.5) \n",
      "\t\tProto:7 001:(0.43) 002:(0.66) \n",
      "\t\tProto:40 001:(0.35) 002:(0.66) \n",
      "\t\tProto:9 001:(0.54) 002:(0.65) \n",
      "\t\tProto:42 001:(0.6) 002:(0.45) \n",
      "\t\tProto:12 001:(0.77) 002:(0.81) \n",
      "\t\tProto:17 001:(0.78) 002:(0.58) \n",
      "\t\tProto:24 001:(0.6) 002:(0.61) \n",
      "\t\tProto:25 001:(0.47) 002:(0.35) \n",
      "\t\tProto:30 001:(0.55) 002:(0.56) \n",
      "\t\tProto:31 001:(0.67) 002:(0.65) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 36.78it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+024\n",
      "\t Child: 024+025\n",
      "\t\tProto:33 024:(0.61) 025:(0.29) \n",
      "\t\tProto:35 024:(0.28) 025:(0.47) \n",
      "\t\tProto:37 024:(0.68) 025:(0.47) \n",
      "\t\tProto:38 024:(0.63) 025:(0.44) \n",
      "\t\tProto:7 024:(0.78) 025:(0.28) \n",
      "\t\tProto:9 024:(0.81) 025:(0.17) \n",
      "\t\tProto:10 024:(0.51) 025:(0.41) \n",
      "\t\tProto:12 024:(0.83) 025:(0.49) \n",
      "\t\tProto:13 024:(0.45) 025:(0.3) \n",
      "\t\tProto:14 024:(0.46) 025:(0.57) \n",
      "\t\tProto:47 024:(0.48) 025:(0.32) \n",
      "\t\tProto:18 024:(0.77) 025:(0.25) \n",
      "\t\tProto:26 024:(0.44) 025:(0.52) \n",
      "\t\tProto:27 024:(0.35) 025:(0.27) \n",
      "\t\tProto:31 024:(0.51) 025:(0.19) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - all image-activations\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    if node.name == 'root':\n",
    "        continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    \n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> (mean_activation, num_images)\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: [0, 0]))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pfs, pooled, _ = net(xs, inference=True)\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            pfs = pfs[node.name].squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                \n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    proto_mean_activations[p][leaf_descendent][0] = ((proto_mean_activations[p][leaf_descendent][0] * \\\n",
    "                                                                      proto_mean_activations[p][leaf_descendent][1]) + pooled[p]) / (proto_mean_activations[p][leaf_descendent][1] + 1)\n",
    "                    proto_mean_activations[p][leaf_descendent][1] += 1                \n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(proto_mean_activations[p][leaf_descendent][0].item(), 2)\n",
    "#                 num_images = proto_mean_activations[p][leaf_descendent][1]\n",
    "#                 logstr += f'{leaf_descendent}:{mean_activation}/{num_images} '\n",
    "                num_images = proto_mean_activations[p][leaf_descendent][1]\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk image-activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:04, 27.80it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:2 050:(0.9812) 051:(0.9933) 053:(0.6588) \n",
      "\t\tProto:3 050:(0.9053) 051:(0.9843) 053:(0.9648) \n",
      "\t\tProto:4 050:(0.9931) 051:(0.9978) 053:(0.9978) \n",
      "\t\tProto:6 050:(0.8988) 051:(0.9403) 053:(0.4896) \n",
      "\t\tProto:7 050:(0.8993) 051:(0.9874) 053:(0.9988) \n",
      "\t\tProto:9 050:(0.8468) 051:(0.9909) 053:(0.0168) \n",
      "\t\tProto:10 050:(0.9056) 051:(0.9806) 053:(0.8222) \n",
      "\t\tProto:12 050:(0.7841) 051:(0.8298) 053:(0.9349) \n",
      "\t\tProto:13 050:(0.9223) 051:(0.9959) 053:(0.8779) \n",
      "\t\tProto:14 050:(0.8708) 051:(0.9791) 053:(0.6037) \n",
      "\t\tProto:16 050:(0.9934) 051:(0.9977) 053:(0.9877) \n",
      "\t\tProto:17 050:(0.0105) 051:(0.8373) 053:(0.9993) \n",
      "\t\tProto:19 050:(0.9081) 051:(0.9834) 053:(0.9472) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:09, 45.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 086+045\n",
      "\t\tProto:0 001:(0.2513) 002:(0.872) 003:(0.9815) 023:(0.0043) 024:(0.0563) 025:(0.0958) 045:(0.9137) 086:(0.0388) 100:(0.002) 101:(0.0415) \n",
      "\t\tProto:1 001:(0.997) 002:(0.9983) 003:(0.9886) 023:(0.9976) 024:(0.9997) 025:(0.9988) 045:(0.9967) 086:(0.7949) 100:(0.9998) 101:(0.9998) \n",
      "\t\tProto:2 001:(0.6493) 002:(0.3787) 003:(0.6034) 023:(0.604) 024:(0.2477) 025:(0.6089) 045:(0.427) 086:(0.0314) 100:(0.6685) 101:(0.5068) \n",
      "\t\tProto:7 001:(0.1635) 002:(0.1849) 003:(0.0658) 023:(0.959) 024:(0.9885) 025:(0.9941) 045:(0.0094) 086:(0.1931) 100:(0.0586) 101:(0.0265) \n",
      "\t\tProto:10 001:(0.148) 002:(0.2155) 003:(0.1924) 023:(0.9361) 024:(0.7214) 025:(0.9685) 045:(0.0453) 086:(0.0569) 100:(0.0128) 101:(0.0163) \n",
      "\t\tProto:11 001:(0.9187) 002:(0.8502) 003:(0.8027) 023:(0.9992) 024:(0.9982) 025:(0.9962) 045:(0.3905) 086:(0.9992) 100:(0.0569) 101:(0.1555) \n",
      "\t\tProto:15 001:(0.8459) 002:(0.9892) 003:(0.933) 023:(0.3663) 024:(0.2743) 025:(0.7468) 045:(0.8844) 086:(0.5302) 100:(0.4635) 101:(0.9978) \n",
      "\t\tProto:17 001:(0.994) 002:(0.9994) 003:(0.9959) 023:(0.7831) 024:(0.093) 025:(0.3625) 045:(0.9992) 086:(0.9997) 100:(0.9425) 101:(0.9995) \n",
      "\t\tProto:18 001:(0.9677) 002:(0.4826) 003:(0.7992) 023:(0.937) 024:(0.8992) 025:(0.8129) 045:(0.1071) 086:(0.9834) 100:(0.9442) 101:(0.0893) \n",
      "\t\tProto:19 001:(0.1321) 002:(0.6939) 003:(0.1967) 023:(0.285) 024:(0.9903) 025:(0.2809) 045:(0.0159) 086:(0.0471) 100:(0.9377) 101:(0.9981) \n",
      "\t Child: 004+032\n",
      "\t\tProto:6 004:(0.5656) 031:(0.8714) 032:(0.5334) 033:(0.9165) \n",
      "\t\tProto:8 004:(0.0047) 031:(0.2739) 032:(0.9997) 033:(0.9984) \n",
      "\t\tProto:9 004:(0.9935) 031:(0.9968) 032:(0.9988) 033:(0.9984) \n",
      "\t\tProto:12 004:(0.014) 031:(0.9669) 032:(0.9924) 033:(0.9583) \n",
      "\t\tProto:14 004:(0.9919) 031:(0.9972) 032:(0.6266) 033:(0.9967) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:03, 25.69it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 050:(0.521) 051:(0.683) \n",
      "\t\tProto:1 050:(0.9178) 051:(0.9853) \n",
      "\t\tProto:3 050:(0.9916) 051:(0.9992) \n",
      "\t\tProto:6 050:(0.9391) 051:(0.9883) \n",
      "\t\tProto:12 050:(0.9874) 051:(0.9838) \n",
      "\t\tProto:13 050:(0.9458) 051:(0.975) \n",
      "\t\tProto:16 050:(0.6865) 051:(0.9197) \n",
      "\t\tProto:17 050:(0.7028) 051:(0.9495) \n",
      "\t\tProto:18 050:(0.1909) 051:(0.9628) \n",
      "\t\tProto:19 050:(0.9987) 051:(0.9997) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:04, 29.96it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:0 031:(0.64) 032:(0.9861) 033:(0.9767) \n",
      "\t\tProto:1 031:(0.955) 032:(0.9973) 033:(0.9998) \n",
      "\t\tProto:2 031:(0.9066) 032:(0.6783) 033:(0.6539) \n",
      "\t\tProto:4 031:(0.9999) 032:(0.9999) 033:(0.9947) \n",
      "\t\tProto:6 031:(0.9708) 032:(0.9904) 033:(0.997) \n",
      "\t\tProto:7 031:(0.9678) 032:(0.9882) 033:(0.9882) \n",
      "\t\tProto:8 031:(0.8236) 032:(0.9993) 033:(0.994) \n",
      "\t\tProto:10 031:(0.6821) 032:(0.429) 033:(0.5492) \n",
      "\t\tProto:12 031:(0.1021) 032:(0.9885) 033:(0.9915) \n",
      "\t\tProto:17 031:(0.9986) 032:(0.4277) 033:(0.7704) \n",
      "\t\tProto:18 031:(0.9996) 032:(0.884) 033:(0.9976) \n",
      "\t\tProto:19 031:(0.9998) 032:(0.3546) 033:(0.9992) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:06, 43.00it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:1 001:(0.9327) 002:(0.941) 003:(0.6165) 023:(0.1006) 024:(0.0545) 025:(0.1164) 045:(0.0277) 100:(0.9982) 101:(0.9943) \n",
      "\t\tProto:3 001:(0.9871) 002:(0.9961) 003:(0.9793) 023:(0.006) 024:(0.0688) 025:(0.0848) 045:(0.9348) 100:(0.1786) 101:(0.5683) \n",
      "\t\tProto:4 001:(0.2581) 002:(0.1579) 003:(0.0572) 023:(0.9996) 024:(1.0) 025:(0.9996) 045:(0.0904) 100:(0.8984) 101:(0.9998) \n",
      "\t\tProto:5 001:(0.9754) 002:(0.5064) 003:(0.0269) 023:(0.8366) 024:(0.9513) 025:(0.2006) 045:(0.1196) 100:(0.6982) 101:(0.9986) \n",
      "\t\tProto:6 001:(0.8895) 002:(0.8011) 003:(0.6659) 023:(0.9614) 024:(0.9995) 025:(0.9979) 045:(0.446) 100:(0.0988) 101:(0.1436) \n",
      "\t\tProto:7 001:(0.6331) 002:(0.1676) 003:(0.1906) 023:(0.8305) 024:(0.9333) 025:(0.9915) 045:(0.2363) 100:(0.0119) 101:(0.0267) \n",
      "\t\tProto:8 001:(0.44) 002:(0.6423) 003:(0.9982) 023:(0.08) 024:(0.0763) 025:(0.2964) 045:(0.9822) 100:(0.0187) 101:(0.1119) \n",
      "\t\tProto:10 001:(0.984) 002:(0.7038) 003:(0.827) 023:(0.1629) 024:(0.0555) 025:(0.1373) 045:(0.4367) 100:(0.9297) 101:(0.908) \n",
      "\t\tProto:12 001:(0.9548) 002:(0.8434) 003:(0.9546) 023:(0.9209) 024:(0.6231) 025:(0.6304) 045:(0.7392) 100:(0.6956) 101:(0.5209) \n",
      "\t\tProto:13 001:(0.0741) 002:(0.1265) 003:(0.1622) 023:(0.9828) 024:(0.9946) 025:(0.9939) 045:(0.0334) 100:(0.2586) 101:(0.0807) \n",
      "\t\tProto:14 001:(0.9905) 002:(0.9957) 003:(0.5297) 023:(0.1434) 024:(0.0821) 025:(0.3413) 045:(0.402) 100:(0.9965) 101:(0.9962) \n",
      "\t\tProto:15 001:(0.7566) 002:(0.9995) 003:(0.4178) 023:(0.0129) 024:(0.0367) 025:(0.0503) 045:(0.9611) 100:(0.9751) 101:(0.8966) \n",
      "\t\tProto:16 001:(0.0436) 002:(0.7709) 003:(0.9952) 023:(0.3687) 024:(0.0444) 025:(0.0237) 045:(0.997) 100:(0.0193) 101:(0.2638) \n",
      "\t\tProto:17 001:(0.9259) 002:(0.8788) 003:(0.134) 023:(0.0339) 024:(0.9792) 025:(0.0586) 045:(0.7367) 100:(0.0168) 101:(0.1748) \n",
      "\t\tProto:18 001:(0.1447) 002:(0.207) 003:(0.3254) 023:(0.1415) 024:(0.5348) 025:(0.8657) 045:(0.0453) 100:(0.1473) 101:(0.046) \n",
      "\t\tProto:19 001:(0.2008) 002:(0.2042) 003:(0.0192) 023:(0.9863) 024:(0.86) 025:(0.9497) 045:(0.0355) 100:(0.7805) 101:(0.0589) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:03, 25.70it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(0.9866) 033:(0.9539) \n",
      "\t\tProto:1 031:(0.9551) 033:(0.9908) \n",
      "\t\tProto:3 031:(0.9999) 033:(0.9987) \n",
      "\t\tProto:6 031:(0.9949) 033:(0.9947) \n",
      "\t\tProto:15 031:(0.9619) 033:(0.9306) \n",
      "\t\tProto:17 031:(0.9817) 033:(0.9623) \n",
      "\t\tProto:18 031:(0.8603) 033:(0.6436) \n",
      "\t\tProto:19 031:(0.9826) 033:(0.9972) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:06, 38.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "\t Child: 101+023\n",
      "\t\tProto:0 023:(0.0884) 024:(0.1109) 025:(0.1002) 100:(0.9923) 101:(1.0) \n",
      "\t\tProto:1 023:(0.9936) 024:(0.9795) 025:(0.9858) 100:(0.7331) 101:(0.0788) \n",
      "\t\tProto:2 023:(0.5907) 024:(0.0124) 025:(0.2712) 100:(0.9996) 101:(0.9977) \n",
      "\t\tProto:3 023:(0.9828) 024:(0.9984) 025:(0.9839) 100:(0.0434) 101:(0.1284) \n",
      "\t\tProto:4 023:(0.7218) 024:(0.936) 025:(0.944) 100:(0.0027) 101:(0.0117) \n",
      "\t\tProto:6 023:(0.5329) 024:(0.9976) 025:(0.1815) 100:(0.9976) 101:(0.9987) \n",
      "\t\tProto:7 023:(0.9738) 024:(0.9996) 025:(0.9996) 100:(0.0839) 101:(0.0534) \n",
      "\t\tProto:8 023:(0.9964) 024:(0.9385) 025:(0.977) 100:(0.9199) 101:(0.9903) \n",
      "\t\tProto:17 023:(0.9531) 024:(0.9808) 025:(0.9845) 100:(0.4185) 101:(0.0421) \n",
      "\t\tProto:19 023:(0.9837) 024:(0.7099) 025:(0.9314) 100:(0.1956) 101:(0.6811) \n",
      "\t Child: 045+003\n",
      "\t\tProto:5 001:(0.9969) 002:(0.9802) 003:(0.9992) 045:(0.9575) \n",
      "\t\tProto:9 001:(0.9813) 002:(0.973) 003:(0.5236) 045:(0.7514) \n",
      "\t\tProto:10 001:(0.5372) 002:(0.9549) 003:(0.9987) 045:(0.9757) \n",
      "\t\tProto:11 001:(0.9957) 002:(0.6432) 003:(0.0556) 045:(0.8602) \n",
      "\t\tProto:13 001:(0.9174) 002:(0.9847) 003:(0.9907) 045:(0.8501) \n",
      "\t\tProto:16 001:(0.9875) 002:(0.9973) 003:(0.1844) 045:(0.8729) \n",
      "\t\tProto:18 001:(0.9903) 002:(0.8374) 003:(0.9986) 045:(0.975) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 30.15it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:1 001:(0.9996) 002:(0.9999) 003:(0.9901) \n",
      "\t\tProto:2 001:(0.9988) 002:(0.3342) 003:(0.9992) \n",
      "\t\tProto:6 001:(0.9782) 002:(0.9997) 003:(0.5232) \n",
      "\t\tProto:8 001:(0.9862) 002:(0.9897) 003:(0.7589) \n",
      "\t\tProto:9 001:(0.9983) 002:(0.9504) 003:(0.9744) \n",
      "\t\tProto:10 001:(0.8371) 002:(0.769) 003:(0.8623) \n",
      "\t\tProto:12 001:(0.4241) 002:(0.9991) 003:(0.9808) \n",
      "\t\tProto:13 001:(0.9967) 002:(0.9814) 003:(0.8451) \n",
      "\t\tProto:17 001:(0.951) 002:(0.8812) 003:(0.989) \n",
      "\t\tProto:18 001:(0.9991) 002:(0.9703) 003:(0.9935) \n",
      "\t\tProto:19 001:(0.5967) 002:(0.9663) 003:(0.8627) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:04, 30.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "\t Child: 023+025\n",
      "\t\tProto:2 023:(0.9925) 024:(0.9999) 025:(0.994) \n",
      "\t\tProto:4 023:(0.6459) 024:(0.9943) 025:(0.9398) \n",
      "\t\tProto:9 023:(0.9866) 024:(0.9997) 025:(0.9869) \n",
      "\t\tProto:10 023:(0.9657) 024:(0.8642) 025:(0.999) \n",
      "\t\tProto:11 023:(0.9872) 024:(0.9962) 025:(0.9848) \n",
      "\t\tProto:13 023:(0.9906) 024:(0.998) 025:(0.9948) \n",
      "\t\tProto:16 023:(0.9859) 024:(0.9008) 025:(0.9961) \n",
      "\t\tProto:17 023:(0.9868) 024:(0.9455) 025:(0.9972) \n",
      "\t\tProto:18 023:(0.9992) 024:(0.9999) 025:(0.9904) \n",
      "\t\tProto:19 023:(0.9889) 024:(0.9981) 025:(0.983) \n",
      "\t Child: 101+100\n",
      "\t\tProto:5 100:(0.9682) 101:(0.963) \n",
      "\t\tProto:6 100:(0.9994) 101:(0.9997) \n",
      "\t\tProto:7 100:(0.9998) 101:(0.9992) \n",
      "\t\tProto:14 100:(0.9957) 101:(0.9989) \n",
      "\t\tProto:15 100:(0.973) 101:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:03, 25.72it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 001:(0.9997) 002:(0.9968) \n",
      "\t\tProto:3 001:(0.9994) 002:(0.9977) \n",
      "\t\tProto:8 001:(0.9884) 002:(0.9832) \n",
      "\t\tProto:9 001:(0.9913) 002:(0.9616) \n",
      "\t\tProto:12 001:(0.9986) 002:(0.9928) \n",
      "\t\tProto:13 001:(0.9929) 002:(0.9881) \n",
      "\t\tProto:17 001:(0.9883) 002:(0.9697) \n",
      "\t\tProto:18 001:(0.967) 002:(0.9936) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:03, 25.78it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:5 024:(0.8877) 025:(0.9721) \n",
      "\t\tProto:7 024:(0.9997) 025:(0.9806) \n",
      "\t\tProto:9 024:(0.9961) 025:(0.9071) \n",
      "\t\tProto:10 024:(0.9947) 025:(0.9869) \n",
      "\t\tProto:14 024:(0.9997) 025:(0.9982) \n",
      "\t\tProto:15 024:(0.9834) 025:(0.8558) \n",
      "\t\tProto:16 024:(0.9996) 025:(0.9967) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk image-activations\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "\n",
    "topk = 10\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    if node.name == 'root':\n",
    "        continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pfs, pooled, _ = net(xs, inference=False)\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            pfs = pfs[node.name].squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                \n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) > topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent], pooled[p].item())\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent], pooled[p].item())\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean(proto_mean_activations[p][leaf_descendent]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk image-activations for descendants AND non-descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 46.76it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "\t Child: cub_052_Pied_billed_Grebe\n",
      "\t\tProto:8 \n",
      "\t\tProto:1 \n",
      "\t\tProto:15 \n",
      "\t Child: 053+050\n",
      "\t\tProto:3 050:(0.3463) 051:(0.6158) 053:(0.9803) \n",
      "\t\tProto:4 050:(0.4718) 051:(0.9665) 053:(0.7302) \n",
      "\t\tProto:9 050:(0.9336) 051:(0.9558) 053:(0.869) \n",
      "\t\tProto:13 050:(0.8445) 051:(0.8138) 053:(0.9754) \n",
      "\t\tProto:16 050:(0.5757) 051:(0.9762) 053:(0.3438) \n",
      "\t\tProto:17 050:(0.3428) 051:(0.6701) 053:(0.9977) \n",
      "\t\tProto:19 050:(0.8314) 051:(0.9786) 053:(0.9491) \n",
      "----------Non-descendants----------\n",
      "\t Child: cub_052_Pied_billed_Grebe\n",
      "\t\tProto:8 050:(0.1338) 051:(0.238) 053:(0.2051) \n",
      "\t\tProto:1 050:(0.1159) 051:(0.1206) 053:(0.1753) \n",
      "\t\tProto:15 050:(0.1034) 051:(0.075) 053:(0.0543) \n",
      "\t Child: 053+050\n",
      "\t\tProto:3 \n",
      "\t\tProto:4 \n",
      "\t\tProto:9 \n",
      "\t\tProto:13 \n",
      "\t\tProto:16 \n",
      "\t\tProto:17 \n",
      "\t\tProto:19 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:06, 69.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 086+045\n",
      "\t\tProto:1 001:(0.997) 002:(0.9861) 003:(0.9936) 023:(0.9999) 024:(0.9999) 025:(0.9987) 045:(0.2215) 086:(0.9653) 100:(0.9999) 101:(0.9995) \n",
      "\t\tProto:18 001:(0.9511) 002:(0.9459) 003:(0.8654) 023:(0.0905) 024:(0.9998) 025:(0.0609) 045:(0.9785) 086:(0.1054) 100:(0.2469) 101:(0.9468) \n",
      "\t\tProto:11 001:(0.8842) 002:(0.9047) 003:(0.7591) 023:(0.9984) 024:(0.9844) 025:(0.9582) 045:(0.0544) 086:(0.9767) 100:(0.9973) 101:(0.9909) \n",
      "\t\tProto:17 001:(0.9986) 002:(0.9951) 003:(0.9996) 023:(0.995) 024:(0.9407) 025:(0.9991) 045:(0.9894) 086:(0.999) 100:(0.9932) 101:(0.9898) \n",
      "\t Child: 004+032\n",
      "\t\tProto:3 004:(0.936) 031:(0.9947) 032:(0.9794) 033:(0.9955) \n",
      "\t\tProto:6 004:(0.0015) 031:(0.9117) 032:(0.0052) 033:(0.5999) \n",
      "\t\tProto:8 004:(0.2968) 031:(0.9245) 032:(0.9603) 033:(0.9758) \n",
      "\t\tProto:9 004:(0.8504) 031:(0.9794) 032:(0.996) 033:(0.9823) \n",
      "\t\tProto:14 004:(0.0786) 031:(0.8892) 032:(0.8984) 033:(0.8613) \n",
      "----------Non-descendants----------\n",
      "\t Child: 086+045\n",
      "\t\tProto:1 004:(0.0112) 031:(0.004) 032:(0.001) 033:(0.0021) \n",
      "\t\tProto:18 004:(0.0009) 031:(0.0069) 032:(0.0012) 033:(0.0464) \n",
      "\t\tProto:11 004:(0.0688) 031:(0.0529) 032:(0.0195) 033:(0.01) \n",
      "\t\tProto:17 004:(0.0366) 031:(0.054) 032:(0.0195) 033:(0.008) \n",
      "\t Child: 004+032\n",
      "\t\tProto:3 001:(0.0098) 002:(0.0071) 003:(0.0081) 023:(0.0049) 024:(0.0006) 025:(0.0031) 045:(0.0048) 086:(0.0013) 100:(0.0032) 101:(0.0118) \n",
      "\t\tProto:6 001:(0.5915) 002:(0.9081) 003:(0.3913) 023:(0.0953) 024:(0.0767) 025:(0.0605) 045:(0.0157) 086:(0.1247) 100:(0.1071) 101:(0.5194) \n",
      "\t\tProto:8 001:(0.0867) 002:(0.0212) 003:(0.0327) 023:(0.0474) 024:(0.0258) 025:(0.0924) 045:(0.0296) 086:(0.2041) 100:(0.0867) 101:(0.0176) \n",
      "\t\tProto:9 001:(0.0027) 002:(0.0005) 003:(0.0019) 023:(0.0018) 024:(0.0004) 025:(0.002) 045:(0.0016) 086:(0.0006) 100:(0.0004) 101:(0.0003) \n",
      "\t\tProto:14 001:(0.0049) 002:(0.0023) 003:(0.0034) 023:(0.0037) 024:(0.0028) 025:(0.0033) 045:(0.003) 086:(0.0285) 100:(0.0013) 101:(0.0013) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 40.74it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 050:(0.5433) 051:(0.8272) \n",
      "\t\tProto:3 050:(0.6736) 051:(0.873) \n",
      "\t\tProto:6 050:(0.9504) 051:(0.9439) \n",
      "\t\tProto:16 050:(0.4021) 051:(0.7833) \n",
      "\t\tProto:18 050:(0.8933) 051:(0.9743) \n",
      "\t\tProto:19 050:(0.64) 051:(0.9804) \n",
      "\t Child: cub_053_Western_Grebe\n",
      "\t\tProto:2 \n",
      "\t\tProto:10 \n",
      "\t\tProto:5 \n",
      "\t\tProto:7 \n",
      "----------Non-descendants----------\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 \n",
      "\t\tProto:3 \n",
      "\t\tProto:6 \n",
      "\t\tProto:16 \n",
      "\t\tProto:18 \n",
      "\t\tProto:19 \n",
      "\t Child: cub_053_Western_Grebe\n",
      "\t\tProto:2 050:(0.108) 051:(0.1042) \n",
      "\t\tProto:10 050:(0.1707) 051:(0.3143) \n",
      "\t\tProto:5 050:(0.0824) 051:(0.2149) \n",
      "\t\tProto:7 050:(0.163) 051:(0.262) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 49.96it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:0 031:(0.9946) 032:(0.2255) 033:(0.9786) \n",
      "\t\tProto:2 031:(0.6317) 032:(0.9211) 033:(0.891) \n",
      "\t\tProto:4 031:(0.3885) 032:(0.9971) 033:(0.9556) \n",
      "\t\tProto:6 031:(0.9643) 032:(0.9706) 033:(0.9453) \n",
      "\t\tProto:8 031:(0.9422) 032:(0.9908) 033:(0.5563) \n",
      "\t\tProto:12 031:(0.9927) 032:(0.2122) 033:(0.9494) \n",
      "\t\tProto:18 031:(0.999) 032:(0.9799) 033:(0.9909) \n",
      "\t\tProto:19 031:(0.951) 032:(0.9913) 033:(0.994) \n",
      "\t Child: cub_004_Groove_billed_Ani\n",
      "\t\tProto:17 \n",
      "\t\tProto:3 \n",
      "\t\tProto:15 \n",
      "----------Non-descendants----------\n",
      "\t Child: 032+033\n",
      "\t\tProto:0 \n",
      "\t\tProto:2 \n",
      "\t\tProto:4 \n",
      "\t\tProto:6 \n",
      "\t\tProto:8 \n",
      "\t\tProto:12 \n",
      "\t\tProto:18 \n",
      "\t\tProto:19 \n",
      "\t Child: cub_004_Groove_billed_Ani\n",
      "\t\tProto:17 031:(0.3437) 032:(0.8141) 033:(0.6763) \n",
      "\t\tProto:3 031:(0.0507) 032:(0.0751) 033:(0.1081) \n",
      "\t\tProto:15 031:(0.0258) 032:(0.0101) 033:(0.0146) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:04, 67.58it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:1 001:(0.9694) 002:(0.9954) 003:(0.4556) 023:(0.1847) 024:(0.1629) 025:(0.1749) 045:(0.0118) 100:(0.9997) 101:(0.9998) \n",
      "\t\tProto:3 001:(0.9738) 002:(0.6426) 003:(0.8053) 023:(0.0736) 024:(0.0238) 025:(0.3744) 045:(0.9204) 100:(0.0618) 101:(0.1105) \n",
      "\t\tProto:5 001:(0.9981) 002:(0.9853) 003:(0.9952) 023:(0.0175) 024:(0.0031) 025:(0.019) 045:(0.9933) 100:(0.1009) 101:(0.0401) \n",
      "\t\tProto:7 001:(0.1499) 002:(0.7044) 003:(0.2562) 023:(0.0846) 024:(0.0271) 025:(0.0557) 045:(0.192) 100:(0.9525) 101:(0.9796) \n",
      "\t\tProto:8 001:(0.4192) 002:(0.3736) 003:(0.5578) 023:(0.981) 024:(0.9617) 025:(0.9983) 045:(0.2218) 100:(0.1904) 101:(0.0393) \n",
      "\t\tProto:10 001:(0.0179) 002:(0.0211) 003:(0.114) 023:(0.9985) 024:(0.9984) 025:(0.9936) 045:(0.0038) 100:(0.8938) 101:(0.1344) \n",
      "\t\tProto:12 001:(0.9929) 002:(0.986) 003:(0.9209) 023:(0.8328) 024:(0.4865) 025:(0.7231) 045:(0.1526) 100:(0.2511) 101:(0.0645) \n",
      "\t\tProto:13 001:(0.1469) 002:(0.019) 003:(0.0367) 023:(0.9996) 024:(0.9982) 025:(0.9976) 045:(0.0014) 100:(0.2072) 101:(0.0562) \n",
      "\t\tProto:14 001:(0.1653) 002:(0.0033) 003:(0.0104) 023:(0.0935) 024:(0.0804) 025:(0.1875) 045:(0.0558) 100:(0.9919) 101:(0.9947) \n",
      "\t\tProto:15 001:(0.5073) 002:(0.9338) 003:(0.1736) 023:(0.1329) 024:(0.3462) 025:(0.2578) 045:(0.0105) 100:(0.9962) 101:(0.9993) \n",
      "\t\tProto:16 001:(0.7519) 002:(0.2613) 003:(0.7874) 023:(0.0544) 024:(0.8813) 025:(0.0982) 045:(0.1164) 100:(0.8977) 101:(0.5895) \n",
      "\t\tProto:18 001:(0.9229) 002:(0.8493) 003:(0.9989) 023:(0.0205) 024:(0.006) 025:(0.0209) 045:(0.8169) 100:(0.0131) 101:(0.0077) \n",
      "\t\tProto:19 001:(0.5217) 002:(0.9378) 003:(0.1074) 023:(0.0769) 024:(0.9996) 025:(0.0351) 045:(0.7655) 100:(0.1308) 101:(0.9615) \n",
      "\t Child: cub_086_Pacific_Loon\n",
      "\t\tProto:9 \n",
      "\t\tProto:11 \n",
      "----------Non-descendants----------\n",
      "\t Child: 045+101\n",
      "\t\tProto:1 \n",
      "\t\tProto:3 \n",
      "\t\tProto:5 \n",
      "\t\tProto:7 \n",
      "\t\tProto:8 \n",
      "\t\tProto:10 \n",
      "\t\tProto:12 \n",
      "\t\tProto:13 \n",
      "\t\tProto:14 \n",
      "\t\tProto:15 \n",
      "\t\tProto:16 \n",
      "\t\tProto:18 \n",
      "\t\tProto:19 \n",
      "\t Child: cub_086_Pacific_Loon\n",
      "\t\tProto:9 001:(0.1121) 002:(0.0835) 003:(0.2495) 023:(0.7822) 024:(0.0181) 025:(0.325) 045:(0.0212) 100:(0.0024) 101:(0.0012) \n",
      "\t\tProto:11 001:(0.0713) 002:(0.1069) 003:(0.081) 023:(0.0812) 024:(0.0077) 025:(0.0524) 045:(0.0743) 100:(0.0276) 101:(0.0155) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 44.81it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(0.9944) 033:(0.9712) \n",
      "\t\tProto:1 031:(0.9883) 033:(0.9595) \n",
      "\t\tProto:3 031:(0.9997) 033:(0.9985) \n",
      "\t\tProto:19 031:(0.9955) 033:(0.9681) \n",
      "\t Child: cub_032_Mangrove_Cuckoo\n",
      "\t\tProto:9 \n",
      "\t\tProto:10 \n",
      "\t\tProto:11 \n",
      "\t\tProto:4 \n",
      "----------Non-descendants----------\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 \n",
      "\t\tProto:1 \n",
      "\t\tProto:3 \n",
      "\t\tProto:19 \n",
      "\t Child: cub_032_Mangrove_Cuckoo\n",
      "\t\tProto:9 031:(0.196) 033:(0.0662) \n",
      "\t\tProto:10 031:(0.3857) 033:(0.8574) \n",
      "\t\tProto:11 031:(0.1348) 033:(0.2112) \n",
      "\t\tProto:4 031:(0.0741) 033:(0.0568) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 61.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "\t Child: 101+023\n",
      "\t\tProto:1 023:(0.9774) 024:(0.9969) 025:(0.9851) 100:(0.9916) 101:(0.9987) \n",
      "\t\tProto:2 023:(0.206) 024:(0.0357) 025:(0.4072) 100:(0.9884) 101:(0.9857) \n",
      "\t\tProto:6 023:(0.9972) 024:(0.9954) 025:(0.9729) 100:(0.9892) 101:(0.997) \n",
      "\t\tProto:7 023:(0.0921) 024:(0.1993) 025:(0.087) 100:(0.9921) 101:(0.9981) \n",
      "\t\tProto:8 023:(0.9961) 024:(0.9862) 025:(0.9989) 100:(0.9986) 101:(0.9994) \n",
      "\t\tProto:19 023:(0.9874) 024:(0.9995) 025:(0.9948) 100:(0.0276) 101:(0.0021) \n",
      "\t Child: 045+003\n",
      "\t\tProto:5 001:(0.9985) 002:(0.9964) 003:(0.9994) 045:(0.992) \n",
      "\t\tProto:9 001:(0.9865) 002:(0.7352) 003:(0.9954) 045:(0.9458) \n",
      "\t\tProto:10 001:(0.979) 002:(0.9684) 003:(0.9944) 045:(0.8819) \n",
      "\t\tProto:13 001:(0.9649) 002:(0.9965) 003:(0.9903) 045:(0.9912) \n",
      "\t\tProto:16 001:(0.9965) 002:(0.9996) 003:(0.9149) 045:(0.7945) \n",
      "----------Non-descendants----------\n",
      "\t Child: 101+023\n",
      "\t\tProto:1 001:(0.0055) 002:(0.0047) 003:(0.0177) 045:(0.0038) \n",
      "\t\tProto:2 001:(0.0161) 002:(0.0012) 003:(0.0085) 045:(0.0231) \n",
      "\t\tProto:6 001:(0.0054) 002:(0.0009) 003:(0.0036) 045:(0.0006) \n",
      "\t\tProto:7 001:(0.0205) 002:(0.1342) 003:(0.0817) 045:(0.0264) \n",
      "\t\tProto:8 001:(0.0852) 002:(0.0107) 003:(0.0188) 045:(0.0164) \n",
      "\t\tProto:19 001:(0.0084) 002:(0.004) 003:(0.0096) 045:(0.0048) \n",
      "\t Child: 045+003\n",
      "\t\tProto:5 023:(0.0099) 024:(0.0058) 025:(0.0424) 100:(0.0918) 101:(0.1046) \n",
      "\t\tProto:9 023:(0.0069) 024:(0.0066) 025:(0.0348) 100:(0.0072) 101:(0.0126) \n",
      "\t\tProto:10 023:(0.0188) 024:(0.0013) 025:(0.0195) 100:(0.0107) 101:(0.012) \n",
      "\t\tProto:13 023:(0.0502) 024:(0.0085) 025:(0.0516) 100:(0.0153) 101:(0.0126) \n",
      "\t\tProto:16 023:(0.1451) 024:(0.059) 025:(0.2717) 100:(0.0191) 101:(0.0274) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 49.26it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:1 001:(0.8834) 002:(0.9829) 003:(0.9798) \n",
      "\t\tProto:2 001:(0.9785) 002:(0.8876) 003:(0.8433) \n",
      "\t\tProto:6 001:(0.7034) 002:(0.8691) 003:(0.8957) \n",
      "\t\tProto:7 001:(0.8719) 002:(0.9192) 003:(0.7221) \n",
      "\t\tProto:9 001:(0.9802) 002:(0.9616) 003:(0.8612) \n",
      "\t\tProto:11 001:(0.7904) 002:(0.8737) 003:(0.9919) \n",
      "\t\tProto:13 001:(0.9946) 002:(0.6872) 003:(0.912) \n",
      "\t\tProto:17 001:(0.9968) 002:(0.9975) 003:(0.9804) \n",
      "\t\tProto:18 001:(0.9768) 002:(0.9807) 003:(0.9698) \n",
      "\t Child: cub_045_Northern_Fulmar\n",
      "\t\tProto:3 \n",
      "\t\tProto:15 \n",
      "----------Non-descendants----------\n",
      "\t Child: 003+002\n",
      "\t\tProto:1 \n",
      "\t\tProto:2 \n",
      "\t\tProto:6 \n",
      "\t\tProto:7 \n",
      "\t\tProto:9 \n",
      "\t\tProto:11 \n",
      "\t\tProto:13 \n",
      "\t\tProto:17 \n",
      "\t\tProto:18 \n",
      "\t Child: cub_045_Northern_Fulmar\n",
      "\t\tProto:3 001:(0.156) 002:(0.0251) 003:(0.074) \n",
      "\t\tProto:15 001:(0.0878) 002:(0.1552) 003:(0.0586) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:02, 50.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "\t Child: 023+025\n",
      "\t\tProto:4 023:(0.9786) 024:(0.9956) 025:(0.9881) \n",
      "\t\tProto:9 023:(0.9653) 024:(0.9989) 025:(0.9683) \n",
      "\t\tProto:10 023:(0.9862) 024:(0.9992) 025:(0.9704) \n",
      "\t\tProto:11 023:(0.9759) 024:(0.9829) 025:(0.9649) \n",
      "\t\tProto:12 023:(0.8701) 024:(0.8798) 025:(0.9418) \n",
      "\t\tProto:13 023:(0.9865) 024:(0.9798) 025:(0.9961) \n",
      "\t\tProto:18 023:(0.9989) 024:(0.9985) 025:(0.9949) \n",
      "\t Child: 101+100\n",
      "\t\tProto:15 100:(0.9955) 101:(0.999) \n",
      "\t\tProto:5 100:(0.9992) 101:(0.9994) \n",
      "\t\tProto:6 100:(0.9998) 101:(1.0) \n",
      "\t\tProto:7 100:(0.9996) 101:(0.9992) \n",
      "----------Non-descendants----------\n",
      "\t Child: 023+025\n",
      "\t\tProto:4 100:(0.028) 101:(0.0128) \n",
      "\t\tProto:9 100:(0.0203) 101:(0.006) \n",
      "\t\tProto:10 100:(0.0663) 101:(0.0066) \n",
      "\t\tProto:11 100:(0.0059) 101:(0.0026) \n",
      "\t\tProto:12 100:(0.0696) 101:(0.0711) \n",
      "\t\tProto:13 100:(0.0197) 101:(0.0056) \n",
      "\t\tProto:18 100:(0.13) 101:(0.0263) \n",
      "\t Child: 101+100\n",
      "\t\tProto:15 023:(0.0354) 024:(0.0341) 025:(0.0232) \n",
      "\t\tProto:5 023:(0.0334) 024:(0.0067) 025:(0.0232) \n",
      "\t\tProto:6 023:(0.0085) 024:(0.0209) 025:(0.0099) \n",
      "\t\tProto:7 023:(0.0129) 024:(0.0175) 025:(0.0089) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.07it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 001:(0.9903) 002:(0.9978) \n",
      "\t\tProto:9 001:(0.9635) 002:(0.9451) \n",
      "\t\tProto:12 001:(0.9817) 002:(0.9971) \n",
      "\t\tProto:13 001:(0.9974) 002:(0.9977) \n",
      "\t\tProto:17 001:(0.9991) 002:(0.9098) \n",
      "\t Child: cub_003_Sooty_Albatross\n",
      "\t\tProto:16 \n",
      "\t\tProto:5 \n",
      "\t\tProto:6 \n",
      "----------Non-descendants----------\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 \n",
      "\t\tProto:9 \n",
      "\t\tProto:12 \n",
      "\t\tProto:13 \n",
      "\t\tProto:17 \n",
      "\t Child: cub_003_Sooty_Albatross\n",
      "\t\tProto:16 001:(0.7956) 002:(0.8146) \n",
      "\t\tProto:5 001:(0.1535) 002:(0.1556) \n",
      "\t\tProto:6 001:(0.2791) 002:(0.1938) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 45.10it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 024:(0.9801) 025:(0.9024) \n",
      "\t\tProto:6 024:(0.9964) 025:(0.9902) \n",
      "\t\tProto:7 024:(0.9901) 025:(0.8847) \n",
      "\t\tProto:9 024:(0.9991) 025:(0.9839) \n",
      "\t\tProto:10 024:(0.9988) 025:(0.7856) \n",
      "\t\tProto:11 024:(0.9925) 025:(0.9013) \n",
      "\t\tProto:14 024:(0.9985) 025:(0.9131) \n",
      "\t Child: cub_023_Brandt_Cormorant\n",
      "\t\tProto:8 \n",
      "\t\tProto:1 \n",
      "\t\tProto:2 \n",
      "\t\tProto:12 \n",
      "----------Non-descendants----------\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 \n",
      "\t\tProto:6 \n",
      "\t\tProto:7 \n",
      "\t\tProto:9 \n",
      "\t\tProto:10 \n",
      "\t\tProto:11 \n",
      "\t\tProto:14 \n",
      "\t Child: cub_023_Brandt_Cormorant\n",
      "\t\tProto:8 024:(0.1691) 025:(0.2864) \n",
      "\t\tProto:1 024:(0.2193) 025:(0.4973) \n",
      "\t\tProto:2 024:(0.0297) 025:(0.1892) \n",
      "\t\tProto:12 024:(0.6795) 025:(0.2621) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk image-activations for descendants AND non-descendants\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "\n",
    "topk = 10\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    if node.name == 'root':\n",
    "        continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "    \n",
    "    # maps proto_number -> non-descendant leaf name -> list of top-k activations\n",
    "    proto_mean_activations_non_descendants = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pfs, pooled, _ = net(xs, inference=False)\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            pfs = pfs[node.name].squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                    \n",
    "                # top-k for all the leaf nodes that are descendant to a particular prototype\n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) > topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent], pooled[p].item())\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent], pooled[p].item())\n",
    "                \n",
    "                # top-k for all the leaf nodes that are NOT descendant to a particular prototype\n",
    "                if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                    leaf_non_descendent = label2name[orig_y.item()][4:7]\n",
    "                    if topk and (len(proto_mean_activations_non_descendants[p][leaf_non_descendent]) > topk):\n",
    "                        heapq.heappushpop(proto_mean_activations_non_descendants[p][leaf_non_descendent], pooled[p].item())\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations_non_descendants[p][leaf_non_descendent], pooled[p].item())\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean(proto_mean_activations[p][leaf_descendent]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "    print(('-'*10)+'Non-descendants'+('-'*10))\n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_non_descendent in proto_mean_activations_non_descendants[p]:\n",
    "                mean_activation = round(np.mean(proto_mean_activations_non_descendants[p][leaf_non_descendent]), 4)\n",
    "                num_images = len(proto_mean_activations_non_descendants[p][leaf_non_descendent])\n",
    "                logstr += f'{leaf_non_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Collecting topk: 0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PIPNet' object has no attribute '_root_classification'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 43\u001b[0m\n\u001b[1;32m     35\u001b[0m imgs \u001b[38;5;241m=\u001b[39m modifiedLabelLoader\u001b[38;5;241m.\u001b[39mfiltered_imgs\n\u001b[1;32m     37\u001b[0m img_iter \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(modifiedLabelLoader),\n\u001b[1;32m     38\u001b[0m                 total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(modifiedLabelLoader),\n\u001b[1;32m     39\u001b[0m                 mininterval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50.\u001b[39m,\n\u001b[1;32m     40\u001b[0m                 desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCollecting topk\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     41\u001b[0m                 ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m classification_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_classification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mweight\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\u001b[39;00m\n\u001b[1;32m     46\u001b[0m proto_mean_activations \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28;01mlambda\u001b[39;00m: defaultdict(get_heap))\n",
      "File \u001b[0;32m~/.conda/envs/hpnet1/lib/python3.8/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PIPNet' object has no attribute '_root_classification'"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            softmaxes, pooled, _ = net(xs, inference=False)\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                \n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) > topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max) = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        patches.append(img_tensor_patch)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images using either NAIVE-HPIPNET or UNIT-SPACE-PROTOPOOL with HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:12, 42.40it/s]\n",
      "/tmp/ipykernel_29568/3292952886.py:56: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  resample=Image.NEAREST ))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:0 050:(0.0932) 051:(0.0942) 052:(0.0937) 053:(0.0919) \n",
      "\t\tProto:9 050:(0.1267) 051:(0.1122) 052:(0.1133) 053:(0.1204) \n",
      "\t Child: 004+086\n",
      "\t\tProto:17 001:(0.4831) 002:(0.5977) 003:(0.5832) 004:(0.6138) 023:(0.5627) 024:(0.5886) 025:(0.5865) 031:(0.5138) 032:(0.5477) 033:(0.5188) 045:(0.5671) 086:(0.5954) 100:(0.6288) 101:(0.4439) \n",
      "\t\tProto:18 001:(0.6322) 002:(0.6612) 003:(0.6551) 004:(0.6503) 023:(0.6214) 024:(0.6485) 025:(0.6534) 031:(0.6256) 032:(0.6332) 033:(0.6148) 045:(0.6365) 086:(0.569) 100:(0.6011) 101:(0.6139) \n",
      "\t\tProto:12 001:(0.1266) 002:(0.1107) 003:(0.1193) 004:(0.1049) 023:(0.1338) 024:(0.1324) 025:(0.1532) 031:(0.1081) 032:(0.1142) 033:(0.1098) 045:(0.1212) 086:(0.1417) 100:(0.1075) 101:(0.2271) \n",
      "\t\tProto:13 001:(0.1359) 002:(0.1227) 003:(0.1339) 004:(0.1183) 023:(0.1406) 024:(0.1158) 025:(0.1203) 031:(0.1107) 032:(0.1097) 033:(0.1276) 045:(0.1427) 086:(0.1381) 100:(0.115) 101:(0.1115) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 37.35it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:16 050:(0.7642) 051:(0.7836) 053:(0.7492) \n",
      "\t\tProto:18 050:(0.0904) 051:(0.0892) 053:(0.0908) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:08, 49.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:2 004:(0.0883) 031:(0.0963) 032:(0.0951) 033:(0.0994) \n",
      "\t\tProto:5 004:(0.8303) 031:(0.8423) 032:(0.8376) 033:(0.8441) \n",
      "\t Child: 086+045\n",
      "\t\tProto:19 001:(0.1002) 002:(0.111) 003:(0.1132) 023:(0.1294) 024:(0.1332) 025:(0.1245) 045:(0.0928) 086:(0.1192) 100:(0.1054) 101:(0.1243) \n",
      "\t\tProto:11 001:(0.7627) 002:(0.7488) 003:(0.7348) 023:(0.7571) 024:(0.7637) 025:(0.7576) 045:(0.651) 086:(0.7458) 100:(0.7601) 101:(0.7371) \n",
      "\t\tProto:14 001:(0.6958) 002:(0.7021) 003:(0.7123) 023:(0.6783) 024:(0.4777) 025:(0.5846) 045:(0.7331) 086:(0.7372) 100:(0.7433) 101:(0.7553) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 45.55it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:16 050:(0.7255) 051:(0.6185) \n",
      "\t\tProto:19 050:(0.799) 051:(0.8551) \n",
      "\t\tProto:12 050:(0.1356) 051:(0.1438) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 41.14it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:17 031:(0.0955) 032:(0.0932) 033:(0.0943) \n",
      "\t\tProto:18 031:(0.4917) 032:(0.4385) 033:(0.4569) \n",
      "\t\tProto:13 031:(0.8135) 032:(0.6979) 033:(0.8166) \n",
      "\t\tProto:14 031:(0.0901) 032:(0.0927) 033:(0.1021) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:05, 55.37it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:19 001:(0.1027) 002:(0.0973) 003:(0.0906) 023:(0.0911) 024:(0.1113) 025:(0.1009) 045:(0.0912) 100:(0.0996) 101:(0.0977) \n",
      "\t\tProto:15 001:(0.5878) 002:(0.5907) 003:(0.5959) 023:(0.5278) 024:(0.5709) 025:(0.5493) 045:(0.5102) 100:(0.5586) 101:(0.5669) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.70it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:18 031:(0.1158) 033:(0.1035) \n",
      "\t\tProto:19 031:(0.8491) 033:(0.8416) \n",
      "\t\tProto:13 031:(0.1099) 033:(0.1086) \n",
      "\t\tProto:14 031:(0.09) 033:(0.0925) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:05, 46.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:4 001:(0.1159) 002:(0.1215) 003:(0.1246) 045:(0.1287) \n",
      "\t\tProto:5 001:(0.1066) 002:(0.11) 003:(0.113) 045:(0.0991) \n",
      "\t Child: 101+023\n",
      "\t\tProto:13 023:(0.1139) 024:(0.1213) 025:(0.1214) 100:(0.1082) 101:(0.1183) \n",
      "\t\tProto:15 023:(0.8593) 024:(0.8611) 025:(0.8567) 100:(0.8665) 101:(0.8626) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 43.80it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:10 001:(0.1494) 002:(0.1426) 003:(0.1231) \n",
      "\t\tProto:11 001:(0.8272) 002:(0.8249) 003:(0.8236) \n",
      "\t\tProto:12 001:(0.3264) 002:(0.3001) 003:(0.3053) \n",
      "\t\tProto:14 001:(0.7395) 002:(0.7469) 003:(0.7439) \n",
      "\t\tProto:15 001:(0.1173) 002:(0.1177) 003:(0.1213) \n",
      "\t\tProto:17 001:(0.1628) 002:(0.1426) 003:(0.1597) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 38.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:1 100:(0.8183) 101:(0.8145) \n",
      "\t\tProto:4 100:(0.0949) 101:(0.0981) \n",
      "\t\tProto:5 100:(0.0901) 101:(0.0914) \n",
      "\t\tProto:9 100:(0.6156) 101:(0.6171) \n",
      "\t Child: 023+025\n",
      "\t\tProto:17 023:(0.7612) 024:(0.7723) 025:(0.7538) \n",
      "\t\tProto:18 023:(0.8237) 024:(0.8326) 025:(0.8277) \n",
      "\t\tProto:11 023:(0.133) 024:(0.1352) 025:(0.1196) \n",
      "\t\tProto:15 023:(0.1039) 024:(0.1017) 025:(0.1058) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 39.72it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:16 001:(0.0961) 002:(0.0942) \n",
      "\t\tProto:17 001:(0.088) 002:(0.1078) \n",
      "\t\tProto:10 001:(0.737) 002:(0.7414) \n",
      "\t\tProto:12 001:(0.7095) 002:(0.7113) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.72it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:10 024:(0.0959) 025:(0.0984) \n",
      "\t\tProto:14 024:(0.5295) 025:(0.5391) \n",
      "\t\tProto:16 024:(0.0969) 025:(0.0949) \n",
      "\t\tProto:17 024:(0.7439) 025:(0.7438) \n",
      "\t\tProto:19 024:(0.7566) 025:(0.664) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "find_non_descendants = False # True, False # param\n",
    "\n",
    "def find_top_percentile_bbox(image, percentile=95):\n",
    "    threshold = np.percentile(image.flatten(), percentile)\n",
    "    mask = image >= threshold\n",
    "    coords = np.argwhere(mask)\n",
    "    if coords.size == 0:\n",
    "        return None, None, None, None\n",
    "    h_min, w_min = coords.min(axis=0)\n",
    "    h_max, w_max = coords.max(axis=0)\n",
    "    h_min, h_max, w_min, w_max = map(int, [h_min, h_max, w_min, w_max])\n",
    "    return h_min, h_max, w_min, w_max\n",
    "\n",
    "def find_high_activation_crop(activation_map, percentile=95):\n",
    "    threshold = np.percentile(activation_map, percentile)\n",
    "    mask = np.ones(activation_map.shape)\n",
    "    mask[activation_map < threshold] = 0\n",
    "    lower_y, upper_y, lower_x, upper_x = 0, 0, 0, 0\n",
    "    for i in range(mask.shape[0]):\n",
    "        if np.amax(mask[i]) > 0.5:\n",
    "            lower_y = i\n",
    "            break\n",
    "    for i in reversed(range(mask.shape[0])):\n",
    "        if np.amax(mask[i]) > 0.5:\n",
    "            upper_y = i\n",
    "            break\n",
    "    for j in range(mask.shape[1]):\n",
    "        if np.amax(mask[:,j]) > 0.5:\n",
    "            lower_x = j\n",
    "            break\n",
    "    for j in reversed(range(mask.shape[1])):\n",
    "        if np.amax(mask[:,j]) > 0.5:\n",
    "            upper_x = j\n",
    "            break\n",
    "    return lower_y, upper_y+1, lower_x, upper_x+1\n",
    "\n",
    "def get_upscaled_activation_uninterpolated(latent_activation, image_size):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    min_image_a = image_a.min()\n",
    "    max_image_a = image_a.max()\n",
    "    image_a = (image_a - min_image_a) / (max_image_a - min_image_a)\n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((image_size[-1], \\\n",
    "                                                                                            image_size[-2]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    \n",
    "    reshaped_image_a = (reshaped_image_a / 255).astype('float16')\n",
    "    reshaped_image_a = (reshaped_image_a * (max_image_a - min_image_a)) + min_image_a\n",
    "    return reshaped_image_a\n",
    "\n",
    "def functional_UnitConv2D(in_features, weight, bias, stride = 1, padding=0):\n",
    "    normalized_weight = F.normalize(weight.data, p=2, dim=(1, 2, 3)) # Normalize the kernels to unit vectors\n",
    "    normalized_input = F.normalize(in_features, p=2, dim=1) # Normalize the input to unit vectors\n",
    "    if bias is not None:\n",
    "        normalized_bias = F.normalize(bias.data, p=2, dim=0) # Normalize the kernels to unit vectors\n",
    "    else:\n",
    "        normalized_bias = None\n",
    "    return F.conv2d(normalized_input, normalized_weight, normalized_bias, stride=stride, padding=padding)\n",
    "\n",
    "def findCorrespondingToMax(base, target):\n",
    "    output, indices = F.max_pool2d(base, kernel_size=(26, 26), return_indices=True)# these are logits\n",
    "    tensor_flattened = target.view(target.shape[0], target.shape[1], -1)\n",
    "    indices_flattened = indices.view(target.shape[0], target.shape[1], -1)\n",
    "    corresponding_values_in_target = torch.gather(tensor_flattened, 2, indices_flattened)\n",
    "    corresponding_values_in_target = corresponding_values_in_target.view(target.shape[0],\\\n",
    "                                     target.shape[1], 1, 1)\n",
    "    pooled_target = corresponding_values_in_target\n",
    "    return pooled_target\n",
    "\n",
    "def customForwardWithCSandSoftmax(net, xs,  inference=False):\n",
    "    features = net.module._net(xs) \n",
    "    proto_features = {}\n",
    "    proto_features_cs = {}\n",
    "    proto_features_softmaxed = {}\n",
    "    pooled = {}\n",
    "    pooled_cs = {}\n",
    "    pooled_softmaxed = {}\n",
    "    out = {}\n",
    "    for node in net.module.root.nodes_with_children():\n",
    "        # this may or may not be cosine similarity based on UniConv2D or Conv2d\n",
    "        proto_features[node.name] = getattr(net.module, '_'+node.name+'_add_on')(features)\n",
    "        \n",
    "        #calculating cosine similarity\n",
    "        prototypes = getattr(net.module, '_'+node.name+'_add_on')\n",
    "        proto_features_cs[node.name] = functional_UnitConv2D(features, prototypes.weight, prototypes.bias)\n",
    "\n",
    "        if net.module.args.softmax == 'y':\n",
    "            softmax_tau = 0.2\n",
    "            proto_features[node.name] = proto_features[node.name] / softmax_tau\n",
    "            proto_features_softmaxed[node.name] = net.module._softmax(proto_features[node.name])\n",
    "            proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "        elif net.module.args.gumbel_softmax == 'y':\n",
    "            proto_features_softmaxed[node.name] = net.module._gumbel_softmax(proto_features[node.name])\n",
    "            proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "\n",
    "        if net.module.args.multiply_cs_softmax == 'y':\n",
    "            proto_features[node.name] = proto_features_cs[node.name] * proto_features_softmaxed[node.name]\n",
    "        pooled[node.name] = net.module._pool(proto_features[node.name])\n",
    "        \n",
    "        # this could be softmax or cosine similarity\n",
    "        pooled_cs[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                     target=proto_features_cs[node.name])\n",
    "        \n",
    "        pooled_softmaxed[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                     target=proto_features_softmaxed[node.name])\n",
    "\n",
    "        if inference:\n",
    "            pooled[node.name] = torch.where(pooled[node.name] < 0.1, 0., pooled[node.name])  #during inference, ignore all prototypes that have 0.1 similarity or lower\n",
    "        out[node.name] = getattr(net.module, '_'+node.name+'_classification')(pooled[node.name]) #shape (bs*2, num_classes) # these are logits\n",
    "\n",
    "    return features, proto_features, pooled, pooled_cs, pooled_softmaxed, out\n",
    "\n",
    "topk = 10 # param, args param\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "font2 = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx # param\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if not find_non_descendants: \n",
    "            # do only when finding descendants\n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = customForwardWithCSandSoftmax(net, xs, inference=False)\n",
    "            _, softmaxes, pooled, pooled_ip, pooled_softmax, _ = model_output\n",
    "#             model_output = net(xs, inference=False)\n",
    "#             if len(model_output) == 3:\n",
    "#                 softmaxes, pooled, _ = model_output\n",
    "#             elif len(model_output) == 4:\n",
    "#                 _, softmaxes, pooled, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            pooled_ip = pooled_ip[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                if not find_non_descendants:\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), pooled_ip[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), pooled_ip[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                else:\n",
    "                    if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), pooled_ip[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), pooled_ip[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            # have this for NON descendants\n",
    "            if len(proto_mean_activations[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 # 3x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 2)\n",
    "                    least_activation = min([round(activation, 2) for activation, *_ in proto_mean_activations[p][leaf_descendent]])\n",
    "                    most_activation = max([round(activation, 2) for activation, *_ in proto_mean_activations[p][leaf_descendent]])\n",
    "                    mean_cosine_similarity = round(np.mean([activation_inner_product for _, activation_inner_product, *_ in proto_mean_activations[p][leaf_descendent]]), 2)\n",
    "                    for ele in heap:\n",
    "                        activation, activation_inner_product, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "#                         overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "#                         overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "#                         patches.append(overlayed_image)\n",
    "                        \n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        \n",
    "                        overlayed_image_pil = Image.fromarray(overlayed_image_np)\n",
    "                        draw = D.Draw(overlayed_image_pil)\n",
    "                        text = f\"{round(activation, 2), round(activation_inner_product, 2)}\"\n",
    "#                         text_width, text_height = draw.textsize(text, font2)\n",
    "                        bbox = draw.textbbox((0, 0), text, font2)\n",
    "                        text_width = bbox[2] - bbox[0]\n",
    "                        text_height = bbox[3] - bbox[1]\n",
    "                        x, y = 224 - text_width - 5, 5  # 10 pixels padding from right\n",
    "                        draw.text((x, y), text, font=font2, fill=(255, 255, 255))\n",
    "                        overlayed_image_np = np.array(overlayed_image_pil)\n",
    "                        \n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "                        \n",
    "#                         pdb.set_trace()\n",
    "                        upscaled_similarity = get_upscaled_activation_uninterpolated(latent_activation, image_size=(args.image_size, args.image_size))\n",
    "                        h_min, h_max, w_min, w_max = find_top_percentile_bbox(upscaled_similarity)\n",
    "#                         h_min, h_max, w_min, w_max = find_high_activation_crop(upscaled_similarity)\n",
    "                        h_min, h_max, w_min, w_max\n",
    "                        bbox_coords = torch.tensor([[w_min, h_min, w_max, h_max]])\n",
    "                        overlayed_bb_image = torchvision.utils.draw_bounding_boxes((overlayed_image * 255).type(torch.uint8), \\\n",
    "                                                                                   bbox_coords, colors='red') / 255\n",
    "                        \n",
    "#                         plt_image = overlayed_bb_image.permute(1, 2, 0)# should be H, W, C with 0 to 1\n",
    "#                         plt.imshow(plt_image)\n",
    "#                         plt.show()\n",
    "#                         pdb.set_trace()\n",
    "                        patches.append(overlayed_bb_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((200, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "                \n",
    "                # weird thing padding should be zero for non descendants else it raises some error\n",
    "                if find_non_descendants:\n",
    "                    padding = 0\n",
    "                else:\n",
    "                    padding = 1\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=padding)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=padding)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], 224), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((350, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "                \n",
    "                prefix = 'non_' if find_non_descendants else ''\n",
    "                os.makedirs(os.path.join(run_path, prefix + f'descendent_specific_topk_heatmap_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, prefix + f'descendent_specific_topk_heatmap_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images using either NAIVE-HPIPNET or UNIT-SPACE-PROTOPOOL with HEATMAP w/o INTERPOLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:25, 21.16it/s]\n",
      "/tmp/ipykernel_1333/1011540195.py:11: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  resample=Image.NEAREST ))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node root\n",
      "\t Child: 004+086\n",
      "\t\tProto:129 001:(0.2612) 002:(0.2903) 003:(0.7122) 004:(0.6036) 023:(0.6768) 024:(0.8801) 025:(0.8108) 031:(0.543) 032:(0.1283) 033:(0.1923) 045:(0.6167) 086:(0.1249) 100:(0.9983) 101:(0.3914) \n",
      "\t\tProto:131 001:(0.4665) 002:(0.9993) 003:(0.0102) 004:(0.0036) 023:(0.0039) 024:(0.0031) 025:(0.0028) 031:(0.1217) 032:(0.0036) 033:(0.0573) 045:(0.0803) 086:(0.0029) 100:(0.9999) 101:(0.9999) \n",
      "\t\tProto:132 001:(0.008) 002:(0.0147) 003:(0.3282) 004:(0.0143) 023:(0.0853) 024:(0.0315) 025:(0.0868) 031:(0.0742) 032:(0.0062) 033:(0.1947) 045:(0.2296) 086:(0.9974) 100:(0.0083) 101:(0.0501) \n",
      "\t\tProto:6 001:(1.0) 002:(0.575) 003:(0.9253) 004:(0.0216) 023:(0.1496) 024:(0.0252) 025:(0.1607) 031:(0.077) 032:(0.0275) 033:(0.0546) 045:(0.1215) 086:(0.3291) 100:(0.1243) 101:(0.0194) \n",
      "\t\tProto:12 001:(0.0043) 002:(0.0096) 003:(0.0079) 004:(0.0102) 023:(0.004) 024:(0.0032) 025:(0.0089) 031:(0.0064) 032:(0.0071) 033:(0.0073) 045:(0.004) 086:(0.0021) 100:(0.0021) 101:(0.0027) \n",
      "\t\tProto:14 001:(0.8683) 002:(0.6119) 003:(1.0) 004:(0.9534) 023:(0.1143) 024:(0.9942) 025:(0.3437) 031:(0.9993) 032:(0.9971) 033:(0.9996) 045:(0.2818) 086:(0.1108) 100:(0.359) 101:(0.2253) \n",
      "\t\tProto:15 001:(0.0085) 002:(0.9993) 003:(0.5623) 004:(0.0116) 023:(0.1076) 024:(1.0) 025:(0.0096) 031:(0.0066) 032:(0.0075) 033:(0.0087) 045:(0.0095) 086:(0.0063) 100:(0.3982) 101:(0.9961) \n",
      "\t\tProto:16 001:(0.5217) 002:(0.5054) 003:(0.9973) 004:(1.0) 023:(0.9641) 024:(0.9999) 025:(1.0) 031:(0.997) 032:(0.9962) 033:(0.9981) 045:(0.5206) 086:(0.0683) 100:(0.9132) 101:(0.0193) \n",
      "\t\tProto:21 001:(0.3487) 002:(0.2658) 003:(0.1569) 004:(0.5785) 023:(0.0186) 024:(0.0618) 025:(0.0585) 031:(0.9858) 032:(0.9889) 033:(0.9189) 045:(0.0131) 086:(0.0069) 100:(0.9999) 101:(0.887) \n",
      "\t\tProto:29 001:(0.9446) 002:(1.0) 003:(0.9953) 004:(0.9883) 023:(0.6897) 024:(0.9788) 025:(0.8856) 031:(0.9961) 032:(0.9926) 033:(0.998) 045:(1.0) 086:(0.0878) 100:(0.9886) 101:(0.2447) \n",
      "\t\tProto:30 001:(0.1611) 002:(0.3236) 003:(0.3626) 004:(0.5703) 023:(0.3255) 024:(0.6233) 025:(0.5281) 031:(0.9882) 032:(0.7097) 033:(0.9722) 045:(0.2189) 086:(0.0037) 100:(0.8249) 101:(0.1659) \n",
      "\t\tProto:34 001:(0.6333) 002:(1.0) 003:(0.9775) 004:(0.0108) 023:(0.0076) 024:(0.0093) 025:(0.0075) 031:(0.0491) 032:(0.0125) 033:(0.2519) 045:(1.0) 086:(0.0266) 100:(1.0) 101:(1.0) \n",
      "\t\tProto:35 001:(0.4552) 002:(0.646) 003:(0.9952) 004:(1.0) 023:(0.994) 024:(0.9998) 025:(0.9738) 031:(0.0838) 032:(0.2724) 033:(0.441) 045:(0.8461) 086:(0.552) 100:(0.3911) 101:(0.3135) \n",
      "\t\tProto:40 001:(0.9522) 002:(0.958) 003:(0.9953) 004:(0.6009) 023:(0.9641) 024:(0.4216) 025:(0.9287) 031:(0.9879) 032:(0.7358) 033:(0.6801) 045:(0.9422) 086:(0.9822) 100:(0.3667) 101:(0.5769) \n",
      "\t\tProto:45 001:(0.5076) 002:(0.5113) 003:(0.7638) 004:(0.053) 023:(0.9397) 024:(0.0796) 025:(0.6714) 031:(0.0354) 032:(0.0923) 033:(0.0415) 045:(0.6336) 086:(0.4498) 100:(0.1152) 101:(0.4532) \n",
      "\t\tProto:50 001:(0.0021) 002:(0.0021) 003:(0.0025) 004:(0.0018) 023:(0.0022) 024:(0.0018) 025:(0.0024) 031:(0.0026) 032:(0.0025) 033:(0.0025) 045:(0.0027) 086:(0.0019) 100:(0.0019) 101:(0.0023) \n",
      "\t\tProto:52 001:(0.2298) 002:(0.4392) 003:(0.9957) 004:(0.7672) 023:(0.9997) 024:(0.6995) 025:(0.9927) 031:(0.3056) 032:(0.2604) 033:(0.3578) 045:(0.7878) 086:(0.9997) 100:(0.9746) 101:(0.9896) \n",
      "\t\tProto:53 001:(0.7025) 002:(0.524) 003:(0.9944) 004:(0.0146) 023:(0.893) 024:(0.5318) 025:(0.3604) 031:(0.0314) 032:(0.0147) 033:(0.0233) 045:(0.0558) 086:(0.16) 100:(0.0066) 101:(0.0344) \n",
      "\t\tProto:60 001:(0.001) 002:(0.001) 003:(0.0019) 004:(0.001) 023:(0.0011) 024:(0.0011) 025:(0.001) 031:(0.0009) 032:(0.0007) 033:(0.0009) 045:(0.001) 086:(0.0011) 100:(0.0007) 101:(0.0007) \n",
      "\t\tProto:61 001:(0.3739) 002:(0.7394) 003:(0.7926) 004:(0.9886) 023:(0.5531) 024:(0.4195) 025:(0.8595) 031:(0.9524) 032:(0.9839) 033:(0.9913) 045:(0.4504) 086:(0.6243) 100:(0.1411) 101:(0.332) \n",
      "\t\tProto:62 001:(0.995) 002:(0.95) 003:(0.7701) 004:(0.1993) 023:(0.0161) 024:(0.0115) 025:(0.0365) 031:(0.8821) 032:(0.8516) 033:(0.901) 045:(0.0752) 086:(0.0046) 100:(0.9986) 101:(0.9984) \n",
      "\t\tProto:65 001:(0.8686) 002:(0.9846) 003:(0.9736) 004:(0.4214) 023:(0.924) 024:(0.2046) 025:(0.4688) 031:(0.9179) 032:(0.5296) 033:(0.5436) 045:(0.4029) 086:(0.9074) 100:(0.0704) 101:(0.3142) \n",
      "\t\tProto:68 001:(0.0345) 002:(0.029) 003:(0.1049) 004:(0.2768) 023:(0.3043) 024:(0.4765) 025:(0.2654) 031:(0.0449) 032:(0.1491) 033:(0.0525) 045:(0.0058) 086:(0.0015) 100:(0.1329) 101:(0.0039) \n",
      "\t\tProto:70 001:(0.9077) 002:(0.7518) 003:(0.9016) 004:(0.0265) 023:(0.0947) 024:(0.0307) 025:(0.0614) 031:(0.0481) 032:(0.0146) 033:(0.0648) 045:(0.3228) 086:(0.1878) 100:(0.9926) 101:(1.0) \n",
      "\t\tProto:72 001:(0.1211) 002:(0.142) 003:(0.9985) 004:(0.9939) 023:(0.3871) 024:(0.8109) 025:(0.7274) 031:(0.949) 032:(0.913) 033:(0.8346) 045:(0.133) 086:(0.002) 100:(0.9808) 101:(0.055) \n",
      "\t\tProto:73 001:(0.0034) 002:(0.0035) 003:(0.0092) 004:(0.014) 023:(0.0025) 024:(0.0026) 025:(0.003) 031:(0.0105) 032:(0.0066) 033:(0.0078) 045:(0.0024) 086:(0.0026) 100:(0.0029) 101:(0.0027) \n",
      "\t\tProto:79 001:(0.4595) 002:(0.4022) 003:(0.5541) 004:(0.9993) 023:(0.9056) 024:(0.9966) 025:(0.9586) 031:(0.9222) 032:(0.99) 033:(0.98) 045:(0.1576) 086:(0.0864) 100:(0.9475) 101:(0.073) \n",
      "\t\tProto:80 001:(0.9886) 002:(0.9865) 003:(0.9708) 004:(0.0182) 023:(0.0508) 024:(0.0175) 025:(0.0157) 031:(0.3904) 032:(0.0351) 033:(0.3118) 045:(0.8791) 086:(0.1903) 100:(0.8995) 101:(0.7914) \n",
      "\t\tProto:103 001:(0.0391) 002:(0.0434) 003:(0.5053) 004:(0.9697) 023:(0.7533) 024:(0.977) 025:(0.6522) 031:(0.132) 032:(0.9756) 033:(0.2571) 045:(0.0256) 086:(0.0477) 100:(0.785) 101:(0.028) \n",
      "\t\tProto:105 001:(0.7624) 002:(0.9014) 003:(0.8649) 004:(0.9976) 023:(0.7241) 024:(0.3853) 025:(0.8873) 031:(0.9182) 032:(0.8414) 033:(0.9791) 045:(0.9675) 086:(0.9636) 100:(0.8259) 101:(0.9981) \n",
      "\t\tProto:109 001:(0.0778) 002:(0.3386) 003:(0.9416) 004:(0.9541) 023:(0.5661) 024:(0.8249) 025:(0.992) 031:(0.7009) 032:(0.6133) 033:(0.1764) 045:(0.5352) 086:(0.2366) 100:(0.9733) 101:(0.5752) \n",
      "\t\tProto:118 001:(0.2291) 002:(0.3492) 003:(0.499) 004:(0.4159) 023:(0.5409) 024:(0.0888) 025:(0.6643) 031:(0.3534) 032:(0.4215) 033:(0.2918) 045:(0.4538) 086:(0.6124) 100:(0.7302) 101:(0.8892) \n",
      "\t\tProto:123 001:(0.6929) 002:(0.6361) 003:(0.974) 004:(0.0183) 023:(0.0741) 024:(0.007) 025:(0.1121) 031:(0.2837) 032:(0.0541) 033:(0.1431) 045:(0.8683) 086:(0.9977) 100:(0.6209) 101:(0.4049) \n",
      "\t\tProto:125 001:(0.048) 002:(0.3891) 003:(0.0436) 004:(0.2434) 023:(0.0428) 024:(0.0404) 025:(0.0167) 031:(0.9999) 032:(0.9882) 033:(0.9999) 045:(0.015) 086:(0.0121) 100:(0.6589) 101:(0.8246) \n",
      "\t Child: 052+053\n",
      "\t\tProto:128 050:(0.5138) 051:(0.3736) 052:(0.7446) 053:(0.3982) \n",
      "\t\tProto:97 050:(0.6196) 051:(0.303) 052:(0.91) 053:(0.0099) \n",
      "\t\tProto:98 050:(0.7116) 051:(0.6591) 052:(0.6992) 053:(0.0019) \n",
      "\t\tProto:133 050:(0.4125) 051:(0.3437) 052:(0.2668) 053:(0.0169) \n",
      "\t\tProto:38 050:(0.2294) 051:(0.9492) 052:(0.0022) 053:(0.5446) \n",
      "\t\tProto:7 050:(0.7819) 051:(0.4993) 052:(0.4239) 053:(0.0516) \n",
      "\t\tProto:122 050:(0.0007) 051:(0.0005) 052:(0.0005) 053:(0.0005) \n",
      "\t\tProto:42 050:(0.3743) 051:(0.3882) 052:(0.19) 053:(0.0024) \n",
      "\t\tProto:108 050:(0.0037) 051:(0.0038) 052:(0.0041) 053:(0.9692) \n",
      "\t\tProto:78 050:(0.0651) 051:(0.5796) 052:(0.0547) 053:(0.9995) \n",
      "\t\tProto:48 050:(0.8763) 051:(0.3793) 052:(0.9303) 053:(0.3146) \n",
      "\t\tProto:54 050:(0.6203) 051:(0.4982) 052:(0.4773) 053:(0.0036) \n",
      "\t\tProto:119 050:(0.0011) 051:(0.0009) 052:(0.001) 053:(0.0007) \n",
      "\t\tProto:25 050:(0.0007) 051:(0.0005) 052:(0.0006) 053:(0.0005) \n",
      "\t\tProto:58 050:(0.4281) 051:(0.9998) 052:(0.0016) 053:(1.0) \n",
      "\t\tProto:27 050:(0.646) 051:(0.3679) 052:(0.8386) 053:(0.0026) \n",
      "\t\tProto:92 050:(0.3552) 051:(0.895) 052:(0.0593) 053:(0.1423) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 44.00it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:2 050:(0.9998) 051:(1.0) 053:(0.9966) \n",
      "\t\tProto:5 050:(0.9836) 051:(1.0) 053:(1.0) \n",
      "\t\tProto:6 050:(0.6288) 051:(0.7202) 053:(0.9992) \n",
      "\t\tProto:7 050:(0.9999) 051:(1.0) 053:(1.0) \n",
      "\t\tProto:12 050:(0.3509) 051:(0.9964) 053:(1.0) \n",
      "\t\tProto:18 050:(0.6924) 051:(0.9923) 053:(0.9999) \n",
      "\t\tProto:22 050:(0.9997) 051:(1.0) 053:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:13, 30.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 086+045\n",
      "\t\tProto:4 001:(0.9952) 002:(0.1224) 003:(0.168) 023:(0.3687) 024:(0.0493) 025:(0.3353) 045:(0.6876) 086:(0.9994) 100:(0.1685) 101:(0.0065) \n",
      "\t\tProto:6 001:(0.0077) 002:(0.0102) 003:(0.0103) 023:(0.0141) 024:(0.0017) 025:(0.0055) 045:(0.0056) 086:(0.008) 100:(0.0042) 101:(0.0064) \n",
      "\t\tProto:9 001:(0.8311) 002:(0.6376) 003:(0.3192) 023:(0.9998) 024:(0.1377) 025:(0.9988) 045:(0.9444) 086:(1.0) 100:(1.0) 101:(0.864) \n",
      "\t\tProto:10 001:(0.8344) 002:(0.9946) 003:(0.4767) 023:(0.9939) 024:(0.8853) 025:(0.9975) 045:(0.1355) 086:(0.9993) 100:(1.0) 101:(1.0) \n",
      "\t\tProto:14 001:(0.6437) 002:(0.1747) 003:(0.1046) 023:(0.9631) 024:(0.9033) 025:(0.9923) 045:(0.0831) 086:(0.9932) 100:(0.9915) 101:(0.2236) \n",
      "\t\tProto:17 001:(0.0891) 002:(0.4045) 003:(0.9989) 023:(0.0456) 024:(0.003) 025:(0.0178) 045:(0.1817) 086:(0.0298) 100:(0.2155) 101:(0.0118) \n",
      "\t\tProto:18 001:(0.7274) 002:(0.9989) 003:(1.0) 023:(0.4726) 024:(1.0) 025:(0.3225) 045:(0.5752) 086:(0.5941) 100:(1.0) 101:(1.0) \n",
      "\t\tProto:32 001:(0.1615) 002:(0.1661) 003:(0.6706) 023:(0.0915) 024:(0.0077) 025:(0.0677) 045:(0.6948) 086:(0.1791) 100:(0.142) 101:(0.0995) \n",
      "\t\tProto:34 001:(0.9877) 002:(0.9698) 003:(0.9958) 023:(0.9997) 024:(1.0) 025:(1.0) 045:(0.9526) 086:(0.9999) 100:(1.0) 101:(0.984) \n",
      "\t\tProto:41 001:(0.9584) 002:(0.4261) 003:(0.5332) 023:(0.3841) 024:(0.0549) 025:(0.4529) 045:(0.9993) 086:(0.9995) 100:(0.5761) 101:(0.9975) \n",
      "\t\tProto:42 001:(0.0845) 002:(0.027) 003:(0.0537) 023:(0.7002) 024:(1.0) 025:(0.8071) 045:(0.0919) 086:(0.4403) 100:(0.2645) 101:(0.3529) \n",
      "\t\tProto:43 001:(0.9999) 002:(0.9797) 003:(0.9188) 023:(0.9961) 024:(1.0) 025:(0.6379) 045:(0.3398) 086:(0.8557) 100:(0.1098) 101:(0.1856) \n",
      "\t\tProto:47 001:(0.9991) 002:(0.9966) 003:(0.9997) 023:(0.9468) 024:(1.0) 025:(0.9508) 045:(0.9996) 086:(0.999) 100:(0.997) 101:(0.9969) \n",
      "\t\tProto:62 001:(0.9614) 002:(0.5553) 003:(0.9014) 023:(0.202) 024:(0.0576) 025:(0.1783) 045:(0.7261) 086:(0.1745) 100:(0.0105) 101:(0.483) \n",
      "\t\tProto:67 001:(0.4874) 002:(0.4831) 003:(0.4646) 023:(0.8044) 024:(0.0482) 025:(0.9124) 045:(0.9285) 086:(0.9829) 100:(0.9632) 101:(0.9626) \n",
      "\t\tProto:70 001:(0.4454) 002:(0.2532) 003:(0.0204) 023:(0.3219) 024:(0.0085) 025:(0.304) 045:(0.0981) 086:(0.4298) 100:(0.7721) 101:(0.3762) \n",
      "\t\tProto:74 001:(0.196) 002:(0.2044) 003:(0.2237) 023:(0.1449) 024:(0.0248) 025:(0.1051) 045:(0.3097) 086:(0.1787) 100:(0.0379) 101:(0.3888) \n",
      "\t\tProto:91 001:(0.8804) 002:(1.0) 003:(1.0) 023:(0.999) 024:(1.0) 025:(0.9996) 045:(0.9405) 086:(0.9885) 100:(1.0) 101:(0.9936) \n",
      "\t\tProto:92 001:(0.0092) 002:(0.0183) 003:(0.0086) 023:(0.0123) 024:(0.0086) 025:(0.0111) 045:(0.0146) 086:(0.0277) 100:(0.2882) 101:(0.2358) \n",
      "\t\tProto:93 001:(0.0058) 002:(0.0023) 003:(0.0046) 023:(0.1342) 024:(0.0048) 025:(0.0666) 045:(0.0037) 086:(0.2658) 100:(0.0092) 101:(0.0041) \n",
      "\t\tProto:101 001:(0.1395) 002:(1.0) 003:(1.0) 023:(0.2096) 024:(0.0424) 025:(0.0117) 045:(1.0) 086:(0.9496) 100:(0.7558) 101:(0.9433) \n",
      "\t Child: 004+032\n",
      "\t\tProto:98 004:(0.6723) 031:(0.9995) 032:(0.9991) 033:(0.9999) \n",
      "\t\tProto:11 004:(0.1006) 031:(0.1391) 032:(0.8872) 033:(0.2677) \n",
      "\t\tProto:44 004:(0.4367) 031:(0.9952) 032:(0.9927) 033:(0.9982) \n",
      "\t\tProto:13 004:(0.2589) 031:(1.0) 032:(0.998) 033:(0.9997) \n",
      "\t\tProto:78 004:(0.9994) 031:(0.671) 032:(1.0) 033:(0.9981) \n",
      "\t\tProto:49 004:(0.0022) 031:(0.0019) 032:(0.002) 033:(0.0023) \n",
      "\t\tProto:19 004:(0.9788) 031:(0.8228) 032:(0.9749) 033:(0.9471) \n",
      "\t\tProto:61 004:(0.0057) 031:(0.0036) 032:(0.005) 033:(0.0054) \n",
      "\t\tProto:85 004:(0.0083) 031:(0.0089) 032:(0.0077) 033:(0.0082) \n",
      "\t\tProto:86 004:(1.0) 031:(0.3139) 032:(0.9946) 033:(0.8839) \n",
      "\t\tProto:87 004:(0.0064) 031:(0.0047) 032:(0.0042) 033:(0.0058) \n",
      "\t\tProto:24 004:(0.9947) 031:(1.0) 032:(0.9997) 033:(1.0) \n",
      "\t\tProto:29 004:(0.9996) 031:(1.0) 032:(0.9817) 033:(0.9995) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 39.96it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:2 050:(0.4666) 051:(0.8831) \n",
      "\t\tProto:3 050:(0.5713) 051:(0.9894) \n",
      "\t\tProto:5 050:(1.0) 051:(1.0) \n",
      "\t\tProto:7 050:(1.0) 051:(1.0) \n",
      "\t\tProto:11 050:(0.9995) 051:(1.0) \n",
      "\t\tProto:12 050:(0.5917) 051:(0.9999) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 47.76it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:5 031:(0.9984) 032:(1.0) 033:(1.0) \n",
      "\t\tProto:10 031:(1.0) 032:(1.0) 033:(1.0) \n",
      "\t\tProto:13 031:(0.9977) 032:(1.0) 033:(0.9991) \n",
      "\t\tProto:14 031:(0.369) 032:(0.0217) 033:(0.2611) \n",
      "\t\tProto:21 031:(1.0) 032:(0.9999) 033:(1.0) \n",
      "\t\tProto:22 031:(0.9996) 032:(0.9996) 033:(0.9883) \n",
      "\t\tProto:23 031:(1.0) 032:(1.0) 033:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:07, 38.62it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:2 001:(0.6185) 002:(0.4642) 003:(0.6889) 023:(0.7201) 024:(0.9498) 025:(0.8116) 045:(0.353) 100:(0.9994) 101:(0.416) \n",
      "\t\tProto:5 001:(0.3571) 002:(0.7915) 003:(0.8149) 023:(0.7134) 024:(0.7455) 025:(0.9465) 045:(0.4859) 100:(0.9925) 101:(0.9972) \n",
      "\t\tProto:6 001:(0.9941) 002:(1.0) 003:(0.9772) 023:(0.9559) 024:(0.9853) 025:(0.9849) 045:(0.9687) 100:(1.0) 101:(1.0) \n",
      "\t\tProto:7 001:(0.6593) 002:(0.9516) 003:(0.9985) 023:(0.989) 024:(0.9887) 025:(0.9767) 045:(0.5532) 100:(1.0) 101:(0.9996) \n",
      "\t\tProto:8 001:(0.9997) 002:(0.9926) 003:(0.9995) 023:(0.9952) 024:(0.8638) 025:(0.9259) 045:(0.8458) 100:(0.6855) 101:(0.3206) \n",
      "\t\tProto:10 001:(0.9996) 002:(0.4097) 003:(0.9993) 023:(0.9803) 024:(0.9975) 025:(0.9144) 045:(0.4911) 100:(0.2063) 101:(0.0952) \n",
      "\t\tProto:11 001:(0.9515) 002:(0.9995) 003:(0.3745) 023:(0.4617) 024:(0.6501) 025:(0.2897) 045:(0.9328) 100:(0.9998) 101:(0.9994) \n",
      "\t\tProto:12 001:(0.9951) 002:(0.7467) 003:(0.8945) 023:(0.7893) 024:(0.9801) 025:(0.8845) 045:(0.7645) 100:(0.9371) 101:(0.5728) \n",
      "\t\tProto:16 001:(0.998) 002:(0.2042) 003:(0.9687) 023:(0.8669) 024:(0.3092) 025:(0.3299) 045:(0.8843) 100:(0.1805) 101:(0.1136) \n",
      "\t\tProto:19 001:(0.1067) 002:(0.0647) 003:(0.098) 023:(0.4852) 024:(0.964) 025:(0.3872) 045:(0.149) 100:(0.096) 101:(0.2448) \n",
      "\t\tProto:20 001:(0.0111) 002:(0.4864) 003:(0.5349) 023:(0.0158) 024:(0.8484) 025:(0.1051) 045:(0.6069) 100:(0.0112) 101:(0.8852) \n",
      "\t\tProto:21 001:(0.0119) 002:(0.838) 003:(0.0205) 023:(0.0391) 024:(0.9991) 025:(0.0139) 045:(0.0119) 100:(0.9801) 101:(1.0) \n",
      "\t\tProto:26 001:(0.9881) 002:(0.9843) 003:(0.9665) 023:(1.0) 024:(1.0) 025:(0.9995) 045:(0.2389) 100:(0.2633) 101:(0.1899) \n",
      "\t\tProto:28 001:(0.4978) 002:(0.4004) 003:(0.9553) 023:(0.952) 024:(1.0) 025:(0.9329) 045:(0.2929) 100:(0.1446) 101:(0.7188) \n",
      "\t\tProto:31 001:(0.654) 002:(0.9785) 003:(0.9911) 023:(0.9308) 024:(0.9973) 025:(0.9996) 045:(0.937) 100:(0.9948) 101:(0.9507) \n",
      "\t\tProto:34 001:(0.9297) 002:(1.0) 003:(0.2594) 023:(0.0327) 024:(0.0442) 025:(0.0228) 045:(0.9631) 100:(0.98) 101:(0.9926) \n",
      "\t\tProto:39 001:(0.4326) 002:(0.1349) 003:(0.6295) 023:(0.4994) 024:(0.6545) 025:(0.7177) 045:(0.0995) 100:(0.8544) 101:(0.1967) \n",
      "\t\tProto:47 001:(0.0357) 002:(0.0414) 003:(0.0363) 023:(0.1276) 024:(0.9994) 025:(0.0447) 045:(0.0396) 100:(0.0405) 101:(0.0335) \n",
      "\t\tProto:53 001:(0.3307) 002:(1.0) 003:(1.0) 023:(0.0416) 024:(1.0) 025:(0.0322) 045:(1.0) 100:(0.6371) 101:(0.5187) \n",
      "\t\tProto:55 001:(0.1095) 002:(0.9976) 003:(0.9999) 023:(0.2679) 024:(0.0738) 025:(0.2494) 045:(0.3397) 100:(0.3667) 101:(0.0278) \n",
      "\t\tProto:61 001:(0.2566) 002:(0.3484) 003:(0.1468) 023:(0.0432) 024:(0.03) 025:(0.1336) 045:(0.0112) 100:(0.9939) 101:(0.9924) \n",
      "\t\tProto:62 001:(0.926) 002:(0.9396) 003:(0.542) 023:(0.2114) 024:(1.0) 025:(0.2399) 045:(0.0929) 100:(0.9969) 101:(0.8426) \n",
      "\t\tProto:69 001:(0.504) 002:(0.8785) 003:(0.8754) 023:(0.9337) 024:(0.9999) 025:(0.9968) 045:(0.7204) 100:(0.9998) 101:(0.8593) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 42.19it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(0.8948) 033:(0.958) \n",
      "\t\tProto:4 031:(1.0) 033:(1.0) \n",
      "\t\tProto:14 031:(1.0) 033:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:07, 37.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:35 001:(0.7919) 002:(0.3484) 003:(0.8752) 045:(0.4736) \n",
      "\t\tProto:5 001:(1.0) 002:(0.9986) 003:(1.0) 045:(0.7853) \n",
      "\t\tProto:8 001:(1.0) 002:(0.9997) 003:(1.0) 045:(1.0) \n",
      "\t\tProto:41 001:(0.0153) 002:(0.919) 003:(0.9993) 045:(0.8159) \n",
      "\t\tProto:42 001:(0.3684) 002:(0.1212) 003:(0.8347) 045:(0.7941) \n",
      "\t\tProto:12 001:(0.9961) 002:(0.9999) 003:(0.8444) 045:(0.6295) \n",
      "\t\tProto:45 001:(0.9839) 002:(0.9911) 003:(0.9999) 045:(0.9983) \n",
      "\t\tProto:19 001:(0.0476) 002:(0.9942) 003:(0.9945) 045:(0.0758) \n",
      "\t\tProto:27 001:(0.9997) 002:(1.0) 003:(0.9992) 045:(0.9985) \n",
      "\t\tProto:61 001:(0.959) 002:(0.9066) 003:(0.9271) 045:(0.6482) \n",
      "\t\tProto:62 001:(1.0) 002:(0.9935) 003:(1.0) 045:(0.9999) \n",
      "\t Child: 101+023\n",
      "\t\tProto:32 023:(0.905) 024:(0.8151) 025:(0.9223) 100:(0.9999) 101:(0.9644) \n",
      "\t\tProto:33 023:(0.9675) 024:(0.8211) 025:(0.8492) 100:(0.9975) 101:(0.3496) \n",
      "\t\tProto:34 023:(0.9645) 024:(0.9995) 025:(0.9925) 100:(0.9927) 101:(0.0599) \n",
      "\t\tProto:37 023:(0.0842) 024:(0.0745) 025:(0.0255) 100:(0.0096) 101:(0.0076) \n",
      "\t\tProto:6 023:(0.0375) 024:(0.0201) 025:(0.0604) 100:(0.996) 101:(0.9972) \n",
      "\t\tProto:7 023:(0.9959) 024:(0.7461) 025:(0.6539) 100:(0.2913) 101:(0.8003) \n",
      "\t\tProto:38 023:(0.553) 024:(1.0) 025:(0.6172) 100:(0.0027) 101:(0.0054) \n",
      "\t\tProto:9 023:(0.1163) 024:(0.0382) 025:(0.0286) 100:(0.9748) 101:(0.9954) \n",
      "\t\tProto:50 023:(0.0664) 024:(0.0273) 025:(0.0478) 100:(0.9719) 101:(0.9987) \n",
      "\t\tProto:51 023:(0.9991) 024:(1.0) 025:(0.9237) 100:(1.0) 101:(1.0) \n",
      "\t\tProto:20 023:(0.505) 024:(0.0607) 025:(0.0621) 100:(0.9904) 101:(0.9998) \n",
      "\t\tProto:21 023:(0.6415) 024:(0.9865) 025:(0.3924) 100:(0.2728) 101:(0.1466) \n",
      "\t\tProto:53 023:(0.8943) 024:(0.9928) 025:(0.6892) 100:(0.9229) 101:(0.1176) \n",
      "\t\tProto:23 023:(0.1115) 024:(1.0) 025:(0.0285) 100:(0.1024) 101:(0.8386) \n",
      "\t\tProto:59 023:(0.9977) 024:(0.9999) 025:(0.9183) 100:(0.9999) 101:(0.0093) \n",
      "\t\tProto:28 023:(0.9996) 024:(0.9996) 025:(1.0) 100:(1.0) 101:(0.9998) \n",
      "\t\tProto:31 023:(0.0558) 024:(0.992) 025:(0.0401) 100:(0.0039) 101:(0.0035) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 44.86it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:2 001:(0.9996) 002:(0.9998) 003:(0.9999) \n",
      "\t\tProto:5 001:(0.9826) 002:(0.999) 003:(0.9957) \n",
      "\t\tProto:10 001:(1.0) 002:(0.94) 003:(1.0) \n",
      "\t\tProto:13 001:(0.9628) 002:(0.9956) 003:(0.9457) \n",
      "\t\tProto:16 001:(1.0) 002:(1.0) 003:(1.0) \n",
      "\t\tProto:17 001:(0.8804) 002:(0.9984) 003:(0.7257) \n",
      "\t\tProto:18 001:(0.1637) 002:(0.9987) 003:(0.8871) \n",
      "\t\tProto:20 001:(0.9901) 002:(0.8146) 003:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 40.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 100:(0.9999) 101:(1.0) \n",
      "\t\tProto:2 100:(1.0) 101:(0.9997) \n",
      "\t\tProto:4 100:(0.7839) 101:(1.0) \n",
      "\t\tProto:8 100:(1.0) 101:(1.0) \n",
      "\t\tProto:11 100:(0.9986) 101:(1.0) \n",
      "\t\tProto:15 100:(0.9998) 101:(1.0) \n",
      "\t\tProto:20 100:(1.0) 101:(1.0) \n",
      "\t\tProto:30 100:(1.0) 101:(1.0) \n",
      "\t\tProto:31 100:(0.9997) 101:(0.9998) \n",
      "\t Child: 023+025\n",
      "\t\tProto:3 023:(1.0) 024:(1.0) 025:(0.9998) \n",
      "\t\tProto:5 023:(0.9963) 024:(1.0) 025:(0.9991) \n",
      "\t\tProto:6 023:(0.9951) 024:(1.0) 025:(0.9155) \n",
      "\t\tProto:7 023:(0.7521) 024:(0.9994) 025:(0.2774) \n",
      "\t\tProto:9 023:(0.9996) 024:(0.9999) 025:(0.9959) \n",
      "\t\tProto:10 023:(0.697) 024:(0.9236) 025:(0.2929) \n",
      "\t\tProto:17 023:(0.9997) 024:(1.0) 025:(0.9999) \n",
      "\t\tProto:18 023:(0.0824) 024:(0.8068) 025:(0.141) \n",
      "\t\tProto:19 023:(0.9991) 024:(1.0) 025:(0.9998) \n",
      "\t\tProto:22 023:(0.8608) 024:(0.9228) 025:(0.9304) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 41.92it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:5 001:(0.9998) 002:(1.0) \n",
      "\t\tProto:7 001:(1.0) 002:(1.0) \n",
      "\t\tProto:10 001:(0.9991) 002:(0.9991) \n",
      "\t\tProto:11 001:(1.0) 002:(1.0) \n",
      "\t\tProto:15 001:(1.0) 002:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 42.86it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 024:(1.0) 025:(0.998) \n",
      "\t\tProto:1 024:(0.9994) 025:(0.1203) \n",
      "\t\tProto:3 024:(1.0) 025:(1.0) \n",
      "\t\tProto:4 024:(0.9996) 025:(0.9755) \n",
      "\t\tProto:8 024:(1.0) 025:(0.9707) \n",
      "\t\tProto:12 024:(0.998) 025:(1.0) \n",
      "\t\tProto:14 024:(1.0) 025:(1.0) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = net(xs, inference=False)\n",
    "            if len(model_output) == 3:\n",
    "                softmaxes, pooled, _ = model_output\n",
    "            elif len(model_output) == 4:\n",
    "                _, softmaxes, pooled, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                          (pooled[p].item(), img_to_open,\\\n",
    "                                           (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                       (pooled[p].item(), img_to_open,\\\n",
    "                                        (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 # 3x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        overlayed_image_np = get_heatmap_uninterpolated(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "                        patches.append(overlayed_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_heatmap_uninterp_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_heatmap_uninterp_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images using either NAIVE-HPIPNET or UNIT-SPACE-PROTOPOOL with HEATMAP w/o INTERPOLATION with SOFTMAX SCORE and INNER PRODUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import pdb\n",
    "\n",
    "# specifically written for 067-incorrect\n",
    "def custom_forward(net, xs, inference):\n",
    "    features = net.module._net(xs) \n",
    "    proto_features = {}\n",
    "    # inner product between normalized unit vectors (cosine similarity)\n",
    "    proto_features_inner_product = {}\n",
    "    pooled = {}\n",
    "    pooled_inner_product = {}\n",
    "    out = {}\n",
    "    for node in net.module.root.nodes_with_children():\n",
    "        proto_features[node.name] = getattr(net.module, '_'+node.name+'_add_on')(features)\n",
    "        proto_features[node.name] = net.module._softmax(proto_features[node.name])\n",
    "        \n",
    "        # getting inner product with kernel and input as unit vectors\n",
    "        add_on = getattr(net.module, '_'+node.name+'_add_on')\n",
    "        normalized_weight = F.normalize(add_on.weight.data, p=2, dim=(1, 2, 3)) # Normalize the kernels to unit vectors\n",
    "        normalized_input = F.normalize(features, p=2, dim=1) # Normalize the input to unit vectors\n",
    "        proto_features_inner_product[node.name] = F.conv2d(normalized_input, normalized_weight, bias=None)\n",
    "\n",
    "        pooled[node.name] = net.module._pool(proto_features[node.name])\n",
    "        if inference:\n",
    "            pooled[node.name] = torch.where(pooled[node.name] < 0.1, 0., pooled[node.name])  #during inference, ignore all prototypes that have 0.1 similarity or lower\n",
    "        out[node.name] = getattr(net.module, '_'+node.name+'_classification')(pooled[node.name]) #shape (bs*2, num_classes)\n",
    "        \n",
    "        # finding correspoding value to pooled in inner product\n",
    "#         pdb.set_trace()\n",
    "        output, indices = F.max_pool2d(proto_features[node.name], kernel_size=(26, 26), return_indices=True)# these are logits\n",
    "        tensor_flattened = proto_features_inner_product[node.name].view(proto_features_inner_product[node.name].shape[0],\\\n",
    "                                                                        proto_features_inner_product[node.name].shape[1], -1)\n",
    "        indices_flattened = indices.view(proto_features_inner_product[node.name].shape[0],\\\n",
    "                                         proto_features_inner_product[node.name].shape[1], -1)\n",
    "        corresponding_values_in_proto_features_inner_product = torch.gather(tensor_flattened, 2, indices_flattened)\n",
    "        corresponding_values_in_proto_features_inner_product = corresponding_values_in_proto_features_inner_product.view(proto_features_inner_product[node.name].shape[0],\\\n",
    "                                         proto_features_inner_product[node.name].shape[1], 1, 1)\n",
    "        pooled_inner_product[node.name] = corresponding_values_in_proto_features_inner_product\n",
    "\n",
    "    return features, proto_features, pooled, pooled_inner_product, out\n",
    "\n",
    "def findCorrespondingToMax(base, target):\n",
    "    output, indices = F.max_pool2d(base, kernel_size=(26, 26), return_indices=True)# these are logits\n",
    "    tensor_flattened = target.view(target.shape[0], target.shape[1], -1)\n",
    "    indices_flattened = indices.view(target.shape[0], target.shape[1], -1)\n",
    "    corresponding_values_in_target = torch.gather(tensor_flattened, 2, indices_flattened)\n",
    "    corresponding_values_in_target = corresponding_values_in_proto_features_inner_product.view(proto_features_inner_product[node.name].shape[0],\\\n",
    "                                     proto_features_inner_product[node.name].shape[1], 1, 1)\n",
    "    pooled_target = corresponding_values_in_target\n",
    "    return pooled_target\n",
    "\n",
    "def customForwardWithCSandSoftmax(net, xs,  inference=False):\n",
    "    features = net.module._net(xs) \n",
    "    proto_features = {}\n",
    "    proto_features_cs = {}\n",
    "    proto_features_softmaxed = {}\n",
    "    pooled = {}\n",
    "    pooled_cs = {}\n",
    "    pooled_softmaxed = {}\n",
    "    out = {}\n",
    "    for node in net.module.root.nodes_with_children():\n",
    "        proto_features[node.name] = getattr(net.module, '_'+node.name+'_add_on')(features)\n",
    "\n",
    "        if net.module.args.softmax == 'y':\n",
    "            proto_features_softmaxed[node.name] = net.module._softmax(proto_features[node.name])\n",
    "            proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "        elif net.module.args.gumbel_softmax == 'y':\n",
    "            proto_features_softmaxed[node.name] = net.module._gumbel_softmax(proto_features[node.name])\n",
    "            proto_features[node.name] = proto_features_softmaxed[node.name] # will be overwritten if args.multiply_cs_softmax == 'y'\n",
    "\n",
    "        if net.module.args.multiply_cs_softmax == 'y':\n",
    "            prototypes = getattr(net.module, '_'+node.name+'_add_on')\n",
    "            proto_features_cs[node.name] = functional_UnitConv2D(features, prototypes.weight, prototypes.bias)\n",
    "            proto_features[node.name] = proto_features_cs[node.name] * proto_features_softmaxed[node.name]\n",
    "\n",
    "        pooled[node.name] = net.module._pool(proto_features[node.name])\n",
    "\n",
    "        pooled_cs[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                     target=proto_features_cs[node.name])\n",
    "\n",
    "        pooled_softmaxed[node.name] = findCorrespondingToMax(base=proto_features[node.name], \\\n",
    "                                                     target=proto_features_softmaxed[node.name])\n",
    "\n",
    "        if inference:\n",
    "            pooled[node.name] = torch.where(pooled[node.name] < 0.1, 0., pooled[node.name])  #during inference, ignore all prototypes that have 0.1 similarity or lower\n",
    "        out[node.name] = getattr(net.module, '_'+node.name+'_classification')(pooled[node.name]) #shape (bs*2, num_classes) # these are logits\n",
    "\n",
    "    return features, proto_features, pooled, pooled_cs, pooled_softmaxed, out\n",
    "\n",
    "\n",
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 6\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 40)\n",
    "font2 = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = custom_forward(net, xs, inference=False)\n",
    "            _, softmaxes, pooled, pooled_ip, _ = model_output\n",
    "#             if len(model_output) == 4:\n",
    "#                 softmaxes, pooled, pooled_ip, _ = model_output\n",
    "#             elif len(model_output) == 5:\n",
    "#                 _, softmaxes, pooled, pooled_ip, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "#             pdb.set_trace()\n",
    "            pooled_ip = pooled_ip[node.name].squeeze()\n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                          (pooled[p].item(), pooled_ip[p].item(), img_to_open,\\\n",
    "                                           (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                       (pooled[p].item(), pooled_ip[p].item(), img_to_open,\\\n",
    "                                        (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 # 3x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 2)\n",
    "                    least_activation = min([round(activation, 2) for activation, *_ in proto_mean_activations[p][leaf_descendent]])\n",
    "                    most_activation = max([round(activation, 2) for activation, *_ in proto_mean_activations[p][leaf_descendent]])\n",
    "                    mean_cosine_similarity = round(np.mean([activation_inner_product for _, activation_inner_product, *_ in proto_mean_activations[p][leaf_descendent]]), 2)\n",
    "                    \n",
    "                    for ele in heap:\n",
    "                        activation, activation_inner_product, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        overlayed_image_np = get_heatmap_uninterpolated(latent_activation, img_tensor)\n",
    "                        \n",
    "                        overlayed_image_pil = Image.fromarray(overlayed_image_np)\n",
    "                        draw = D.Draw(overlayed_image_pil)\n",
    "                        text = f\"{round(activation, 2), round(activation_inner_product, 2)}\"\n",
    "                        text_width, text_height = draw.textsize(text, font2)\n",
    "                        x, y = 224 - text_width - 5, 5  # 10 pixels padding from right\n",
    "                        draw.text((x, y), text, font=font2, fill=(255, 255, 255))\n",
    "                        overlayed_image_np = np.array(overlayed_image_pil)\n",
    "                        \n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "                        patches.append(overlayed_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation} ({least_activation}-{most_activation}), {mean_cosine_similarity}, {round(mean_activation*mean_cosine_similarity, 2)}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((350, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((200, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_heatmap2_uninterp_cosine_and_softmax_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_heatmap2_uninterp_cosine_and_softmax_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images using either NAIVE-HPIPNET or UNIT-SPACE-PROTOPOOL with HEATMAP with SOFTMAX SCORE and INNER PRODUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import pdb\n",
    "\n",
    "# specifically written for 067-incorrect\n",
    "def custom_forward(net, xs, inference):\n",
    "    features = net.module._net(xs) \n",
    "    proto_features = {}\n",
    "    # inner product between normalized unit vectors (cosine similarity)\n",
    "    proto_features_inner_product = {}\n",
    "    pooled = {}\n",
    "    pooled_inner_product = {}\n",
    "    out = {}\n",
    "    for node in net.module.root.nodes_with_children():\n",
    "        proto_features[node.name] = getattr(net.module, '_'+node.name+'_add_on')(features)\n",
    "        proto_features[node.name] = net.module._softmax(proto_features[node.name])\n",
    "        \n",
    "        # getting inner product with kernel and input as unit vectors\n",
    "        add_on = getattr(net.module, '_'+node.name+'_add_on')\n",
    "        normalized_weight = F.normalize(add_on.weight.data, p=2, dim=(1, 2, 3)) # Normalize the kernels to unit vectors\n",
    "        normalized_input = F.normalize(features, p=2, dim=1) # Normalize the input to unit vectors\n",
    "        proto_features_inner_product[node.name] = F.conv2d(normalized_input, normalized_weight, bias=None)\n",
    "\n",
    "        pooled[node.name] = net.module._pool(proto_features[node.name])\n",
    "        if inference:\n",
    "            pooled[node.name] = torch.where(pooled[node.name] < 0.1, 0., pooled[node.name])  #during inference, ignore all prototypes that have 0.1 similarity or lower\n",
    "        out[node.name] = getattr(net.module, '_'+node.name+'_classification')(pooled[node.name]) #shape (bs*2, num_classes)\n",
    "        \n",
    "        # finding correspoding value to pooled in inner product\n",
    "#         pdb.set_trace()\n",
    "        output, indices = F.max_pool2d(proto_features[node.name], kernel_size=(26, 26), return_indices=True)# these are logits\n",
    "        tensor_flattened = proto_features_inner_product[node.name].view(proto_features_inner_product[node.name].shape[0],\\\n",
    "                                                                        proto_features_inner_product[node.name].shape[1], -1)\n",
    "        indices_flattened = indices.view(proto_features_inner_product[node.name].shape[0],\\\n",
    "                                         proto_features_inner_product[node.name].shape[1], -1)\n",
    "        corresponding_values_in_proto_features_inner_product = torch.gather(tensor_flattened, 2, indices_flattened)\n",
    "        corresponding_values_in_proto_features_inner_product = corresponding_values_in_proto_features_inner_product.view(proto_features_inner_product[node.name].shape[0],\\\n",
    "                                         proto_features_inner_product[node.name].shape[1], 1, 1)\n",
    "        pooled_inner_product[node.name] = corresponding_values_in_proto_features_inner_product\n",
    "\n",
    "    return features, proto_features, pooled, pooled_inner_product, out\n",
    "\n",
    "\n",
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = custom_forward(net, xs, inference=False)\n",
    "            _, softmaxes, pooled, pooled_ip, _ = model_output\n",
    "#             if len(model_output) == 4:\n",
    "#                 softmaxes, pooled, pooled_ip, _ = model_output\n",
    "#             elif len(model_output) == 5:\n",
    "#                 _, softmaxes, pooled, pooled_ip, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "#             pdb.set_trace()\n",
    "            pooled_ip = pooled_ip[node.name].squeeze()\n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                          (pooled[p].item(), pooled_ip[p].item(), img_to_open,\\\n",
    "                                           (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                       (pooled[p].item(), pooled_ip[p].item(), img_to_open,\\\n",
    "                                        (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 # 3x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    mean_cosine_similarity = round(np.mean([activation_inner_product for _, activation_inner_product, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    \n",
    "                    for ele in heap:\n",
    "                        activation, activation_inner_product, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "                        patches.append(overlayed_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {mean_cosine_similarity}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((200, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((200, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_heatmap_cosine_and_softmax_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_heatmap_cosine_and_softmax_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import pdb\n",
    "\n",
    "# specifically written for 067-incorrect\n",
    "def custom_forward(net, xs, inference):\n",
    "    features = net.module._net(xs) \n",
    "    proto_features = {}\n",
    "    # inner product between normalized unit vectors (cosine similarity)\n",
    "    proto_features_inner_product = {}\n",
    "    pooled = {}\n",
    "    pooled_inner_product = {}\n",
    "    out = {}\n",
    "    for node in net.module.root.nodes_with_children():\n",
    "        proto_features[node.name] = getattr(net.module, '_'+node.name+'_add_on')(features)\n",
    "        proto_features[node.name] = net.module._softmax(proto_features[node.name])\n",
    "        \n",
    "        # getting inner product with kernel and input as unit vectors\n",
    "        add_on = getattr(net.module, '_'+node.name+'_add_on')\n",
    "        normalized_weight = F.normalize(add_on.weight.data, p=2, dim=(1, 2, 3)) # Normalize the kernels to unit vectors\n",
    "        normalized_input = F.normalize(features, p=2, dim=1) # Normalize the input to unit vectors\n",
    "        proto_features_inner_product[node.name] = F.conv2d(normalized_input, normalized_weight, bias=None)\n",
    "\n",
    "        pooled[node.name] = net.module._pool(proto_features[node.name])\n",
    "        if inference:\n",
    "            pooled[node.name] = torch.where(pooled[node.name] < 0.1, 0., pooled[node.name])  #during inference, ignore all prototypes that have 0.1 similarity or lower\n",
    "        out[node.name] = getattr(net.module, '_'+node.name+'_classification')(pooled[node.name]) #shape (bs*2, num_classes)\n",
    "        \n",
    "        # finding correspoding value to pooled in inner product\n",
    "#         pdb.set_trace()\n",
    "        output, indices = F.max_pool2d(proto_features[node.name], kernel_size=(26, 26), return_indices=True)# these are logits\n",
    "        tensor_flattened = proto_features_inner_product[node.name].view(proto_features_inner_product[node.name].shape[0],\\\n",
    "                                                                        proto_features_inner_product[node.name].shape[1], -1)\n",
    "        indices_flattened = indices.view(proto_features_inner_product[node.name].shape[0],\\\n",
    "                                         proto_features_inner_product[node.name].shape[1], -1)\n",
    "        corresponding_values_in_proto_features_inner_product = torch.gather(tensor_flattened, 2, indices_flattened)\n",
    "        corresponding_values_in_proto_features_inner_product = corresponding_values_in_proto_features_inner_product.view(proto_features_inner_product[node.name].shape[0],\\\n",
    "                                         proto_features_inner_product[node.name].shape[1], 1, 1)\n",
    "        pooled_inner_product[node.name] = corresponding_values_in_proto_features_inner_product\n",
    "\n",
    "    return features, proto_features, pooled, pooled_inner_product, out\n",
    "\n",
    "\n",
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = custom_forward(net, xs, inference=False)\n",
    "            _, softmaxes, pooled, pooled_ip, _ = model_output\n",
    "#             if len(model_output) == 4:\n",
    "#                 softmaxes, pooled, pooled_ip, _ = model_output\n",
    "#             elif len(model_output) == 5:\n",
    "#                 _, softmaxes, pooled, pooled_ip, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "#             pdb.set_trace()\n",
    "            pooled_ip = pooled_ip[node.name].squeeze()\n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                          (pooled[p].item(), pooled_ip[p].item(), img_to_open,\\\n",
    "                                           (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                       (pooled[p].item(), pooled_ip[p].item(), img_to_open,\\\n",
    "                                        (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 # 3x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    mean_cosine_similarity = round(np.mean([activation_inner_product for _, activation_inner_product, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    \n",
    "                    for ele in heap:\n",
    "                        activation, activation_inner_product, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "                        patches.append(overlayed_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {mean_cosine_similarity}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((200, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((200, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_heatmap_cosine_and_softmax_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_heatmap_cosine_and_softmax_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf NON descendents - topk images using either NAIVE-HPIPNET or UNIT-SPACE-PROTOPOOL with HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 41.04it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "----------Non-descendants----------\n",
      "\t Child: 053+050\n",
      "\t\tProto:0 052:(0.0908) \n",
      "\t\tProto:9 052:(0.1684) \n",
      "\t\tProto:10 052:(0.2038) \n",
      "\t\tProto:15 052:(0.1064) \n",
      "\t\tProto:16 052:(0.1612) \n",
      "\t Child: cub_052_Pied_billed_Grebe\n",
      "\t\tProto:18 050:(0.0764) 051:(0.065) 053:(0.065) \n",
      "\t\tProto:2 050:(0.0597) 051:(0.0575) 053:(0.0513) \n",
      "\t\tProto:11 050:(0.0623) 051:(0.0493) 053:(0.0501) \n",
      "\t\tProto:13 050:(0.0715) 051:(0.0722) 053:(0.0685) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:06, 60.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "----------Non-descendants----------\n",
      "\t Child: 086+045\n",
      "\t\tProto:2 004:(0.0882) 031:(0.0819) 032:(0.0524) 033:(0.0531) \n",
      "\t\tProto:7 004:(0.0508) 031:(0.0197) 032:(0.0349) 033:(0.024) \n",
      "\t\tProto:11 004:(0.0106) 031:(0.0116) 032:(0.0073) 033:(0.0091) \n",
      "\t\tProto:15 004:(0.0689) 031:(0.0445) 032:(0.058) 033:(0.0493) \n",
      "\t\tProto:17 004:(0.1065) 031:(0.0536) 032:(0.057) 033:(0.0407) \n",
      "\t Child: 004+032\n",
      "\t\tProto:9 001:(0.0716) 002:(0.0669) 003:(0.0741) 023:(0.0739) 024:(0.0926) 025:(0.0714) 045:(0.0844) 086:(0.0665) 100:(0.0646) 101:(0.0607) \n",
      "\t\tProto:19 001:(0.06) 002:(0.0529) 003:(0.0428) 023:(0.049) 024:(0.0508) 025:(0.0543) 045:(0.0547) 086:(0.0497) 100:(0.0461) 101:(0.0529) \n",
      "\t\tProto:14 001:(0.0197) 002:(0.0302) 003:(0.027) 023:(0.0227) 024:(0.0345) 025:(0.0239) 045:(0.0221) 086:(0.0238) 100:(0.0187) 101:(0.0463) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 35.61it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "----------Non-descendants----------\n",
      "\t Child: cub_053_Western_Grebe\n",
      "\t\tProto:9 050:(0.0756) 051:(0.0558) \n",
      "\t\tProto:3 050:(0.0852) 051:(0.0545) \n",
      "\t\tProto:17 050:(0.0967) 051:(0.1059) \n",
      "\t Child: 050+051\n",
      "\t\tProto:5 053:(0.0629) \n",
      "\t\tProto:7 053:(0.0509) \n",
      "\t\tProto:10 053:(0.041) \n",
      "\t\tProto:13 053:(0.0291) \n",
      "\t\tProto:15 053:(0.0408) \n",
      "\t\tProto:19 053:(0.0408) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 40.46it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "----------Non-descendants----------\n",
      "\t Child: 032+033\n",
      "\t\tProto:3 004:(0.0283) \n",
      "\t\tProto:5 004:(0.0315) \n",
      "\t\tProto:8 004:(0.0383) \n",
      "\t\tProto:9 004:(0.0375) \n",
      "\t\tProto:13 004:(0.0129) \n",
      "\t\tProto:14 004:(0.0415) \n",
      "\t Child: cub_004_Groove_billed_Ani\n",
      "\t\tProto:18 031:(0.048) 032:(0.0517) 033:(0.0499) \n",
      "\t\tProto:19 031:(0.0383) 032:(0.0342) 033:(0.0325) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:05, 55.76it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "----------Non-descendants----------\n",
      "\t Child: 045+101\n",
      "\t\tProto:4 086:(0.0654) \n",
      "\t\tProto:8 086:(0.0471) \n",
      "\t\tProto:9 086:(0.0482) \n",
      "\t\tProto:10 086:(0.0798) \n",
      "\t\tProto:12 086:(0.1416) \n",
      "\t\tProto:14 086:(0.0201) \n",
      "\t\tProto:15 086:(0.134) \n",
      "\t\tProto:16 086:(0.0419) \n",
      "\t\tProto:17 086:(0.1218) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 35.33it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "----------Non-descendants----------\n",
      "\t Child: cub_032_Mangrove_Cuckoo\n",
      "\t\tProto:0 031:(0.0819) 033:(0.0837) \n",
      "\t\tProto:10 031:(0.0782) 033:(0.0825) \n",
      "\t\tProto:4 031:(0.0446) 033:(0.0307) \n",
      "\t\tProto:15 031:(0.1248) 033:(0.17) \n",
      "\t Child: 033+031\n",
      "\t\tProto:11 032:(0.0243) \n",
      "\t\tProto:16 032:(0.0182) \n",
      "\t\tProto:3 032:(0.0503) \n",
      "\t\tProto:5 032:(0.0381) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 54.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "----------Non-descendants----------\n",
      "\t Child: 101+023\n",
      "\t\tProto:2 001:(0.0804) 002:(0.0647) 003:(0.065) 045:(0.0625) \n",
      "\t\tProto:5 001:(0.0633) 002:(0.0377) 003:(0.0322) 045:(0.0452) \n",
      "\t\tProto:7 001:(0.0963) 002:(0.0331) 003:(0.0281) 045:(0.0293) \n",
      "\t\tProto:10 001:(0.0752) 002:(0.0169) 003:(0.0332) 045:(0.0291) \n",
      "\t\tProto:13 001:(0.1336) 002:(0.1355) 003:(0.1384) 045:(0.1419) \n",
      "\t\tProto:15 001:(0.0753) 002:(0.0308) 003:(0.0305) 045:(0.036) \n",
      "\t Child: 045+003\n",
      "\t\tProto:9 023:(0.0903) 024:(0.0388) 025:(0.0643) 100:(0.0388) 101:(0.1533) \n",
      "\t\tProto:17 023:(0.0425) 024:(0.0231) 025:(0.029) 100:(0.026) 101:(0.0466) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 38.87it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "----------Non-descendants----------\n",
      "\t Child: 003+002\n",
      "\t\tProto:0 045:(0.1016) \n",
      "\t\tProto:3 045:(0.0997) \n",
      "\t\tProto:7 045:(0.0667) \n",
      "\t\tProto:8 045:(0.264) \n",
      "\t\tProto:11 045:(0.1125) \n",
      "\t\tProto:15 045:(0.0718) \n",
      "\t\tProto:18 045:(0.0444) \n",
      "\t Child: cub_045_Northern_Fulmar\n",
      "\t\tProto:1 001:(0.0961) 002:(0.0953) 003:(0.0363) \n",
      "\t\tProto:5 001:(0.0521) 002:(0.0817) 003:(0.0903) \n",
      "\t\tProto:12 001:(0.0787) 002:(0.0768) 003:(0.0962) \n",
      "\t\tProto:16 001:(0.1059) 002:(0.1418) 003:(0.1131) \n",
      "\t\tProto:17 001:(0.0743) 002:(0.0635) 003:(0.1048) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 44.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "----------Non-descendants----------\n",
      "\t Child: 101+100\n",
      "\t\tProto:16 023:(0.0293) 024:(0.0338) 025:(0.0361) \n",
      "\t\tProto:2 023:(0.0413) 024:(0.0386) 025:(0.042) \n",
      "\t\tProto:7 023:(0.0114) 024:(0.0151) 025:(0.0121) \n",
      "\t Child: 023+025\n",
      "\t\tProto:6 100:(0.0969) 101:(0.0412) \n",
      "\t\tProto:9 100:(0.0581) 101:(0.0628) \n",
      "\t\tProto:11 100:(0.0344) 101:(0.031) \n",
      "\t\tProto:14 100:(0.0714) 101:(0.0686) \n",
      "\t\tProto:18 100:(0.0701) 101:(0.0604) \n",
      "\t\tProto:19 100:(0.1134) 101:(0.1207) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 33.90it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "----------Non-descendants----------\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 003:(0.0495) \n",
      "\t\tProto:1 003:(0.0777) \n",
      "\t\tProto:8 003:(0.0899) \n",
      "\t\tProto:14 003:(0.0235) \n",
      "\t\tProto:16 003:(0.0354) \n",
      "\t\tProto:18 003:(0.0942) \n",
      "\t\tProto:19 003:(0.0203) \n",
      "\t Child: cub_003_Sooty_Albatross\n",
      "\t\tProto:4 001:(0.0714) 002:(0.1001) \n",
      "\t\tProto:7 001:(0.0676) 002:(0.0674) \n",
      "\t\tProto:11 001:(0.0644) 002:(0.083) \n",
      "\t\tProto:15 001:(0.1199) 002:(0.1413) \n",
      "\t\tProto:17 001:(0.0358) 002:(0.044) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 34.55it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "----------Non-descendants----------\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 023:(0.0918) \n",
      "\t\tProto:2 023:(0.1261) \n",
      "\t\tProto:5 023:(0.1107) \n",
      "\t\tProto:12 023:(0.119) \n",
      "\t\tProto:13 023:(0.1062) \n",
      "\t\tProto:16 023:(0.089) \n",
      "\t\tProto:17 023:(0.128) \n",
      "\t Child: cub_023_Brandt_Cormorant\n",
      "\t\tProto:8 024:(0.0321) 025:(0.0582) \n",
      "\t\tProto:10 024:(0.1141) 025:(0.1576) \n",
      "\t\tProto:7 024:(0.0612) 025:(0.1679) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images NON DESCENDANTS\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    if node.name == 'root':\n",
    "        continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "#     # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "#     proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "    \n",
    "    # maps proto_number -> non-descendant leaf name -> list of top-k activations\n",
    "    proto_mean_activations_non_descendants = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        # comment this for NON descendants\n",
    "#         if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "#             continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = net(xs, inference=False)\n",
    "            if len(model_output) == 3:\n",
    "                softmaxes, pooled, _ = model_output\n",
    "            elif len(model_output) == 4:\n",
    "                _, softmaxes, pooled, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "#                 if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "#                     continue\n",
    "                    \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                # top-k for all the leaf nodes that are NOT descendant to a particular prototype\n",
    "                if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                    leaf_non_descendent = label2name[orig_y.item()][4:7]\n",
    "                    img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                    if topk and (len(proto_mean_activations_non_descendants[p][leaf_non_descendent]) >= topk):\n",
    "                        heapq.heappushpop(proto_mean_activations_non_descendants[p][leaf_non_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations_non_descendants[p][leaf_non_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "                \n",
    "#                 if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "#                     child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "#                     leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "#                     img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "#                     if topk and (len(proto_mean_activations[p][leaf_descendent]) > topk):\n",
    "#                         heapq.heappushpop(proto_mean_activations[p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "#                     else:\n",
    "#                         heapq.heappush(proto_mean_activations[p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    print(('-'*10)+'Non-descendants'+('-'*10))\n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_non_descendent in proto_mean_activations_non_descendants[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations_non_descendants[p][leaf_non_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations_non_descendants[p][leaf_non_descendent])\n",
    "                logstr += f'{leaf_non_descendent}:({mean_activation}) '\n",
    "                \n",
    "            print(logstr)\n",
    "            \n",
    "            # have this for NON descendants\n",
    "            if len(proto_mean_activations_non_descendants[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 # 7x the width of a patch\n",
    "                \n",
    "                for leaf_non_descendent, heap in proto_mean_activations_non_descendants[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations_non_descendants[p][leaf_non_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "                        patches.append(overlayed_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_non_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "                    \n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=0)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=0)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, 'non_descendent_specific_topk_heatmap', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, 'non_descendent_specific_topk_heatmap', node.name, f'nd-{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images (marks whether overspecific or shared trait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:22, 23.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node root\n",
      "\t Child: 052+053\n",
      "OVERSPECIFIC \t\tProto:0 050:(0.3723) 051:(0.7658) 052:(0.0123) 053:(0.0155) \n",
      "> \u001b[0;32m/tmp/ipykernel_59216/165405032.py\u001b[0m(151)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    149 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    150 \u001b[0;31m                \u001b[0;31m# merging right description with the grid of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 151 \u001b[0;31m                \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_right_descriptions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    152 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    153 \u001b[0;31m                \u001b[0;31m# description on the top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> grid.shape\n",
      "torch.Size([3, 197, 364])\n",
      "ipdb> grid_right_descriptions.shape\n",
      "torch.Size([3, 133, 338])\n",
      "ipdb> patches[0].shape\n",
      "torch.Size([3, 48, 32])\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images (marks whether overspecific or shared trait)\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            softmaxes, pooled, _ = net(xs, inference=False)\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                    \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                \n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) > topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            topk_mean_activations = []\n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                topk_mean_activations.append(mean_activation)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            \n",
    "            relevant_proto = np.all(np.array(topk_mean_activations) > THRESHOLD)\n",
    "            \n",
    "            \n",
    "            print(('SHARED ' if relevant_proto else 'OVERSPECIFIC ') + logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    std_activation = round(np.std([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max) = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        text = f'{round(activation)}'\n",
    "                        txtimage = Image.new(\"RGB\", (img_tensor_patch.shape[-1],\\\n",
    "                                                     img_tensor_patch.shape[-2]//2), (0, 0, 0))\n",
    "                        draw = D.Draw(txtimage)         \n",
    "                        draw.text((5, img_tensor_patch[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                        txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                        \n",
    "                        img_tensor_patch = torch.cat([img_tensor_patch, txttensor], dim=1)\n",
    "                        patches.append(img_tensor_patch)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'mean={mean_activation}, std={std_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "                \n",
    "                pdb.set_trace()\n",
    "                \n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}' + (', SHARED-FEATURE' if relevant_proto else ', NON-SHARED/OVERSPECIFIC')\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "                \n",
    "                if relevant_proto:\n",
    "                    os.makedirs(os.path.join(run_path, f'r_descendent_specific_topk_ep={epoch}', node.name), exist_ok=True)\n",
    "                    torchvision.utils.save_image(grid, os.path.join(run_path, f'r_descendent_specific_topk_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "                else:\n",
    "                    os.makedirs(os.path.join(run_path, f'nr_descendent_specific_topk_ep={epoch}', node.name), exist_ok=True)\n",
    "                    torchvision.utils.save_image(grid, os.path.join(run_path, f'nr_descendent_specific_topk_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf NON-descendents - topk images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 50.85it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "----------Non-descendants----------\n",
      "\t Child: 053+050\n",
      "\t\tProto:3 \n",
      "\t\tProto:4 \n",
      "\t\tProto:9 \n",
      "\t\tProto:13 \n",
      "\t\tProto:16 \n",
      "\t\tProto:17 \n",
      "\t\tProto:19 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:06, 66.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "----------Non-descendants----------\n",
      "\t Child: 086+045\n",
      "\t\tProto:1 004:(0.0112) 031:(0.004) 032:(0.001) 033:(0.0021) \n",
      "\t\tProto:18 004:(0.0009) 031:(0.0069) 032:(0.0012) 033:(0.0464) \n",
      "\t\tProto:11 004:(0.0688) 031:(0.0529) 032:(0.0195) 033:(0.01) \n",
      "\t\tProto:17 004:(0.0366) 031:(0.054) 032:(0.0195) 033:(0.008) \n",
      "\t Child: 004+032\n",
      "\t\tProto:3 001:(0.0098) 002:(0.0071) 003:(0.0081) 023:(0.0049) 024:(0.0006) 025:(0.0031) 045:(0.0048) 086:(0.0013) 100:(0.0032) 101:(0.0118) \n",
      "\t\tProto:6 001:(0.5915) 002:(0.9081) 003:(0.3913) 023:(0.0953) 024:(0.0767) 025:(0.0605) 045:(0.0157) 086:(0.1247) 100:(0.1071) 101:(0.5194) \n",
      "\t\tProto:8 001:(0.0867) 002:(0.0212) 003:(0.0327) 023:(0.0474) 024:(0.0258) 025:(0.0924) 045:(0.0296) 086:(0.2041) 100:(0.0867) 101:(0.0176) \n",
      "\t\tProto:9 001:(0.0027) 002:(0.0005) 003:(0.0019) 023:(0.0018) 024:(0.0004) 025:(0.002) 045:(0.0016) 086:(0.0006) 100:(0.0004) 101:(0.0003) \n",
      "\t\tProto:14 001:(0.0049) 002:(0.0023) 003:(0.0034) 023:(0.0037) 024:(0.0028) 025:(0.0033) 045:(0.003) 086:(0.0285) 100:(0.0013) 101:(0.0013) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 42.46it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "----------Non-descendants----------\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 \n",
      "\t\tProto:3 \n",
      "\t\tProto:6 \n",
      "\t\tProto:16 \n",
      "\t\tProto:18 \n",
      "\t\tProto:19 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 50.39it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "----------Non-descendants----------\n",
      "\t Child: 032+033\n",
      "\t\tProto:0 \n",
      "\t\tProto:2 \n",
      "\t\tProto:4 \n",
      "\t\tProto:6 \n",
      "\t\tProto:8 \n",
      "\t\tProto:12 \n",
      "\t\tProto:18 \n",
      "\t\tProto:19 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:04, 65.06it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "----------Non-descendants----------\n",
      "\t Child: 045+101\n",
      "\t\tProto:1 \n",
      "\t\tProto:3 \n",
      "\t\tProto:5 \n",
      "\t\tProto:7 \n",
      "\t\tProto:8 \n",
      "\t\tProto:10 \n",
      "\t\tProto:12 \n",
      "\t\tProto:13 \n",
      "\t\tProto:14 \n",
      "\t\tProto:15 \n",
      "\t\tProto:16 \n",
      "\t\tProto:18 \n",
      "\t\tProto:19 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.08it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "----------Non-descendants----------\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 \n",
      "\t\tProto:1 \n",
      "\t\tProto:3 \n",
      "\t\tProto:19 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 59.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "----------Non-descendants----------\n",
      "\t Child: 101+023\n",
      "\t\tProto:1 001:(0.0055) 002:(0.0047) 003:(0.0177) 045:(0.0038) \n",
      "\t\tProto:2 001:(0.0161) 002:(0.0012) 003:(0.0085) 045:(0.0231) \n",
      "\t\tProto:6 001:(0.0054) 002:(0.0009) 003:(0.0036) 045:(0.0006) \n",
      "\t\tProto:7 001:(0.0205) 002:(0.1342) 003:(0.0817) 045:(0.0264) \n",
      "\t\tProto:8 001:(0.0852) 002:(0.0107) 003:(0.0188) 045:(0.0164) \n",
      "\t\tProto:19 001:(0.0084) 002:(0.004) 003:(0.0096) 045:(0.0048) \n",
      "\t Child: 045+003\n",
      "\t\tProto:5 023:(0.0099) 024:(0.0058) 025:(0.0424) 100:(0.0918) 101:(0.1046) \n",
      "\t\tProto:9 023:(0.0069) 024:(0.0066) 025:(0.0348) 100:(0.0072) 101:(0.0126) \n",
      "\t\tProto:10 023:(0.0188) 024:(0.0013) 025:(0.0195) 100:(0.0107) 101:(0.012) \n",
      "\t\tProto:13 023:(0.0502) 024:(0.0085) 025:(0.0516) 100:(0.0153) 101:(0.0126) \n",
      "\t\tProto:16 023:(0.1451) 024:(0.059) 025:(0.2717) 100:(0.0191) 101:(0.0274) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 49.56it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "----------Non-descendants----------\n",
      "\t Child: 003+002\n",
      "\t\tProto:1 \n",
      "\t\tProto:2 \n",
      "\t\tProto:6 \n",
      "\t\tProto:7 \n",
      "\t\tProto:9 \n",
      "\t\tProto:11 \n",
      "\t\tProto:13 \n",
      "\t\tProto:17 \n",
      "\t\tProto:18 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 48.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "----------Non-descendants----------\n",
      "\t Child: 023+025\n",
      "\t\tProto:4 100:(0.028) 101:(0.0128) \n",
      "\t\tProto:9 100:(0.0203) 101:(0.006) \n",
      "\t\tProto:10 100:(0.0663) 101:(0.0066) \n",
      "\t\tProto:11 100:(0.0059) 101:(0.0026) \n",
      "\t\tProto:12 100:(0.0696) 101:(0.0711) \n",
      "\t\tProto:13 100:(0.0197) 101:(0.0056) \n",
      "\t\tProto:18 100:(0.13) 101:(0.0263) \n",
      "\t Child: 101+100\n",
      "\t\tProto:15 023:(0.0354) 024:(0.0341) 025:(0.0232) \n",
      "\t\tProto:5 023:(0.0334) 024:(0.0067) 025:(0.0232) \n",
      "\t\tProto:6 023:(0.0085) 024:(0.0209) 025:(0.0099) \n",
      "\t\tProto:7 023:(0.0129) 024:(0.0175) 025:(0.0089) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 44.54it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "----------Non-descendants----------\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 \n",
      "\t\tProto:9 \n",
      "\t\tProto:12 \n",
      "\t\tProto:13 \n",
      "\t\tProto:17 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.64it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "----------Non-descendants----------\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 \n",
      "\t\tProto:6 \n",
      "\t\tProto:7 \n",
      "\t\tProto:9 \n",
      "\t\tProto:10 \n",
      "\t\tProto:11 \n",
      "\t\tProto:14 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images NON DESCENDANTS\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    if node.name == 'root':\n",
    "        continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "#     # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "#     proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "    \n",
    "    # maps proto_number -> non-descendant leaf name -> list of top-k activations\n",
    "    proto_mean_activations_non_descendants = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            softmaxes, pooled, _ = net(xs, inference=False)\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                    \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                \n",
    "                # top-k for all the leaf nodes that are NOT descendant to a particular prototype\n",
    "                if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                    leaf_non_descendent = label2name[orig_y.item()][4:7]\n",
    "                    img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                    if topk and (len(proto_mean_activations_non_descendants[p][leaf_non_descendent]) > topk):\n",
    "                        heapq.heappushpop(proto_mean_activations_non_descendants[p][leaf_non_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations_non_descendants[p][leaf_non_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "                \n",
    "#                 if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "#                     child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "#                     leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "#                     img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "#                     if topk and (len(proto_mean_activations[p][leaf_descendent]) > topk):\n",
    "#                         heapq.heappushpop(proto_mean_activations[p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "#                     else:\n",
    "#                         heapq.heappush(proto_mean_activations[p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    print(('-'*10)+'Non-descendants'+('-'*10))\n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_non_descendent in proto_mean_activations_non_descendants[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations_non_descendants[p][leaf_non_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations_non_descendants[p][leaf_non_descendent])\n",
    "                logstr += f'{leaf_non_descendent}:({mean_activation}) '\n",
    "                \n",
    "            print(logstr)\n",
    "            \n",
    "            if len(proto_mean_activations_non_descendants[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                \n",
    "                for leaf_non_descendent, heap in proto_mean_activations_non_descendants[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations_non_descendants[p][leaf_non_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max) = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        patches.append(img_tensor_patch)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_non_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, 'descendent_specific_topk', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, 'descendent_specific_topk', node.name, f'nd-{child_classname}-p{p}.png'))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations (pre softmax) on leaf descendents - topk images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 51.69it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:3 050:(7.5616) 051:(10.9245) 053:(12.4432) \n",
      "\t\tProto:4 050:(9.0902) 051:(14.765) 053:(12.5877) \n",
      "\t\tProto:9 050:(11.7112) 051:(11.2247) 053:(9.7535) \n",
      "\t\tProto:13 050:(10.3942) 051:(12.3614) 053:(11.9564) \n",
      "\t\tProto:16 050:(8.1902) 051:(10.2694) 053:(7.1765) \n",
      "\t\tProto:17 050:(5.6001) 051:(8.1006) 053:(10.9681) \n",
      "\t\tProto:19 050:(13.4178) 051:(15.3893) 053:(12.0207) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:05, 74.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 086+045\n",
      "\t\tProto:1 001:(13.9237) 002:(11.7985) 003:(13.0308) 023:(19.0249) 024:(15.6177) 025:(15.9277) 045:(4.6504) 086:(12.6023) 100:(15.8779) 101:(14.917) \n",
      "\t\tProto:18 001:(10.2416) 002:(10.355) 003:(9.4581) 023:(2.4925) 024:(13.9303) 025:(2.3613) 045:(11.1423) 086:(5.2245) 100:(5.3945) 101:(9.3831) \n",
      "\t\tProto:11 001:(10.3628) 002:(10.3516) 003:(8.7142) 023:(15.2329) 024:(11.2425) 025:(10.271) 045:(4.3224) 086:(11.2974) 100:(16.598) 101:(14.8635) \n",
      "\t\tProto:17 001:(13.5753) 002:(12.4992) 003:(13.4857) 023:(13.3064) 024:(10.7805) 025:(12.5992) 045:(12.1194) 086:(13.943) 100:(11.298) 101:(10.6391) \n",
      "\t Child: 004+032\n",
      "\t\tProto:3 004:(10.0838) 031:(12.5361) 032:(11.6779) 033:(13.3897) \n",
      "\t\tProto:6 004:(-0.4042) 031:(10.5651) 032:(1.0094) 033:(9.2764) \n",
      "\t\tProto:8 004:(6.1032) 031:(10.6371) 032:(11.2718) 033:(11.7435) \n",
      "\t\tProto:9 004:(9.0818) 031:(11.2533) 032:(14.196) 033:(13.3036) \n",
      "\t\tProto:14 004:(3.6695) 031:(10.8972) 032:(10.3763) 033:(11.7972) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.23it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 050:(8.3235) 051:(10.19) \n",
      "\t\tProto:3 050:(9.5879) 051:(10.2631) \n",
      "\t\tProto:6 050:(13.3113) 051:(11.7775) \n",
      "\t\tProto:16 050:(7.2326) 051:(12.7878) \n",
      "\t\tProto:18 050:(8.3049) 051:(10.8592) \n",
      "\t\tProto:19 050:(9.4988) 051:(13.672) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 56.61it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:0 031:(12.0725) 032:(5.9815) 033:(11.1138) \n",
      "\t\tProto:2 031:(7.8783) 032:(10.1635) 033:(10.4963) \n",
      "\t\tProto:4 031:(8.7987) 032:(16.5308) 033:(13.0054) \n",
      "\t\tProto:6 031:(10.5092) 032:(14.2422) 033:(11.8465) \n",
      "\t\tProto:8 031:(10.7717) 032:(13.1364) 033:(5.9794) \n",
      "\t\tProto:12 031:(14.0438) 032:(7.3442) 033:(12.4378) \n",
      "\t\tProto:18 031:(13.3962) 032:(10.8846) 033:(12.7338) \n",
      "\t\tProto:19 031:(11.287) 032:(14.8485) 033:(13.4779) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:04, 71.44it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:1 001:(11.5095) 002:(13.7669) 003:(7.9022) 023:(7.301) 024:(5.3688) 025:(5.8896) 045:(3.0428) 100:(16.767) 101:(17.365) \n",
      "\t\tProto:3 001:(9.5772) 002:(7.2521) 003:(8.5863) 023:(2.8577) 024:(4.6193) 025:(5.9812) 045:(9.0443) 100:(3.5419) 101:(1.9309) \n",
      "\t\tProto:5 001:(12.4361) 002:(11.6747) 003:(13.9392) 023:(1.0827) 024:(0.5679) 025:(1.3642) 045:(11.6246) 100:(2.4607) 101:(0.4513) \n",
      "\t\tProto:7 001:(5.2401) 002:(8.5393) 003:(5.9958) 023:(3.9392) 024:(4.3454) 025:(3.42) 045:(5.0165) 100:(10.8439) 101:(11.2438) \n",
      "\t\tProto:8 001:(8.0998) 002:(6.4392) 003:(7.5567) 023:(15.126) 024:(13.4093) 025:(14.5355) 045:(5.4789) 100:(5.6974) 101:(3.4716) \n",
      "\t\tProto:10 001:(1.0189) 002:(2.1303) 003:(1.7599) 023:(14.5272) 024:(13.1642) 025:(13.4337) 045:(-0.499) 100:(10.5124) 101:(5.8299) \n",
      "\t\tProto:12 001:(12.9199) 002:(11.4251) 003:(11.4565) 023:(10.9962) 024:(10.433) 025:(8.7772) 045:(4.2088) 100:(5.8494) 101:(4.8817) \n",
      "\t\tProto:13 001:(4.1631) 002:(2.6143) 003:(1.6394) 023:(17.8554) 024:(14.7957) 025:(14.6745) 045:(-0.2151) 100:(7.0291) 101:(6.0502) \n",
      "\t\tProto:14 001:(2.0665) 002:(-0.5163) 003:(0.6153) 023:(1.7884) 024:(3.7996) 025:(3.9947) 045:(1.4738) 100:(12.9504) 101:(11.7004) \n",
      "\t\tProto:15 001:(6.4838) 002:(10.213) 003:(4.0124) 023:(4.6359) 024:(5.7756) 025:(3.9631) 045:(0.2855) 100:(14.0879) 101:(14.6692) \n",
      "\t\tProto:16 001:(7.7983) 002:(4.2061) 003:(8.8205) 023:(4.1521) 024:(9.5718) 025:(3.3803) 045:(3.5851) 100:(7.8234) 101:(6.4689) \n",
      "\t\tProto:18 001:(10.807) 002:(9.2313) 003:(14.6321) 023:(3.5422) 024:(1.861) 025:(2.4943) 045:(9.5609) 100:(2.7729) 101:(1.9642) \n",
      "\t\tProto:19 001:(5.4088) 002:(10.1833) 003:(2.7225) 023:(2.0908) 024:(13.8828) 025:(1.2819) 045:(9.0108) 100:(3.3964) 101:(9.4615) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 45.83it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(16.9391) 033:(15.3924) \n",
      "\t\tProto:1 031:(15.0387) 033:(14.6168) \n",
      "\t\tProto:3 031:(16.1197) 033:(15.6397) \n",
      "\t\tProto:19 031:(12.8608) 033:(12.9994) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 66.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "\t Child: 101+023\n",
      "\t\tProto:1 023:(14.6978) 024:(14.8445) 025:(14.0366) 100:(17.0984) 101:(15.8693) \n",
      "\t\tProto:2 023:(4.7626) 024:(6.6527) 025:(7.8944) 100:(13.9811) 101:(13.9916) \n",
      "\t\tProto:6 023:(16.1387) 024:(14.8966) 025:(12.2047) 100:(14.7373) 101:(16.8536) \n",
      "\t\tProto:7 023:(6.1339) 024:(6.7499) 025:(4.7184) 100:(13.6997) 101:(14.6195) \n",
      "\t\tProto:8 023:(16.0441) 024:(16.2358) 025:(15.8322) 100:(13.8403) 101:(15.024) \n",
      "\t\tProto:19 023:(13.4676) 024:(14.2465) 025:(13.8796) 100:(2.6952) 101:(1.9487) \n",
      "\t Child: 045+003\n",
      "\t\tProto:5 001:(15.1437) 002:(13.3598) 003:(14.2943) 045:(12.2736) \n",
      "\t\tProto:9 001:(14.3449) 002:(10.7705) 003:(16.1946) 045:(11.4274) \n",
      "\t\tProto:10 001:(13.7206) 002:(12.2371) 003:(14.0368) 045:(10.4529) \n",
      "\t\tProto:13 001:(13.8332) 002:(13.9942) 003:(14.0112) 045:(12.6148) \n",
      "\t\tProto:16 001:(16.0209) 002:(17.4585) 003:(12.6037) 045:(9.9245) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 53.63it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:1 001:(12.8103) 002:(13.4532) 003:(13.5658) \n",
      "\t\tProto:2 001:(11.9235) 002:(9.3393) 003:(8.8047) \n",
      "\t\tProto:6 001:(9.5532) 002:(10.6986) 003:(11.4388) \n",
      "\t\tProto:7 001:(9.3143) 002:(10.4015) 003:(8.4804) \n",
      "\t\tProto:9 001:(16.0026) 002:(12.9231) 003:(13.4987) \n",
      "\t\tProto:11 001:(12.7909) 002:(10.9987) 003:(14.0966) \n",
      "\t\tProto:13 001:(14.094) 002:(8.3385) 003:(11.3179) \n",
      "\t\tProto:17 001:(13.2237) 002:(12.8563) 003:(12.0119) \n",
      "\t\tProto:18 001:(12.4813) 002:(11.737) 003:(11.3647) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:02, 54.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "\t Child: 023+025\n",
      "\t\tProto:4 023:(11.4795) 024:(12.8876) 025:(11.5604) \n",
      "\t\tProto:9 023:(13.7499) 024:(15.9818) 025:(12.4509) \n",
      "\t\tProto:10 023:(14.3595) 024:(14.747) 025:(9.9039) \n",
      "\t\tProto:11 023:(14.7181) 024:(13.6501) 025:(13.717) \n",
      "\t\tProto:12 023:(13.6124) 024:(12.2496) 025:(13.5227) \n",
      "\t\tProto:13 023:(14.8648) 024:(14.7736) 025:(15.731) \n",
      "\t\tProto:18 023:(17.6066) 024:(15.5944) 025:(14.3804) \n",
      "\t Child: 101+100\n",
      "\t\tProto:15 100:(13.715) 101:(15.3015) \n",
      "\t\tProto:5 100:(15.7071) 101:(17.3337) \n",
      "\t\tProto:6 100:(19.4372) 101:(18.6695) \n",
      "\t\tProto:7 100:(17.7803) 101:(17.0496) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.96it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 001:(16.0733) 002:(17.7723) \n",
      "\t\tProto:9 001:(12.2972) 002:(12.6936) \n",
      "\t\tProto:12 001:(13.5685) 002:(15.2353) \n",
      "\t\tProto:13 001:(18.722) 002:(16.6388) \n",
      "\t\tProto:17 001:(12.9027) 002:(8.5177) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 48.21it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 024:(8.9474) 025:(8.2109) \n",
      "\t\tProto:6 024:(15.531) 025:(15.8605) \n",
      "\t\tProto:7 024:(15.559) 025:(11.1817) \n",
      "\t\tProto:9 024:(16.2546) 025:(13.7065) \n",
      "\t\tProto:10 024:(14.5695) 025:(10.9088) \n",
      "\t\tProto:11 024:(11.9045) 025:(9.2858) \n",
      "\t\tProto:14 024:(14.0196) 025:(10.111) \n"
     ]
    }
   ],
   "source": [
    "# Proto activations (pre softmax) on leaf descendents - topk images (NOT COMPLETED)\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    if node.name == 'root':\n",
    "        continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # softmaxes, pooled, _ = net(xs, inference=False)\n",
    "            \n",
    "            features = net.module._net(xs)\n",
    "            proto_features = getattr(net.module, '_'+node.name+'_add_on')(features)\n",
    "            softmaxes = net.module._softmax(proto_features)\n",
    "            pooled = net.module._pool(softmaxes)\n",
    "            \n",
    "            proto_features = proto_features.squeeze(0)\n",
    "            pooled = pooled.squeeze(0) \n",
    "            # softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                    \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                \n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) > topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent], (proto_features[p, h_idx, w_idx].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent], (proto_features[p, h_idx, w_idx].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max) = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        patches.append(img_tensor_patch)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, 'descendent_specific_topk_presoftmax', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, 'descendent_specific_topk_presoftmax', node.name, f'{child_classname}-p{p}.png'))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations (pre softmax) on leaf NON-descendents - topk images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 55.56it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:3 \n",
      "\t\tProto:4 \n",
      "\t\tProto:9 \n",
      "\t\tProto:13 \n",
      "\t\tProto:16 \n",
      "\t\tProto:17 \n",
      "\t\tProto:19 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:05, 79.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 086+045\n",
      "\t\tProto:1 004:(0.8481) 031:(0.8941) 032:(0.157) 033:(0.8638) \n",
      "\t\tProto:18 004:(0.17) 031:(0.5397) 032:(-0.2593) 033:(1.7116) \n",
      "\t\tProto:11 004:(3.817) 031:(3.8497) 032:(3.6254) 033:(3.4279) \n",
      "\t\tProto:17 004:(1.7489) 031:(1.1175) 032:(0.9885) 033:(0.5073) \n",
      "\t Child: 004+032\n",
      "\t\tProto:3 001:(1.648) 002:(1.1371) 003:(0.9296) 023:(1.7536) 024:(-0.3624) 025:(1.1118) 045:(0.6031) 086:(1.8149) 100:(1.3185) 101:(1.8435) \n",
      "\t\tProto:6 001:(6.6329) 002:(9.1988) 003:(6.2612) 023:(3.5502) 024:(3.8001) 025:(4.2532) 045:(2.6137) 086:(4.9135) 100:(4.255) 101:(6.6131) \n",
      "\t\tProto:8 001:(4.5169) 002:(3.6005) 003:(2.8996) 023:(3.296) 024:(3.8802) 025:(3.8114) 045:(3.0081) 086:(5.735) 100:(3.6954) 101:(3.2221) \n",
      "\t\tProto:9 001:(-1.0514) 002:(-1.0791) 003:(-0.8709) 023:(-0.8303) 024:(-0.8198) 025:(-0.9671) 045:(-0.3961) 086:(-0.7979) 100:(-1.2566) 101:(-1.5098) \n",
      "\t\tProto:14 001:(0.5451) 002:(1.3593) 003:(-0.0518) 023:(-0.59) 024:(-0.2692) 025:(-0.6485) 045:(-0.1795) 086:(0.6697) 100:(-0.9403) 101:(0.1743) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.85it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 \n",
      "\t\tProto:3 \n",
      "\t\tProto:6 \n",
      "\t\tProto:16 \n",
      "\t\tProto:18 \n",
      "\t\tProto:19 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 54.17it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:0 \n",
      "\t\tProto:2 \n",
      "\t\tProto:4 \n",
      "\t\tProto:6 \n",
      "\t\tProto:8 \n",
      "\t\tProto:12 \n",
      "\t\tProto:18 \n",
      "\t\tProto:19 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:04, 73.99it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:1 \n",
      "\t\tProto:3 \n",
      "\t\tProto:5 \n",
      "\t\tProto:7 \n",
      "\t\tProto:8 \n",
      "\t\tProto:10 \n",
      "\t\tProto:12 \n",
      "\t\tProto:13 \n",
      "\t\tProto:14 \n",
      "\t\tProto:15 \n",
      "\t\tProto:16 \n",
      "\t\tProto:18 \n",
      "\t\tProto:19 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 47.10it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 \n",
      "\t\tProto:1 \n",
      "\t\tProto:3 \n",
      "\t\tProto:19 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 65.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "\t Child: 101+023\n",
      "\t\tProto:1 001:(1.3781) 002:(4.0232) 003:(1.3883) 045:(0.9545) \n",
      "\t\tProto:2 001:(3.0311) 002:(1.6816) 003:(1.9775) 045:(2.2511) \n",
      "\t\tProto:6 001:(2.5878) 002:(2.7541) 003:(1.1415) 045:(-0.8077) \n",
      "\t\tProto:7 001:(3.8018) 002:(5.4269) 003:(3.6716) 045:(3.1115) \n",
      "\t\tProto:8 001:(3.1642) 002:(3.8786) 003:(2.0983) 045:(3.4103) \n",
      "\t\tProto:19 001:(0.6304) 002:(0.7701) 003:(0.8864) 045:(0.9136) \n",
      "\t Child: 045+003\n",
      "\t\tProto:5 023:(0.9603) 024:(0.2081) 025:(2.0554) 100:(2.3239) 101:(2.1106) \n",
      "\t\tProto:9 023:(1.1199) 024:(2.6554) 025:(2.0557) 100:(1.5269) 101:(2.1388) \n",
      "\t\tProto:10 023:(3.1938) 024:(1.3303) 025:(2.1188) 100:(1.8741) 101:(3.1418) \n",
      "\t\tProto:13 023:(0.9417) 024:(1.3984) 025:(1.305) 100:(1.6584) 101:(1.408) \n",
      "\t\tProto:16 023:(7.4774) 024:(5.1187) 025:(6.3422) 100:(6.2049) 101:(6.4094) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 54.67it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:1 \n",
      "\t\tProto:2 \n",
      "\t\tProto:6 \n",
      "\t\tProto:7 \n",
      "\t\tProto:9 \n",
      "\t\tProto:11 \n",
      "\t\tProto:13 \n",
      "\t\tProto:17 \n",
      "\t\tProto:18 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:02, 55.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "\t Child: 023+025\n",
      "\t\tProto:4 100:(3.2932) 101:(3.0964) \n",
      "\t\tProto:9 100:(4.2342) 101:(2.1687) \n",
      "\t\tProto:10 100:(2.7922) 101:(1.4697) \n",
      "\t\tProto:11 100:(1.236) 101:(3.6891) \n",
      "\t\tProto:12 100:(6.7522) 101:(6.5739) \n",
      "\t\tProto:13 100:(3.2816) 101:(1.3457) \n",
      "\t\tProto:18 100:(1.3261) 101:(0.5338) \n",
      "\t Child: 101+100\n",
      "\t\tProto:15 023:(2.051) 024:(2.466) 025:(1.0789) \n",
      "\t\tProto:5 023:(0.8497) 024:(2.6664) 025:(2.0372) \n",
      "\t\tProto:6 023:(1.8135) 024:(2.5358) 025:(0.4884) \n",
      "\t\tProto:7 023:(0.8948) 024:(1.48) 025:(1.2706) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 49.07it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 \n",
      "\t\tProto:9 \n",
      "\t\tProto:12 \n",
      "\t\tProto:13 \n",
      "\t\tProto:17 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 50.57it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 \n",
      "\t\tProto:6 \n",
      "\t\tProto:7 \n",
      "\t\tProto:9 \n",
      "\t\tProto:10 \n",
      "\t\tProto:11 \n",
      "\t\tProto:14 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Proto activations (pre softmax) on leaf NON-descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    if node.name == 'root':\n",
    "        continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # softmaxes, pooled, _ = net(xs, inference=False)\n",
    "            \n",
    "            features = net.module._net(xs)\n",
    "            proto_features = getattr(net.module, '_'+node.name+'_add_on')(features)\n",
    "            softmaxes = net.module._softmax(proto_features)\n",
    "            pooled = net.module._pool(softmaxes)\n",
    "            \n",
    "            proto_features = proto_features.squeeze(0)\n",
    "            pooled = pooled.squeeze(0) \n",
    "            # softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                    \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                \n",
    "                if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) > topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent], (proto_features[p, h_idx, w_idx].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent], (proto_features[p, h_idx, w_idx].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if len(proto_mean_activations[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max) = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        patches.append(img_tensor_patch)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, 'descendent_specific_topk_presoftmax', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, 'descendent_specific_topk_presoftmax', node.name, f'nd-{child_classname}-p{p}.png'))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations (scores -> proto_activation*weight) on leaf descendents - topk images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 50.00it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:3 050:(0.9529) 051:(1.6938) 053:(2.6966) \n",
      "\t\tProto:4 050:(0.967) 051:(1.9807) 053:(1.4966) \n",
      "\t\tProto:9 050:(2.6367) 051:(2.6995) 053:(2.4543) \n",
      "\t\tProto:13 050:(1.4765) 051:(1.4228) 053:(1.7056) \n",
      "\t\tProto:16 050:(1.8832) 051:(3.1936) 053:(1.1246) \n",
      "\t\tProto:17 050:(0.4404) 051:(0.8612) 053:(1.2822) \n",
      "\t\tProto:19 050:(3.4319) 051:(4.0389) 053:(3.9173) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:07, 54.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 086+045\n",
      "\t\tProto:1 001:(4.3188) 002:(4.2716) 003:(4.3041) 023:(4.3316) 024:(4.3317) 025:(4.3261) 045:(0.9593) 086:(4.1818) 100:(4.3315) 101:(4.3298) \n",
      "\t\tProto:18 001:(2.3883) 002:(2.3751) 003:(2.1731) 023:(0.227) 024:(2.5106) 025:(0.1532) 045:(2.4572) 086:(0.2646) 100:(0.6201) 101:(2.3774) \n",
      "\t\tProto:11 001:(2.9054) 002:(2.9728) 003:(2.4945) 023:(3.2803) 024:(3.2345) 025:(3.1484) 045:(0.1788) 086:(3.209) 100:(3.2767) 101:(3.2558) \n",
      "\t\tProto:17 001:(4.8714) 002:(4.8543) 003:(4.8761) 023:(4.854) 024:(4.5893) 025:(4.8736) 045:(4.8267) 086:(4.8735) 100:(4.8449) 101:(4.8283) \n",
      "\t Child: 004+032\n",
      "\t\tProto:3 004:(2.9379) 031:(3.1223) 032:(3.0742) 033:(3.1248) \n",
      "\t\tProto:6 004:(0.0001) 031:(0.0526) 032:(0.0003) 033:(0.0346) \n",
      "\t\tProto:8 004:(0.076) 031:(0.2366) 032:(0.2457) 033:(0.2497) \n",
      "\t\tProto:9 004:(3.3763) 031:(3.8886) 032:(3.9546) 033:(3.9003) \n",
      "\t\tProto:14 004:(0.2145) 031:(2.4269) 032:(2.4523) 033:(2.3512) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 47.21it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 050:(1.2862) 051:(1.9582) \n",
      "\t\tProto:3 050:(2.0965) 051:(2.7172) \n",
      "\t\tProto:6 050:(3.141) 051:(3.1193) \n",
      "\t\tProto:16 050:(0.9455) 051:(1.8418) \n",
      "\t\tProto:18 050:(0.1036) 051:(0.113) \n",
      "\t\tProto:19 050:(2.3963) 051:(3.6708) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 43.39it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:0 031:(1.0536) 032:(0.2389) 033:(1.0367) \n",
      "\t\tProto:2 031:(0.4491) 032:(0.6548) 033:(0.6335) \n",
      "\t\tProto:4 031:(1.3148) 032:(3.3738) 033:(3.2335) \n",
      "\t\tProto:6 031:(3.3762) 032:(3.3981) 033:(3.3096) \n",
      "\t\tProto:8 031:(1.38) 032:(1.4513) 033:(0.8152) \n",
      "\t\tProto:12 031:(2.8455) 032:(0.6083) 033:(2.7214) \n",
      "\t\tProto:18 031:(2.7017) 032:(2.6501) 033:(2.6797) \n",
      "\t\tProto:19 031:(3.3279) 032:(3.4688) 033:(3.478) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:05, 53.96it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:1 001:(2.2838) 002:(2.3451) 003:(1.0736) 023:(0.435) 024:(0.3838) 025:(0.412) 045:(0.0277) 100:(2.3552) 101:(2.3553) \n",
      "\t\tProto:3 001:(2.532) 002:(1.6709) 003:(2.0938) 023:(0.1914) 024:(0.0619) 025:(0.9732) 045:(2.3931) 100:(0.1605) 101:(0.2872) \n",
      "\t\tProto:5 001:(3.9396) 002:(3.8892) 003:(3.9283) 023:(0.0693) 024:(0.0122) 025:(0.075) 045:(3.9209) 100:(0.3982) 101:(0.1584) \n",
      "\t\tProto:7 001:(0.151) 002:(0.7098) 003:(0.2582) 023:(0.0852) 024:(0.0273) 025:(0.0562) 045:(0.1936) 100:(0.9599) 101:(0.9871) \n",
      "\t\tProto:8 001:(1.3479) 002:(1.201) 003:(1.7929) 023:(3.1537) 024:(3.0916) 025:(3.2093) 045:(0.7131) 100:(0.6123) 101:(0.1263) \n",
      "\t\tProto:10 001:(0.0676) 002:(0.0797) 003:(0.4305) 023:(3.7718) 024:(3.7714) 025:(3.7531) 045:(0.0143) 100:(3.3761) 101:(0.5077) \n",
      "\t\tProto:12 001:(2.1831) 002:(2.1678) 003:(2.0246) 023:(1.831) 024:(1.0694) 025:(1.5898) 045:(0.3354) 100:(0.5522) 101:(0.1418) \n",
      "\t\tProto:13 001:(0.4457) 002:(0.0577) 003:(0.1112) 023:(3.0335) 024:(3.0292) 025:(3.0272) 045:(0.0042) 100:(0.6291) 101:(0.1705) \n",
      "\t\tProto:14 001:(0.5362) 002:(0.0106) 003:(0.0337) 023:(0.3032) 024:(0.2606) 025:(0.6083) 045:(0.181) 100:(3.2178) 101:(3.2271) \n",
      "\t\tProto:15 001:(1.6124) 002:(2.9687) 003:(0.552) 023:(0.4224) 024:(1.1003) 025:(0.8194) 045:(0.0335) 100:(3.167) 101:(3.1767) \n",
      "\t\tProto:16 001:(1.717) 002:(0.5969) 003:(1.798) 023:(0.1242) 024:(2.0125) 025:(0.2243) 045:(0.2659) 100:(2.0501) 101:(1.3462) \n",
      "\t\tProto:18 001:(2.2976) 002:(2.1144) 003:(2.4868) 023:(0.051) 024:(0.015) 025:(0.0519) 045:(2.0337) 100:(0.0325) 101:(0.0191) \n",
      "\t\tProto:19 001:(1.4578) 002:(2.6199) 003:(0.3002) 023:(0.2148) 024:(2.7924) 025:(0.0981) 045:(2.1387) 100:(0.3654) 101:(2.686) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.99it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(2.9883) 033:(2.9185) \n",
      "\t\tProto:1 031:(1.2407) 033:(1.2046) \n",
      "\t\tProto:3 031:(3.8938) 033:(3.8892) \n",
      "\t\tProto:19 031:(2.1762) 033:(2.1162) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:05, 50.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "\t Child: 101+023\n",
      "\t\tProto:1 023:(3.1222) 024:(3.1844) 025:(3.1468) 100:(3.1675) 101:(3.1903) \n",
      "\t\tProto:2 023:(0.4542) 024:(0.0787) 025:(0.8978) 100:(2.1796) 101:(2.1735) \n",
      "\t\tProto:6 023:(3.6944) 024:(3.6878) 025:(3.6042) 100:(3.6648) 101:(3.6934) \n",
      "\t\tProto:7 023:(0.0184) 024:(0.0398) 025:(0.0174) 100:(0.1979) 101:(0.1991) \n",
      "\t\tProto:8 023:(3.2148) 024:(3.1827) 025:(3.2237) 100:(3.223) 101:(3.2253) \n",
      "\t\tProto:19 023:(1.4577) 024:(1.4756) 025:(1.4686) 100:(0.0408) 101:(0.0031) \n",
      "\t Child: 045+003\n",
      "\t\tProto:5 001:(3.222) 002:(3.2153) 003:(3.2248) 045:(3.2009) \n",
      "\t\tProto:9 001:(2.2476) 002:(1.6751) 003:(2.2679) 045:(2.1549) \n",
      "\t\tProto:10 001:(2.4256) 002:(2.3993) 003:(2.4638) 045:(2.1852) \n",
      "\t\tProto:13 001:(3.008) 002:(3.1065) 003:(3.0871) 045:(3.0902) \n",
      "\t\tProto:16 001:(1.4014) 002:(1.4057) 003:(1.2867) 045:(1.1173) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 48.80it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:1 001:(1.487) 002:(1.6546) 003:(1.6494) \n",
      "\t\tProto:2 001:(1.7784) 002:(1.6133) 003:(1.5328) \n",
      "\t\tProto:6 001:(0.3732) 002:(0.4611) 003:(0.4751) \n",
      "\t\tProto:7 001:(0.1149) 002:(0.1212) 003:(0.0952) \n",
      "\t\tProto:9 001:(2.0008) 002:(1.9628) 003:(1.7577) \n",
      "\t\tProto:11 001:(1.625) 002:(1.7965) 003:(2.0395) \n",
      "\t\tProto:13 001:(2.5494) 002:(1.7616) 003:(2.3377) \n",
      "\t\tProto:17 001:(4.3339) 002:(4.337) 003:(4.2627) \n",
      "\t\tProto:18 001:(2.5026) 002:(2.5126) 003:(2.4846) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 42.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "\t Child: 023+025\n",
      "\t\tProto:4 023:(1.9598) 024:(1.9939) 025:(1.9788) \n",
      "\t\tProto:9 023:(1.4488) 024:(1.4992) 025:(1.4533) \n",
      "\t\tProto:10 023:(1.4015) 024:(1.4199) 025:(1.379) \n",
      "\t\tProto:11 023:(2.6012) 024:(2.6199) 025:(2.5719) \n",
      "\t\tProto:12 023:(0.1511) 024:(0.1528) 025:(0.1636) \n",
      "\t\tProto:13 023:(2.9055) 024:(2.8857) 025:(2.9337) \n",
      "\t\tProto:18 023:(3.3207) 024:(3.3193) 025:(3.3072) \n",
      "\t Child: 101+100\n",
      "\t\tProto:15 100:(2.0381) 101:(2.0453) \n",
      "\t\tProto:5 100:(1.4792) 101:(1.4796) \n",
      "\t\tProto:6 100:(3.6827) 101:(3.6832) \n",
      "\t\tProto:7 100:(3.7665) 101:(3.7648) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 48.18it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 001:(3.1762) 002:(3.2003) \n",
      "\t\tProto:9 001:(0.1948) 002:(0.1911) \n",
      "\t\tProto:12 001:(3.589) 002:(3.6451) \n",
      "\t\tProto:13 001:(3.5498) 002:(3.551) \n",
      "\t\tProto:17 001:(2.4816) 002:(2.26) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.66it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 024:(0.8611) 025:(0.7929) \n",
      "\t\tProto:6 024:(0.5784) 025:(0.5748) \n",
      "\t\tProto:7 024:(2.3964) 025:(2.1413) \n",
      "\t\tProto:9 024:(2.9654) 025:(2.9203) \n",
      "\t\tProto:10 024:(1.6659) 025:(1.31) \n",
      "\t\tProto:11 024:(1.7408) 025:(1.5809) \n",
      "\t\tProto:14 024:(2.679) 025:(2.4499) \n"
     ]
    }
   ],
   "source": [
    "# Proto activations (scores -> proto_activation*weight) on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    if node.name == 'root':\n",
    "        continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            softmaxes, pooled, _ = net(xs, inference=False)\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                relevant_class_weight = classification_weights[:, p][classification_weights[:, p] > 1e-3]\n",
    "                \n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                \n",
    "                if len(relevant_proto_class_names) > 1:\n",
    "                    raise Exception(f\"P{p} of node {node.name} is relevant to more than one class {relevant_proto_class_names}\")\n",
    "                \n",
    "                relevant_class_weight = relevant_class_weight.item()\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                \n",
    "                    \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                \n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) > topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent], (pooled[p].item()*relevant_class_weight, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent], (pooled[p].item()*relevant_class_weight, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max) = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        patches.append(img_tensor_patch)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, 'descendent_specific_topk_scores', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, 'descendent_specific_topk_scores', node.name, f'{child_classname}-p{p}.png'))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            softmaxes, pooled, _ = net(xs, inference=False)\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                    \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                \n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) > topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max) = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        patches.append(img_tensor_patch)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images after using tanh-desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 330it [00:05, 58.72it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 78\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# of add_ons of each child node and doing softmax on them\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     softmaxes, pooled, _ \u001b[38;5;241m=\u001b[39m net(xs, inference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m     pooled \u001b[38;5;241m=\u001b[39m pooled[node\u001b[38;5;241m.\u001b[39mname][child_node\u001b[38;5;241m.\u001b[39mname]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     80\u001b[0m     softmaxes \u001b[38;5;241m=\u001b[39m softmaxes[node\u001b[38;5;241m.\u001b[39mname]\u001b[38;5;66;03m#.squeeze(0)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            if coarse_label2name[ys.item()] != child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written\n",
    "                    if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                        continue\n",
    "                        \n",
    "                    h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes_of_child_node.shape, patchsize, skip, h_idx, w_idx)\n",
    "                    \n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "#                         child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) > topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "#                     pdb.set_trace()\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max) = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        patches.append(img_tensor_patch)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images after using unit-sphere & tanh-desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:03, 140.39it/s]\n",
      "Collecting topk: 540it [00:09, 55.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 052+053 {18, 11, 20, 13} --------------------\n",
      "-------------------- 004+086 {96, 1, 2, 39, 80, 83, 20, 53, 84, 30} --------------------\n",
      "-------------------- 052+053 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 19, 21, 22, 23} --------------------\n",
      "-------------------- 004+086 {0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103} --------------------\n",
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:18 050:(0.3224) 051:(0.5289) 052:(0.2688) 053:(0.6115) \n",
      "\t\tProto:11 050:(0.6517) 051:(0.6445) 052:(0.6527) 053:(0.3735) \n",
      "\t\tProto:20 050:(0.4741) 051:(0.5075) 052:(0.5022) 053:(0.2589) \n",
      "\t\tProto:13 050:(0.6036) 051:(0.5833) 052:(0.5662) 053:(0.3894) \n",
      "\t Child: 004+086\n",
      "\t\tProto:96 001:(0.5111) 002:(0.5501) 003:(0.5323) 004:(0.5836) 023:(0.4943) 024:(0.4769) 025:(0.5284) 031:(0.5764) 032:(0.5585) 033:(0.5312) 045:(0.534) 086:(0.5197) 100:(0.5268) 101:(0.5216) \n",
      "\t\tProto:1 001:(0.1821) 002:(0.1959) 003:(0.1979) 004:(0.2218) 023:(0.1907) 024:(0.1184) 025:(0.1717) 031:(0.215) 032:(0.2137) 033:(0.2063) 045:(0.1728) 086:(0.1593) 100:(0.1421) 101:(0.124) \n",
      "\t\tProto:2 001:(0.3508) 002:(0.3477) 003:(0.2319) 004:(0.2603) 023:(0.303) 024:(0.3151) 025:(0.2953) 031:(0.2709) 032:(0.15) 033:(0.2073) 045:(0.2716) 086:(0.2373) 100:(0.3307) 101:(0.2845) \n",
      "\t\tProto:39 001:(0.1836) 002:(0.1912) 003:(0.2224) 004:(0.2492) 023:(0.1876) 024:(0.1307) 025:(0.1703) 031:(0.2351) 032:(0.2322) 033:(0.2564) 045:(0.1754) 086:(0.1438) 100:(0.1708) 101:(0.1959) \n",
      "\t\tProto:80 001:(0.1416) 002:(0.1287) 003:(0.159) 004:(0.1065) 023:(0.1326) 024:(0.0992) 025:(0.0937) 031:(0.1055) 032:(0.1076) 033:(0.1096) 045:(0.1591) 086:(0.1103) 100:(0.1063) 101:(0.1129) \n",
      "\t\tProto:83 001:(0.2142) 002:(0.2136) 003:(0.2698) 004:(0.1688) 023:(0.2411) 024:(0.1444) 025:(0.1618) 031:(0.1762) 032:(0.1705) 033:(0.1897) 045:(0.2148) 086:(0.2046) 100:(0.1628) 101:(0.2014) \n",
      "\t\tProto:20 001:(0.3689) 002:(0.3607) 003:(0.264) 004:(0.3371) 023:(0.2967) 024:(0.332) 025:(0.3081) 031:(0.2863) 032:(0.2824) 033:(0.3005) 045:(0.1826) 086:(0.1979) 100:(0.2734) 101:(0.174) \n",
      "\t\tProto:53 001:(0.2774) 002:(0.2925) 003:(0.3464) 004:(0.4645) 023:(0.4219) 024:(0.4766) 025:(0.4793) 031:(0.3893) 032:(0.3592) 033:(0.3744) 045:(0.3408) 086:(0.2234) 100:(0.4674) 101:(0.2955) \n",
      "\t\tProto:84 001:(0.1393) 002:(0.1483) 003:(0.1263) 004:(0.1529) 023:(0.16) 024:(0.1471) 025:(0.1594) 031:(0.1408) 032:(0.0992) 033:(0.1323) 045:(0.1374) 086:(0.143) 100:(0.1302) 101:(0.1192) \n",
      "\t\tProto:30 001:(0.1302) 002:(0.151) 003:(0.1383) 004:(0.1363) 023:(0.1271) 024:(0.0901) 025:(0.0888) 031:(0.1445) 032:(0.1374) 033:(0.1392) 045:(0.1155) 086:(0.0975) 100:(0.1041) 101:(0.0982) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 72.51it/s]  \n",
      "Collecting topk: 120it [00:02, 41.14it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 053+050 {0, 4, 5, 7, 12} --------------------\n",
      "-------------------- 053+050 {1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:0 050:(0.6018) 051:(0.6573) 053:(0.4821) \n",
      "\t\tProto:4 050:(0.6982) 051:(0.7354) 053:(0.7513) \n",
      "\t\tProto:5 050:(0.7782) 051:(0.8249) 053:(0.7996) \n",
      "\t\tProto:7 050:(0.3938) 051:(0.4381) 053:(0.4319) \n",
      "\t\tProto:12 050:(0.2812) 051:(0.3068) 053:(0.3904) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:03, 121.14it/s]\n",
      "Collecting topk: 420it [00:07, 59.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 004+032 {3, 6, 12, 19, 20} --------------------\n",
      "-------------------- 086+045 {33, 66, 6, 70, 22, 55, 29} --------------------\n",
      "-------------------- 004+032 {0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 23} --------------------\n",
      "-------------------- 086+045 {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71} --------------------\n",
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:3 004:(0.2749) 031:(0.3765) 032:(0.3545) 033:(0.3979) \n",
      "\t\tProto:6 004:(0.3775) 031:(0.3835) 032:(0.3265) 033:(0.3926) \n",
      "\t\tProto:12 004:(0.656) 031:(0.5929) 032:(0.5623) 033:(0.6189) \n",
      "\t\tProto:19 004:(0.2689) 031:(0.44) 032:(0.3415) 033:(0.4406) \n",
      "\t\tProto:20 004:(0.4277) 031:(0.6322) 032:(0.5991) 033:(0.6219) \n",
      "\t Child: 086+045\n",
      "\t\tProto:33 001:(0.1989) 002:(0.1869) 003:(0.2129) 023:(0.4262) 024:(0.4197) 025:(0.4387) 045:(0.1953) 086:(0.3889) 100:(0.2343) 101:(0.2375) \n",
      "\t\tProto:66 001:(0.1443) 002:(0.1516) 003:(0.1438) 023:(0.1331) 024:(0.1375) 025:(0.1449) 045:(0.1883) 086:(0.1648) 100:(0.0977) 101:(0.164) \n",
      "\t\tProto:6 001:(0.6457) 002:(0.5974) 003:(0.6025) 023:(0.5345) 024:(0.4713) 025:(0.5332) 045:(0.606) 086:(0.5751) 100:(0.5726) 101:(0.5841) \n",
      "\t\tProto:70 001:(0.5566) 002:(0.5244) 003:(0.5271) 023:(0.4602) 024:(0.4198) 025:(0.4706) 045:(0.5269) 086:(0.4724) 100:(0.5131) 101:(0.5179) \n",
      "\t\tProto:22 001:(0.2746) 002:(0.2188) 003:(0.2395) 023:(0.2327) 024:(0.1857) 025:(0.2566) 045:(0.2312) 086:(0.2758) 100:(0.2633) 101:(0.2604) \n",
      "\t\tProto:55 001:(0.2109) 002:(0.1403) 003:(0.1532) 023:(0.0766) 024:(0.0969) 025:(0.0622) 045:(0.1575) 086:(0.16) 100:(0.1359) 101:(0.1355) \n",
      "\t\tProto:29 001:(0.1767) 002:(0.1281) 003:(0.1364) 023:(0.1748) 024:(0.1836) 025:(0.1861) 045:(0.1337) 086:(0.2874) 100:(0.2168) 101:(0.1684) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 54.06it/s]   \n",
      "Collecting topk: 90it [00:02, 36.47it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 050+051 {0, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 050+051 {1} --------------------\n",
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 050:(0.6595) 051:(0.773) \n",
      "\t\tProto:2 050:(0.5292) 051:(0.596) \n",
      "\t\tProto:3 050:(0.2493) 051:(0.1498) \n",
      "\t\tProto:4 050:(0.4782) 051:(0.4411) \n",
      "\t\tProto:5 050:(0.403) 051:(0.2806) \n",
      "\t\tProto:6 050:(0.2847) 051:(0.3088) \n",
      "\t\tProto:7 050:(0.6833) 051:(0.7682) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 78.65it/s]  \n",
      "Collecting topk: 120it [00:02, 41.21it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 032+033 {1, 3, 4, 7, 8, 12, 13, 15} --------------------\n",
      "-------------------- 032+033 {0, 2, 5, 6, 9, 10, 11, 14} --------------------\n",
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:1 031:(0.5933) 032:(0.5973) 033:(0.5693) \n",
      "\t\tProto:3 031:(0.6457) 032:(0.5805) 033:(0.571) \n",
      "\t\tProto:4 031:(0.214) 032:(0.1365) 033:(0.2244) \n",
      "\t\tProto:7 031:(0.3754) 032:(0.3439) 033:(0.3951) \n",
      "\t\tProto:8 031:(0.3565) 032:(0.3079) 033:(0.3477) \n",
      "\t\tProto:12 031:(0.5921) 032:(0.5478) 033:(0.5841) \n",
      "\t\tProto:13 031:(0.3858) 032:(0.2704) 033:(0.4004) \n",
      "\t\tProto:15 031:(0.4102) 032:(0.371) 033:(0.3568) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:01, 179.65it/s] \n",
      "Collecting topk: 300it [00:06, 42.89it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+101 {4, 5, 9, 10, 17, 18, 19, 24, 25, 26, 27, 28, 31, 32, 34, 39, 41, 44, 45, 49, 50, 51, 58, 59, 60, 63} --------------------\n",
      "-------------------- 045+101 {0, 1, 2, 3, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 29, 30, 33, 35, 36, 37, 38, 40, 42, 43, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62} --------------------\n",
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:4 001:(0.1567) 002:(0.1822) 003:(0.1681) 023:(0.1522) 024:(0.1955) 025:(0.1807) 045:(0.1498) 100:(0.2344) 101:(0.2268) \n",
      "\t\tProto:5 001:(0.1477) 002:(0.1367) 003:(0.1737) 023:(0.1846) 024:(0.2069) 025:(0.1864) 045:(0.1252) 100:(0.2062) 101:(0.1185) \n",
      "\t\tProto:9 001:(0.2545) 002:(0.2588) 003:(0.2427) 023:(0.2479) 024:(0.2601) 025:(0.2498) 045:(0.2492) 100:(0.2702) 101:(0.2609) \n",
      "\t\tProto:10 001:(0.2098) 002:(0.2168) 003:(0.2308) 023:(0.2301) 024:(0.2344) 025:(0.2199) 045:(0.2074) 100:(0.2335) 101:(0.2056) \n",
      "\t\tProto:17 001:(0.1932) 002:(0.1924) 003:(0.194) 023:(0.1935) 024:(0.1928) 025:(0.1914) 045:(0.1936) 100:(0.192) 101:(0.1889) \n",
      "\t\tProto:18 001:(0.2721) 002:(0.282) 003:(0.2756) 023:(0.282) 024:(0.2942) 025:(0.2734) 045:(0.2522) 100:(0.2874) 101:(0.2652) \n",
      "\t\tProto:19 001:(0.1326) 002:(0.1208) 003:(0.1398) 023:(0.1645) 024:(0.1817) 025:(0.1676) 045:(0.1245) 100:(0.1877) 101:(0.1254) \n",
      "\t\tProto:24 001:(0.1132) 002:(0.1203) 003:(0.1168) 023:(0.1173) 024:(0.151) 025:(0.1137) 045:(0.1119) 100:(0.1732) 101:(0.16) \n",
      "\t\tProto:25 001:(0.1337) 002:(0.1361) 003:(0.1353) 023:(0.148) 024:(0.1929) 025:(0.1567) 045:(0.1448) 100:(0.1451) 101:(0.1348) \n",
      "\t\tProto:26 001:(0.2315) 002:(0.262) 003:(0.2395) 023:(0.161) 024:(0.158) 025:(0.1549) 045:(0.2617) 100:(0.1175) 101:(0.2163) \n",
      "\t\tProto:27 001:(0.2131) 002:(0.211) 003:(0.2161) 023:(0.2146) 024:(0.2092) 025:(0.205) 045:(0.2156) 100:(0.2072) 101:(0.2061) \n",
      "\t\tProto:28 001:(0.1458) 002:(0.1921) 003:(0.2289) 023:(0.2431) 024:(0.2746) 025:(0.2444) 045:(0.1252) 100:(0.2777) 101:(0.1765) \n",
      "\t\tProto:31 001:(0.165) 002:(0.1648) 003:(0.1728) 023:(0.1666) 024:(0.172) 025:(0.1606) 045:(0.153) 100:(0.1742) 101:(0.1628) \n",
      "\t\tProto:32 001:(0.1231) 002:(0.1129) 003:(0.1216) 023:(0.1585) 024:(0.1706) 025:(0.1641) 045:(0.1178) 100:(0.1286) 101:(0.1113) \n",
      "\t\tProto:34 001:(0.1252) 002:(0.1381) 003:(0.1451) 023:(0.1571) 024:(0.1608) 025:(0.1363) 045:(0.101) 100:(0.1567) 101:(0.0857) \n",
      "\t\tProto:39 001:(0.1424) 002:(0.1403) 003:(0.1441) 023:(0.1223) 024:(0.0986) 025:(0.1041) 045:(0.1308) 100:(0.183) 101:(0.1913) \n",
      "\t\tProto:41 001:(0.1874) 002:(0.1873) 003:(0.2083) 023:(0.2001) 024:(0.2142) 025:(0.2018) 045:(0.1528) 100:(0.203) 101:(0.1431) \n",
      "\t\tProto:44 001:(0.0981) 002:(0.0938) 003:(0.1347) 023:(0.1864) 024:(0.1929) 025:(0.1726) 045:(0.0892) 100:(0.2721) 101:(0.2575) \n",
      "\t\tProto:45 001:(0.1203) 002:(0.1175) 003:(0.1113) 023:(0.1176) 024:(0.1127) 025:(0.1077) 045:(0.0953) 100:(0.115) 101:(0.1114) \n",
      "\t\tProto:49 001:(0.1657) 002:(0.1541) 003:(0.1185) 023:(0.1181) 024:(0.14) 025:(0.1039) 045:(0.0841) 100:(0.1869) 101:(0.1729) \n",
      "\t\tProto:50 001:(0.2115) 002:(0.2049) 003:(0.2011) 023:(0.2116) 024:(0.2234) 025:(0.2066) 045:(0.2047) 100:(0.2313) 101:(0.2037) \n",
      "\t\tProto:51 001:(0.2565) 002:(0.2295) 003:(0.2884) 023:(0.3266) 024:(0.3511) 025:(0.311) 045:(0.1807) 100:(0.3212) 101:(0.2186) \n",
      "\t\tProto:58 001:(0.1616) 002:(0.141) 003:(0.1421) 023:(0.146) 024:(0.1634) 025:(0.1451) 045:(0.1479) 100:(0.1676) 101:(0.1664) \n",
      "\t\tProto:59 001:(0.1892) 002:(0.1903) 003:(0.1846) 023:(0.1804) 024:(0.1894) 025:(0.1866) 045:(0.185) 100:(0.1903) 101:(0.1864) \n",
      "\t\tProto:60 001:(0.2071) 002:(0.1906) 003:(0.2327) 023:(0.2496) 024:(0.2543) 025:(0.1947) 045:(0.151) 100:(0.2499) 101:(0.1725) \n",
      "\t\tProto:63 001:(0.3799) 002:(0.3823) 003:(0.3703) 023:(0.3713) 024:(0.3958) 025:(0.3767) 045:(0.3706) 100:(0.4063) 101:(0.3851) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 51.76it/s]   \n",
      "Collecting topk: 90it [00:02, 36.43it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 033+031 {0, 2, 3, 4, 6} --------------------\n",
      "-------------------- 033+031 {1, 5, 7} --------------------\n",
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(0.4807) 033:(0.4616) \n",
      "\t\tProto:2 031:(0.8752) 033:(0.8493) \n",
      "\t\tProto:3 031:(0.4735) 033:(0.4492) \n",
      "\t\tProto:4 031:(0.6412) 033:(0.6034) \n",
      "\t\tProto:6 031:(0.7761) 033:(0.7219) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:03, 76.04it/s]\n",
      "Collecting topk: 270it [00:04, 67.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+003 {2, 5, 8, 12, 14, 19} --------------------\n",
      "-------------------- 101+023 {4, 10, 16, 17, 18, 19, 28, 31} --------------------\n",
      "-------------------- 045+003 {0, 1, 3, 4, 6, 7, 9, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23} --------------------\n",
      "-------------------- 101+023 {0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30} --------------------\n",
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:2 001:(0.5555) 002:(0.5532) 003:(0.5581) 045:(0.5252) \n",
      "\t\tProto:5 001:(0.5084) 002:(0.5138) 003:(0.501) 045:(0.5132) \n",
      "\t\tProto:8 001:(0.3175) 002:(0.3091) 003:(0.3163) 045:(0.3117) \n",
      "\t\tProto:12 001:(0.4407) 002:(0.4386) 003:(0.4393) 045:(0.4195) \n",
      "\t\tProto:14 001:(0.573) 002:(0.63) 003:(0.5254) 045:(0.6495) \n",
      "\t\tProto:19 001:(0.6359) 002:(0.6387) 003:(0.6375) 045:(0.6567) \n",
      "\t Child: 101+023\n",
      "\t\tProto:4 023:(0.5267) 024:(0.5849) 025:(0.4806) 100:(0.7271) 101:(0.7219) \n",
      "\t\tProto:10 023:(0.2657) 024:(0.2619) 025:(0.2585) 100:(0.3557) 101:(0.3481) \n",
      "\t\tProto:16 023:(0.5802) 024:(0.5681) 025:(0.5893) 100:(0.3766) 101:(0.321) \n",
      "\t\tProto:17 023:(0.3033) 024:(0.3205) 025:(0.322) 100:(0.291) 101:(0.272) \n",
      "\t\tProto:18 023:(0.2274) 024:(0.2599) 025:(0.2447) 100:(0.2682) 101:(0.2234) \n",
      "\t\tProto:19 023:(0.285) 024:(0.3073) 025:(0.306) 100:(0.4096) 101:(0.4198) \n",
      "\t\tProto:28 023:(0.2468) 024:(0.2565) 025:(0.2539) 100:(0.0941) 101:(0.0929) \n",
      "\t\tProto:31 023:(0.1977) 024:(0.1917) 025:(0.1892) 100:(0.1552) 101:(0.1715) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 73.22it/s]  \n",
      "Collecting topk: 120it [00:03, 39.58it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 003+002 {0, 8, 14, 7} --------------------\n",
      "-------------------- 003+002 {1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15} --------------------\n",
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:0 001:(0.8316) 002:(0.8128) 003:(0.8287) \n",
      "\t\tProto:8 001:(0.6097) 002:(0.6205) 003:(0.6777) \n",
      "\t\tProto:14 001:(0.6213) 002:(0.6221) 003:(0.5518) \n",
      "\t\tProto:7 001:(0.7652) 002:(0.7501) 003:(0.7189) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:02, 60.78it/s]\n",
      "Collecting topk: 150it [00:02, 50.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 101+100 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 023+025 {2, 3, 4, 6, 12} --------------------\n",
      "-------------------- 023+025 {0, 1, 5, 7, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 100:(0.2837) 101:(0.3593) \n",
      "\t\tProto:1 100:(0.7365) 101:(0.7306) \n",
      "\t\tProto:2 100:(0.7673) 101:(0.7536) \n",
      "\t\tProto:3 100:(0.2328) 101:(0.212) \n",
      "\t\tProto:4 100:(0.4729) 101:(0.445) \n",
      "\t\tProto:5 100:(0.5522) 101:(0.5454) \n",
      "\t\tProto:6 100:(0.7209) 101:(0.7072) \n",
      "\t\tProto:7 100:(0.2771) 101:(0.3756) \n",
      "\t Child: 023+025\n",
      "\t\tProto:2 023:(0.7714) 024:(0.756) 025:(0.7596) \n",
      "\t\tProto:3 023:(0.4703) 024:(0.5075) 025:(0.4745) \n",
      "\t\tProto:4 023:(0.3722) 024:(0.4047) 025:(0.3518) \n",
      "\t\tProto:6 023:(0.4741) 024:(0.5056) 025:(0.4779) \n",
      "\t\tProto:12 023:(0.505) 024:(0.4987) 025:(0.5021) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 49.89it/s]   \n",
      "Collecting topk: 90it [00:02, 37.73it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 002+001 {0, 1, 2, 3, 7} --------------------\n",
      "-------------------- 002+001 {4, 5, 6} --------------------\n",
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 001:(0.5614) 002:(0.5602) \n",
      "\t\tProto:1 001:(0.4688) 002:(0.4623) \n",
      "\t\tProto:2 001:(0.7611) 002:(0.7502) \n",
      "\t\tProto:3 001:(0.2713) 002:(0.2649) \n",
      "\t\tProto:7 001:(0.8971) 002:(0.9128) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 58.57it/s]   \n",
      "Collecting topk: 90it [00:02, 36.42it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 025+024 {0, 1, 3, 4, 5, 7} --------------------\n",
      "-------------------- 025+024 {2, 6} --------------------\n",
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 024:(0.5855) 025:(0.6178) \n",
      "\t\tProto:1 024:(0.2654) 025:(0.2592) \n",
      "\t\tProto:3 024:(0.8018) 025:(0.5688) \n",
      "\t\tProto:4 024:(0.6614) 025:(0.5576) \n",
      "\t\tProto:5 024:(0.4765) 025:(0.4864) \n",
      "\t\tProto:7 024:(0.8539) 025:(0.7967) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            if coarse_label2name[ys.item()] != child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                _, softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written\n",
    "                    if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                        continue\n",
    "                        \n",
    "                    h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes_of_child_node.shape, patchsize, skip, h_idx, w_idx)\n",
    "                    \n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "#                         child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) > topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "#                     pdb.set_trace()\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max) = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        patches.append(img_tensor_patch)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images after using UNIT-SPHERE & TANH-DESC with SOFTMAX (only use if the original model doesnt do softmax) using HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:04, 130.73it/s]\n",
      "Collecting topk: 540it [00:09, 54.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 052+053 {18, 11, 20, 13} --------------------\n",
      "-------------------- 004+086 {96, 1, 2, 39, 80, 83, 20, 53, 84, 30} --------------------\n",
      "-------------------- 052+053 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 19, 21, 22, 23} --------------------\n",
      "-------------------- 004+086 {0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103} --------------------\n",
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:18 050:(0.0107) 051:(0.0132) 052:(0.0103) 053:(0.0143) \n",
      "\t\tProto:11 050:(0.0148) 051:(0.0147) 052:(0.0149) 053:(0.0114) \n",
      "\t\tProto:20 050:(0.0126) 051:(0.013) 052:(0.0129) 053:(0.0101) \n",
      "\t\tProto:13 050:(0.0141) 051:(0.0139) 052:(0.0137) 053:(0.0116) \n",
      "\t Child: 004+086\n",
      "\t\tProto:96 001:(0.0129) 002:(0.0134) 003:(0.0132) 004:(0.0139) 023:(0.0127) 024:(0.0125) 025:(0.0132) 031:(0.0138) 032:(0.0135) 033:(0.0132) 045:(0.0132) 086:(0.013) 100:(0.0131) 101:(0.013) \n",
      "\t\tProto:1 001:(0.0093) 002:(0.0094) 003:(0.0095) 004:(0.0097) 023:(0.0094) 024:(0.0088) 025:(0.0092) 031:(0.0096) 032:(0.0096) 033:(0.0095) 045:(0.0092) 086:(0.0091) 100:(0.009) 101:(0.0088) \n",
      "\t\tProto:2 001:(0.011) 002:(0.0109) 003:(0.0098) 004:(0.01) 023:(0.0105) 024:(0.0106) 025:(0.0104) 031:(0.0102) 032:(0.009) 033:(0.0095) 045:(0.0102) 086:(0.0099) 100:(0.0108) 101:(0.0103) \n",
      "\t\tProto:39 001:(0.0093) 002:(0.0094) 003:(0.0097) 004:(0.0099) 023:(0.0094) 024:(0.0089) 025:(0.0092) 031:(0.0098) 032:(0.0098) 033:(0.01) 045:(0.0093) 086:(0.009) 100:(0.0092) 101:(0.0094) \n",
      "\t\tProto:80 001:(0.009) 002:(0.0088) 003:(0.0091) 004:(0.0087) 023:(0.0089) 024:(0.0086) 025:(0.0085) 031:(0.0086) 032:(0.0087) 033:(0.0087) 045:(0.0091) 086:(0.0087) 100:(0.0087) 101:(0.0087) \n",
      "\t\tProto:83 001:(0.0096) 002:(0.0096) 003:(0.0101) 004:(0.0092) 023:(0.0099) 024:(0.009) 025:(0.0091) 031:(0.0092) 032:(0.0092) 033:(0.0094) 045:(0.0096) 086:(0.0095) 100:(0.0091) 101:(0.0095) \n",
      "\t\tProto:20 001:(0.0112) 002:(0.0111) 003:(0.0101) 004:(0.0109) 023:(0.0105) 024:(0.0108) 025:(0.0106) 031:(0.0104) 032:(0.0103) 033:(0.0105) 045:(0.0093) 086:(0.0095) 100:(0.0102) 101:(0.0092) \n",
      "\t\tProto:53 001:(0.0103) 002:(0.0104) 003:(0.011) 004:(0.0123) 023:(0.0118) 024:(0.0125) 025:(0.0125) 031:(0.0115) 032:(0.0111) 033:(0.0113) 045:(0.0109) 086:(0.0097) 100:(0.0124) 101:(0.0105) \n",
      "\t\tProto:84 001:(0.0089) 002:(0.009) 003:(0.0088) 004:(0.009) 023:(0.0091) 024:(0.009) 025:(0.0091) 031:(0.0089) 032:(0.0086) 033:(0.0088) 045:(0.0089) 086:(0.009) 100:(0.0089) 101:(0.0087) \n",
      "\t\tProto:30 001:(0.0089) 002:(0.0091) 003:(0.0089) 004:(0.0089) 023:(0.0088) 024:(0.0085) 025:(0.0085) 031:(0.009) 032:(0.0089) 033:(0.0089) 045:(0.0087) 086:(0.0086) 100:(0.0086) 101:(0.0086) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 59.77it/s]  \n",
      "Collecting topk: 120it [00:03, 34.75it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 053+050 {0, 4, 5, 7, 12} --------------------\n",
      "-------------------- 053+050 {1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:0 050:(0.0885) 051:(0.0927) 053:(0.0792) \n",
      "\t\tProto:4 050:(0.0922) 051:(0.095) 053:(0.0963) \n",
      "\t\tProto:5 050:(0.1023) 051:(0.1069) 053:(0.1042) \n",
      "\t\tProto:7 050:(0.0703) 051:(0.0734) 053:(0.071) \n",
      "\t\tProto:12 050:(0.0658) 051:(0.0672) 053:(0.0729) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:03, 106.11it/s]\n",
      "Collecting topk: 420it [00:07, 55.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 004+032 {3, 6, 12, 19, 20} --------------------\n",
      "-------------------- 086+045 {33, 66, 6, 70, 22, 55, 29} --------------------\n",
      "-------------------- 004+032 {0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 23} --------------------\n",
      "-------------------- 086+045 {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71} --------------------\n",
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:3 004:(0.0136) 031:(0.0149) 032:(0.0146) 033:(0.0152) \n",
      "\t\tProto:6 004:(0.0151) 031:(0.0151) 032:(0.0143) 033:(0.0153) \n",
      "\t\tProto:12 004:(0.0199) 031:(0.0187) 032:(0.0182) 033:(0.0192) \n",
      "\t\tProto:19 004:(0.0135) 031:(0.0159) 032:(0.0144) 033:(0.0159) \n",
      "\t\tProto:20 004:(0.0158) 031:(0.0193) 032:(0.0187) 033:(0.0191) \n",
      "\t Child: 086+045\n",
      "\t\tProto:33 001:(0.0126) 002:(0.0125) 003:(0.0128) 023:(0.0158) 024:(0.0157) 025:(0.016) 045:(0.0126) 086:(0.0152) 100:(0.0131) 101:(0.0132) \n",
      "\t\tProto:66 001:(0.012) 002:(0.0121) 003:(0.0119) 023:(0.0118) 024:(0.0119) 025:(0.012) 045:(0.0126) 086:(0.0122) 100:(0.0115) 101:(0.0123) \n",
      "\t\tProto:6 001:(0.0195) 002:(0.0186) 003:(0.0187) 023:(0.0175) 024:(0.0165) 025:(0.0174) 045:(0.0187) 086:(0.0181) 100:(0.0181) 101:(0.0184) \n",
      "\t\tProto:70 001:(0.0178) 002:(0.0173) 003:(0.0173) 023:(0.0162) 024:(0.0156) 025:(0.0164) 045:(0.0173) 086:(0.0164) 100:(0.0171) 101:(0.0172) \n",
      "\t\tProto:22 001:(0.0135) 002:(0.0128) 003:(0.013) 023:(0.0129) 024:(0.0124) 025:(0.0132) 045:(0.0129) 086:(0.0135) 100:(0.0133) 101:(0.0133) \n",
      "\t\tProto:55 001:(0.0127) 002:(0.0119) 003:(0.0121) 023:(0.0112) 024:(0.0115) 025:(0.0111) 045:(0.0121) 086:(0.0121) 100:(0.0119) 101:(0.0119) \n",
      "\t\tProto:29 001:(0.0123) 002:(0.0117) 003:(0.0118) 023:(0.0122) 024:(0.0124) 025:(0.0124) 045:(0.0118) 086:(0.0137) 100:(0.0128) 101:(0.0123) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 45.44it/s]   \n",
      "Collecting topk: 90it [00:02, 30.05it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 050+051 {0, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 050+051 {1} --------------------\n",
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 050:(0.1471) 051:(0.1631) \n",
      "\t\tProto:2 050:(0.1242) 051:(0.1309) \n",
      "\t\tProto:3 050:(0.1054) 051:(0.0931) \n",
      "\t\tProto:4 050:(0.1246) 051:(0.1218) \n",
      "\t\tProto:5 050:(0.1151) 051:(0.104) \n",
      "\t\tProto:6 050:(0.0991) 051:(0.1002) \n",
      "\t\tProto:7 050:(0.1479) 051:(0.1586) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 62.51it/s]  \n",
      "Collecting topk: 120it [00:03, 34.40it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 032+033 {1, 3, 4, 7, 8, 12, 13, 15} --------------------\n",
      "-------------------- 032+033 {0, 2, 5, 6, 9, 10, 11, 14} --------------------\n",
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:1 031:(0.0832) 032:(0.0838) 033:(0.0815) \n",
      "\t\tProto:3 031:(0.0859) 032:(0.081) 033:(0.0807) \n",
      "\t\tProto:4 031:(0.0596) 032:(0.054) 033:(0.0598) \n",
      "\t\tProto:7 031:(0.0675) 032:(0.0661) 033:(0.0683) \n",
      "\t\tProto:8 031:(0.0663) 032:(0.0643) 033:(0.0658) \n",
      "\t\tProto:12 031:(0.0819) 032:(0.0785) 033:(0.082) \n",
      "\t\tProto:13 031:(0.0687) 032:(0.0615) 033:(0.0692) \n",
      "\t\tProto:15 031:(0.0682) 032:(0.0658) 033:(0.0655) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:02, 135.64it/s] \n",
      "Collecting topk: 300it [00:08, 35.84it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+101 {4, 5, 9, 10, 17, 18, 19, 24, 25, 26, 27, 28, 31, 32, 34, 39, 41, 44, 45, 49, 50, 51, 58, 59, 60, 63} --------------------\n",
      "-------------------- 045+101 {0, 1, 2, 3, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 29, 30, 33, 35, 36, 37, 38, 40, 42, 43, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62} --------------------\n",
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:4 001:(0.0171) 002:(0.0175) 003:(0.0172) 023:(0.017) 024:(0.0177) 025:(0.0175) 045:(0.0171) 100:(0.0183) 101:(0.0183) \n",
      "\t\tProto:5 001:(0.0168) 002:(0.0167) 003:(0.0173) 023:(0.0174) 024:(0.0178) 025:(0.0175) 045:(0.0165) 100:(0.0178) 101:(0.0165) \n",
      "\t\tProto:9 001:(0.0187) 002:(0.0188) 003:(0.0185) 023:(0.0186) 024:(0.0188) 025:(0.0186) 045:(0.0186) 100:(0.019) 101:(0.0188) \n",
      "\t\tProto:10 001:(0.0181) 002:(0.0182) 003:(0.0184) 023:(0.0184) 024:(0.0184) 025:(0.0182) 045:(0.018) 100:(0.0184) 101:(0.018) \n",
      "\t\tProto:17 001:(0.0178) 002:(0.0178) 003:(0.0178) 023:(0.0178) 024:(0.0178) 025:(0.0177) 045:(0.0178) 100:(0.0177) 101:(0.0177) \n",
      "\t\tProto:18 001:(0.0191) 002:(0.0193) 003:(0.0192) 023:(0.0193) 024:(0.0195) 025:(0.0191) 045:(0.0188) 100:(0.0194) 101:(0.019) \n",
      "\t\tProto:19 001:(0.0167) 002:(0.0165) 003:(0.0168) 023:(0.0171) 024:(0.0174) 025:(0.0172) 045:(0.0166) 100:(0.0175) 101:(0.0166) \n",
      "\t\tProto:24 001:(0.0164) 002:(0.0166) 003:(0.0165) 023:(0.0165) 024:(0.017) 025:(0.0164) 045:(0.0165) 100:(0.0173) 101:(0.0171) \n",
      "\t\tProto:25 001:(0.0168) 002:(0.0168) 003:(0.0168) 023:(0.017) 024:(0.0179) 025:(0.0172) 045:(0.017) 100:(0.017) 101:(0.0168) \n",
      "\t\tProto:26 001:(0.0185) 002:(0.019) 003:(0.0187) 023:(0.0172) 024:(0.0171) 025:(0.0171) 045:(0.019) 100:(0.0164) 101:(0.0181) \n",
      "\t\tProto:27 001:(0.0182) 002:(0.0181) 003:(0.0182) 023:(0.0182) 024:(0.0181) 025:(0.018) 045:(0.0182) 100:(0.018) 101:(0.018) \n",
      "\t\tProto:28 001:(0.0169) 002:(0.0177) 003:(0.0183) 023:(0.0186) 024:(0.0191) 025:(0.0186) 045:(0.0166) 100:(0.0192) 101:(0.0174) \n",
      "\t\tProto:31 001:(0.0172) 002:(0.0172) 003:(0.0173) 023:(0.0172) 024:(0.0173) 025:(0.0171) 045:(0.017) 100:(0.0174) 101:(0.0172) \n",
      "\t\tProto:32 001:(0.0166) 002:(0.0164) 003:(0.0166) 023:(0.0172) 024:(0.0174) 025:(0.0173) 045:(0.0165) 100:(0.0167) 101:(0.0163) \n",
      "\t\tProto:34 001:(0.0166) 002:(0.0167) 003:(0.0168) 023:(0.0169) 024:(0.017) 025:(0.0166) 045:(0.0161) 100:(0.0169) 101:(0.016) \n",
      "\t\tProto:39 001:(0.0169) 002:(0.0168) 003:(0.017) 023:(0.0166) 024:(0.0162) 025:(0.0163) 045:(0.0167) 100:(0.0176) 101:(0.0177) \n",
      "\t\tProto:41 001:(0.0175) 002:(0.0175) 003:(0.0178) 023:(0.0176) 024:(0.0179) 025:(0.0177) 045:(0.017) 100:(0.0177) 101:(0.0168) \n",
      "\t\tProto:44 001:(0.0162) 002:(0.0162) 003:(0.0167) 023:(0.0175) 024:(0.0176) 025:(0.0173) 045:(0.016) 100:(0.019) 101:(0.0189) \n",
      "\t\tProto:45 001:(0.0165) 002:(0.0165) 003:(0.0163) 023:(0.0164) 024:(0.0163) 025:(0.0162) 045:(0.0162) 100:(0.0163) 101:(0.0164) \n",
      "\t\tProto:49 001:(0.0174) 002:(0.0173) 003:(0.0165) 023:(0.0164) 024:(0.0169) 025:(0.0162) 045:(0.016) 100:(0.0178) 101:(0.0175) \n",
      "\t\tProto:50 001:(0.0179) 002:(0.0178) 003:(0.0177) 023:(0.0179) 024:(0.0181) 025:(0.0178) 045:(0.0178) 100:(0.0182) 101:(0.0177) \n",
      "\t\tProto:51 001:(0.0187) 002:(0.0183) 003:(0.0193) 023:(0.02) 024:(0.0204) 025:(0.0197) 045:(0.0175) 100:(0.0199) 101:(0.0182) \n",
      "\t\tProto:58 001:(0.0172) 002:(0.0169) 003:(0.0169) 023:(0.017) 024:(0.0173) 025:(0.0169) 045:(0.017) 100:(0.0173) 101:(0.0173) \n",
      "\t\tProto:59 001:(0.0176) 002:(0.0177) 003:(0.0176) 023:(0.0175) 024:(0.0176) 025:(0.0176) 045:(0.0176) 100:(0.0176) 101:(0.0176) \n",
      "\t\tProto:60 001:(0.0178) 002:(0.0176) 003:(0.0183) 023:(0.0185) 024:(0.0186) 025:(0.0175) 045:(0.017) 100:(0.0185) 101:(0.0175) \n",
      "\t\tProto:63 001:(0.0212) 002:(0.0212) 003:(0.021) 023:(0.021) 024:(0.0215) 025:(0.0211) 045:(0.021) 100:(0.0217) 101:(0.0213) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 45.43it/s]   \n",
      "Collecting topk: 90it [00:02, 32.32it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 033+031 {0, 2, 3, 4, 6} --------------------\n",
      "-------------------- 033+031 {1, 5, 7} --------------------\n",
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(0.1164) 033:(0.1153) \n",
      "\t\tProto:2 031:(0.1785) 033:(0.1742) \n",
      "\t\tProto:3 031:(0.1281) 033:(0.1246) \n",
      "\t\tProto:4 031:(0.1371) 033:(0.1327) \n",
      "\t\tProto:6 031:(0.1603) 033:(0.1538) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 61.40it/s]\n",
      "Collecting topk: 270it [00:04, 62.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+003 {2, 5, 8, 12, 14, 19} --------------------\n",
      "-------------------- 101+023 {4, 10, 16, 17, 18, 19, 28, 31} --------------------\n",
      "-------------------- 045+003 {0, 1, 3, 4, 6, 7, 9, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23} --------------------\n",
      "-------------------- 101+023 {0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30} --------------------\n",
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:2 001:(0.0299) 002:(0.03) 003:(0.03) 045:(0.0291) \n",
      "\t\tProto:5 001:(0.0286) 002:(0.0288) 003:(0.0284) 045:(0.0288) \n",
      "\t\tProto:8 001:(0.0236) 002:(0.0234) 003:(0.0235) 045:(0.0234) \n",
      "\t\tProto:12 001:(0.0266) 002:(0.0267) 003:(0.0266) 045:(0.0261) \n",
      "\t\tProto:14 001:(0.0308) 002:(0.0326) 003:(0.0293) 045:(0.0332) \n",
      "\t\tProto:19 001:(0.0325) 002:(0.0327) 003:(0.0326) 045:(0.0332) \n",
      "\t Child: 101+023\n",
      "\t\tProto:4 023:(0.0299) 024:(0.0316) 025:(0.0285) 100:(0.0359) 101:(0.0357) \n",
      "\t\tProto:10 023:(0.0226) 024:(0.0225) 025:(0.0225) 100:(0.0248) 101:(0.0247) \n",
      "\t\tProto:16 023:(0.031) 024:(0.0306) 025:(0.0313) 100:(0.0256) 101:(0.0244) \n",
      "\t\tProto:17 023:(0.0237) 024:(0.0241) 025:(0.0241) 100:(0.0235) 101:(0.0231) \n",
      "\t\tProto:18 023:(0.0224) 024:(0.0231) 025:(0.0228) 100:(0.0233) 101:(0.022) \n",
      "\t\tProto:19 023:(0.0238) 024:(0.0242) 025:(0.0242) 100:(0.0265) 101:(0.0268) \n",
      "\t\tProto:28 023:(0.0226) 024:(0.0228) 025:(0.0228) 100:(0.0196) 101:(0.0196) \n",
      "\t\tProto:31 023:(0.0212) 024:(0.0211) 025:(0.021) 100:(0.0204) 101:(0.0209) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 57.00it/s]  \n",
      "Collecting topk: 120it [00:03, 34.74it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 003+002 {0, 8, 14, 7} --------------------\n",
      "-------------------- 003+002 {1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15} --------------------\n",
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:0 001:(0.1042) 002:(0.1023) 003:(0.1041) \n",
      "\t\tProto:8 001:(0.0844) 002:(0.0846) 003:(0.09) \n",
      "\t\tProto:14 001:(0.0832) 002:(0.0832) 003:(0.0784) \n",
      "\t\tProto:7 001:(0.0977) 002:(0.0964) 003:(0.0942) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:02, 54.89it/s]\n",
      "Collecting topk: 150it [00:03, 42.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 101+100 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 023+025 {2, 3, 4, 6, 12} --------------------\n",
      "-------------------- 023+025 {0, 1, 5, 7, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 100:(0.0541) 101:(0.0578) \n",
      "\t\tProto:1 100:(0.0845) 101:(0.084) \n",
      "\t\tProto:2 100:(0.086) 101:(0.0846) \n",
      "\t\tProto:3 100:(0.0505) 101:(0.0485) \n",
      "\t\tProto:4 100:(0.0659) 101:(0.0643) \n",
      "\t\tProto:5 100:(0.0684) 101:(0.0676) \n",
      "\t\tProto:6 100:(0.0803) 101:(0.0787) \n",
      "\t\tProto:7 100:(0.0544) 101:(0.0598) \n",
      "\t Child: 023+025\n",
      "\t\tProto:2 023:(0.0854) 024:(0.0838) 025:(0.0843) \n",
      "\t\tProto:3 023:(0.0649) 024:(0.0673) 025:(0.0652) \n",
      "\t\tProto:4 023:(0.0592) 024:(0.0611) 025:(0.058) \n",
      "\t\tProto:6 023:(0.0643) 024:(0.0657) 025:(0.0645) \n",
      "\t\tProto:12 023:(0.0661) 024:(0.0652) 025:(0.0658) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 45.17it/s]   \n",
      "Collecting topk: 90it [00:02, 34.20it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 002+001 {0, 1, 2, 3, 7} --------------------\n",
      "-------------------- 002+001 {4, 5, 6} --------------------\n",
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 001:(0.1317) 002:(0.1311) \n",
      "\t\tProto:1 001:(0.1224) 002:(0.1217) \n",
      "\t\tProto:2 001:(0.1562) 002:(0.1544) \n",
      "\t\tProto:3 001:(0.1002) 002:(0.0995) \n",
      "\t\tProto:7 001:(0.1833) 002:(0.1862) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 52.50it/s]   \n",
      "Collecting topk: 90it [00:02, 31.92it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 025+024 {0, 1, 3, 4, 5, 7} --------------------\n",
      "-------------------- 025+024 {2, 6} --------------------\n",
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 024:(0.1347) 025:(0.138) \n",
      "\t\tProto:1 024:(0.1011) 025:(0.1006) \n",
      "\t\tProto:3 024:(0.169) 025:(0.1424) \n",
      "\t\tProto:4 024:(0.1411) 025:(0.1268) \n",
      "\t\tProto:5 024:(0.1198) 025:(0.1202) \n",
      "\t\tProto:7 024:(0.1676) 025:(0.1583) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "# Code to be done, doing softmax requires modification of pooled as well so its a bit of a work\n",
    "\n",
    "# IMPORTANT: the h_idx and w_idx could be different than actual if you the model originally doesnt do softmax but you're doing \n",
    "# softmax during visualization\n",
    "# So never finding bounding boxes using softmax if the model does not originally use softmax\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "# overlayed_image_np = get_heatmap(latent_activation, xs)\n",
    "# Image.fromarray(overlayed_image_np).show()\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            if coarse_label2name[ys.item()] != child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                _, softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                \n",
    "                # masking the below line to do pooling after softmax\n",
    "                # pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                \n",
    "                # assuming the model doesnt do softmax, doing softmax here\n",
    "                softmaxes = net.module._softmax(softmaxes)\n",
    "                                \n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                # Doing pooling here AFTER the SOFTMAX\n",
    "                pooled = net.module._pool(softmaxes_of_child_node).squeeze(0)\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written\n",
    "                    if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                        continue\n",
    "                        \n",
    "                    h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes_of_child_node.shape, patchsize, skip, h_idx, w_idx)\n",
    "                    latent_activation = softmaxes_of_child_node[:, p, :, :]\n",
    "                    \n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) > topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                         (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "#                         bbox_coords = torch.tensor([[w_coor_min, h_coor_min, w_coor_max, h_coor_max]])\n",
    "#                         bb_image = torchvision.utils.draw_bounding_boxes((img_tensor * 255).type(torch.uint8), bbox_coords, colors='red') / 255\n",
    "#                         pdb.set_trace()\n",
    "                        patches.append(overlayed_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_heatmap_after_softmax_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_heatmap_after_softmax_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images after using unit-sphere & tanh-desc WITH gradient based image coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_gradients(model, input_image, output, node_name, child_name, p, num_steps=100, device='cuda'):\n",
    "    model.eval()\n",
    "\n",
    "    baseline = torch.zeros((1, 3, 224, 224)).to(device)  # Assuming input size is 224x224 and 3 channels (RGB)\n",
    "\n",
    "    gradients = torch.autograd.grad(outputs=output, inputs=input_image, retain_graph=True)[0]\n",
    "\n",
    "    integrated_gradients = torch.zeros_like(input_image)\n",
    "\n",
    "    scaling_factor = (input_image - baseline) / num_steps\n",
    "\n",
    "    for i in range(1, num_steps + 1):\n",
    "        step_input = baseline + i * scaling_factor\n",
    "        _, softmaxes, pooled, _ = model(step_input, inference=False)\n",
    "        output = pooled[node_name][child_name].squeeze(0)[p]\n",
    "        step_gradients = torch.autograd.grad(outputs=output, inputs=step_input, retain_graph=True)[0]\n",
    "        integrated_gradients += step_gradients\n",
    "\n",
    "    integrated_gradients /= num_steps\n",
    "\n",
    "    return integrated_gradients\n",
    "\n",
    "\n",
    "def get_img_coordinates_using_gradients(model, input_image, output, node_name, child_name, p, patch_size=32, num_steps=100, device='cuda'):\n",
    "\n",
    "    attributions = integrated_gradients(model, input_image, output, node_name, child_name, p, num_steps)\n",
    "\n",
    "    grayscale_attributions = torch.sum(attributions, dim=1, keepdim=True)\n",
    "\n",
    "    best_patch_coords = None\n",
    "    best_score = None\n",
    "\n",
    "    for i in range(grayscale_attributions.size(2) - patch_size + 1):\n",
    "        for j in range(grayscale_attributions.size(3) - patch_size + 1):\n",
    "            h_coord_min, h_coord_max, w_coord_min, w_coord_max = i, i+patch_size, j, j+patch_size\n",
    "            patch = grayscale_attributions[:, :, h_coord_min:h_coord_max, w_coord_min:w_coord_max]\n",
    "            \n",
    "            score = torch.sum(patch)\n",
    "            \n",
    "            if best_score is None or score > best_score:\n",
    "                best_score = score\n",
    "                best_patch_coords = (h_coord_min, h_coord_max, w_coord_min, w_coord_max)\n",
    "\n",
    "    return best_patch_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [15:24,  1.71s/it]\n",
      "Collecting topk: 177it [57:26, 19.37s/it]"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates #, get_img_coordinates_using_gradients\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            if coarse_label2name[ys.item()] != child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.enable_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                xs.requires_grad = True\n",
    "                _, softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written\n",
    "                    if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                        continue\n",
    "                    \n",
    "                    \n",
    "                    h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates_using_gradients(model=net, input_image=xs, output=pooled[p], \\\n",
    "                                                                                                         node_name=node.name, child_name=child_node.name, \\\n",
    "                                                                                                         p=p, device=device, num_steps=10)\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "#                         child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) > topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "#                     pdb.set_trace()\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max) = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        patches.append(img_tensor_patch)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_using_gradient_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_using_gradient_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images after using UNIT-SPHERE & TANH-DESC with BOUNDING BOXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:03, 136.52it/s]\n",
      "Collecting topk: 540it [00:10, 50.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 052+053 {18, 11, 20, 13} --------------------\n",
      "-------------------- 004+086 {96, 1, 2, 39, 80, 83, 20, 53, 84, 30} --------------------\n",
      "-------------------- 052+053 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 19, 21, 22, 23} --------------------\n",
      "-------------------- 004+086 {0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103} --------------------\n",
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:18 050:(0.3224) 051:(0.5289) 052:(0.2688) 053:(0.6115) \n",
      "\t\tProto:11 050:(0.6517) 051:(0.6445) 052:(0.6527) 053:(0.3735) \n",
      "\t\tProto:20 050:(0.4741) 051:(0.5075) 052:(0.5022) 053:(0.2589) \n",
      "\t\tProto:13 050:(0.6036) 051:(0.5833) 052:(0.5662) 053:(0.3894) \n",
      "\t Child: 004+086\n",
      "\t\tProto:96 001:(0.5111) 002:(0.5501) 003:(0.5323) 004:(0.5836) 023:(0.4943) 024:(0.4769) 025:(0.5284) 031:(0.5764) 032:(0.5585) 033:(0.5312) 045:(0.534) 086:(0.5197) 100:(0.5268) 101:(0.5216) \n",
      "\t\tProto:1 001:(0.1821) 002:(0.1959) 003:(0.1979) 004:(0.2218) 023:(0.1907) 024:(0.1184) 025:(0.1717) 031:(0.215) 032:(0.2137) 033:(0.2063) 045:(0.1728) 086:(0.1593) 100:(0.1421) 101:(0.124) \n",
      "\t\tProto:2 001:(0.3508) 002:(0.3477) 003:(0.2319) 004:(0.2603) 023:(0.303) 024:(0.3151) 025:(0.2953) 031:(0.2709) 032:(0.15) 033:(0.2073) 045:(0.2716) 086:(0.2373) 100:(0.3307) 101:(0.2845) \n",
      "\t\tProto:39 001:(0.1836) 002:(0.1912) 003:(0.2224) 004:(0.2492) 023:(0.1876) 024:(0.1307) 025:(0.1703) 031:(0.2351) 032:(0.2322) 033:(0.2564) 045:(0.1754) 086:(0.1438) 100:(0.1708) 101:(0.1959) \n",
      "\t\tProto:80 001:(0.1416) 002:(0.1287) 003:(0.159) 004:(0.1065) 023:(0.1326) 024:(0.0992) 025:(0.0937) 031:(0.1055) 032:(0.1076) 033:(0.1096) 045:(0.1591) 086:(0.1103) 100:(0.1063) 101:(0.1129) \n",
      "\t\tProto:83 001:(0.2142) 002:(0.2136) 003:(0.2698) 004:(0.1688) 023:(0.2411) 024:(0.1444) 025:(0.1618) 031:(0.1762) 032:(0.1705) 033:(0.1897) 045:(0.2148) 086:(0.2046) 100:(0.1628) 101:(0.2014) \n",
      "\t\tProto:20 001:(0.3689) 002:(0.3607) 003:(0.264) 004:(0.3371) 023:(0.2967) 024:(0.332) 025:(0.3081) 031:(0.2863) 032:(0.2824) 033:(0.3005) 045:(0.1826) 086:(0.1979) 100:(0.2734) 101:(0.174) \n",
      "\t\tProto:53 001:(0.2774) 002:(0.2925) 003:(0.3464) 004:(0.4645) 023:(0.4219) 024:(0.4766) 025:(0.4793) 031:(0.3893) 032:(0.3592) 033:(0.3744) 045:(0.3408) 086:(0.2234) 100:(0.4674) 101:(0.2955) \n",
      "\t\tProto:84 001:(0.1393) 002:(0.1483) 003:(0.1263) 004:(0.1529) 023:(0.16) 024:(0.1471) 025:(0.1594) 031:(0.1408) 032:(0.0992) 033:(0.1323) 045:(0.1374) 086:(0.143) 100:(0.1302) 101:(0.1192) \n",
      "\t\tProto:30 001:(0.1302) 002:(0.151) 003:(0.1383) 004:(0.1363) 023:(0.1271) 024:(0.0901) 025:(0.0888) 031:(0.1445) 032:(0.1374) 033:(0.1392) 045:(0.1155) 086:(0.0975) 100:(0.1041) 101:(0.0982) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 60.40it/s]  \n",
      "Collecting topk: 120it [00:03, 37.57it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 053+050 {0, 4, 5, 7, 12} --------------------\n",
      "-------------------- 053+050 {1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:0 050:(0.6018) 051:(0.6573) 053:(0.4821) \n",
      "\t\tProto:4 050:(0.6982) 051:(0.7354) 053:(0.7513) \n",
      "\t\tProto:5 050:(0.7782) 051:(0.8249) 053:(0.7996) \n",
      "\t\tProto:7 050:(0.3938) 051:(0.4381) 053:(0.4319) \n",
      "\t\tProto:12 050:(0.2812) 051:(0.3068) 053:(0.3904) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:03, 107.68it/s]\n",
      "Collecting topk: 420it [00:07, 55.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 004+032 {3, 6, 12, 19, 20} --------------------\n",
      "-------------------- 086+045 {33, 66, 6, 70, 22, 55, 29} --------------------\n",
      "-------------------- 004+032 {0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 23} --------------------\n",
      "-------------------- 086+045 {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71} --------------------\n",
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:3 004:(0.2749) 031:(0.3765) 032:(0.3545) 033:(0.3979) \n",
      "\t\tProto:6 004:(0.3775) 031:(0.3835) 032:(0.3265) 033:(0.3926) \n",
      "\t\tProto:12 004:(0.656) 031:(0.5929) 032:(0.5623) 033:(0.6189) \n",
      "\t\tProto:19 004:(0.2689) 031:(0.44) 032:(0.3415) 033:(0.4406) \n",
      "\t\tProto:20 004:(0.4277) 031:(0.6322) 032:(0.5991) 033:(0.6219) \n",
      "\t Child: 086+045\n",
      "\t\tProto:33 001:(0.1989) 002:(0.1869) 003:(0.2129) 023:(0.4262) 024:(0.4197) 025:(0.4387) 045:(0.1953) 086:(0.3889) 100:(0.2343) 101:(0.2375) \n",
      "\t\tProto:66 001:(0.1443) 002:(0.1516) 003:(0.1438) 023:(0.1331) 024:(0.1375) 025:(0.1449) 045:(0.1883) 086:(0.1648) 100:(0.0977) 101:(0.164) \n",
      "\t\tProto:6 001:(0.6457) 002:(0.5974) 003:(0.6025) 023:(0.5345) 024:(0.4713) 025:(0.5332) 045:(0.606) 086:(0.5751) 100:(0.5726) 101:(0.5841) \n",
      "\t\tProto:70 001:(0.5566) 002:(0.5244) 003:(0.5271) 023:(0.4602) 024:(0.4198) 025:(0.4706) 045:(0.5269) 086:(0.4724) 100:(0.5131) 101:(0.5179) \n",
      "\t\tProto:22 001:(0.2746) 002:(0.2188) 003:(0.2395) 023:(0.2327) 024:(0.1857) 025:(0.2566) 045:(0.2312) 086:(0.2758) 100:(0.2633) 101:(0.2604) \n",
      "\t\tProto:55 001:(0.2109) 002:(0.1403) 003:(0.1532) 023:(0.0766) 024:(0.0969) 025:(0.0622) 045:(0.1575) 086:(0.16) 100:(0.1359) 101:(0.1355) \n",
      "\t\tProto:29 001:(0.1767) 002:(0.1281) 003:(0.1364) 023:(0.1748) 024:(0.1836) 025:(0.1861) 045:(0.1337) 086:(0.2874) 100:(0.2168) 101:(0.1684) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.14it/s]   \n",
      "Collecting topk: 90it [00:02, 33.88it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 050+051 {0, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 050+051 {1} --------------------\n",
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 050:(0.6595) 051:(0.773) \n",
      "\t\tProto:2 050:(0.5292) 051:(0.596) \n",
      "\t\tProto:3 050:(0.2493) 051:(0.1498) \n",
      "\t\tProto:4 050:(0.4782) 051:(0.4411) \n",
      "\t\tProto:5 050:(0.403) 051:(0.2806) \n",
      "\t\tProto:6 050:(0.2847) 051:(0.3088) \n",
      "\t\tProto:7 050:(0.6833) 051:(0.7682) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 66.04it/s]  \n",
      "Collecting topk: 120it [00:03, 36.79it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 032+033 {1, 3, 4, 7, 8, 12, 13, 15} --------------------\n",
      "-------------------- 032+033 {0, 2, 5, 6, 9, 10, 11, 14} --------------------\n",
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:1 031:(0.5933) 032:(0.5973) 033:(0.5693) \n",
      "\t\tProto:3 031:(0.6457) 032:(0.5805) 033:(0.571) \n",
      "\t\tProto:4 031:(0.214) 032:(0.1365) 033:(0.2244) \n",
      "\t\tProto:7 031:(0.3754) 032:(0.3439) 033:(0.3951) \n",
      "\t\tProto:8 031:(0.3565) 032:(0.3079) 033:(0.3477) \n",
      "\t\tProto:12 031:(0.5921) 032:(0.5478) 033:(0.5841) \n",
      "\t\tProto:13 031:(0.3858) 032:(0.2704) 033:(0.4004) \n",
      "\t\tProto:15 031:(0.4102) 032:(0.371) 033:(0.3568) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:02, 145.57it/s] \n",
      "Collecting topk: 300it [00:07, 39.34it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+101 {4, 5, 9, 10, 17, 18, 19, 24, 25, 26, 27, 28, 31, 32, 34, 39, 41, 44, 45, 49, 50, 51, 58, 59, 60, 63} --------------------\n",
      "-------------------- 045+101 {0, 1, 2, 3, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 29, 30, 33, 35, 36, 37, 38, 40, 42, 43, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62} --------------------\n",
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:4 001:(0.1567) 002:(0.1822) 003:(0.1681) 023:(0.1522) 024:(0.1955) 025:(0.1807) 045:(0.1498) 100:(0.2344) 101:(0.2268) \n",
      "\t\tProto:5 001:(0.1477) 002:(0.1367) 003:(0.1737) 023:(0.1846) 024:(0.2069) 025:(0.1864) 045:(0.1252) 100:(0.2062) 101:(0.1185) \n",
      "\t\tProto:9 001:(0.2545) 002:(0.2588) 003:(0.2427) 023:(0.2479) 024:(0.2601) 025:(0.2498) 045:(0.2492) 100:(0.2702) 101:(0.2609) \n",
      "\t\tProto:10 001:(0.2098) 002:(0.2168) 003:(0.2308) 023:(0.2301) 024:(0.2344) 025:(0.2199) 045:(0.2074) 100:(0.2335) 101:(0.2056) \n",
      "\t\tProto:17 001:(0.1932) 002:(0.1924) 003:(0.194) 023:(0.1935) 024:(0.1928) 025:(0.1914) 045:(0.1936) 100:(0.192) 101:(0.1889) \n",
      "\t\tProto:18 001:(0.2721) 002:(0.282) 003:(0.2756) 023:(0.282) 024:(0.2942) 025:(0.2734) 045:(0.2522) 100:(0.2874) 101:(0.2652) \n",
      "\t\tProto:19 001:(0.1326) 002:(0.1208) 003:(0.1398) 023:(0.1645) 024:(0.1817) 025:(0.1676) 045:(0.1245) 100:(0.1877) 101:(0.1254) \n",
      "\t\tProto:24 001:(0.1132) 002:(0.1203) 003:(0.1168) 023:(0.1173) 024:(0.151) 025:(0.1137) 045:(0.1119) 100:(0.1732) 101:(0.16) \n",
      "\t\tProto:25 001:(0.1337) 002:(0.1361) 003:(0.1353) 023:(0.148) 024:(0.1929) 025:(0.1567) 045:(0.1448) 100:(0.1451) 101:(0.1348) \n",
      "\t\tProto:26 001:(0.2315) 002:(0.262) 003:(0.2395) 023:(0.161) 024:(0.158) 025:(0.1549) 045:(0.2617) 100:(0.1175) 101:(0.2163) \n",
      "\t\tProto:27 001:(0.2131) 002:(0.211) 003:(0.2161) 023:(0.2146) 024:(0.2092) 025:(0.205) 045:(0.2156) 100:(0.2072) 101:(0.2061) \n",
      "\t\tProto:28 001:(0.1458) 002:(0.1921) 003:(0.2289) 023:(0.2431) 024:(0.2746) 025:(0.2444) 045:(0.1252) 100:(0.2777) 101:(0.1765) \n",
      "\t\tProto:31 001:(0.165) 002:(0.1648) 003:(0.1728) 023:(0.1666) 024:(0.172) 025:(0.1606) 045:(0.153) 100:(0.1742) 101:(0.1628) \n",
      "\t\tProto:32 001:(0.1231) 002:(0.1129) 003:(0.1216) 023:(0.1585) 024:(0.1706) 025:(0.1641) 045:(0.1178) 100:(0.1286) 101:(0.1113) \n",
      "\t\tProto:34 001:(0.1252) 002:(0.1381) 003:(0.1451) 023:(0.1571) 024:(0.1608) 025:(0.1363) 045:(0.101) 100:(0.1567) 101:(0.0857) \n",
      "\t\tProto:39 001:(0.1424) 002:(0.1403) 003:(0.1441) 023:(0.1223) 024:(0.0986) 025:(0.1041) 045:(0.1308) 100:(0.183) 101:(0.1913) \n",
      "\t\tProto:41 001:(0.1874) 002:(0.1873) 003:(0.2083) 023:(0.2001) 024:(0.2142) 025:(0.2018) 045:(0.1528) 100:(0.203) 101:(0.1431) \n",
      "\t\tProto:44 001:(0.0981) 002:(0.0938) 003:(0.1347) 023:(0.1864) 024:(0.1929) 025:(0.1726) 045:(0.0892) 100:(0.2721) 101:(0.2575) \n",
      "\t\tProto:45 001:(0.1203) 002:(0.1175) 003:(0.1113) 023:(0.1176) 024:(0.1127) 025:(0.1077) 045:(0.0953) 100:(0.115) 101:(0.1114) \n",
      "\t\tProto:49 001:(0.1657) 002:(0.1541) 003:(0.1185) 023:(0.1181) 024:(0.14) 025:(0.1039) 045:(0.0841) 100:(0.1869) 101:(0.1729) \n",
      "\t\tProto:50 001:(0.2115) 002:(0.2049) 003:(0.2011) 023:(0.2116) 024:(0.2234) 025:(0.2066) 045:(0.2047) 100:(0.2313) 101:(0.2037) \n",
      "\t\tProto:51 001:(0.2565) 002:(0.2295) 003:(0.2884) 023:(0.3266) 024:(0.3511) 025:(0.311) 045:(0.1807) 100:(0.3212) 101:(0.2186) \n",
      "\t\tProto:58 001:(0.1616) 002:(0.141) 003:(0.1421) 023:(0.146) 024:(0.1634) 025:(0.1451) 045:(0.1479) 100:(0.1676) 101:(0.1664) \n",
      "\t\tProto:59 001:(0.1892) 002:(0.1903) 003:(0.1846) 023:(0.1804) 024:(0.1894) 025:(0.1866) 045:(0.185) 100:(0.1903) 101:(0.1864) \n",
      "\t\tProto:60 001:(0.2071) 002:(0.1906) 003:(0.2327) 023:(0.2496) 024:(0.2543) 025:(0.1947) 045:(0.151) 100:(0.2499) 101:(0.1725) \n",
      "\t\tProto:63 001:(0.3799) 002:(0.3823) 003:(0.3703) 023:(0.3713) 024:(0.3958) 025:(0.3767) 045:(0.3706) 100:(0.4063) 101:(0.3851) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 44.87it/s]   \n",
      "Collecting topk: 90it [00:02, 33.44it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 033+031 {0, 2, 3, 4, 6} --------------------\n",
      "-------------------- 033+031 {1, 5, 7} --------------------\n",
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(0.4807) 033:(0.4616) \n",
      "\t\tProto:2 031:(0.8752) 033:(0.8493) \n",
      "\t\tProto:3 031:(0.4735) 033:(0.4492) \n",
      "\t\tProto:4 031:(0.6412) 033:(0.6034) \n",
      "\t\tProto:6 031:(0.7761) 033:(0.7219) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:03, 69.09it/s]\n",
      "Collecting topk: 270it [00:04, 60.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+003 {2, 5, 8, 12, 14, 19} --------------------\n",
      "-------------------- 101+023 {4, 10, 16, 17, 18, 19, 28, 31} --------------------\n",
      "-------------------- 045+003 {0, 1, 3, 4, 6, 7, 9, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23} --------------------\n",
      "-------------------- 101+023 {0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30} --------------------\n",
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:2 001:(0.5555) 002:(0.5532) 003:(0.5581) 045:(0.5252) \n",
      "\t\tProto:5 001:(0.5084) 002:(0.5138) 003:(0.501) 045:(0.5132) \n",
      "\t\tProto:8 001:(0.3175) 002:(0.3091) 003:(0.3163) 045:(0.3117) \n",
      "\t\tProto:12 001:(0.4407) 002:(0.4386) 003:(0.4393) 045:(0.4195) \n",
      "\t\tProto:14 001:(0.573) 002:(0.63) 003:(0.5254) 045:(0.6495) \n",
      "\t\tProto:19 001:(0.6359) 002:(0.6387) 003:(0.6375) 045:(0.6567) \n",
      "\t Child: 101+023\n",
      "\t\tProto:4 023:(0.5267) 024:(0.5849) 025:(0.4806) 100:(0.7271) 101:(0.7219) \n",
      "\t\tProto:10 023:(0.2657) 024:(0.2619) 025:(0.2585) 100:(0.3557) 101:(0.3481) \n",
      "\t\tProto:16 023:(0.5802) 024:(0.5681) 025:(0.5893) 100:(0.3766) 101:(0.321) \n",
      "\t\tProto:17 023:(0.3033) 024:(0.3205) 025:(0.322) 100:(0.291) 101:(0.272) \n",
      "\t\tProto:18 023:(0.2274) 024:(0.2599) 025:(0.2447) 100:(0.2682) 101:(0.2234) \n",
      "\t\tProto:19 023:(0.285) 024:(0.3073) 025:(0.306) 100:(0.4096) 101:(0.4198) \n",
      "\t\tProto:28 023:(0.2468) 024:(0.2565) 025:(0.2539) 100:(0.0941) 101:(0.0929) \n",
      "\t\tProto:31 023:(0.1977) 024:(0.1917) 025:(0.1892) 100:(0.1552) 101:(0.1715) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 59.65it/s]  \n",
      "Collecting topk: 120it [00:03, 36.26it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 003+002 {0, 8, 14, 7} --------------------\n",
      "-------------------- 003+002 {1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15} --------------------\n",
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:0 001:(0.8316) 002:(0.8128) 003:(0.8287) \n",
      "\t\tProto:8 001:(0.6097) 002:(0.6205) 003:(0.6777) \n",
      "\t\tProto:14 001:(0.6213) 002:(0.6221) 003:(0.5518) \n",
      "\t\tProto:7 001:(0.7652) 002:(0.7501) 003:(0.7189) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:02, 53.06it/s]\n",
      "Collecting topk: 150it [00:03, 46.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 101+100 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 023+025 {2, 3, 4, 6, 12} --------------------\n",
      "-------------------- 023+025 {0, 1, 5, 7, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 100:(0.2837) 101:(0.3593) \n",
      "\t\tProto:1 100:(0.7365) 101:(0.7306) \n",
      "\t\tProto:2 100:(0.7673) 101:(0.7536) \n",
      "\t\tProto:3 100:(0.2328) 101:(0.212) \n",
      "\t\tProto:4 100:(0.4729) 101:(0.445) \n",
      "\t\tProto:5 100:(0.5522) 101:(0.5454) \n",
      "\t\tProto:6 100:(0.7209) 101:(0.7072) \n",
      "\t\tProto:7 100:(0.2771) 101:(0.3756) \n",
      "\t Child: 023+025\n",
      "\t\tProto:2 023:(0.7714) 024:(0.756) 025:(0.7596) \n",
      "\t\tProto:3 023:(0.4703) 024:(0.5075) 025:(0.4745) \n",
      "\t\tProto:4 023:(0.3722) 024:(0.4047) 025:(0.3518) \n",
      "\t\tProto:6 023:(0.4741) 024:(0.5056) 025:(0.4779) \n",
      "\t\tProto:12 023:(0.505) 024:(0.4987) 025:(0.5021) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 49.40it/s]   \n",
      "Collecting topk: 90it [00:02, 33.20it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 002+001 {0, 1, 2, 3, 7} --------------------\n",
      "-------------------- 002+001 {4, 5, 6} --------------------\n",
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 001:(0.5614) 002:(0.5602) \n",
      "\t\tProto:1 001:(0.4688) 002:(0.4623) \n",
      "\t\tProto:2 001:(0.7611) 002:(0.7502) \n",
      "\t\tProto:3 001:(0.2713) 002:(0.2649) \n",
      "\t\tProto:7 001:(0.8971) 002:(0.9128) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 49.26it/s]   \n",
      "Collecting topk: 90it [00:02, 32.87it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 025+024 {0, 1, 3, 4, 5, 7} --------------------\n",
      "-------------------- 025+024 {2, 6} --------------------\n",
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 024:(0.5855) 025:(0.6178) \n",
      "\t\tProto:1 024:(0.2654) 025:(0.2592) \n",
      "\t\tProto:3 024:(0.8018) 025:(0.5688) \n",
      "\t\tProto:4 024:(0.6614) 025:(0.5576) \n",
      "\t\tProto:5 024:(0.4765) 025:(0.4864) \n",
      "\t\tProto:7 024:(0.8539) 025:(0.7967) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            if coarse_label2name[ys.item()] != child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                _, softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written\n",
    "                    if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                        continue\n",
    "                        \n",
    "                    h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes_of_child_node.shape, patchsize, skip, h_idx, w_idx)\n",
    "                    \n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "#                         child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) > topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "#                     pdb.set_trace()\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max) = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        bbox_coords = torch.tensor([[w_coor_min, h_coor_min, w_coor_max, h_coor_max]])\n",
    "                        bb_image = torchvision.utils.draw_bounding_boxes((img_tensor * 255).type(torch.uint8), bbox_coords, colors='red') / 255\n",
    "                        patches.append(bb_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_bb_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_bb_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on NON leaf descendents - topk images after using UNIT-SPHERE & TANH-DESC with BOUNDING BOXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:08, 62.71it/s]\n",
      "Collecting topk: 540it [00:04, 121.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 052+053 {18, 11, 20, 13} --------------------\n",
      "-------------------- 004+086 {96, 1, 2, 39, 80, 83, 20, 53, 84, 30} --------------------\n",
      "-------------------- 052+053 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 19, 21, 22, 23} --------------------\n",
      "-------------------- 004+086 {0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103} --------------------\n",
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:18 001:(0.0439) 002:(0.0603) 003:(0.04) 004:(0.0376) 023:(0.0475) 024:(0.0428) 025:(0.0419) 031:(0.0857) 032:(0.0403) 033:(0.0711) 045:(0.0332) 086:(0.1032) 100:(0.0293) 101:(0.104) \n",
      "\t\tProto:11 001:(0.0218) 002:(0.0185) 003:(0.0208) 004:(0.0259) 023:(0.0212) 024:(0.0239) 025:(0.0268) 031:(0.0266) 032:(0.0237) 033:(0.0259) 045:(0.021) 086:(0.0277) 100:(0.0236) 101:(0.021) \n",
      "\t\tProto:20 001:(0.0491) 002:(0.0506) 003:(0.0407) 004:(0.0457) 023:(0.0468) 024:(0.0377) 025:(0.0475) 031:(0.0383) 032:(0.0377) 033:(0.0399) 045:(0.0397) 086:(0.0737) 100:(0.0383) 101:(0.0452) \n",
      "\t\tProto:13 001:(0.0315) 002:(0.0301) 003:(0.0266) 004:(0.0315) 023:(0.0359) 024:(0.0428) 025:(0.0336) 031:(0.0413) 032:(0.0286) 033:(0.0313) 045:(0.0293) 086:(0.0365) 100:(0.0333) 101:(0.0262) \n",
      "\t Child: 004+086\n",
      "\t\tProto:96 050:(0.0938) 051:(0.0463) 052:(0.059) 053:(0.0926) \n",
      "\t\tProto:1 050:(0.0961) 051:(0.0784) 052:(0.0925) 053:(0.0953) \n",
      "\t\tProto:2 050:(0.0445) 051:(0.0609) 052:(0.0795) 053:(0.0853) \n",
      "\t\tProto:39 050:(0.061) 051:(0.0616) 052:(0.0658) 053:(0.0608) \n",
      "\t\tProto:80 050:(0.091) 051:(0.0878) 052:(0.0955) 053:(0.0836) \n",
      "\t\tProto:83 050:(0.1377) 051:(0.1439) 052:(0.1483) 053:(0.1416) \n",
      "\t\tProto:20 050:(0.0637) 051:(0.0647) 052:(0.0757) 053:(0.0723) \n",
      "\t\tProto:53 050:(0.0604) 051:(0.0333) 052:(0.0594) 053:(0.0432) \n",
      "\t\tProto:84 050:(0.0858) 051:(0.0861) 052:(0.0865) 053:(0.0902) \n",
      "\t\tProto:30 050:(0.0696) 051:(0.0687) 052:(0.0665) 053:(0.071) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 41.27it/s]  \n",
      "Collecting topk: 120it [00:02, 58.84it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- cub_052_Pied_billed_Grebe {0, 2} --------------------\n",
      "-------------------- 053+050 {0, 4, 5, 7, 12} --------------------\n",
      "-------------------- cub_052_Pied_billed_Grebe {1, 3} --------------------\n",
      "-------------------- 053+050 {1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 052+053\n",
      "\t Child: cub_052_Pied_billed_Grebe\n",
      "\t\tProto:0 050:(0.0713) 051:(0.0463) 053:(0.0521) \n",
      "\t\tProto:2 050:(0.0531) 051:(0.0465) 053:(0.0474) \n",
      "\t Child: 053+050\n",
      "\t\tProto:0 052:(0.0641) \n",
      "\t\tProto:4 052:(0.0893) \n",
      "\t\tProto:5 052:(0.124) \n",
      "\t\tProto:7 052:(0.0795) \n",
      "\t\tProto:12 052:(0.2036) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:06, 63.11it/s]\n",
      "Collecting topk: 420it [00:04, 103.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 004+032 {3, 6, 12, 19, 20} --------------------\n",
      "-------------------- 086+045 {33, 66, 6, 70, 22, 55, 29} --------------------\n",
      "-------------------- 004+032 {0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 23} --------------------\n",
      "-------------------- 086+045 {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71} --------------------\n",
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:3 001:(0.0459) 002:(0.0526) 003:(0.0483) 023:(0.048) 024:(0.0567) 025:(0.0477) 045:(0.0445) 086:(0.0496) 100:(0.0511) 101:(0.0575) \n",
      "\t\tProto:6 001:(0.0362) 002:(0.0434) 003:(0.0449) 023:(0.0392) 024:(0.0347) 025:(0.0338) 045:(0.0415) 086:(0.0429) 100:(0.036) 101:(0.0401) \n",
      "\t\tProto:12 001:(0.0215) 002:(0.0229) 003:(0.0262) 023:(0.025) 024:(0.0187) 025:(0.0219) 045:(0.0359) 086:(0.0516) 100:(0.0209) 101:(0.0232) \n",
      "\t\tProto:19 001:(0.0392) 002:(0.0378) 003:(0.0398) 023:(0.0443) 024:(0.0353) 025:(0.0398) 045:(0.0381) 086:(0.0401) 100:(0.0377) 101:(0.0469) \n",
      "\t\tProto:20 001:(0.0463) 002:(0.0377) 003:(0.0451) 023:(0.031) 024:(0.074) 025:(0.0381) 045:(0.0361) 086:(0.0395) 100:(0.0414) 101:(0.0804) \n",
      "\t Child: 086+045\n",
      "\t\tProto:33 004:(0.0143) 031:(0.0108) 032:(0.0128) 033:(0.0105) \n",
      "\t\tProto:66 004:(0.0726) 031:(0.0557) 032:(0.0498) 033:(0.0538) \n",
      "\t\tProto:6 004:(0.0304) 031:(0.0125) 032:(0.0073) 033:(0.0098) \n",
      "\t\tProto:70 004:(0.0309) 031:(0.019) 032:(0.0157) 033:(0.0125) \n",
      "\t\tProto:22 004:(0.0353) 031:(0.0396) 032:(0.0365) 033:(0.034) \n",
      "\t\tProto:55 004:(0.044) 031:(0.0498) 032:(0.0443) 033:(0.0507) \n",
      "\t\tProto:29 004:(0.0687) 031:(0.0458) 032:(0.0429) 033:(0.0446) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 35.98it/s]   \n",
      "Collecting topk: 90it [00:01, 46.28it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- cub_053_Western_Grebe {0, 2, 3} --------------------\n",
      "-------------------- 050+051 {0, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- cub_053_Western_Grebe {1} --------------------\n",
      "-------------------- 050+051 {1} --------------------\n",
      "Node 053+050\n",
      "\t Child: cub_053_Western_Grebe\n",
      "\t\tProto:0 050:(0.1009) 051:(0.0969) \n",
      "\t\tProto:2 050:(0.1062) 051:(0.1332) \n",
      "\t\tProto:3 050:(0.1319) 051:(0.1678) \n",
      "\t Child: 050+051\n",
      "\t\tProto:0 053:(0.0348) \n",
      "\t\tProto:2 053:(0.0341) \n",
      "\t\tProto:3 053:(0.0438) \n",
      "\t\tProto:4 053:(0.0549) \n",
      "\t\tProto:5 053:(0.0488) \n",
      "\t\tProto:6 053:(0.0592) \n",
      "\t\tProto:7 053:(0.0328) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 41.55it/s]  \n",
      "Collecting topk: 120it [00:02, 57.21it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- cub_004_Groove_billed_Ani {0, 2, 3} --------------------\n",
      "-------------------- 032+033 {1, 3, 4, 7, 8, 12, 13, 15} --------------------\n",
      "-------------------- cub_004_Groove_billed_Ani {1} --------------------\n",
      "-------------------- 032+033 {0, 2, 5, 6, 9, 10, 11, 14} --------------------\n",
      "Node 004+032\n",
      "\t Child: cub_004_Groove_billed_Ani\n",
      "\t\tProto:0 031:(0.0313) 032:(0.0363) 033:(0.0543) \n",
      "\t\tProto:2 031:(0.0452) 032:(0.0442) 033:(0.0411) \n",
      "\t\tProto:3 031:(0.0454) 032:(0.05) 033:(0.0645) \n",
      "\t Child: 032+033\n",
      "\t\tProto:1 004:(0.0335) \n",
      "\t\tProto:3 004:(0.0235) \n",
      "\t\tProto:4 004:(0.0703) \n",
      "\t\tProto:7 004:(0.0404) \n",
      "\t\tProto:8 004:(0.0255) \n",
      "\t\tProto:12 004:(0.0209) \n",
      "\t\tProto:13 004:(0.0404) \n",
      "\t\tProto:15 004:(0.0372) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:05, 52.60it/s]  \n",
      "Collecting topk: 300it [00:02, 123.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- cub_086_Pacific_Loon {0, 1, 2} --------------------\n",
      "-------------------- 045+101 {4, 5, 9, 10, 17, 18, 19, 24, 25, 26, 27, 28, 31, 32, 34, 39, 41, 44, 45, 49, 50, 51, 58, 59, 60, 63} --------------------\n",
      "-------------------- cub_086_Pacific_Loon {3} --------------------\n",
      "-------------------- 045+101 {0, 1, 2, 3, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 29, 30, 33, 35, 36, 37, 38, 40, 42, 43, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62} --------------------\n",
      "Node 086+045\n",
      "\t Child: cub_086_Pacific_Loon\n",
      "\t\tProto:0 001:(0.026) 002:(0.0377) 003:(0.027) 023:(0.0241) 024:(0.0231) 025:(0.0234) 045:(0.0235) 100:(0.0313) 101:(0.0298) \n",
      "\t\tProto:1 001:(0.0361) 002:(0.0378) 003:(0.0393) 023:(0.0393) 024:(0.0382) 025:(0.0455) 045:(0.0487) 100:(0.0422) 101:(0.0418) \n",
      "\t\tProto:2 001:(0.0172) 002:(0.0177) 003:(0.0251) 023:(0.0189) 024:(0.0164) 025:(0.0168) 045:(0.0162) 100:(0.0228) 101:(0.0205) \n",
      "\t Child: 045+101\n",
      "\t\tProto:4 086:(0.1153) \n",
      "\t\tProto:5 086:(0.0752) \n",
      "\t\tProto:9 086:(0.2432) \n",
      "\t\tProto:10 086:(0.1992) \n",
      "\t\tProto:17 086:(0.192) \n",
      "\t\tProto:18 086:(0.2336) \n",
      "\t\tProto:19 086:(0.1221) \n",
      "\t\tProto:24 086:(0.1111) \n",
      "\t\tProto:25 086:(0.077) \n",
      "\t\tProto:26 086:(0.0837) \n",
      "\t\tProto:27 086:(0.2146) \n",
      "\t\tProto:28 086:(0.0717) \n",
      "\t\tProto:31 086:(0.164) \n",
      "\t\tProto:32 086:(0.0925) \n",
      "\t\tProto:34 086:(0.0864) \n",
      "\t\tProto:39 086:(0.0848) \n",
      "\t\tProto:41 086:(0.084) \n",
      "\t\tProto:44 086:(0.0805) \n",
      "\t\tProto:45 086:(0.0801) \n",
      "\t\tProto:49 086:(0.0909) \n",
      "\t\tProto:50 086:(0.1956) \n",
      "\t\tProto:51 086:(0.0621) \n",
      "\t\tProto:58 086:(0.1377) \n",
      "\t\tProto:59 086:(0.1826) \n",
      "\t\tProto:60 086:(0.0697) \n",
      "\t\tProto:63 086:(0.3545) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 37.37it/s]   \n",
      "Collecting topk: 90it [00:01, 45.30it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- cub_032_Mangrove_Cuckoo {0, 1, 3} --------------------\n",
      "-------------------- 033+031 {0, 2, 3, 4, 6} --------------------\n",
      "-------------------- cub_032_Mangrove_Cuckoo {2} --------------------\n",
      "-------------------- 033+031 {1, 5, 7} --------------------\n",
      "Node 032+033\n",
      "\t Child: cub_032_Mangrove_Cuckoo\n",
      "\t\tProto:0 031:(0.1451) 033:(0.2639) \n",
      "\t\tProto:1 031:(0.098) 033:(0.2233) \n",
      "\t\tProto:3 031:(0.1071) 033:(0.2037) \n",
      "\t Child: 033+031\n",
      "\t\tProto:0 032:(0.0673) \n",
      "\t\tProto:2 032:(0.0254) \n",
      "\t\tProto:3 032:(0.0314) \n",
      "\t\tProto:4 032:(0.0305) \n",
      "\t\tProto:6 032:(0.0425) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 65.43it/s]\n",
      "Collecting topk: 270it [00:03, 72.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+003 {2, 5, 8, 12, 14, 19} --------------------\n",
      "-------------------- 101+023 {4, 10, 16, 17, 18, 19, 28, 31} --------------------\n",
      "-------------------- 045+003 {0, 1, 3, 4, 6, 7, 9, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23} --------------------\n",
      "-------------------- 101+023 {0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30} --------------------\n",
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:2 023:(0.0283) 024:(0.0174) 025:(0.0447) 100:(0.0422) 101:(0.0197) \n",
      "\t\tProto:5 023:(0.034) 024:(0.0287) 025:(0.0715) 100:(0.0343) 101:(0.0362) \n",
      "\t\tProto:8 023:(0.0383) 024:(0.0329) 025:(0.0513) 100:(0.0389) 101:(0.0338) \n",
      "\t\tProto:12 023:(0.026) 024:(0.0189) 025:(0.0419) 100:(0.0387) 101:(0.0203) \n",
      "\t\tProto:14 023:(0.0382) 024:(0.0258) 025:(0.0628) 100:(0.0281) 101:(0.0298) \n",
      "\t\tProto:19 023:(0.0297) 024:(0.0214) 025:(0.0743) 100:(0.0216) 101:(0.025) \n",
      "\t Child: 101+023\n",
      "\t\tProto:4 001:(0.0828) 002:(0.0158) 003:(0.0225) 045:(0.0436) \n",
      "\t\tProto:10 001:(0.0764) 002:(0.0318) 003:(0.0362) 045:(0.0434) \n",
      "\t\tProto:16 001:(0.079) 002:(0.0254) 003:(0.0332) 045:(0.035) \n",
      "\t\tProto:17 001:(0.0778) 002:(0.0586) 003:(0.0744) 045:(0.0525) \n",
      "\t\tProto:18 001:(0.0761) 002:(0.0697) 003:(0.105) 045:(0.0591) \n",
      "\t\tProto:19 001:(0.078) 002:(0.0427) 003:(0.1061) 045:(0.053) \n",
      "\t\tProto:28 001:(0.0965) 002:(0.0905) 003:(0.0842) 045:(0.0929) \n",
      "\t\tProto:31 001:(0.0677) 002:(0.0556) 003:(0.0609) 045:(0.0604) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 39.87it/s]  \n",
      "Collecting topk: 120it [00:02, 58.87it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- cub_045_Northern_Fulmar {0, 1, 2} --------------------\n",
      "-------------------- 003+002 {0, 8, 14, 7} --------------------\n",
      "-------------------- cub_045_Northern_Fulmar {3} --------------------\n",
      "-------------------- 003+002 {1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15} --------------------\n",
      "Node 045+003\n",
      "\t Child: cub_045_Northern_Fulmar\n",
      "\t\tProto:0 001:(0.0863) 002:(0.1029) 003:(0.0804) \n",
      "\t\tProto:1 001:(0.0482) 002:(0.0526) 003:(0.0401) \n",
      "\t\tProto:2 001:(0.0584) 002:(0.0596) 003:(0.0549) \n",
      "\t Child: 003+002\n",
      "\t\tProto:0 045:(0.2051) \n",
      "\t\tProto:8 045:(0.1084) \n",
      "\t\tProto:14 045:(0.1118) \n",
      "\t\tProto:7 045:(0.1774) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 49.75it/s]\n",
      "Collecting topk: 150it [00:02, 59.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 101+100 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 023+025 {2, 3, 4, 6, 12} --------------------\n",
      "-------------------- 023+025 {0, 1, 5, 7, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 023:(0.0525) 024:(0.0444) 025:(0.0493) \n",
      "\t\tProto:1 023:(0.0365) 024:(0.033) 025:(0.0446) \n",
      "\t\tProto:2 023:(0.0274) 024:(0.0261) 025:(0.029) \n",
      "\t\tProto:3 023:(0.048) 024:(0.0465) 025:(0.0472) \n",
      "\t\tProto:4 023:(0.0666) 024:(0.063) 025:(0.0674) \n",
      "\t\tProto:5 023:(0.032) 024:(0.0282) 025:(0.0313) \n",
      "\t\tProto:6 023:(0.0187) 024:(0.0172) 025:(0.0256) \n",
      "\t\tProto:7 023:(0.0592) 024:(0.0567) 025:(0.0568) \n",
      "\t Child: 023+025\n",
      "\t\tProto:2 100:(0.0317) 101:(0.0328) \n",
      "\t\tProto:3 100:(0.044) 101:(0.0448) \n",
      "\t\tProto:4 100:(0.1224) 101:(0.0532) \n",
      "\t\tProto:6 100:(0.0392) 101:(0.0433) \n",
      "\t\tProto:12 100:(0.0486) 101:(0.0499) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 35.10it/s]   \n",
      "Collecting topk: 90it [00:01, 46.41it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- cub_003_Sooty_Albatross {2, 3} --------------------\n",
      "-------------------- 002+001 {0, 1, 2, 3, 7} --------------------\n",
      "-------------------- cub_003_Sooty_Albatross {0, 1} --------------------\n",
      "-------------------- 002+001 {4, 5, 6} --------------------\n",
      "Node 003+002\n",
      "\t Child: cub_003_Sooty_Albatross\n",
      "\t\tProto:2 001:(0.1335) 002:(0.1414) \n",
      "\t\tProto:3 001:(0.178) 002:(0.1799) \n",
      "\t Child: 002+001\n",
      "\t\tProto:0 003:(0.088) \n",
      "\t\tProto:1 003:(0.073) \n",
      "\t\tProto:2 003:(0.1136) \n",
      "\t\tProto:3 003:(0.0722) \n",
      "\t\tProto:7 003:(0.048) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 36.72it/s]   \n",
      "Collecting topk: 90it [00:01, 45.17it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- cub_023_Brandt_Cormorant {0, 1, 2} --------------------\n",
      "-------------------- 025+024 {0, 1, 3, 4, 5, 7} --------------------\n",
      "-------------------- cub_023_Brandt_Cormorant {3} --------------------\n",
      "-------------------- 025+024 {2, 6} --------------------\n",
      "Node 023+025\n",
      "\t Child: cub_023_Brandt_Cormorant\n",
      "\t\tProto:0 024:(0.0344) 025:(0.0982) \n",
      "\t\tProto:1 024:(0.0441) 025:(0.0568) \n",
      "\t\tProto:2 024:(0.0434) 025:(0.0838) \n",
      "\t Child: 025+024\n",
      "\t\tProto:0 023:(0.3104) \n",
      "\t\tProto:1 023:(0.1824) \n",
      "\t\tProto:3 023:(0.2483) \n",
      "\t\tProto:4 023:(0.2868) \n",
      "\t\tProto:5 023:(0.2609) \n",
      "\t\tProto:7 023:(0.5086) \n",
      "Done !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            # masking for NON descendants\n",
    "#             if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "#                 continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            # going for non descendants so skip if the image actually belongs to the child_node considered in this loop\n",
    "            if coarse_label2name[ys.item()] == child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                _, softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written, masking for NON descendants\n",
    "#                     if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "#                         continue\n",
    "                        \n",
    "                    h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes_of_child_node.shape, patchsize, skip, h_idx, w_idx)\n",
    "                    \n",
    "                    # going for NON descendants so images course label should not be in relevant class names\n",
    "                    if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "#                         child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) > topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent], (pooled[p].item(), img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max)))\n",
    "#                     pdb.set_trace()\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if len(proto_mean_activations[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max) = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        bbox_coords = torch.tensor([[w_coor_min, h_coor_min, w_coor_max, h_coor_max]])\n",
    "                        bb_image = torchvision.utils.draw_bounding_boxes((img_tensor * 255).type(torch.uint8), bbox_coords, colors='red') / 255\n",
    "                        patches.append(bb_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'non_descendent_specific_topk_bb_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'non_descendent_specific_topk_bb_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images after using TANH-DESC with HEAT MAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:04, 127.94it/s]\n",
      "Collecting topk: 540it [00:13, 41.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 052+053 {0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23} --------------------\n",
      "-------------------- 004+086 {0, 1, 3, 4, 6, 7, 9, 11, 12, 13, 15, 16, 17, 18, 20, 21, 26, 28, 31, 32, 37, 38, 39, 43, 45, 46, 48, 49, 52, 53, 60, 63, 64, 65, 67, 72, 73, 74, 78, 80, 81, 83, 84, 86, 90, 93, 95, 96, 97, 98, 101} --------------------\n",
      "-------------------- 052+053 {8} --------------------\n",
      "-------------------- 004+086 {2, 5, 8, 10, 14, 19, 22, 23, 24, 25, 27, 29, 30, 33, 34, 35, 36, 40, 41, 42, 44, 47, 50, 51, 54, 55, 56, 57, 58, 59, 61, 62, 66, 68, 69, 70, 71, 75, 76, 77, 79, 82, 85, 87, 88, 89, 91, 92, 94, 99, 100, 102, 103} --------------------\n",
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:0 050:(0.7606) 051:(0.8758) 052:(0.7187) 053:(0.7696) \n",
      "\t\tProto:1 050:(0.5665) 051:(0.8536) 052:(0.7468) 053:(0.7175) \n",
      "\t\tProto:2 050:(0.9051) 051:(0.9275) 052:(0.9068) 053:(0.9827) \n",
      "\t\tProto:3 050:(0.4354) 051:(0.7945) 052:(0.854) 053:(0.8633) \n",
      "\t\tProto:4 050:(0.9609) 051:(0.9437) 052:(0.9869) 053:(0.6173) \n",
      "\t\tProto:5 050:(0.6087) 051:(0.8857) 052:(0.9002) 053:(0.9537) \n",
      "\t\tProto:6 050:(0.6441) 051:(0.6348) 052:(0.6789) 053:(0.7768) \n",
      "\t\tProto:7 050:(0.971) 051:(0.9729) 052:(0.8417) 053:(0.8811) \n",
      "\t\tProto:9 050:(0.6395) 051:(0.9396) 052:(0.7693) 053:(0.804) \n",
      "\t\tProto:10 050:(0.8481) 051:(0.9713) 052:(0.888) 053:(0.973) \n",
      "\t\tProto:11 050:(0.9179) 051:(0.9533) 052:(0.9595) 053:(0.9323) \n",
      "\t\tProto:12 050:(0.9141) 051:(0.908) 052:(0.907) 053:(0.9287) \n",
      "\t\tProto:13 050:(0.8813) 051:(0.9462) 052:(0.8265) 053:(0.9142) \n",
      "\t\tProto:14 050:(0.2778) 051:(0.7687) 052:(0.6663) 053:(0.8893) \n",
      "\t\tProto:15 050:(0.7396) 051:(0.8925) 052:(0.8325) 053:(0.9914) \n",
      "\t\tProto:16 050:(0.9637) 051:(0.9894) 052:(0.9767) 053:(0.9369) \n",
      "\t\tProto:17 050:(0.9729) 051:(0.996) 052:(0.9875) 053:(0.9972) \n",
      "\t\tProto:18 050:(0.949) 051:(0.9703) 052:(0.7978) 053:(0.9607) \n",
      "\t\tProto:19 050:(0.8231) 051:(0.9738) 052:(0.9174) 053:(0.969) \n",
      "\t\tProto:20 050:(0.9764) 051:(0.9896) 052:(0.9904) 053:(0.9479) \n",
      "\t\tProto:21 050:(0.7482) 051:(0.9126) 052:(0.9255) 053:(0.9731) \n",
      "\t\tProto:22 050:(0.4561) 051:(0.8819) 052:(0.756) 053:(0.9057) \n",
      "\t\tProto:23 050:(0.7629) 051:(0.9287) 052:(0.9203) 053:(0.9685) \n",
      "\t Child: 004+086\n",
      "\t\tProto:0 001:(0.8683) 002:(0.8624) 003:(0.6837) 004:(0.6662) 023:(0.8246) 024:(0.7739) 025:(0.6969) 031:(0.7402) 032:(0.7404) 033:(0.6756) 045:(0.7292) 086:(0.8232) 100:(0.8716) 101:(0.8781) \n",
      "\t\tProto:1 001:(0.7643) 002:(0.6786) 003:(0.7943) 004:(0.6194) 023:(0.7682) 024:(0.5128) 025:(0.7914) 031:(0.5251) 032:(0.6023) 033:(0.6187) 045:(0.4012) 086:(0.671) 100:(0.8106) 101:(0.5743) \n",
      "\t\tProto:3 001:(0.7731) 002:(0.6108) 003:(0.6716) 004:(0.7591) 023:(0.6761) 024:(0.8152) 025:(0.7272) 031:(0.8175) 032:(0.8182) 033:(0.8985) 045:(0.6872) 086:(0.8562) 100:(0.5371) 101:(0.7878) \n",
      "\t\tProto:4 001:(0.7074) 002:(0.6529) 003:(0.5421) 004:(0.7168) 023:(0.6475) 024:(0.7268) 025:(0.8668) 031:(0.6406) 032:(0.6657) 033:(0.8157) 045:(0.6334) 086:(0.4742) 100:(0.8127) 101:(0.7165) \n",
      "\t\tProto:6 001:(0.5957) 002:(0.4838) 003:(0.555) 004:(0.7979) 023:(0.6995) 024:(0.4357) 025:(0.7372) 031:(0.4771) 032:(0.5558) 033:(0.489) 045:(0.475) 086:(0.2388) 100:(0.3064) 101:(0.4118) \n",
      "\t\tProto:7 001:(0.4627) 002:(0.5517) 003:(0.5383) 004:(0.7916) 023:(0.8343) 024:(0.8425) 025:(0.9147) 031:(0.7351) 032:(0.8549) 033:(0.8351) 045:(0.4598) 086:(0.5167) 100:(0.8303) 101:(0.4966) \n",
      "\t\tProto:9 001:(0.5137) 002:(0.7143) 003:(0.9157) 004:(0.3354) 023:(0.7126) 024:(0.791) 025:(0.7259) 031:(0.4437) 032:(0.4525) 033:(0.5614) 045:(0.6791) 086:(0.7428) 100:(0.5273) 101:(0.7298) \n",
      "\t\tProto:11 001:(0.7462) 002:(0.6808) 003:(0.5606) 004:(0.7053) 023:(0.7038) 024:(0.7616) 025:(0.8531) 031:(0.5728) 032:(0.5906) 033:(0.5709) 045:(0.7973) 086:(0.1759) 100:(0.754) 101:(0.4451) \n",
      "\t\tProto:12 001:(0.5931) 002:(0.6764) 003:(0.7867) 004:(0.8763) 023:(0.7549) 024:(0.6281) 025:(0.8269) 031:(0.7902) 032:(0.6341) 033:(0.6935) 045:(0.4038) 086:(0.5215) 100:(0.7956) 101:(0.7798) \n",
      "\t\tProto:13 001:(0.7765) 002:(0.6376) 003:(0.8145) 004:(0.5842) 023:(0.4716) 024:(0.5197) 025:(0.5912) 031:(0.777) 032:(0.8363) 033:(0.448) 045:(0.3595) 086:(0.3816) 100:(0.8383) 101:(0.6395) \n",
      "\t\tProto:15 001:(0.8035) 002:(0.8223) 003:(0.6154) 004:(0.6917) 023:(0.8096) 024:(0.9225) 025:(0.7084) 031:(0.5934) 032:(0.5327) 033:(0.5465) 045:(0.6146) 086:(0.9338) 100:(0.6296) 101:(0.9063) \n",
      "\t\tProto:16 001:(0.8965) 002:(0.8487) 003:(0.7886) 004:(0.3267) 023:(0.8166) 024:(0.8068) 025:(0.8023) 031:(0.541) 032:(0.4729) 033:(0.5401) 045:(0.4398) 086:(0.4448) 100:(0.5126) 101:(0.4671) \n",
      "\t\tProto:17 001:(0.9451) 002:(0.9083) 003:(0.9024) 004:(0.9206) 023:(0.9519) 024:(0.9059) 025:(0.9442) 031:(0.8324) 032:(0.9769) 033:(0.9091) 045:(0.9601) 086:(0.8909) 100:(0.8054) 101:(0.6361) \n",
      "\t\tProto:18 001:(0.6603) 002:(0.8702) 003:(0.7376) 004:(0.7503) 023:(0.6758) 024:(0.5515) 025:(0.5325) 031:(0.7662) 032:(0.7303) 033:(0.5916) 045:(0.6998) 086:(0.2616) 100:(0.5435) 101:(0.5744) \n",
      "\t\tProto:20 001:(0.811) 002:(0.8462) 003:(0.8369) 004:(0.8887) 023:(0.8049) 024:(0.7704) 025:(0.6979) 031:(0.8073) 032:(0.8618) 033:(0.8467) 045:(0.7007) 086:(0.8577) 100:(0.5858) 101:(0.7911) \n",
      "\t\tProto:21 001:(0.6481) 002:(0.6874) 003:(0.8016) 004:(0.8262) 023:(0.8004) 024:(0.8288) 025:(0.8707) 031:(0.7234) 032:(0.7019) 033:(0.7493) 045:(0.7646) 086:(0.8552) 100:(0.858) 101:(0.8944) \n",
      "\t\tProto:26 001:(0.6638) 002:(0.7148) 003:(0.6985) 004:(0.897) 023:(0.7066) 024:(0.8565) 025:(0.7583) 031:(0.8351) 032:(0.6754) 033:(0.6396) 045:(0.7287) 086:(0.6259) 100:(0.7994) 101:(0.7773) \n",
      "\t\tProto:28 001:(0.6963) 002:(0.5876) 003:(0.6697) 004:(0.8787) 023:(0.6937) 024:(0.7442) 025:(0.7673) 031:(0.5056) 032:(0.6723) 033:(0.5846) 045:(0.6695) 086:(0.5778) 100:(0.7915) 101:(0.6783) \n",
      "\t\tProto:31 001:(0.8151) 002:(0.8091) 003:(0.8468) 004:(0.8435) 023:(0.8445) 024:(0.801) 025:(0.7403) 031:(0.9553) 032:(0.8124) 033:(0.8678) 045:(0.7916) 086:(0.9143) 100:(0.8668) 101:(0.6027) \n",
      "\t\tProto:32 001:(0.9274) 002:(0.8263) 003:(0.8755) 004:(0.6564) 023:(0.9174) 024:(0.7923) 025:(0.9072) 031:(0.7449) 032:(0.8219) 033:(0.7248) 045:(0.7117) 086:(0.9097) 100:(0.654) 101:(0.6097) \n",
      "\t\tProto:37 001:(0.8802) 002:(0.6798) 003:(0.663) 004:(0.6244) 023:(0.8561) 024:(0.6899) 025:(0.7782) 031:(0.7578) 032:(0.5997) 033:(0.621) 045:(0.5831) 086:(0.8736) 100:(0.7352) 101:(0.5774) \n",
      "\t\tProto:38 001:(0.914) 002:(0.8069) 003:(0.9124) 004:(0.6649) 023:(0.8225) 024:(0.7178) 025:(0.9114) 031:(0.6143) 032:(0.4618) 033:(0.8839) 045:(0.857) 086:(0.7008) 100:(0.8787) 101:(0.6892) \n",
      "\t\tProto:39 001:(0.7811) 002:(0.6434) 003:(0.659) 004:(0.3937) 023:(0.7596) 024:(0.549) 025:(0.6447) 031:(0.8353) 032:(0.7299) 033:(0.4258) 045:(0.6032) 086:(0.7658) 100:(0.5145) 101:(0.5959) \n",
      "\t\tProto:43 001:(0.4663) 002:(0.3397) 003:(0.6664) 004:(0.6766) 023:(0.7108) 024:(0.6059) 025:(0.5289) 031:(0.5458) 032:(0.484) 033:(0.4191) 045:(0.6662) 086:(0.7) 100:(0.872) 101:(0.7037) \n",
      "\t\tProto:45 001:(0.6392) 002:(0.7969) 003:(0.5888) 004:(0.7441) 023:(0.7127) 024:(0.5132) 025:(0.7256) 031:(0.5955) 032:(0.375) 033:(0.6052) 045:(0.6733) 086:(0.6943) 100:(0.5132) 101:(0.6205) \n",
      "\t\tProto:46 001:(0.8596) 002:(0.5931) 003:(0.8299) 004:(0.6237) 023:(0.9188) 024:(0.8544) 025:(0.7993) 031:(0.7111) 032:(0.7543) 033:(0.5799) 045:(0.6693) 086:(0.8694) 100:(0.8082) 101:(0.7205) \n",
      "\t\tProto:48 001:(0.8557) 002:(0.8429) 003:(0.4862) 004:(0.346) 023:(0.9002) 024:(0.863) 025:(0.8723) 031:(0.4029) 032:(0.4038) 033:(0.3957) 045:(0.6591) 086:(0.8674) 100:(0.6411) 101:(0.6179) \n",
      "\t\tProto:49 001:(0.7485) 002:(0.8588) 003:(0.5724) 004:(0.6934) 023:(0.7278) 024:(0.6806) 025:(0.7272) 031:(0.6361) 032:(0.816) 033:(0.8112) 045:(0.6695) 086:(0.7872) 100:(0.6238) 101:(0.7049) \n",
      "\t\tProto:52 001:(0.6933) 002:(0.7133) 003:(0.8535) 004:(0.7482) 023:(0.7278) 024:(0.6635) 025:(0.8144) 031:(0.7079) 032:(0.7974) 033:(0.7496) 045:(0.7672) 086:(0.6224) 100:(0.8096) 101:(0.5675) \n",
      "\t\tProto:53 001:(0.539) 002:(0.5122) 003:(0.7445) 004:(0.6012) 023:(0.6413) 024:(0.7684) 025:(0.8048) 031:(0.6178) 032:(0.6423) 033:(0.7163) 045:(0.6089) 086:(0.4992) 100:(0.9541) 101:(0.4235) \n",
      "\t\tProto:60 001:(0.729) 002:(0.7126) 003:(0.8541) 004:(0.7996) 023:(0.7556) 024:(0.6936) 025:(0.7081) 031:(0.8664) 032:(0.8058) 033:(0.7617) 045:(0.7728) 086:(0.6486) 100:(0.5101) 101:(0.8128) \n",
      "\t\tProto:63 001:(0.8043) 002:(0.871) 003:(0.8149) 004:(0.5831) 023:(0.7793) 024:(0.8528) 025:(0.8334) 031:(0.5148) 032:(0.5303) 033:(0.5508) 045:(0.701) 086:(0.8009) 100:(0.6891) 101:(0.7992) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tProto:64 001:(0.8029) 002:(0.8957) 003:(0.6934) 004:(0.8164) 023:(0.8951) 024:(0.6508) 025:(0.624) 031:(0.6833) 032:(0.7278) 033:(0.8189) 045:(0.4584) 086:(0.9364) 100:(0.6785) 101:(0.6129) \n",
      "\t\tProto:65 001:(0.7729) 002:(0.6962) 003:(0.7142) 004:(0.7449) 023:(0.88) 024:(0.8208) 025:(0.895) 031:(0.8301) 032:(0.9138) 033:(0.8899) 045:(0.7997) 086:(0.8876) 100:(0.5349) 101:(0.5159) \n",
      "\t\tProto:67 001:(0.7103) 002:(0.8602) 003:(0.8524) 004:(0.7157) 023:(0.5626) 024:(0.7448) 025:(0.7425) 031:(0.7986) 032:(0.6707) 033:(0.7588) 045:(0.5776) 086:(0.2875) 100:(0.6202) 101:(0.6421) \n",
      "\t\tProto:72 001:(0.8975) 002:(0.8831) 003:(0.8377) 004:(0.7362) 023:(0.7951) 024:(0.8531) 025:(0.8329) 031:(0.6847) 032:(0.5036) 033:(0.7139) 045:(0.8106) 086:(0.7149) 100:(0.5694) 101:(0.7705) \n",
      "\t\tProto:73 001:(0.8703) 002:(0.5665) 003:(0.6715) 004:(0.5914) 023:(0.7113) 024:(0.852) 025:(0.7143) 031:(0.6723) 032:(0.786) 033:(0.6285) 045:(0.7195) 086:(0.8779) 100:(0.6101) 101:(0.813) \n",
      "\t\tProto:74 001:(0.7906) 002:(0.6841) 003:(0.7062) 004:(0.7147) 023:(0.812) 024:(0.8149) 025:(0.7018) 031:(0.5568) 032:(0.7698) 033:(0.6941) 045:(0.7061) 086:(0.833) 100:(0.581) 101:(0.7892) \n",
      "\t\tProto:78 001:(0.5838) 002:(0.7589) 003:(0.7761) 004:(0.9167) 023:(0.7437) 024:(0.6914) 025:(0.7657) 031:(0.7709) 032:(0.7256) 033:(0.5561) 045:(0.4874) 086:(0.5138) 100:(0.7701) 101:(0.8365) \n",
      "\t\tProto:80 001:(0.7363) 002:(0.6584) 003:(0.707) 004:(0.6646) 023:(0.7156) 024:(0.8148) 025:(0.6861) 031:(0.8477) 032:(0.7883) 033:(0.6045) 045:(0.381) 086:(0.7628) 100:(0.7207) 101:(0.8104) \n",
      "\t\tProto:81 001:(0.7844) 002:(0.6888) 003:(0.8468) 004:(0.7519) 023:(0.689) 024:(0.4979) 025:(0.7406) 031:(0.6121) 032:(0.6699) 033:(0.6646) 045:(0.6474) 086:(0.7014) 100:(0.7035) 101:(0.5838) \n",
      "\t\tProto:83 001:(0.7825) 002:(0.7926) 003:(0.7446) 004:(0.8213) 023:(0.7126) 024:(0.8055) 025:(0.8101) 031:(0.5736) 032:(0.6393) 033:(0.606) 045:(0.6391) 086:(0.6948) 100:(0.6324) 101:(0.9061) \n",
      "\t\tProto:84 001:(0.8163) 002:(0.8191) 003:(0.5401) 004:(0.8444) 023:(0.6565) 024:(0.8453) 025:(0.7116) 031:(0.8877) 032:(0.8437) 033:(0.8171) 045:(0.7633) 086:(0.8956) 100:(0.6312) 101:(0.5568) \n",
      "\t\tProto:86 001:(0.714) 002:(0.7527) 003:(0.5073) 004:(0.5312) 023:(0.7729) 024:(0.7561) 025:(0.8012) 031:(0.7541) 032:(0.6686) 033:(0.6933) 045:(0.6256) 086:(0.8715) 100:(0.8716) 101:(0.5529) \n",
      "\t\tProto:90 001:(0.819) 002:(0.7995) 003:(0.8882) 004:(0.6159) 023:(0.8696) 024:(0.5329) 025:(0.5471) 031:(0.6448) 032:(0.8053) 033:(0.6093) 045:(0.6724) 086:(0.7539) 100:(0.6983) 101:(0.5042) \n",
      "\t\tProto:93 001:(0.6585) 002:(0.6933) 003:(0.7637) 004:(0.4879) 023:(0.5206) 024:(0.6826) 025:(0.741) 031:(0.6708) 032:(0.4917) 033:(0.6526) 045:(0.8268) 086:(0.6513) 100:(0.7555) 101:(0.8573) \n",
      "\t\tProto:95 001:(0.7693) 002:(0.8621) 003:(0.7877) 004:(0.8365) 023:(0.737) 024:(0.7546) 025:(0.7598) 031:(0.6171) 032:(0.6031) 033:(0.5856) 045:(0.7558) 086:(0.5161) 100:(0.8312) 101:(0.8499) \n",
      "\t\tProto:96 001:(0.7966) 002:(0.7963) 003:(0.6123) 004:(0.4464) 023:(0.8731) 024:(0.8373) 025:(0.7123) 031:(0.581) 032:(0.6327) 033:(0.5791) 045:(0.6358) 086:(0.6839) 100:(0.573) 101:(0.5308) \n",
      "\t\tProto:97 001:(0.7221) 002:(0.7623) 003:(0.9279) 004:(0.659) 023:(0.8884) 024:(0.7304) 025:(0.8391) 031:(0.8238) 032:(0.7409) 033:(0.6758) 045:(0.8329) 086:(0.6065) 100:(0.5683) 101:(0.5412) \n",
      "\t\tProto:98 001:(0.6779) 002:(0.7361) 003:(0.7168) 004:(0.8367) 023:(0.8499) 024:(0.8997) 025:(0.8411) 031:(0.7195) 032:(0.8909) 033:(0.8367) 045:(0.5579) 086:(0.7838) 100:(0.8181) 101:(0.7326) \n",
      "\t\tProto:101 001:(0.7043) 002:(0.6701) 003:(0.8273) 004:(0.9094) 023:(0.4651) 024:(0.6874) 025:(0.5528) 031:(0.6612) 032:(0.7473) 033:(0.635) 045:(0.4022) 086:(0.2747) 100:(0.5481) 101:(0.5222) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 58.38it/s]  \n",
      "Collecting topk: 120it [00:03, 37.26it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 053+050 {0, 2, 3, 5, 7, 8, 9, 11, 12, 13, 14} --------------------\n",
      "-------------------- 053+050 {1, 4, 6, 10, 15} --------------------\n",
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:0 050:(0.9317) 051:(0.96) 053:(0.9976) \n",
      "\t\tProto:2 050:(0.9905) 051:(0.9972) 053:(0.9971) \n",
      "\t\tProto:3 050:(0.9963) 051:(0.9991) 053:(0.9978) \n",
      "\t\tProto:5 050:(0.9998) 051:(1.0) 053:(0.9998) \n",
      "\t\tProto:7 050:(0.9906) 051:(0.9983) 053:(0.9969) \n",
      "\t\tProto:8 050:(0.9989) 051:(0.9992) 053:(0.9992) \n",
      "\t\tProto:9 050:(0.9962) 051:(0.9995) 053:(0.9996) \n",
      "\t\tProto:11 050:(0.9285) 051:(0.9943) 053:(0.9846) \n",
      "\t\tProto:12 050:(0.9918) 051:(0.996) 053:(0.9913) \n",
      "\t\tProto:13 050:(0.8477) 051:(0.9989) 053:(0.9903) \n",
      "\t\tProto:14 050:(0.9984) 051:(0.9985) 053:(0.999) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:04, 95.46it/s]\n",
      "Collecting topk: 420it [00:08, 51.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 004+032 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23} --------------------\n",
      "-------------------- 086+045 {2, 6, 7, 9, 11, 12, 16, 22, 24, 25, 26, 30, 31, 34, 35, 36, 37, 38, 40, 43, 44, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 61, 63, 64, 69, 70, 71} --------------------\n",
      "-------------------- 004+032 {12, 13} --------------------\n",
      "-------------------- 086+045 {0, 1, 3, 4, 5, 8, 10, 13, 14, 15, 17, 18, 19, 20, 21, 23, 27, 28, 29, 32, 33, 39, 41, 42, 45, 47, 49, 52, 59, 60, 62, 65, 66, 67, 68} --------------------\n",
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:0 004:(0.9841) 031:(0.9949) 032:(0.9982) 033:(0.9892) \n",
      "\t\tProto:1 004:(0.949) 031:(0.9637) 032:(0.9717) 033:(0.9761) \n",
      "\t\tProto:2 004:(0.9659) 031:(0.9706) 032:(0.9783) 033:(0.9135) \n",
      "\t\tProto:3 004:(0.8549) 031:(0.9854) 032:(0.953) 033:(0.9788) \n",
      "\t\tProto:4 004:(0.9878) 031:(0.9973) 032:(0.9955) 033:(0.9927) \n",
      "\t\tProto:5 004:(0.7142) 031:(0.8634) 032:(0.9862) 033:(0.9853) \n",
      "\t\tProto:6 004:(0.9489) 031:(0.9913) 032:(0.9847) 033:(0.9621) \n",
      "\t\tProto:7 004:(0.9636) 031:(0.9813) 032:(0.9784) 033:(0.9738) \n",
      "\t\tProto:8 004:(0.9867) 031:(0.9095) 032:(0.9896) 033:(0.9869) \n",
      "\t\tProto:9 004:(0.9895) 031:(0.98) 032:(0.9962) 033:(0.9824) \n",
      "\t\tProto:10 004:(0.9739) 031:(0.9852) 032:(0.9854) 033:(0.9657) \n",
      "\t\tProto:11 004:(0.9644) 031:(0.9476) 032:(0.9733) 033:(0.9033) \n",
      "\t\tProto:14 004:(0.9446) 031:(0.9653) 032:(0.9816) 033:(0.973) \n",
      "\t\tProto:15 004:(0.948) 031:(0.9614) 032:(0.979) 033:(0.9624) \n",
      "\t\tProto:16 004:(0.9794) 031:(0.9891) 032:(0.9639) 033:(0.9685) \n",
      "\t\tProto:17 004:(0.9446) 031:(0.893) 032:(0.814) 033:(0.8303) \n",
      "\t\tProto:18 004:(0.8684) 031:(0.9737) 032:(0.9436) 033:(0.9674) \n",
      "\t\tProto:19 004:(0.9474) 031:(0.9834) 032:(0.9165) 033:(0.9667) \n",
      "\t\tProto:20 004:(0.9051) 031:(0.9782) 032:(0.9766) 033:(0.9706) \n",
      "\t\tProto:21 004:(0.7804) 031:(0.9917) 032:(0.9615) 033:(0.9861) \n",
      "\t\tProto:22 004:(0.9186) 031:(0.9703) 032:(0.9282) 033:(0.9522) \n",
      "\t\tProto:23 004:(0.8618) 031:(0.971) 032:(0.9633) 033:(0.8947) \n",
      "\t Child: 086+045\n",
      "\t\tProto:2 001:(0.8834) 002:(0.8334) 003:(0.9459) 023:(0.8111) 024:(0.6702) 025:(0.7414) 045:(0.8346) 086:(0.8492) 100:(0.8721) 101:(0.9151) \n",
      "\t\tProto:6 001:(0.9046) 002:(0.8861) 003:(0.7518) 023:(0.8619) 024:(0.8547) 025:(0.7379) 045:(0.8705) 086:(0.7815) 100:(0.8024) 101:(0.731) \n",
      "\t\tProto:7 001:(0.9729) 002:(0.5318) 003:(0.7645) 023:(0.8178) 024:(0.8071) 025:(0.7056) 045:(0.7213) 086:(0.6694) 100:(0.7671) 101:(0.7761) \n",
      "\t\tProto:9 001:(0.6874) 002:(0.6428) 003:(0.6281) 023:(0.8619) 024:(0.8299) 025:(0.8288) 045:(0.6843) 086:(0.7643) 100:(0.9787) 101:(0.8927) \n",
      "\t\tProto:11 001:(0.8882) 002:(0.8573) 003:(0.8127) 023:(0.9481) 024:(0.9465) 025:(0.9165) 045:(0.8355) 086:(0.9122) 100:(0.907) 101:(0.7125) \n",
      "\t\tProto:12 001:(0.7184) 002:(0.6511) 003:(0.5097) 023:(0.907) 024:(0.8431) 025:(0.847) 045:(0.5561) 086:(0.7181) 100:(0.735) 101:(0.6357) \n",
      "\t\tProto:16 001:(0.8436) 002:(0.703) 003:(0.7779) 023:(0.8052) 024:(0.8551) 025:(0.8538) 045:(0.8402) 086:(0.64) 100:(0.9023) 101:(0.7151) \n",
      "\t\tProto:22 001:(0.8196) 002:(0.8729) 003:(0.5425) 023:(0.8573) 024:(0.855) 025:(0.8032) 045:(0.7086) 086:(0.8517) 100:(0.9373) 101:(0.9226) \n",
      "\t\tProto:24 001:(0.7668) 002:(0.899) 003:(0.6348) 023:(0.6536) 024:(0.7672) 025:(0.7076) 045:(0.6441) 086:(0.7678) 100:(0.6655) 101:(0.8481) \n",
      "\t\tProto:25 001:(0.8967) 002:(0.499) 003:(0.6926) 023:(0.864) 024:(0.7033) 025:(0.8233) 045:(0.6578) 086:(0.8604) 100:(0.8597) 101:(0.8111) \n",
      "\t\tProto:26 001:(0.9085) 002:(0.8853) 003:(0.8071) 023:(0.9368) 024:(0.9098) 025:(0.8969) 045:(0.7407) 086:(0.901) 100:(0.7762) 101:(0.7743) \n",
      "\t\tProto:30 001:(0.8916) 002:(0.7289) 003:(0.8863) 023:(0.9344) 024:(0.8394) 025:(0.8278) 045:(0.4865) 086:(0.8819) 100:(0.9285) 101:(0.927) \n",
      "\t\tProto:31 001:(0.7641) 002:(0.5143) 003:(0.5729) 023:(0.8806) 024:(0.8471) 025:(0.8357) 045:(0.3875) 086:(0.8622) 100:(0.8856) 101:(0.85) \n",
      "\t\tProto:34 001:(0.93) 002:(0.9146) 003:(0.9365) 023:(0.9211) 024:(0.8238) 025:(0.8997) 045:(0.8925) 086:(0.9443) 100:(0.748) 101:(0.7743) \n",
      "\t\tProto:35 001:(0.9498) 002:(0.8436) 003:(0.7491) 023:(0.8939) 024:(0.8059) 025:(0.672) 045:(0.9007) 086:(0.8438) 100:(0.9301) 101:(0.8638) \n",
      "\t\tProto:36 001:(0.6694) 002:(0.7822) 003:(0.7651) 023:(0.884) 024:(0.7808) 025:(0.8176) 045:(0.5901) 086:(0.82) 100:(0.512) 101:(0.5616) \n",
      "\t\tProto:37 001:(0.8997) 002:(0.7894) 003:(0.7832) 023:(0.922) 024:(0.7714) 025:(0.7119) 045:(0.6382) 086:(0.8836) 100:(0.9349) 101:(0.9724) \n",
      "\t\tProto:38 001:(0.9288) 002:(0.9532) 003:(0.8058) 023:(0.8331) 024:(0.948) 025:(0.9222) 045:(0.8756) 086:(0.8504) 100:(0.8221) 101:(0.8385) \n",
      "\t\tProto:40 001:(0.8091) 002:(0.8334) 003:(0.8656) 023:(0.9164) 024:(0.937) 025:(0.8694) 045:(0.5376) 086:(0.9086) 100:(0.6953) 101:(0.7099) \n",
      "\t\tProto:43 001:(0.8234) 002:(0.756) 003:(0.7523) 023:(0.8741) 024:(0.9131) 025:(0.8889) 045:(0.6099) 086:(0.7858) 100:(0.7264) 101:(0.6265) \n",
      "\t\tProto:44 001:(0.8931) 002:(0.827) 003:(0.837) 023:(0.9281) 024:(0.8082) 025:(0.9332) 045:(0.8593) 086:(0.905) 100:(0.9176) 101:(0.8548) \n",
      "\t\tProto:46 001:(0.8887) 002:(0.8551) 003:(0.7066) 023:(0.8072) 024:(0.8365) 025:(0.6368) 045:(0.6621) 086:(0.8173) 100:(0.7453) 101:(0.7643) \n",
      "\t\tProto:48 001:(0.9364) 002:(0.6703) 003:(0.9308) 023:(0.82) 024:(0.8306) 025:(0.7098) 045:(0.8677) 086:(0.7491) 100:(0.7477) 101:(0.9197) \n",
      "\t\tProto:50 001:(0.9296) 002:(0.852) 003:(0.6872) 023:(0.9469) 024:(0.781) 025:(0.9702) 045:(0.7505) 086:(0.9214) 100:(0.9126) 101:(0.9266) \n",
      "\t\tProto:51 001:(0.9469) 002:(0.9709) 003:(0.9622) 023:(0.9076) 024:(0.9853) 025:(0.9112) 045:(0.9155) 086:(0.9392) 100:(0.9064) 101:(0.9127) \n",
      "\t\tProto:53 001:(0.9368) 002:(0.7285) 003:(0.754) 023:(0.762) 024:(0.7017) 025:(0.5849) 045:(0.7995) 086:(0.7287) 100:(0.474) 101:(0.3978) \n",
      "\t\tProto:54 001:(0.9588) 002:(0.9502) 003:(0.9304) 023:(0.8686) 024:(0.8463) 025:(0.9211) 045:(0.8694) 086:(0.958) 100:(0.7535) 101:(0.7575) \n",
      "\t\tProto:55 001:(0.8353) 002:(0.9057) 003:(0.754) 023:(0.9084) 024:(0.9365) 025:(0.9315) 045:(0.7915) 086:(0.9568) 100:(0.7817) 101:(0.7978) \n",
      "\t\tProto:56 001:(0.9728) 002:(0.9405) 003:(0.918) 023:(0.9004) 024:(0.9657) 025:(0.8631) 045:(0.8963) 086:(0.9285) 100:(0.921) 101:(0.9656) \n",
      "\t\tProto:57 001:(0.6936) 002:(0.7867) 003:(0.6102) 023:(0.8554) 024:(0.7148) 025:(0.8358) 045:(0.5679) 086:(0.747) 100:(0.5541) 101:(0.4966) \n",
      "\t\tProto:58 001:(0.9828) 002:(0.8502) 003:(0.9062) 023:(0.8394) 024:(0.8809) 025:(0.856) 045:(0.8296) 086:(0.9426) 100:(0.9011) 101:(0.8986) \n",
      "\t\tProto:61 001:(0.7344) 002:(0.8253) 003:(0.6346) 023:(0.7406) 024:(0.8804) 025:(0.9182) 045:(0.9022) 086:(0.8115) 100:(0.6802) 101:(0.859) \n",
      "\t\tProto:63 001:(0.9432) 002:(0.8746) 003:(0.9591) 023:(0.8893) 024:(0.8028) 025:(0.8696) 045:(0.7704) 086:(0.8511) 100:(0.7782) 101:(0.7821) \n",
      "\t\tProto:64 001:(0.9638) 002:(0.868) 003:(0.8374) 023:(0.8225) 024:(0.8874) 025:(0.9588) 045:(0.8418) 086:(0.8596) 100:(0.6166) 101:(0.7974) \n",
      "\t\tProto:69 001:(0.8512) 002:(0.8046) 003:(0.8267) 023:(0.8898) 024:(0.8883) 025:(0.9437) 045:(0.5719) 086:(0.719) 100:(0.9081) 101:(0.8377) \n",
      "\t\tProto:70 001:(0.8125) 002:(0.7561) 003:(0.6986) 023:(0.7413) 024:(0.8136) 025:(0.7034) 045:(0.7641) 086:(0.7579) 100:(0.8432) 101:(0.8642) \n",
      "\t\tProto:71 001:(0.9278) 002:(0.6764) 003:(0.9252) 023:(0.9319) 024:(0.8546) 025:(0.9396) 045:(0.9051) 086:(0.9752) 100:(0.9247) 101:(0.7724) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 39.56it/s]   \n",
      "Collecting topk: 90it [00:02, 33.11it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 050+051 {0, 1, 3, 4, 5, 6} --------------------\n",
      "-------------------- 050+051 {2, 7} --------------------\n",
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 050:(0.9999) 051:(1.0) \n",
      "\t\tProto:1 050:(0.9897) 051:(0.9988) \n",
      "\t\tProto:3 050:(0.9983) 051:(0.9988) \n",
      "\t\tProto:4 050:(0.9924) 051:(0.9988) \n",
      "\t\tProto:5 050:(0.9952) 051:(0.9976) \n",
      "\t\tProto:6 050:(0.9833) 051:(0.9965) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 65.77it/s]  \n",
      "Collecting topk: 120it [00:03, 37.52it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 032+033 {1, 2, 3, 6, 7, 8, 9, 10, 11, 13, 14} --------------------\n",
      "-------------------- 032+033 {0, 4, 5, 12, 15} --------------------\n",
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:1 031:(0.988) 032:(0.999) 033:(0.9897) \n",
      "\t\tProto:2 031:(0.9986) 032:(0.9987) 033:(0.9982) \n",
      "\t\tProto:3 031:(0.9991) 032:(0.9997) 033:(0.9992) \n",
      "\t\tProto:6 031:(0.9914) 032:(0.991) 033:(0.9876) \n",
      "\t\tProto:7 031:(0.9987) 032:(0.9991) 033:(0.9952) \n",
      "\t\tProto:8 031:(0.9985) 032:(0.9968) 033:(0.997) \n",
      "\t\tProto:9 031:(0.9995) 032:(0.9979) 033:(0.9998) \n",
      "\t\tProto:10 031:(0.9909) 032:(0.9992) 033:(0.9968) \n",
      "\t\tProto:11 031:(0.9918) 032:(0.9984) 033:(0.9969) \n",
      "\t\tProto:13 031:(0.9977) 032:(0.9863) 033:(0.9927) \n",
      "\t\tProto:14 031:(0.9939) 032:(0.9941) 033:(0.9966) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:02, 143.33it/s] \n",
      "Collecting topk: 300it [00:07, 41.81it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+101 {2, 3, 4, 6, 8, 13, 17, 20, 22, 24, 26, 29, 34, 37, 42, 43, 45, 50, 53, 54, 56, 63} --------------------\n",
      "-------------------- 045+101 {0, 1, 5, 7, 9, 10, 11, 12, 14, 15, 16, 18, 19, 21, 23, 25, 27, 28, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 44, 46, 47, 48, 49, 51, 52, 55, 57, 58, 59, 60, 61, 62} --------------------\n",
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:2 001:(0.9658) 002:(0.9389) 003:(0.8472) 023:(0.8018) 024:(0.9077) 025:(0.8657) 045:(0.7981) 100:(0.9626) 101:(0.8721) \n",
      "\t\tProto:3 001:(0.7435) 002:(0.7024) 003:(0.8855) 023:(0.7871) 024:(0.7925) 025:(0.6878) 045:(0.8692) 100:(0.8743) 101:(0.6966) \n",
      "\t\tProto:4 001:(0.83) 002:(0.753) 003:(0.7434) 023:(0.7803) 024:(0.9008) 025:(0.7476) 045:(0.5834) 100:(0.6956) 101:(0.7774) \n",
      "\t\tProto:6 001:(0.9512) 002:(0.8196) 003:(0.8712) 023:(0.9057) 024:(0.9415) 025:(0.8409) 045:(0.7487) 100:(0.8275) 101:(0.9062) \n",
      "\t\tProto:8 001:(0.8278) 002:(0.9337) 003:(0.8991) 023:(0.8894) 024:(0.8302) 025:(0.8951) 045:(0.9156) 100:(0.8955) 101:(0.8691) \n",
      "\t\tProto:13 001:(0.9037) 002:(0.8122) 003:(0.8249) 023:(0.4949) 024:(0.7512) 025:(0.7622) 045:(0.7052) 100:(0.8028) 101:(0.6964) \n",
      "\t\tProto:17 001:(0.9289) 002:(0.8254) 003:(0.8581) 023:(0.9728) 024:(0.9693) 025:(0.8613) 045:(0.863) 100:(0.9149) 101:(0.8105) \n",
      "\t\tProto:20 001:(0.844) 002:(0.8892) 003:(0.9575) 023:(0.9411) 024:(0.9477) 025:(0.8802) 045:(0.8941) 100:(0.8894) 101:(0.8863) \n",
      "\t\tProto:22 001:(0.9627) 002:(0.9602) 003:(0.9271) 023:(0.8329) 024:(0.5838) 025:(0.5113) 045:(0.8572) 100:(0.8051) 101:(0.9633) \n",
      "\t\tProto:24 001:(0.9574) 002:(0.8321) 003:(0.8932) 023:(0.8935) 024:(0.9605) 025:(0.8687) 045:(0.6752) 100:(0.945) 101:(0.9288) \n",
      "\t\tProto:26 001:(0.9367) 002:(0.9063) 003:(0.7287) 023:(0.8775) 024:(0.8235) 025:(0.8213) 045:(0.7736) 100:(0.9386) 101:(0.8755) \n",
      "\t\tProto:29 001:(0.7968) 002:(0.6836) 003:(0.8516) 023:(0.9523) 024:(0.8505) 025:(0.7976) 045:(0.6451) 100:(0.9695) 101:(0.7674) \n",
      "\t\tProto:34 001:(0.8674) 002:(0.9159) 003:(0.9093) 023:(0.8763) 024:(0.9725) 025:(0.9903) 045:(0.8756) 100:(0.9634) 101:(0.7788) \n",
      "\t\tProto:37 001:(0.8432) 002:(0.8792) 003:(0.9604) 023:(0.94) 024:(0.9662) 025:(0.943) 045:(0.9305) 100:(0.9435) 101:(0.869) \n",
      "\t\tProto:42 001:(0.6762) 002:(0.7757) 003:(0.8688) 023:(0.8821) 024:(0.8686) 025:(0.9518) 045:(0.8257) 100:(0.9278) 101:(0.8732) \n",
      "\t\tProto:43 001:(0.9767) 002:(0.9654) 003:(0.8995) 023:(0.8148) 024:(0.8121) 025:(0.8177) 045:(0.8896) 100:(0.7358) 101:(0.9098) \n",
      "\t\tProto:45 001:(0.9221) 002:(0.8304) 003:(0.909) 023:(0.7485) 024:(0.8498) 025:(0.818) 045:(0.9311) 100:(0.9839) 101:(0.857) \n",
      "\t\tProto:50 001:(0.9717) 002:(0.9756) 003:(0.9597) 023:(0.9324) 024:(0.8114) 025:(0.8483) 045:(0.8497) 100:(0.8368) 101:(0.9549) \n",
      "\t\tProto:53 001:(0.9871) 002:(0.9094) 003:(0.9035) 023:(0.9235) 024:(0.9898) 025:(0.9221) 045:(0.8647) 100:(0.9229) 101:(0.8216) \n",
      "\t\tProto:54 001:(0.8693) 002:(0.9532) 003:(0.9518) 023:(0.8141) 024:(0.9273) 025:(0.9111) 045:(0.9259) 100:(0.8762) 101:(0.9368) \n",
      "\t\tProto:56 001:(0.8811) 002:(0.7562) 003:(0.6847) 023:(0.9052) 024:(0.9718) 025:(0.8246) 045:(0.6841) 100:(0.9956) 101:(0.962) \n",
      "\t\tProto:63 001:(0.9011) 002:(0.8427) 003:(0.6315) 023:(0.951) 024:(0.937) 025:(0.8791) 045:(0.5859) 100:(0.738) 101:(0.8128) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 43.92it/s]   \n",
      "Collecting topk: 90it [00:02, 32.58it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 033+031 {0, 1, 3, 4, 5, 7} --------------------\n",
      "-------------------- 033+031 {2, 6} --------------------\n",
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(0.9998) 033:(0.9989) \n",
      "\t\tProto:1 031:(1.0) 033:(0.9987) \n",
      "\t\tProto:3 031:(0.9993) 033:(0.999) \n",
      "\t\tProto:4 031:(1.0) 033:(0.9998) \n",
      "\t\tProto:5 031:(1.0) 033:(1.0) \n",
      "\t\tProto:7 031:(0.9998) 033:(0.9996) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 64.10it/s]\n",
      "Collecting topk: 270it [00:04, 56.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+003 {1, 2, 4, 5, 6, 7, 8, 9, 11, 14, 15, 16, 17, 18, 19, 20, 22} --------------------\n",
      "-------------------- 101+023 {2, 3, 4, 8, 9, 11, 12, 14, 16, 17, 18, 19, 20, 23, 24, 25, 27, 28, 29, 31} --------------------\n",
      "-------------------- 045+003 {0, 3, 10, 12, 13, 21, 23} --------------------\n",
      "-------------------- 101+023 {0, 1, 5, 6, 7, 10, 13, 15, 21, 22, 26, 30} --------------------\n",
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:1 001:(0.9964) 002:(0.9816) 003:(0.9944) 045:(0.9844) \n",
      "\t\tProto:2 001:(0.945) 002:(0.8971) 003:(0.803) 045:(0.9168) \n",
      "\t\tProto:4 001:(0.9402) 002:(0.9838) 003:(0.9839) 045:(0.9653) \n",
      "\t\tProto:5 001:(0.998) 002:(0.9946) 003:(0.9872) 045:(0.9964) \n",
      "\t\tProto:6 001:(0.9908) 002:(0.9736) 003:(0.9878) 045:(0.92) \n",
      "\t\tProto:7 001:(0.9927) 002:(0.9549) 003:(0.978) 045:(0.972) \n",
      "\t\tProto:8 001:(0.9923) 002:(0.9872) 003:(0.9507) 045:(0.9735) \n",
      "\t\tProto:9 001:(0.9951) 002:(0.9578) 003:(0.9782) 045:(0.9871) \n",
      "\t\tProto:11 001:(0.9893) 002:(0.9915) 003:(0.9983) 045:(0.9683) \n",
      "\t\tProto:14 001:(0.9841) 002:(0.9901) 003:(0.9935) 045:(0.9763) \n",
      "\t\tProto:15 001:(0.9838) 002:(0.9835) 003:(0.9898) 045:(0.9796) \n",
      "\t\tProto:16 001:(0.9718) 002:(0.9559) 003:(0.9596) 045:(0.9543) \n",
      "\t\tProto:17 001:(0.9803) 002:(0.9606) 003:(0.9897) 045:(0.9552) \n",
      "\t\tProto:18 001:(0.9791) 002:(0.9854) 003:(0.9363) 045:(0.9516) \n",
      "\t\tProto:19 001:(0.9845) 002:(0.9865) 003:(0.9992) 045:(0.9739) \n",
      "\t\tProto:20 001:(0.9844) 002:(0.974) 003:(0.997) 045:(0.9879) \n",
      "\t\tProto:22 001:(0.9726) 002:(0.9715) 003:(0.9662) 045:(0.9617) \n",
      "\t Child: 101+023\n",
      "\t\tProto:2 023:(0.9667) 024:(0.981) 025:(0.9858) 100:(0.9749) 101:(0.9924) \n",
      "\t\tProto:3 023:(0.996) 024:(0.997) 025:(0.995) 100:(0.9809) 101:(0.9903) \n",
      "\t\tProto:4 023:(0.978) 024:(0.9952) 025:(0.9775) 100:(0.9722) 101:(0.9388) \n",
      "\t\tProto:8 023:(0.9342) 024:(0.9798) 025:(0.8487) 100:(0.9574) 101:(0.7747) \n",
      "\t\tProto:9 023:(0.9501) 024:(0.945) 025:(0.9701) 100:(0.9072) 101:(0.9807) \n",
      "\t\tProto:11 023:(0.98) 024:(0.9841) 025:(0.9891) 100:(0.942) 101:(0.9846) \n",
      "\t\tProto:12 023:(0.938) 024:(0.976) 025:(0.853) 100:(0.9837) 101:(0.9885) \n",
      "\t\tProto:14 023:(0.9523) 024:(0.934) 025:(0.9606) 100:(0.9878) 101:(0.9937) \n",
      "\t\tProto:16 023:(0.9667) 024:(0.9988) 025:(0.9616) 100:(0.9864) 101:(0.9891) \n",
      "\t\tProto:17 023:(0.9786) 024:(0.9898) 025:(0.9696) 100:(0.9869) 101:(0.9784) \n",
      "\t\tProto:18 023:(0.9801) 024:(0.9644) 025:(0.7722) 100:(0.9885) 101:(0.9435) \n",
      "\t\tProto:19 023:(0.9038) 024:(0.9619) 025:(0.9488) 100:(0.9754) 101:(0.9868) \n",
      "\t\tProto:20 023:(0.9903) 024:(0.99) 025:(0.9737) 100:(0.9082) 101:(0.9486) \n",
      "\t\tProto:23 023:(0.9716) 024:(0.9844) 025:(0.9843) 100:(0.9808) 101:(0.9479) \n",
      "\t\tProto:24 023:(0.9656) 024:(0.9938) 025:(0.9902) 100:(0.9738) 101:(0.9905) \n",
      "\t\tProto:25 023:(0.9775) 024:(0.9686) 025:(0.9706) 100:(0.9854) 101:(0.9846) \n",
      "\t\tProto:27 023:(0.9647) 024:(0.9861) 025:(0.8825) 100:(0.8538) 101:(0.9544) \n",
      "\t\tProto:28 023:(0.9854) 024:(0.9962) 025:(0.9901) 100:(0.9363) 101:(0.9871) \n",
      "\t\tProto:29 023:(0.879) 024:(0.988) 025:(0.9424) 100:(0.9692) 101:(0.9855) \n",
      "\t\tProto:31 023:(0.9815) 024:(0.9941) 025:(0.9874) 100:(0.9197) 101:(0.9558) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 61.69it/s]  \n",
      "Collecting topk: 120it [00:03, 38.77it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 003+002 {0, 1, 4, 5, 6, 8, 10, 13, 14, 15} --------------------\n",
      "-------------------- 003+002 {2, 3, 7, 9, 11, 12} --------------------\n",
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:0 001:(0.9983) 002:(0.9998) 003:(0.9998) \n",
      "\t\tProto:1 001:(0.9994) 002:(0.9894) 003:(0.98) \n",
      "\t\tProto:4 001:(0.999) 002:(0.9937) 003:(0.9973) \n",
      "\t\tProto:5 001:(0.9987) 002:(0.997) 003:(0.9976) \n",
      "\t\tProto:6 001:(0.9983) 002:(0.9987) 003:(0.9982) \n",
      "\t\tProto:8 001:(0.9742) 002:(0.9449) 003:(0.9817) \n",
      "\t\tProto:10 001:(0.9991) 002:(0.9992) 003:(0.9966) \n",
      "\t\tProto:13 001:(0.9986) 002:(0.9976) 003:(0.999) \n",
      "\t\tProto:14 001:(0.9992) 002:(0.9985) 003:(0.9984) \n",
      "\t\tProto:15 001:(0.9975) 002:(0.9973) 003:(0.9991) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:02, 51.26it/s]\n",
      "Collecting topk: 150it [00:03, 47.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 101+100 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 023+025 {0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "-------------------- 023+025 {12, 5, 6} --------------------\n",
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 100:(0.9999) 101:(0.9999) \n",
      "\t\tProto:1 100:(1.0) 101:(0.9998) \n",
      "\t\tProto:2 100:(0.9998) 101:(0.9998) \n",
      "\t\tProto:3 100:(0.9997) 101:(0.9944) \n",
      "\t\tProto:4 100:(0.9998) 101:(1.0) \n",
      "\t\tProto:5 100:(0.9996) 101:(0.9996) \n",
      "\t\tProto:6 100:(0.9998) 101:(0.9997) \n",
      "\t\tProto:7 100:(1.0) 101:(1.0) \n",
      "\t Child: 023+025\n",
      "\t\tProto:0 023:(0.9989) 024:(0.9997) 025:(0.9989) \n",
      "\t\tProto:1 023:(0.9938) 024:(0.9995) 025:(0.9939) \n",
      "\t\tProto:2 023:(0.9979) 024:(0.9992) 025:(0.9972) \n",
      "\t\tProto:3 023:(0.9977) 024:(0.9974) 025:(0.9966) \n",
      "\t\tProto:4 023:(0.9966) 024:(0.9954) 025:(0.9959) \n",
      "\t\tProto:7 023:(0.9999) 024:(0.9996) 025:(1.0) \n",
      "\t\tProto:8 023:(0.9895) 024:(0.999) 025:(0.9942) \n",
      "\t\tProto:9 023:(0.9989) 024:(0.9995) 025:(0.9992) \n",
      "\t\tProto:10 023:(0.9997) 024:(0.9991) 025:(0.9996) \n",
      "\t\tProto:11 023:(0.9917) 024:(0.99) 025:(0.996) \n",
      "\t\tProto:13 023:(0.9996) 024:(1.0) 025:(0.9999) \n",
      "\t\tProto:14 023:(0.9968) 024:(0.9921) 025:(0.9945) \n",
      "\t\tProto:15 023:(0.9993) 024:(0.9979) 025:(0.9993) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 43.53it/s]   \n",
      "Collecting topk: 90it [00:02, 33.87it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 002+001 {0, 1, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 002+001 {2} --------------------\n",
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 001:(0.9986) 002:(0.9989) \n",
      "\t\tProto:1 001:(0.9999) 002:(0.9995) \n",
      "\t\tProto:3 001:(1.0) 002:(0.9999) \n",
      "\t\tProto:4 001:(0.9999) 002:(0.9997) \n",
      "\t\tProto:5 001:(0.9995) 002:(1.0) \n",
      "\t\tProto:6 001:(0.9999) 002:(0.9997) \n",
      "\t\tProto:7 001:(1.0) 002:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 49.85it/s]   \n",
      "Collecting topk: 90it [00:02, 33.62it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 025+024 {1, 2, 3, 6, 7} --------------------\n",
      "-------------------- 025+024 {0, 4, 5} --------------------\n",
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:1 024:(1.0) 025:(1.0) \n",
      "\t\tProto:2 024:(0.9998) 025:(0.9917) \n",
      "\t\tProto:3 024:(1.0) 025:(0.9991) \n",
      "\t\tProto:6 024:(1.0) 025:(0.9965) \n",
      "\t\tProto:7 024:(1.0) 025:(0.9989) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "# overlayed_image_np = get_heatmap(latent_activation, xs)\n",
    "# Image.fromarray(overlayed_image_np).show()\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            if coarse_label2name[ys.item()] != child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written\n",
    "                    if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                        continue\n",
    "                        \n",
    "                    h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes_of_child_node.shape, patchsize, skip, h_idx, w_idx)\n",
    "                    latent_activation = softmaxes_of_child_node[:, p, :, :]\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) > topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                         (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "#                         bbox_coords = torch.tensor([[w_coor_min, h_coor_min, w_coor_max, h_coor_max]])\n",
    "#                         bb_image = torchvision.utils.draw_bounding_boxes((img_tensor * 255).type(torch.uint8), bbox_coords, colors='red') / 255\n",
    "#                         pdb.set_trace()\n",
    "                        patches.append(overlayed_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_heatmap_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_heatmap_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on NON leaf descendents - topk images after using TANH-DESC with HEAT MAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:09, 54.53it/s]\n",
      "Collecting topk: 540it [00:05, 102.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 052+053 {0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23} --------------------\n",
      "-------------------- 004+086 {0, 1, 3, 4, 6, 7, 9, 11, 12, 13, 15, 16, 17, 18, 20, 21, 26, 28, 31, 32, 37, 38, 39, 43, 45, 46, 48, 49, 52, 53, 60, 63, 64, 65, 67, 72, 73, 74, 78, 80, 81, 83, 84, 86, 90, 93, 95, 96, 97, 98, 101} --------------------\n",
      "-------------------- 052+053 {8} --------------------\n",
      "-------------------- 004+086 {2, 5, 8, 10, 14, 19, 22, 23, 24, 25, 27, 29, 30, 33, 34, 35, 36, 40, 41, 42, 44, 47, 50, 51, 54, 55, 56, 57, 58, 59, 61, 62, 66, 68, 69, 70, 71, 75, 76, 77, 79, 82, 85, 87, 88, 89, 91, 92, 94, 99, 100, 102, 103} --------------------\n",
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:0 001:(0.0008) 002:(0.0001) 003:(0.0012) 004:(0.0004) 023:(0.011) 024:(0.005) 025:(0.002) 031:(0.0006) 032:(0.0004) 033:(0.0001) 045:(0.0004) 086:(0.0068) 100:(0.0103) 101:(0.0023) \n",
      "\t\tProto:1 001:(0.017) 002:(0.003) 003:(0.0029) 004:(0.0002) 023:(0.1087) 024:(0.0064) 025:(0.0038) 031:(0.0018) 032:(0.0018) 033:(0.0005) 045:(0.0006) 086:(0.0056) 100:(0.0098) 101:(0.0034) \n",
      "\t\tProto:2 001:(0.0003) 002:(0.0004) 003:(0.0158) 004:(0.0003) 023:(0.01) 024:(0.0053) 025:(0.1406) 031:(0.0043) 032:(0.0118) 033:(0.0115) 045:(0.0003) 086:(0.0071) 100:(0.0001) 101:(0.0038) \n",
      "\t\tProto:3 001:(0.0126) 002:(0.0014) 003:(0.0316) 004:(0.0341) 023:(0.0378) 024:(0.0108) 025:(0.0504) 031:(0.0106) 032:(0.129) 033:(0.0191) 045:(0.0053) 086:(0.0081) 100:(0.0134) 101:(0.0434) \n",
      "\t\tProto:4 001:(0.1057) 002:(0.0004) 003:(0.0006) 004:(0.0001) 023:(0.1186) 024:(0.1108) 025:(0.0801) 031:(0.0002) 032:(0.0011) 033:(0.0001) 045:(0.0006) 086:(0.1188) 100:(0.2324) 101:(0.0013) \n",
      "\t\tProto:5 001:(0.0008) 002:(0.0001) 003:(0.001) 004:(0.0001) 023:(0.0024) 024:(0.0013) 025:(0.0107) 031:(0.0002) 032:(0.0032) 033:(0.0008) 045:(0.0002) 086:(0.0525) 100:(0.0007) 101:(0.0049) \n",
      "\t\tProto:6 001:(0.0032) 002:(0.0005) 003:(0.0024) 004:(0.0049) 023:(0.0589) 024:(0.0003) 025:(0.0081) 031:(0.015) 032:(0.1067) 033:(0.0035) 045:(0.0472) 086:(0.0232) 100:(0.0455) 101:(0.0069) \n",
      "\t\tProto:7 001:(0.2261) 002:(0.0093) 003:(0.006) 004:(0.0001) 023:(0.1386) 024:(0.0629) 025:(0.1629) 031:(0.0002) 032:(0.0004) 033:(0.0002) 045:(0.0002) 086:(0.1571) 100:(0.1743) 101:(0.0244) \n",
      "\t\tProto:9 001:(0.008) 002:(0.002) 003:(0.0205) 004:(0.0019) 023:(0.0729) 024:(0.0217) 025:(0.0235) 031:(0.0763) 032:(0.0118) 033:(0.0057) 045:(0.0015) 086:(0.0097) 100:(0.0044) 101:(0.0086) \n",
      "\t\tProto:10 001:(0.1103) 002:(0.0189) 003:(0.0713) 004:(0.0058) 023:(0.0192) 024:(0.0112) 025:(0.0264) 031:(0.1211) 032:(0.0552) 033:(0.1238) 045:(0.0111) 086:(0.1037) 100:(0.1196) 101:(0.0948) \n",
      "\t\tProto:11 001:(0.0097) 002:(0.0008) 003:(0.001) 004:(0.0005) 023:(0.0303) 024:(0.0074) 025:(0.0004) 031:(0.0003) 032:(0.001) 033:(0.0002) 045:(0.0001) 086:(0.0086) 100:(0.0233) 101:(0.0005) \n",
      "\t\tProto:12 001:(0.0001) 002:(0.0) 003:(0.0004) 004:(0.0001) 023:(0.0057) 024:(0.0224) 025:(0.0207) 031:(0.0008) 032:(0.0097) 033:(0.0087) 045:(0.0002) 086:(0.0403) 100:(0.0002) 101:(0.0007) \n",
      "\t\tProto:13 001:(0.0015) 002:(0.0001) 003:(0.0007) 004:(0.0004) 023:(0.0464) 024:(0.0119) 025:(0.0098) 031:(0.0318) 032:(0.0183) 033:(0.0479) 045:(0.0007) 086:(0.0272) 100:(0.0009) 101:(0.0035) \n",
      "\t\tProto:14 001:(0.0147) 002:(0.0027) 003:(0.0029) 004:(0.0016) 023:(0.0636) 024:(0.0036) 025:(0.0242) 031:(0.0036) 032:(0.0104) 033:(0.0049) 045:(0.0039) 086:(0.0103) 100:(0.0015) 101:(0.0073) \n",
      "\t\tProto:15 001:(0.0022) 002:(0.0001) 003:(0.0003) 004:(0.0) 023:(0.0034) 024:(0.0002) 025:(0.0003) 031:(0.0663) 032:(0.0057) 033:(0.0094) 045:(0.0) 086:(0.0192) 100:(0.0009) 101:(0.0007) \n",
      "\t\tProto:16 001:(0.1659) 002:(0.2616) 003:(0.1253) 004:(0.0188) 023:(0.0164) 024:(0.1545) 025:(0.11) 031:(0.0658) 032:(0.0786) 033:(0.0317) 045:(0.0977) 086:(0.3371) 100:(0.2072) 101:(0.2284) \n",
      "\t\tProto:17 001:(0.0018) 002:(0.0004) 003:(0.0007) 004:(0.0011) 023:(0.1164) 024:(0.0185) 025:(0.0259) 031:(0.044) 032:(0.0038) 033:(0.0123) 045:(0.0001) 086:(0.1072) 100:(0.047) 101:(0.0149) \n",
      "\t\tProto:18 001:(0.0012) 002:(0.0005) 003:(0.004) 004:(0.001) 023:(0.0764) 024:(0.0021) 025:(0.0002) 031:(0.013) 032:(0.0014) 033:(0.0006) 045:(0.0001) 086:(0.047) 100:(0.0125) 101:(0.0007) \n",
      "\t\tProto:19 001:(0.0138) 002:(0.0016) 003:(0.0132) 004:(0.0094) 023:(0.0161) 024:(0.001) 025:(0.0234) 031:(0.1379) 032:(0.0342) 033:(0.0181) 045:(0.0006) 086:(0.0772) 100:(0.0141) 101:(0.1082) \n",
      "\t\tProto:20 001:(0.1356) 002:(0.0019) 003:(0.002) 004:(0.0007) 023:(0.3155) 024:(0.0953) 025:(0.254) 031:(0.0005) 032:(0.0008) 033:(0.0002) 045:(0.0107) 086:(0.3476) 100:(0.1357) 101:(0.0442) \n",
      "\t\tProto:21 001:(0.0087) 002:(0.0077) 003:(0.0058) 004:(0.002) 023:(0.1091) 024:(0.0154) 025:(0.1159) 031:(0.0062) 032:(0.0692) 033:(0.0408) 045:(0.0036) 086:(0.0225) 100:(0.0056) 101:(0.099) \n",
      "\t\tProto:22 001:(0.0072) 002:(0.0002) 003:(0.0021) 004:(0.0009) 023:(0.036) 024:(0.0039) 025:(0.0061) 031:(0.0156) 032:(0.0106) 033:(0.0696) 045:(0.0002) 086:(0.068) 100:(0.0076) 101:(0.0213) \n",
      "\t\tProto:23 001:(0.0022) 002:(0.0002) 003:(0.0019) 004:(0.0) 023:(0.0047) 024:(0.0002) 025:(0.0002) 031:(0.0173) 032:(0.0103) 033:(0.0006) 045:(0.0006) 086:(0.1409) 100:(0.0008) 101:(0.0002) \n",
      "\t Child: 004+086\n",
      "\t\tProto:0 050:(0.4808) 051:(0.1694) 052:(0.391) 053:(0.4537) \n",
      "\t\tProto:1 050:(0.25) 051:(0.2422) 052:(0.1571) 053:(0.3801) \n",
      "\t\tProto:3 050:(0.5727) 051:(0.53) 052:(0.4557) 053:(0.2971) \n",
      "\t\tProto:4 050:(0.5889) 051:(0.5205) 052:(0.4978) 053:(0.3867) \n",
      "\t\tProto:6 050:(0.133) 051:(0.076) 052:(0.1006) 053:(0.1005) \n",
      "\t\tProto:7 050:(0.0978) 051:(0.021) 052:(0.0283) 053:(0.0883) \n",
      "\t\tProto:9 050:(0.3093) 051:(0.3022) 052:(0.3258) 053:(0.1206) \n",
      "\t\tProto:11 050:(0.0211) 051:(0.0236) 052:(0.0219) 053:(0.0633) \n",
      "\t\tProto:12 050:(0.0858) 051:(0.0682) 052:(0.1382) 053:(0.1797) \n",
      "\t\tProto:13 050:(0.0964) 051:(0.247) 052:(0.1689) 053:(0.2034) \n",
      "\t\tProto:15 050:(0.1152) 051:(0.2426) 052:(0.2657) 053:(0.0703) \n",
      "\t\tProto:16 050:(0.3368) 051:(0.1662) 052:(0.3362) 053:(0.4819) \n",
      "\t\tProto:17 050:(0.887) 051:(0.9214) 052:(0.7895) 053:(0.6952) \n",
      "\t\tProto:18 050:(0.0547) 051:(0.028) 052:(0.0211) 053:(0.0521) \n",
      "\t\tProto:20 050:(0.4617) 051:(0.3854) 052:(0.6101) 053:(0.444) \n",
      "\t\tProto:21 050:(0.2253) 051:(0.3389) 052:(0.569) 053:(0.4001) \n",
      "\t\tProto:26 050:(0.254) 051:(0.3405) 052:(0.4603) 053:(0.1875) \n",
      "\t\tProto:28 050:(0.1624) 051:(0.0872) 052:(0.1326) 053:(0.0523) \n",
      "\t\tProto:31 050:(0.2565) 051:(0.405) 052:(0.3534) 053:(0.7245) \n",
      "\t\tProto:32 050:(0.8926) 051:(0.8269) 052:(0.8906) 053:(0.6352) \n",
      "\t\tProto:37 050:(0.3809) 051:(0.3299) 052:(0.447) 053:(0.2573) \n",
      "\t\tProto:38 050:(0.2649) 051:(0.4088) 052:(0.4367) 053:(0.351) \n",
      "\t\tProto:39 050:(0.5091) 051:(0.3377) 052:(0.4537) 053:(0.455) \n",
      "\t\tProto:43 050:(0.1729) 051:(0.3132) 052:(0.3546) 053:(0.2465) \n",
      "\t\tProto:45 050:(0.1839) 051:(0.2981) 052:(0.1959) 053:(0.6021) \n",
      "\t\tProto:46 050:(0.6962) 051:(0.6889) 052:(0.6146) 053:(0.4678) \n",
      "\t\tProto:48 050:(0.3735) 051:(0.3644) 052:(0.5723) 053:(0.4443) \n",
      "\t\tProto:49 050:(0.3144) 051:(0.4038) 052:(0.3956) 053:(0.2118) \n",
      "\t\tProto:52 050:(0.1605) 051:(0.1949) 052:(0.0691) 053:(0.22) \n",
      "\t\tProto:53 050:(0.0036) 051:(0.0067) 052:(0.12) 053:(0.0115) \n",
      "\t\tProto:60 050:(0.1547) 051:(0.1998) 052:(0.2489) 053:(0.1004) \n",
      "\t\tProto:63 050:(0.3626) 051:(0.282) 052:(0.3582) 053:(0.3468) \n",
      "\t\tProto:64 050:(0.176) 051:(0.2997) 052:(0.5771) 053:(0.4749) \n",
      "\t\tProto:65 050:(0.8549) 051:(0.7724) 052:(0.8714) 053:(0.6435) \n",
      "\t\tProto:67 050:(0.0376) 051:(0.0473) 052:(0.101) 053:(0.1738) \n",
      "\t\tProto:72 050:(0.284) 051:(0.3297) 052:(0.6038) 053:(0.4945) \n",
      "\t\tProto:73 050:(0.7659) 051:(0.5137) 052:(0.4228) 053:(0.6928) \n",
      "\t\tProto:74 050:(0.4467) 051:(0.1952) 052:(0.4307) 053:(0.0789) \n",
      "\t\tProto:78 050:(0.1155) 051:(0.02) 052:(0.115) 053:(0.236) \n",
      "\t\tProto:80 050:(0.139) 051:(0.0678) 052:(0.4159) 053:(0.1381) \n",
      "\t\tProto:81 050:(0.324) 051:(0.4193) 052:(0.4412) 053:(0.6294) \n",
      "\t\tProto:83 050:(0.3394) 051:(0.4566) 052:(0.3089) 053:(0.4803) \n",
      "\t\tProto:84 050:(0.222) 051:(0.1614) 052:(0.1438) 053:(0.1494) \n",
      "\t\tProto:86 050:(0.4852) 051:(0.5542) 052:(0.4133) 053:(0.629) \n",
      "\t\tProto:90 050:(0.3083) 051:(0.1876) 052:(0.4174) 053:(0.2574) \n",
      "\t\tProto:93 050:(0.3041) 051:(0.2848) 052:(0.1563) 053:(0.4699) \n",
      "\t\tProto:95 050:(0.2734) 051:(0.0966) 052:(0.0906) 053:(0.0947) \n",
      "\t\tProto:96 050:(0.3846) 051:(0.1258) 052:(0.5837) 053:(0.1084) \n",
      "\t\tProto:97 050:(0.0943) 051:(0.0354) 052:(0.1122) 053:(0.1628) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tProto:98 050:(0.6511) 051:(0.3134) 052:(0.5506) 053:(0.4602) \n",
      "\t\tProto:101 050:(0.0284) 051:(0.0581) 052:(0.163) 053:(0.1168) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 35.57it/s]  \n",
      "Collecting topk: 120it [00:01, 68.58it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:06, 60.56it/s]\n",
      "Collecting topk: 420it [00:04, 92.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 004+032 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23} --------------------\n",
      "-------------------- 086+045 {2, 6, 7, 9, 11, 12, 16, 22, 24, 25, 26, 30, 31, 34, 35, 36, 37, 38, 40, 43, 44, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 61, 63, 64, 69, 70, 71} --------------------\n",
      "-------------------- 004+032 {12, 13} --------------------\n",
      "-------------------- 086+045 {0, 1, 3, 4, 5, 8, 10, 13, 14, 15, 17, 18, 19, 20, 21, 23, 27, 28, 29, 32, 33, 39, 41, 42, 45, 47, 49, 52, 59, 60, 62, 65, 66, 67, 68} --------------------\n",
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:0 001:(0.0715) 002:(0.0398) 003:(0.042) 023:(0.0013) 024:(0.0008) 025:(0.0146) 045:(0.0008) 086:(0.0721) 100:(0.0132) 101:(0.0028) \n",
      "\t\tProto:1 001:(0.0008) 002:(0.0004) 003:(0.0003) 023:(0.0005) 024:(0.0005) 025:(0.0001) 045:(0.0002) 086:(0.0136) 100:(0.0001) 101:(0.004) \n",
      "\t\tProto:2 001:(0.0251) 002:(0.0053) 003:(0.0048) 023:(0.0005) 024:(0.0008) 025:(0.0242) 045:(0.0009) 086:(0.0725) 100:(0.0005) 101:(0.0009) \n",
      "\t\tProto:3 001:(0.0501) 002:(0.0312) 003:(0.0098) 023:(0.0208) 024:(0.0045) 025:(0.0733) 045:(0.0014) 086:(0.0044) 100:(0.002) 101:(0.0026) \n",
      "\t\tProto:4 001:(0.1303) 002:(0.0021) 003:(0.0031) 023:(0.0205) 024:(0.0105) 025:(0.0972) 045:(0.0191) 086:(0.059) 100:(0.0049) 101:(0.02) \n",
      "\t\tProto:5 001:(0.0143) 002:(0.0024) 003:(0.0904) 023:(0.0148) 024:(0.0158) 025:(0.0524) 045:(0.003) 086:(0.0083) 100:(0.0018) 101:(0.0136) \n",
      "\t\tProto:6 001:(0.0014) 002:(0.0001) 003:(0.0012) 023:(0.0045) 024:(0.0007) 025:(0.0001) 045:(0.0088) 086:(0.0026) 100:(0.0001) 101:(0.0426) \n",
      "\t\tProto:7 001:(0.0013) 002:(0.0003) 003:(0.0024) 023:(0.0003) 024:(0.0002) 025:(0.0002) 045:(0.0004) 086:(0.0152) 100:(0.0001) 101:(0.0183) \n",
      "\t\tProto:8 001:(0.0048) 002:(0.0004) 003:(0.0219) 023:(0.0002) 024:(0.0014) 025:(0.0047) 045:(0.0018) 086:(0.0018) 100:(0.0014) 101:(0.0213) \n",
      "\t\tProto:9 001:(0.0088) 002:(0.0038) 003:(0.0027) 023:(0.0148) 024:(0.0058) 025:(0.0237) 045:(0.0006) 086:(0.0248) 100:(0.0054) 101:(0.0014) \n",
      "\t\tProto:10 001:(0.0051) 002:(0.0001) 003:(0.0027) 023:(0.0062) 024:(0.0091) 025:(0.0584) 045:(0.0014) 086:(0.0407) 100:(0.0002) 101:(0.0146) \n",
      "\t\tProto:11 001:(0.0054) 002:(0.0003) 003:(0.0001) 023:(0.002) 024:(0.0) 025:(0.0013) 045:(0.0004) 086:(0.0217) 100:(0.0003) 101:(0.0004) \n",
      "\t\tProto:14 001:(0.0728) 002:(0.0006) 003:(0.0008) 023:(0.007) 024:(0.0083) 025:(0.0024) 045:(0.0007) 086:(0.0266) 100:(0.0009) 101:(0.006) \n",
      "\t\tProto:15 001:(0.005) 002:(0.1339) 003:(0.0201) 023:(0.1134) 024:(0.0867) 025:(0.0434) 045:(0.0231) 086:(0.0027) 100:(0.0798) 101:(0.1476) \n",
      "\t\tProto:16 001:(0.1203) 002:(0.0012) 003:(0.0109) 023:(0.0047) 024:(0.012) 025:(0.1332) 045:(0.0894) 086:(0.0827) 100:(0.002) 101:(0.0482) \n",
      "\t\tProto:17 001:(0.1716) 002:(0.2012) 003:(0.1143) 023:(0.1366) 024:(0.0975) 025:(0.2694) 045:(0.0343) 086:(0.0077) 100:(0.1453) 101:(0.1215) \n",
      "\t\tProto:18 001:(0.0315) 002:(0.0214) 003:(0.0476) 023:(0.0259) 024:(0.0482) 025:(0.0241) 045:(0.0227) 086:(0.0204) 100:(0.0921) 101:(0.1188) \n",
      "\t\tProto:19 001:(0.0019) 002:(0.0001) 003:(0.0018) 023:(0.0094) 024:(0.0005) 025:(0.0055) 045:(0.0009) 086:(0.0143) 100:(0.0011) 101:(0.0026) \n",
      "\t\tProto:20 001:(0.0271) 002:(0.0144) 003:(0.0007) 023:(0.0001) 024:(0.0) 025:(0.0003) 045:(0.0001) 086:(0.0452) 100:(0.0) 101:(0.0005) \n",
      "\t\tProto:21 001:(0.082) 002:(0.0015) 003:(0.002) 023:(0.0002) 024:(0.0001) 025:(0.0242) 045:(0.002) 086:(0.0053) 100:(0.0006) 101:(0.0024) \n",
      "\t\tProto:22 001:(0.0919) 002:(0.0469) 003:(0.179) 023:(0.0897) 024:(0.3548) 025:(0.3104) 045:(0.0063) 086:(0.0336) 100:(0.5467) 101:(0.102) \n",
      "\t\tProto:23 001:(0.0329) 002:(0.0399) 003:(0.1133) 023:(0.0183) 024:(0.0295) 025:(0.078) 045:(0.0158) 086:(0.0218) 100:(0.0379) 101:(0.0106) \n",
      "\t Child: 086+045\n",
      "\t\tProto:2 004:(0.1713) 031:(0.0066) 032:(0.017) 033:(0.1012) \n",
      "\t\tProto:6 004:(0.0864) 031:(0.0019) 032:(0.0037) 033:(0.0364) \n",
      "\t\tProto:7 004:(0.0612) 031:(0.0014) 032:(0.0002) 033:(0.0024) \n",
      "\t\tProto:9 004:(0.124) 031:(0.022) 032:(0.0248) 033:(0.0959) \n",
      "\t\tProto:11 004:(0.3206) 031:(0.4937) 032:(0.377) 033:(0.2137) \n",
      "\t\tProto:12 004:(0.3804) 031:(0.0084) 032:(0.0144) 033:(0.0602) \n",
      "\t\tProto:16 004:(0.0156) 031:(0.0363) 032:(0.0089) 033:(0.0128) \n",
      "\t\tProto:22 004:(0.0294) 031:(0.035) 032:(0.0083) 033:(0.001) \n",
      "\t\tProto:24 004:(0.1501) 031:(0.0024) 032:(0.0216) 033:(0.0188) \n",
      "\t\tProto:25 004:(0.0277) 031:(0.0011) 032:(0.0013) 033:(0.0229) \n",
      "\t\tProto:26 004:(0.1344) 031:(0.1201) 032:(0.1525) 033:(0.1523) \n",
      "\t\tProto:30 004:(0.0219) 031:(0.0014) 032:(0.0489) 033:(0.0084) \n",
      "\t\tProto:31 004:(0.1286) 031:(0.0023) 032:(0.0045) 033:(0.0109) \n",
      "\t\tProto:34 004:(0.3261) 031:(0.1794) 032:(0.1646) 033:(0.2571) \n",
      "\t\tProto:35 004:(0.1537) 031:(0.0464) 032:(0.168) 033:(0.1625) \n",
      "\t\tProto:36 004:(0.0714) 031:(0.0562) 032:(0.0202) 033:(0.0117) \n",
      "\t\tProto:37 004:(0.0143) 031:(0.0002) 032:(0.0009) 033:(0.0787) \n",
      "\t\tProto:38 004:(0.4972) 031:(0.4294) 032:(0.2729) 033:(0.3671) \n",
      "\t\tProto:40 004:(0.0127) 031:(0.0407) 032:(0.0137) 033:(0.0813) \n",
      "\t\tProto:43 004:(0.1488) 031:(0.0193) 032:(0.0748) 033:(0.078) \n",
      "\t\tProto:44 004:(0.0039) 031:(0.0023) 032:(0.0106) 033:(0.0014) \n",
      "\t\tProto:46 004:(0.1364) 031:(0.039) 032:(0.0976) 033:(0.0717) \n",
      "\t\tProto:48 004:(0.1592) 031:(0.0092) 032:(0.0359) 033:(0.0576) \n",
      "\t\tProto:50 004:(0.009) 031:(0.0018) 032:(0.0007) 033:(0.0033) \n",
      "\t\tProto:51 004:(0.4184) 031:(0.6088) 032:(0.4829) 033:(0.4297) \n",
      "\t\tProto:53 004:(0.144) 031:(0.0135) 032:(0.0251) 033:(0.0525) \n",
      "\t\tProto:54 004:(0.5064) 031:(0.4888) 032:(0.4879) 033:(0.4059) \n",
      "\t\tProto:55 004:(0.0663) 031:(0.0019) 032:(0.0096) 033:(0.0604) \n",
      "\t\tProto:56 004:(0.5274) 031:(0.5831) 032:(0.5435) 033:(0.4418) \n",
      "\t\tProto:57 004:(0.0045) 031:(0.0053) 032:(0.0029) 033:(0.0069) \n",
      "\t\tProto:58 004:(0.0182) 031:(0.0005) 032:(0.0076) 033:(0.0301) \n",
      "\t\tProto:61 004:(0.1745) 031:(0.0888) 032:(0.1638) 033:(0.3792) \n",
      "\t\tProto:63 004:(0.1942) 031:(0.0359) 032:(0.0583) 033:(0.0486) \n",
      "\t\tProto:64 004:(0.1895) 031:(0.3043) 032:(0.0948) 033:(0.3018) \n",
      "\t\tProto:69 004:(0.0188) 031:(0.0007) 032:(0.0003) 033:(0.0171) \n",
      "\t\tProto:70 004:(0.0119) 031:(0.0033) 032:(0.0119) 033:(0.0178) \n",
      "\t\tProto:71 004:(0.095) 031:(0.0085) 032:(0.0709) 033:(0.106) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 31.65it/s]   \n",
      "Collecting topk: 90it [00:01, 49.00it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 38.24it/s]  \n",
      "Collecting topk: 120it [00:01, 65.91it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:05, 52.08it/s]  \n",
      "Collecting topk: 300it [00:02, 143.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 34.73it/s]   \n",
      "Collecting topk: 90it [00:01, 50.63it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- cub_032_Mangrove_Cuckoo {2} --------------------\n",
      "Node 032+033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 60.38it/s]\n",
      "Collecting topk: 270it [00:04, 62.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+003 {1, 2, 4, 5, 6, 7, 8, 9, 11, 14, 15, 16, 17, 18, 19, 20, 22} --------------------\n",
      "-------------------- 101+023 {2, 3, 4, 8, 9, 11, 12, 14, 16, 17, 18, 19, 20, 23, 24, 25, 27, 28, 29, 31} --------------------\n",
      "-------------------- 045+003 {0, 3, 10, 12, 13, 21, 23} --------------------\n",
      "-------------------- 101+023 {0, 1, 5, 6, 7, 10, 13, 15, 21, 22, 26, 30} --------------------\n",
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:1 023:(0.0426) 024:(0.0116) 025:(0.0515) 100:(0.0025) 101:(0.0025) \n",
      "\t\tProto:2 023:(0.0042) 024:(0.0056) 025:(0.1334) 100:(0.0715) 101:(0.0437) \n",
      "\t\tProto:4 023:(0.2699) 024:(0.0195) 025:(0.1594) 100:(0.0868) 101:(0.0888) \n",
      "\t\tProto:5 023:(0.08) 024:(0.005) 025:(0.1337) 100:(0.0215) 101:(0.1373) \n",
      "\t\tProto:6 023:(0.0001) 024:(0.002) 025:(0.0061) 100:(0.0017) 101:(0.0032) \n",
      "\t\tProto:7 023:(0.4174) 024:(0.0807) 025:(0.1421) 100:(0.028) 101:(0.0818) \n",
      "\t\tProto:8 023:(0.1311) 024:(0.0116) 025:(0.2155) 100:(0.0191) 101:(0.0352) \n",
      "\t\tProto:9 023:(0.015) 024:(0.0082) 025:(0.0265) 100:(0.0056) 101:(0.0365) \n",
      "\t\tProto:11 023:(0.0338) 024:(0.0919) 025:(0.1025) 100:(0.0052) 101:(0.1065) \n",
      "\t\tProto:14 023:(0.0456) 024:(0.0481) 025:(0.1373) 100:(0.1913) 101:(0.0229) \n",
      "\t\tProto:15 023:(0.0848) 024:(0.0794) 025:(0.1074) 100:(0.0093) 101:(0.0175) \n",
      "\t\tProto:16 023:(0.0047) 024:(0.0075) 025:(0.0123) 100:(0.0051) 101:(0.0061) \n",
      "\t\tProto:17 023:(0.0007) 024:(0.0025) 025:(0.0392) 100:(0.0009) 101:(0.0076) \n",
      "\t\tProto:18 023:(0.0099) 024:(0.0046) 025:(0.0493) 100:(0.0067) 101:(0.0709) \n",
      "\t\tProto:19 023:(0.0005) 024:(0.0104) 025:(0.0333) 100:(0.0064) 101:(0.0018) \n",
      "\t\tProto:20 023:(0.0245) 024:(0.0149) 025:(0.0638) 100:(0.0245) 101:(0.0052) \n",
      "\t\tProto:22 023:(0.0125) 024:(0.0086) 025:(0.0361) 100:(0.0099) 101:(0.0051) \n",
      "\t Child: 101+023\n",
      "\t\tProto:2 001:(0.0741) 002:(0.002) 003:(0.0242) 045:(0.0011) \n",
      "\t\tProto:3 001:(0.0955) 002:(0.0723) 003:(0.0414) 045:(0.0376) \n",
      "\t\tProto:4 001:(0.1916) 002:(0.0547) 003:(0.0143) 045:(0.0092) \n",
      "\t\tProto:8 001:(0.1563) 002:(0.0048) 003:(0.0142) 045:(0.0031) \n",
      "\t\tProto:9 001:(0.0067) 002:(0.0167) 003:(0.0113) 045:(0.0025) \n",
      "\t\tProto:11 001:(0.3675) 002:(0.1839) 003:(0.3141) 045:(0.0897) \n",
      "\t\tProto:12 001:(0.1153) 002:(0.0178) 003:(0.0418) 045:(0.0168) \n",
      "\t\tProto:14 001:(0.3572) 002:(0.1063) 003:(0.2764) 045:(0.146) \n",
      "\t\tProto:16 001:(0.0121) 002:(0.0244) 003:(0.0008) 045:(0.0004) \n",
      "\t\tProto:17 001:(0.0912) 002:(0.021) 003:(0.0038) 045:(0.0045) \n",
      "\t\tProto:18 001:(0.043) 002:(0.1002) 003:(0.0943) 045:(0.0018) \n",
      "\t\tProto:19 001:(0.0319) 002:(0.0074) 003:(0.0013) 045:(0.002) \n",
      "\t\tProto:20 001:(0.0987) 002:(0.1224) 003:(0.0542) 045:(0.0382) \n",
      "\t\tProto:23 001:(0.0805) 002:(0.0385) 003:(0.1578) 045:(0.0286) \n",
      "\t\tProto:24 001:(0.1) 002:(0.0946) 003:(0.0662) 045:(0.0089) \n",
      "\t\tProto:25 001:(0.4653) 002:(0.3392) 003:(0.1178) 045:(0.19) \n",
      "\t\tProto:27 001:(0.4336) 002:(0.3247) 003:(0.2084) 045:(0.1564) \n",
      "\t\tProto:28 001:(0.0046) 002:(0.0124) 003:(0.0233) 045:(0.0028) \n",
      "\t\tProto:29 001:(0.004) 002:(0.0046) 003:(0.0258) 045:(0.0101) \n",
      "\t\tProto:31 001:(0.1219) 002:(0.0867) 003:(0.0749) 045:(0.0623) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 37.68it/s]  \n",
      "Collecting topk: 120it [00:01, 62.74it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- cub_045_Northern_Fulmar {1} --------------------\n",
      "Node 045+003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 46.11it/s]\n",
      "Collecting topk: 150it [00:02, 51.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 101+100 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 023+025 {0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "-------------------- 023+025 {12, 5, 6} --------------------\n",
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 023:(0.0637) 024:(0.0212) 025:(0.026) \n",
      "\t\tProto:1 023:(0.0129) 024:(0.0069) 025:(0.0286) \n",
      "\t\tProto:2 023:(0.1105) 024:(0.0809) 025:(0.1431) \n",
      "\t\tProto:3 023:(0.0248) 024:(0.0195) 025:(0.0763) \n",
      "\t\tProto:4 023:(0.0114) 024:(0.0026) 025:(0.0059) \n",
      "\t\tProto:5 023:(0.0547) 024:(0.0005) 025:(0.0037) \n",
      "\t\tProto:6 023:(0.0171) 024:(0.0166) 025:(0.02) \n",
      "\t\tProto:7 023:(0.0053) 024:(0.0297) 025:(0.0176) \n",
      "\t Child: 023+025\n",
      "\t\tProto:0 100:(0.2113) 101:(0.2148) \n",
      "\t\tProto:1 100:(0.1247) 101:(0.0593) \n",
      "\t\tProto:2 100:(0.0723) 101:(0.0049) \n",
      "\t\tProto:3 100:(0.3465) 101:(0.0789) \n",
      "\t\tProto:4 100:(0.2171) 101:(0.1771) \n",
      "\t\tProto:7 100:(0.1975) 101:(0.0113) \n",
      "\t\tProto:8 100:(0.173) 101:(0.0378) \n",
      "\t\tProto:9 100:(0.027) 101:(0.0727) \n",
      "\t\tProto:10 100:(0.0067) 101:(0.1057) \n",
      "\t\tProto:11 100:(0.102) 101:(0.0355) \n",
      "\t\tProto:13 100:(0.0147) 101:(0.0028) \n",
      "\t\tProto:14 100:(0.0666) 101:(0.042) \n",
      "\t\tProto:15 100:(0.0917) 101:(0.0148) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 32.12it/s]   \n",
      "Collecting topk: 90it [00:01, 49.67it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 34.90it/s]   \n",
      "Collecting topk: 90it [00:01, 50.57it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "Done !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on NON leaf descendents - topk images after using TANH-DESC with HEAT MAPS\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "# overlayed_image_np = get_heatmap(latent_activation, xs)\n",
    "# Image.fromarray(overlayed_image_np).show()\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            # masking for NON descendant\n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            if coarse_label2name[ys.item()] == child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written, # masking for NON descendant\n",
    "#                     if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "#                         continue\n",
    "                        \n",
    "                    h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes_of_child_node.shape, patchsize, skip, h_idx, w_idx)\n",
    "                    latent_activation = softmaxes_of_child_node[:, p, :, :]\n",
    "                    if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) > topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                         (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            # have this for NON descendant\n",
    "            if len(proto_mean_activations_non_descendants[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "#                         bbox_coords = torch.tensor([[w_coor_min, h_coor_min, w_coor_max, h_coor_max]])\n",
    "#                         bb_image = torchvision.utils.draw_bounding_boxes((img_tensor * 255).type(torch.uint8), bbox_coords, colors='red') / 255\n",
    "#                         pdb.set_trace()\n",
    "                        patches.append(overlayed_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'non_descendent_specific_topk_heatmap_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'non_descendent_specific_topk_heatmap_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images after using UNIT-SPHERE with HEAT MAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:06, 82.54it/s]\n",
      "Collecting topk: 540it [00:13, 39.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 052+053 {1, 3, 5, 7, 10, 13, 14, 20, 21} --------------------\n",
      "-------------------- 004+086 {0, 3, 6, 10, 12, 16, 21, 22, 23, 27, 28, 29, 32, 36, 43, 48, 50, 51, 52, 53, 55, 56, 59, 69, 72, 74, 80, 81, 83, 84, 86, 89, 90, 91, 97, 98, 99, 101} --------------------\n",
      "-------------------- 052+053 {0, 2, 4, 6, 8, 9, 11, 12, 15, 16, 17, 18, 19, 22, 23} --------------------\n",
      "-------------------- 004+086 {1, 2, 4, 5, 7, 8, 9, 11, 13, 14, 15, 17, 18, 19, 20, 24, 25, 26, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 54, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 73, 75, 76, 77, 78, 79, 82, 85, 87, 88, 92, 93, 94, 95, 96, 100, 102, 103} --------------------\n",
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:1 050:(0.2033) 051:(0.2199) 052:(0.2234) 053:(0.1552) \n",
      "\t\tProto:3 050:(0.2086) 051:(0.1842) 052:(0.1527) 053:(0.1949) \n",
      "\t\tProto:5 050:(0.2017) 051:(0.263) 052:(0.1739) 053:(0.2904) \n",
      "\t\tProto:7 050:(0.1949) 051:(0.235) 052:(0.2099) 053:(0.2334) \n",
      "\t\tProto:10 050:(0.3408) 051:(0.3517) 052:(0.3291) 053:(0.3273) \n",
      "\t\tProto:13 050:(0.1399) 051:(0.1613) 052:(0.1916) 053:(0.1053) \n",
      "\t\tProto:14 050:(0.2247) 051:(0.2517) 052:(0.2269) 053:(0.2502) \n",
      "\t\tProto:20 050:(0.1459) 051:(0.1225) 052:(0.1112) 053:(0.1491) \n",
      "\t\tProto:21 050:(0.194) 051:(0.1992) 052:(0.1817) 053:(0.1701) \n",
      "\t Child: 004+086\n",
      "\t\tProto:0 001:(0.1196) 002:(0.1523) 003:(0.0883) 004:(0.1197) 023:(0.1004) 024:(0.0873) 025:(0.0803) 031:(0.096) 032:(0.1052) 033:(0.096) 045:(0.0853) 086:(0.0616) 100:(0.0847) 101:(0.0886) \n",
      "\t\tProto:3 001:(0.0867) 002:(0.0851) 003:(0.0834) 004:(0.0442) 023:(0.08) 024:(0.0657) 025:(0.0677) 031:(0.0694) 032:(0.069) 033:(0.0427) 045:(0.1006) 086:(0.0786) 100:(0.034) 101:(0.0881) \n",
      "\t\tProto:6 001:(0.1191) 002:(0.0835) 003:(0.0754) 004:(0.1307) 023:(0.0733) 024:(0.0975) 025:(0.0894) 031:(0.1194) 032:(0.1168) 033:(0.1222) 045:(0.0701) 086:(0.0982) 100:(0.1005) 101:(0.0847) \n",
      "\t\tProto:10 001:(0.1711) 002:(0.162) 003:(0.1837) 004:(0.1738) 023:(0.1327) 024:(0.1581) 025:(0.1421) 031:(0.1939) 032:(0.1807) 033:(0.1933) 045:(0.1288) 086:(0.2159) 100:(0.1353) 101:(0.1723) \n",
      "\t\tProto:12 001:(0.0994) 002:(0.0849) 003:(0.1227) 004:(0.1008) 023:(0.0935) 024:(0.0671) 025:(0.0801) 031:(0.1349) 032:(0.1036) 033:(0.1304) 045:(0.0935) 086:(0.0712) 100:(0.085) 101:(0.0537) \n",
      "\t\tProto:16 001:(0.0484) 002:(0.0123) 003:(0.0824) 004:(0.0521) 023:(0.0334) 024:(0.0837) 025:(0.0314) 031:(0.0937) 032:(0.0629) 033:(0.0824) 045:(0.0536) 086:(0.032) 100:(0.1045) 101:(0.1185) \n",
      "\t\tProto:21 001:(0.1804) 002:(0.1271) 003:(0.1334) 004:(0.2226) 023:(0.1511) 024:(0.1672) 025:(0.1673) 031:(0.1494) 032:(0.1701) 033:(0.1499) 045:(0.1092) 086:(0.1114) 100:(0.1411) 101:(0.1348) \n",
      "\t\tProto:22 001:(0.0576) 002:(0.0348) 003:(0.0733) 004:(0.0536) 023:(0.0803) 024:(0.0756) 025:(0.043) 031:(0.0727) 032:(0.0513) 033:(0.0768) 045:(0.0949) 086:(0.0904) 100:(0.0738) 101:(0.0882) \n",
      "\t\tProto:23 001:(0.0635) 002:(0.059) 003:(0.0763) 004:(0.0485) 023:(0.1014) 024:(0.0739) 025:(0.0923) 031:(0.1267) 032:(0.0825) 033:(0.1084) 045:(0.0839) 086:(0.0731) 100:(0.0851) 101:(0.0846) \n",
      "\t\tProto:27 001:(0.1108) 002:(0.1122) 003:(0.1296) 004:(0.1905) 023:(0.1579) 024:(0.1889) 025:(0.1662) 031:(0.1349) 032:(0.1082) 033:(0.1398) 045:(0.0949) 086:(0.1114) 100:(0.1212) 101:(0.0707) \n",
      "\t\tProto:28 001:(0.0831) 002:(0.0879) 003:(0.115) 004:(0.0755) 023:(0.0897) 024:(0.0848) 025:(0.0708) 031:(0.0647) 032:(0.0573) 033:(0.0621) 045:(0.0879) 086:(0.0731) 100:(0.0605) 101:(0.0741) \n",
      "\t\tProto:29 001:(0.1281) 002:(0.1629) 003:(0.1455) 004:(0.1553) 023:(0.0971) 024:(0.1087) 025:(0.0866) 031:(0.1609) 032:(0.1434) 033:(0.1654) 045:(0.1188) 086:(0.1302) 100:(0.1463) 101:(0.1375) \n",
      "\t\tProto:32 001:(0.0855) 002:(0.0803) 003:(0.0766) 004:(0.0837) 023:(0.0733) 024:(0.0382) 025:(0.1037) 031:(0.0986) 032:(0.0396) 033:(0.0881) 045:(0.0581) 086:(0.1255) 100:(0.0522) 101:(0.0621) \n",
      "\t\tProto:36 001:(0.0384) 002:(0.0662) 003:(0.0515) 004:(0.1342) 023:(0.0808) 024:(0.1207) 025:(0.1328) 031:(0.1029) 032:(0.0583) 033:(0.1019) 045:(0.0854) 086:(0.025) 100:(0.0844) 101:(0.0664) \n",
      "\t\tProto:43 001:(0.1085) 002:(0.1049) 003:(0.0943) 004:(0.1331) 023:(0.1075) 024:(0.1148) 025:(0.1171) 031:(0.1026) 032:(0.1235) 033:(0.114) 045:(0.0925) 086:(0.0402) 100:(0.0998) 101:(0.0896) \n",
      "\t\tProto:48 001:(0.0725) 002:(0.0737) 003:(0.0429) 004:(0.0449) 023:(0.0549) 024:(0.0846) 025:(0.0494) 031:(0.1072) 032:(0.1281) 033:(0.1339) 045:(0.0813) 086:(0.0555) 100:(0.045) 101:(0.0857) \n",
      "\t\tProto:50 001:(0.0937) 002:(0.09) 003:(0.0969) 004:(0.066) 023:(0.0597) 024:(0.0756) 025:(0.0689) 031:(0.1174) 032:(0.1048) 033:(0.1339) 045:(0.0812) 086:(0.0838) 100:(0.054) 101:(0.0789) \n",
      "\t\tProto:51 001:(0.1421) 002:(0.1213) 003:(0.1494) 004:(0.2135) 023:(0.1956) 024:(0.1999) 025:(0.1872) 031:(0.1291) 032:(0.1362) 033:(0.1443) 045:(0.1921) 086:(0.124) 100:(0.1868) 101:(0.1009) \n",
      "\t\tProto:52 001:(0.0846) 002:(0.0947) 003:(0.0757) 004:(0.0283) 023:(0.0871) 024:(0.1283) 025:(0.0853) 031:(0.0331) 032:(0.0349) 033:(0.0476) 045:(0.0486) 086:(0.0617) 100:(0.0753) 101:(0.1172) \n",
      "\t\tProto:53 001:(0.1158) 002:(0.12) 003:(0.0726) 004:(0.077) 023:(0.0618) 024:(0.086) 025:(0.0852) 031:(0.0678) 032:(0.0848) 033:(0.0874) 045:(0.1585) 086:(0.0686) 100:(0.1232) 101:(0.1438) \n",
      "\t\tProto:55 001:(0.1049) 002:(0.1123) 003:(0.1372) 004:(0.1422) 023:(0.14) 024:(0.1416) 025:(0.1172) 031:(0.0877) 032:(0.0843) 033:(0.0858) 045:(0.132) 086:(0.1357) 100:(0.0888) 101:(0.0652) \n",
      "\t\tProto:56 001:(0.084) 002:(0.0591) 003:(0.0848) 004:(0.0567) 023:(0.0461) 024:(0.0439) 025:(0.0545) 031:(0.1294) 032:(0.0998) 033:(0.1131) 045:(0.0585) 086:(0.0695) 100:(0.0436) 101:(0.0214) \n",
      "\t\tProto:59 001:(0.0953) 002:(0.0691) 003:(0.0943) 004:(0.0682) 023:(0.0646) 024:(0.0725) 025:(0.0758) 031:(0.1386) 032:(0.0716) 033:(0.121) 045:(0.1018) 086:(0.0904) 100:(0.1394) 101:(0.144) \n",
      "\t\tProto:69 001:(0.0998) 002:(0.0765) 003:(0.134) 004:(0.051) 023:(0.0749) 024:(0.0844) 025:(0.066) 031:(0.1022) 032:(0.0972) 033:(0.0782) 045:(0.0883) 086:(0.0493) 100:(0.1001) 101:(0.0655) \n",
      "\t\tProto:72 001:(0.1353) 002:(0.1423) 003:(0.1056) 004:(0.02) 023:(0.0884) 024:(0.0922) 025:(0.057) 031:(0.07) 032:(0.0535) 033:(0.0778) 045:(0.0734) 086:(0.0854) 100:(0.1358) 101:(0.1262) \n",
      "\t\tProto:74 001:(0.0664) 002:(0.0705) 003:(0.0748) 004:(0.1335) 023:(0.1008) 024:(0.1228) 025:(0.1095) 031:(0.1358) 032:(0.1191) 033:(0.1277) 045:(0.0887) 086:(0.0524) 100:(0.1035) 101:(0.088) \n",
      "\t\tProto:80 001:(0.0762) 002:(0.0585) 003:(0.069) 004:(0.0651) 023:(0.0616) 024:(0.0812) 025:(0.0587) 031:(0.0724) 032:(0.0853) 033:(0.0785) 045:(0.0903) 086:(0.0674) 100:(0.0671) 101:(0.0691) \n",
      "\t\tProto:81 001:(0.087) 002:(0.08) 003:(0.0735) 004:(0.0727) 023:(0.0566) 024:(0.0494) 025:(0.079) 031:(0.0791) 032:(0.062) 033:(0.0717) 045:(0.0586) 086:(0.0959) 100:(0.0985) 101:(0.077) \n",
      "\t\tProto:83 001:(0.068) 002:(0.0636) 003:(0.0748) 004:(0.0783) 023:(0.1061) 024:(0.0771) 025:(0.0793) 031:(0.0816) 032:(0.056) 033:(0.0712) 045:(0.0774) 086:(0.1087) 100:(0.091) 101:(0.1016) \n",
      "\t\tProto:84 001:(0.0657) 002:(0.0567) 003:(0.061) 004:(0.1146) 023:(0.125) 024:(0.126) 025:(0.1051) 031:(0.0626) 032:(0.0844) 033:(0.0712) 045:(0.0612) 086:(0.0795) 100:(0.0619) 101:(0.0754) \n",
      "\t\tProto:86 001:(0.1414) 002:(0.1289) 003:(0.1321) 004:(0.1092) 023:(0.1262) 024:(0.1829) 025:(0.1328) 031:(0.1242) 032:(0.1314) 033:(0.131) 045:(0.1144) 086:(0.1415) 100:(0.1695) 101:(0.1662) \n",
      "\t\tProto:89 001:(0.1151) 002:(0.1063) 003:(0.12) 004:(0.1294) 023:(0.092) 024:(0.0959) 025:(0.0874) 031:(0.1229) 032:(0.1413) 033:(0.1234) 045:(0.0832) 086:(0.0453) 100:(0.0842) 101:(0.0664) \n",
      "\t\tProto:90 001:(0.065) 002:(0.0532) 003:(0.0661) 004:(0.0789) 023:(0.0808) 024:(0.0909) 025:(0.0935) 031:(0.0841) 032:(0.0855) 033:(0.0969) 045:(0.1075) 086:(0.0448) 100:(0.0986) 101:(0.0556) \n",
      "\t\tProto:91 001:(0.0823) 002:(0.072) 003:(0.0834) 004:(0.0635) 023:(0.0586) 024:(0.0866) 025:(0.0823) 031:(0.0453) 032:(0.0637) 033:(0.0525) 045:(0.1094) 086:(0.0524) 100:(0.0973) 101:(0.1004) \n",
      "\t\tProto:97 001:(0.1458) 002:(0.1171) 003:(0.1671) 004:(0.2395) 023:(0.201) 024:(0.1896) 025:(0.1848) 031:(0.2281) 032:(0.2374) 033:(0.2334) 045:(0.145) 086:(0.1129) 100:(0.1968) 101:(0.0643) \n",
      "\t\tProto:98 001:(0.1842) 002:(0.1944) 003:(0.1541) 004:(0.2042) 023:(0.1316) 024:(0.1595) 025:(0.139) 031:(0.1566) 032:(0.1914) 033:(0.1676) 045:(0.0945) 086:(0.0399) 100:(0.1849) 101:(0.2043) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tProto:99 001:(0.0781) 002:(0.0758) 003:(0.0929) 004:(0.1214) 023:(0.1233) 024:(0.1057) 025:(0.1194) 031:(0.1077) 032:(0.107) 033:(0.1111) 045:(0.0713) 086:(0.0971) 100:(0.0818) 101:(0.0854) \n",
      "\t\tProto:101 001:(0.176) 002:(0.1696) 003:(0.1073) 004:(0.1705) 023:(0.1373) 024:(0.0893) 025:(0.1014) 031:(0.1604) 032:(0.1697) 033:(0.1588) 045:(0.0681) 086:(0.1517) 100:(0.0681) 101:(0.0986) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 51.03it/s]  \n",
      "Collecting topk: 120it [00:03, 32.90it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 053+050 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15} --------------------\n",
      "-------------------- 053+050 {13} --------------------\n",
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:0 050:(0.1285) 051:(0.1184) 053:(0.0579) \n",
      "\t\tProto:1 050:(0.1263) 051:(0.0982) 053:(0.0769) \n",
      "\t\tProto:2 050:(0.1081) 051:(0.0904) 053:(0.0742) \n",
      "\t\tProto:3 050:(0.295) 051:(0.3856) 053:(0.3471) \n",
      "\t\tProto:4 050:(0.1199) 051:(0.1568) 053:(0.1289) \n",
      "\t\tProto:5 050:(0.1462) 051:(0.0999) 053:(0.0573) \n",
      "\t\tProto:6 050:(0.1116) 051:(0.1282) 053:(0.1097) \n",
      "\t\tProto:7 050:(0.1205) 051:(0.1335) 053:(0.1166) \n",
      "\t\tProto:8 050:(0.2201) 051:(0.3237) 053:(0.2588) \n",
      "\t\tProto:9 050:(0.1257) 051:(0.1877) 053:(0.1544) \n",
      "\t\tProto:10 050:(0.4297) 051:(0.5428) 053:(0.528) \n",
      "\t\tProto:11 050:(0.4732) 051:(0.4486) 053:(0.3921) \n",
      "\t\tProto:12 050:(0.2408) 051:(0.2465) 053:(0.2477) \n",
      "\t\tProto:14 050:(0.2546) 051:(0.3163) 053:(0.3852) \n",
      "\t\tProto:15 050:(0.2047) 051:(0.2242) 053:(0.2403) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:04, 101.99it/s]\n",
      "Collecting topk: 420it [00:08, 48.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 004+032 {0, 2, 4, 6, 9, 10, 14, 15, 17, 18, 19, 21, 22} --------------------\n",
      "-------------------- 086+045 {3, 6, 8, 12, 13, 15, 16, 17, 21, 26, 28, 30, 33, 34, 37, 40, 42, 44, 46, 49, 50, 52, 53, 54, 55, 57, 58, 60, 61, 62, 63, 66, 70, 71} --------------------\n",
      "-------------------- 004+032 {1, 3, 5, 7, 8, 11, 12, 13, 16, 20, 23} --------------------\n",
      "-------------------- 086+045 {0, 1, 2, 4, 5, 7, 9, 10, 11, 14, 18, 19, 20, 22, 23, 24, 25, 27, 29, 31, 32, 35, 36, 38, 39, 41, 43, 45, 47, 48, 51, 56, 59, 64, 65, 67, 68, 69} --------------------\n",
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:0 004:(0.1639) 031:(0.2137) 032:(0.2145) 033:(0.2166) \n",
      "\t\tProto:2 004:(0.1955) 031:(0.2219) 032:(0.2143) 033:(0.2151) \n",
      "\t\tProto:4 004:(0.1649) 031:(0.1836) 032:(0.2023) 033:(0.1941) \n",
      "\t\tProto:6 004:(0.2684) 031:(0.3287) 032:(0.3768) 033:(0.3958) \n",
      "\t\tProto:9 004:(0.2057) 031:(0.2595) 032:(0.2185) 033:(0.2536) \n",
      "\t\tProto:10 004:(0.1355) 031:(0.1816) 032:(0.2028) 033:(0.2125) \n",
      "\t\tProto:14 004:(0.1329) 031:(0.1385) 032:(0.1441) 033:(0.1249) \n",
      "\t\tProto:15 004:(0.1585) 031:(0.1411) 032:(0.074) 033:(0.1352) \n",
      "\t\tProto:17 004:(0.2309) 031:(0.3159) 032:(0.2353) 033:(0.3026) \n",
      "\t\tProto:18 004:(0.1332) 031:(0.1791) 032:(0.2356) 033:(0.1968) \n",
      "\t\tProto:19 004:(0.134) 031:(0.1668) 032:(0.1647) 033:(0.1573) \n",
      "\t\tProto:21 004:(0.106) 031:(0.1946) 032:(0.1696) 033:(0.174) \n",
      "\t\tProto:22 004:(0.2396) 031:(0.2655) 032:(0.2432) 033:(0.253) \n",
      "\t Child: 086+045\n",
      "\t\tProto:3 001:(0.0764) 002:(0.1064) 003:(0.0971) 023:(0.1089) 024:(0.0773) 025:(0.1006) 045:(0.1289) 086:(0.0488) 100:(0.0532) 101:(0.0606) \n",
      "\t\tProto:6 001:(0.1049) 002:(0.0873) 003:(0.1415) 023:(0.0791) 024:(0.0395) 025:(0.075) 045:(0.0966) 086:(0.0927) 100:(0.0901) 101:(0.0897) \n",
      "\t\tProto:8 001:(0.1111) 002:(0.0974) 003:(0.103) 023:(0.1083) 024:(0.0546) 025:(0.0658) 045:(0.0867) 086:(0.0756) 100:(0.0808) 101:(0.078) \n",
      "\t\tProto:12 001:(0.1178) 002:(0.0779) 003:(0.1249) 023:(0.0794) 024:(0.1051) 025:(0.0715) 045:(0.0499) 086:(0.0502) 100:(0.0149) 101:(0.0464) \n",
      "\t\tProto:13 001:(0.1125) 002:(0.05) 003:(0.0895) 023:(0.1355) 024:(0.1153) 025:(0.1221) 045:(0.1013) 086:(0.1024) 100:(0.0827) 101:(0.0807) \n",
      "\t\tProto:15 001:(0.0587) 002:(0.0932) 003:(0.1049) 023:(0.049) 024:(0.1615) 025:(0.0816) 045:(0.111) 086:(0.0965) 100:(0.1162) 101:(0.1244) \n",
      "\t\tProto:16 001:(0.1366) 002:(0.1216) 003:(0.1664) 023:(0.155) 024:(0.1061) 025:(0.1439) 045:(0.1188) 086:(0.1475) 100:(0.1111) 101:(0.1357) \n",
      "\t\tProto:17 001:(0.1233) 002:(0.0976) 003:(0.1352) 023:(0.0974) 024:(0.0722) 025:(0.0894) 045:(0.1298) 086:(0.0883) 100:(0.1087) 101:(0.0812) \n",
      "\t\tProto:21 001:(0.0777) 002:(0.0969) 003:(0.2402) 023:(0.1517) 024:(0.1249) 025:(0.1568) 045:(0.0963) 086:(0.1008) 100:(0.0806) 101:(0.1031) \n",
      "\t\tProto:26 001:(0.1342) 002:(0.1189) 003:(0.1106) 023:(0.1167) 024:(0.1313) 025:(0.1185) 045:(0.0875) 086:(0.0996) 100:(0.1352) 101:(0.0962) \n",
      "\t\tProto:28 001:(0.0528) 002:(0.0614) 003:(0.0792) 023:(0.0983) 024:(0.0602) 025:(0.0656) 045:(0.0602) 086:(0.0949) 100:(0.0508) 101:(0.0545) \n",
      "\t\tProto:30 001:(0.1904) 002:(0.1952) 003:(0.1132) 023:(0.134) 024:(0.1795) 025:(0.1079) 045:(0.1021) 086:(0.179) 100:(0.1713) 101:(0.1851) \n",
      "\t\tProto:33 001:(0.2124) 002:(0.2442) 003:(0.2563) 023:(0.2364) 024:(0.1867) 025:(0.266) 045:(0.2673) 086:(0.286) 100:(0.299) 101:(0.303) \n",
      "\t\tProto:34 001:(0.0878) 002:(0.0688) 003:(0.0553) 023:(0.0581) 024:(0.0685) 025:(0.0896) 045:(0.0803) 086:(0.1259) 100:(0.073) 101:(0.1536) \n",
      "\t\tProto:37 001:(0.0995) 002:(0.0821) 003:(0.1123) 023:(0.0657) 024:(0.129) 025:(0.1007) 045:(0.16) 086:(0.1142) 100:(0.0738) 101:(0.1363) \n",
      "\t\tProto:40 001:(0.0933) 002:(0.0803) 003:(0.1116) 023:(0.0977) 024:(0.0993) 025:(0.0966) 045:(0.1203) 086:(0.0935) 100:(0.0699) 101:(0.0522) \n",
      "\t\tProto:42 001:(0.0741) 002:(0.0601) 003:(0.1124) 023:(0.05) 024:(0.1082) 025:(0.0764) 045:(0.1405) 086:(0.0653) 100:(0.0711) 101:(0.0693) \n",
      "\t\tProto:44 001:(0.1159) 002:(0.0818) 003:(0.0712) 023:(0.0723) 024:(0.0571) 025:(0.0825) 045:(0.0943) 086:(0.1025) 100:(0.0911) 101:(0.0964) \n",
      "\t\tProto:46 001:(0.0921) 002:(0.0823) 003:(0.1455) 023:(0.1075) 024:(0.1043) 025:(0.0949) 045:(0.1266) 086:(0.0531) 100:(0.1062) 101:(0.0517) \n",
      "\t\tProto:49 001:(0.097) 002:(0.1246) 003:(0.0988) 023:(0.0425) 024:(0.0577) 025:(0.0916) 045:(0.0672) 086:(0.0377) 100:(0.0337) 101:(0.095) \n",
      "\t\tProto:50 001:(0.1818) 002:(0.1989) 003:(0.1963) 023:(0.1489) 024:(0.1357) 025:(0.0899) 045:(0.1283) 086:(0.1042) 100:(0.0935) 101:(0.1142) \n",
      "\t\tProto:52 001:(0.1673) 002:(0.1574) 003:(0.1433) 023:(0.097) 024:(0.0788) 025:(0.0802) 045:(0.1225) 086:(0.1306) 100:(0.1798) 101:(0.1434) \n",
      "\t\tProto:53 001:(0.0972) 002:(0.0766) 003:(0.1115) 023:(0.0808) 024:(0.0686) 025:(0.079) 045:(0.099) 086:(0.0962) 100:(0.0924) 101:(0.0693) \n",
      "\t\tProto:54 001:(0.0808) 002:(0.0875) 003:(0.0807) 023:(0.0497) 024:(0.0593) 025:(0.063) 045:(0.0642) 086:(0.0729) 100:(0.0811) 101:(0.0566) \n",
      "\t\tProto:55 001:(0.141) 002:(0.1241) 003:(0.1291) 023:(0.0904) 024:(0.1034) 025:(0.0792) 045:(0.2063) 086:(0.0666) 100:(0.1262) 101:(0.1433) \n",
      "\t\tProto:57 001:(0.1303) 002:(0.1253) 003:(0.1067) 023:(0.0771) 024:(0.0924) 025:(0.0846) 045:(0.2089) 086:(0.0556) 100:(0.0852) 101:(0.0605) \n",
      "\t\tProto:58 001:(0.1122) 002:(0.0933) 003:(0.1244) 023:(0.107) 024:(0.1102) 025:(0.1066) 045:(0.1335) 086:(0.0899) 100:(0.1067) 101:(0.0963) \n",
      "\t\tProto:60 001:(0.0773) 002:(0.1373) 003:(0.0811) 023:(0.0596) 024:(0.1805) 025:(0.1624) 045:(0.1759) 086:(0.1005) 100:(0.1822) 101:(0.1406) \n",
      "\t\tProto:61 001:(0.1408) 002:(0.1402) 003:(0.1298) 023:(0.0944) 024:(0.0707) 025:(0.1104) 045:(0.1163) 086:(0.0697) 100:(0.0946) 101:(0.0705) \n",
      "\t\tProto:62 001:(0.0662) 002:(0.0911) 003:(0.0565) 023:(0.0544) 024:(0.0431) 025:(0.0796) 045:(0.1099) 086:(0.1222) 100:(0.0978) 101:(0.0798) \n",
      "\t\tProto:63 001:(0.0878) 002:(0.0866) 003:(0.0651) 023:(0.101) 024:(0.0679) 025:(0.1321) 045:(0.1166) 086:(0.1518) 100:(0.1046) 101:(0.1143) \n",
      "\t\tProto:66 001:(0.2312) 002:(0.2368) 003:(0.1329) 023:(0.1071) 024:(0.1147) 025:(0.1638) 045:(0.1287) 086:(0.1403) 100:(0.1374) 101:(0.1509) \n",
      "\t\tProto:70 001:(0.0897) 002:(0.0944) 003:(0.0971) 023:(0.0754) 024:(0.0742) 025:(0.063) 045:(0.0466) 086:(0.046) 100:(0.0564) 101:(0.0752) \n",
      "\t\tProto:71 001:(0.1113) 002:(0.1175) 003:(0.0955) 023:(0.0993) 024:(0.072) 025:(0.0894) 045:(0.0909) 086:(0.0766) 100:(0.0873) 101:(0.0833) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 41.40it/s]   \n",
      "Collecting topk: 90it [00:03, 28.53it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 050+051 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 050:(0.2565) 051:(0.2845) \n",
      "\t\tProto:1 050:(0.2466) 051:(0.2785) \n",
      "\t\tProto:2 050:(0.3402) 051:(0.2641) \n",
      "\t\tProto:3 050:(0.4097) 051:(0.4189) \n",
      "\t\tProto:4 050:(0.596) 051:(0.6132) \n",
      "\t\tProto:5 050:(0.3734) 051:(0.4) \n",
      "\t\tProto:6 050:(0.4765) 051:(0.5271) \n",
      "\t\tProto:7 050:(0.312) 051:(0.3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 64.60it/s]  \n",
      "Collecting topk: 120it [00:03, 33.17it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 032+033 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15} --------------------\n",
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:0 031:(0.1225) 032:(0.0921) 033:(0.0698) \n",
      "\t\tProto:1 031:(0.1201) 032:(0.1103) 033:(0.1324) \n",
      "\t\tProto:2 031:(0.1484) 032:(0.1664) 033:(0.1419) \n",
      "\t\tProto:3 031:(0.2926) 032:(0.2599) 033:(0.2895) \n",
      "\t\tProto:4 031:(0.3357) 032:(0.2249) 033:(0.2673) \n",
      "\t\tProto:5 031:(0.1119) 032:(0.1244) 033:(0.1052) \n",
      "\t\tProto:6 031:(0.0968) 032:(0.1531) 033:(0.0924) \n",
      "\t\tProto:7 031:(0.2791) 032:(0.1908) 033:(0.2347) \n",
      "\t\tProto:8 031:(0.3586) 032:(0.3706) 033:(0.3619) \n",
      "\t\tProto:9 031:(0.1695) 032:(0.1555) 033:(0.1221) \n",
      "\t\tProto:10 031:(0.1233) 032:(0.1306) 033:(0.1303) \n",
      "\t\tProto:11 031:(0.1418) 032:(0.2056) 033:(0.1341) \n",
      "\t\tProto:12 031:(0.1175) 032:(0.0904) 033:(0.0963) \n",
      "\t\tProto:13 031:(0.4169) 032:(0.454) 033:(0.4578) \n",
      "\t\tProto:14 031:(0.1548) 032:(0.1349) 033:(0.1205) \n",
      "\t\tProto:15 031:(0.2914) 032:(0.385) 033:(0.3081) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:02, 129.35it/s] \n",
      "Collecting topk: 300it [00:08, 34.13it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+101 {0, 1, 4, 5, 6, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 32, 33, 36, 37, 38, 39, 41, 42, 43, 44, 45, 50, 51, 53, 54, 56, 59, 60, 62, 63} --------------------\n",
      "-------------------- 045+101 {2, 3, 7, 12, 15, 23, 24, 25, 27, 31, 34, 35, 40, 46, 47, 48, 49, 52, 55, 57, 58, 61} --------------------\n",
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:0 001:(0.1023) 002:(0.1213) 003:(0.1051) 023:(0.0371) 024:(0.0302) 025:(0.0447) 045:(0.0912) 100:(0.0957) 101:(0.1025) \n",
      "\t\tProto:1 001:(0.1028) 002:(0.0902) 003:(0.1186) 023:(0.0957) 024:(0.0908) 025:(0.0849) 045:(0.0976) 100:(0.0754) 101:(0.0714) \n",
      "\t\tProto:4 001:(0.1013) 002:(0.0584) 003:(0.0998) 023:(0.1269) 024:(0.1266) 025:(0.1325) 045:(0.1253) 100:(0.1025) 101:(0.1014) \n",
      "\t\tProto:5 001:(0.1221) 002:(0.1034) 003:(0.1248) 023:(0.1414) 024:(0.1415) 025:(0.1464) 045:(0.1184) 100:(0.1613) 101:(0.1045) \n",
      "\t\tProto:6 001:(0.1138) 002:(0.0949) 003:(0.1002) 023:(0.141) 024:(0.1262) 025:(0.1252) 045:(0.1368) 100:(0.0803) 101:(0.1137) \n",
      "\t\tProto:8 001:(0.0643) 002:(0.1014) 003:(0.0816) 023:(0.0747) 024:(0.1158) 025:(0.0723) 045:(0.115) 100:(0.1011) 101:(0.0707) \n",
      "\t\tProto:9 001:(0.1513) 002:(0.1527) 003:(0.1731) 023:(0.082) 024:(0.1052) 025:(0.0933) 045:(0.1219) 100:(0.1689) 101:(0.1671) \n",
      "\t\tProto:10 001:(0.1092) 002:(0.0729) 003:(0.1185) 023:(0.1395) 024:(0.1361) 025:(0.1379) 045:(0.1136) 100:(0.133) 101:(0.0817) \n",
      "\t\tProto:11 001:(0.185) 002:(0.1128) 003:(0.2106) 023:(0.1328) 024:(0.1566) 025:(0.1215) 045:(0.1487) 100:(0.1583) 101:(0.1573) \n",
      "\t\tProto:13 001:(0.1379) 002:(0.1243) 003:(0.1223) 023:(0.0611) 024:(0.0636) 025:(0.0647) 045:(0.0759) 100:(0.0662) 101:(0.0944) \n",
      "\t\tProto:14 001:(0.0703) 002:(0.0726) 003:(0.084) 023:(0.0734) 024:(0.049) 025:(0.0817) 045:(0.0839) 100:(0.0783) 101:(0.0504) \n",
      "\t\tProto:16 001:(0.1558) 002:(0.1527) 003:(0.1945) 023:(0.1029) 024:(0.1593) 025:(0.1017) 045:(0.1179) 100:(0.1175) 101:(0.1214) \n",
      "\t\tProto:17 001:(0.0916) 002:(0.1432) 003:(0.082) 023:(0.0887) 024:(0.0957) 025:(0.0923) 045:(0.1483) 100:(0.1736) 101:(0.1533) \n",
      "\t\tProto:18 001:(0.0224) 002:(0.0577) 003:(0.0829) 023:(0.064) 024:(0.1032) 025:(0.0733) 045:(0.05) 100:(0.1282) 101:(0.1423) \n",
      "\t\tProto:19 001:(0.1455) 002:(0.1163) 003:(0.1393) 023:(0.1) 024:(0.1597) 025:(0.1055) 045:(0.1166) 100:(0.1392) 101:(0.0727) \n",
      "\t\tProto:20 001:(0.1576) 002:(0.1521) 003:(0.1466) 023:(0.1499) 024:(0.1477) 025:(0.1625) 045:(0.1112) 100:(0.1362) 101:(0.0797) \n",
      "\t\tProto:21 001:(0.0639) 002:(0.06) 003:(0.0934) 023:(0.1282) 024:(0.1343) 025:(0.1328) 045:(0.0607) 100:(0.0844) 101:(0.097) \n",
      "\t\tProto:22 001:(0.1249) 002:(0.0794) 003:(0.1224) 023:(0.0678) 024:(0.0641) 025:(0.0853) 045:(0.1108) 100:(0.1404) 101:(0.1398) \n",
      "\t\tProto:26 001:(0.2369) 002:(0.2384) 003:(0.186) 023:(0.2486) 024:(0.2362) 025:(0.2444) 045:(0.2143) 100:(0.246) 101:(0.2593) \n",
      "\t\tProto:28 001:(0.0876) 002:(0.129) 003:(0.0749) 023:(0.0455) 024:(0.0623) 025:(0.0396) 045:(0.0738) 100:(0.0355) 101:(0.0645) \n",
      "\t\tProto:29 001:(0.1238) 002:(0.1025) 003:(0.0914) 023:(0.0872) 024:(0.1367) 025:(0.0861) 045:(0.0535) 100:(0.0876) 101:(0.1056) \n",
      "\t\tProto:30 001:(0.0871) 002:(0.093) 003:(0.0849) 023:(0.1468) 024:(0.1448) 025:(0.135) 045:(0.1172) 100:(0.19) 101:(0.1917) \n",
      "\t\tProto:32 001:(0.1351) 002:(0.1095) 003:(0.1263) 023:(0.1653) 024:(0.1995) 025:(0.17) 045:(0.1194) 100:(0.1388) 101:(0.093) \n",
      "\t\tProto:33 001:(0.137) 002:(0.1284) 003:(0.1184) 023:(0.1115) 024:(0.0916) 025:(0.1111) 045:(0.1108) 100:(0.0687) 101:(0.057) \n",
      "\t\tProto:36 001:(0.0914) 002:(0.1032) 003:(0.0421) 023:(0.0551) 024:(0.0733) 025:(0.0717) 045:(0.0744) 100:(0.0517) 101:(0.0627) \n",
      "\t\tProto:37 001:(0.0503) 002:(0.0497) 003:(0.0539) 023:(0.0987) 024:(0.0981) 025:(0.0656) 045:(0.0805) 100:(0.0905) 101:(0.0851) \n",
      "\t\tProto:38 001:(0.0964) 002:(0.098) 003:(0.1046) 023:(0.0753) 024:(0.1158) 025:(0.0879) 045:(0.0657) 100:(0.0788) 101:(0.0429) \n",
      "\t\tProto:39 001:(0.1017) 002:(0.0976) 003:(0.1215) 023:(0.1193) 024:(0.0897) 025:(0.1102) 045:(0.1162) 100:(0.0792) 101:(0.0836) \n",
      "\t\tProto:41 001:(0.086) 002:(0.101) 003:(0.0611) 023:(0.0807) 024:(0.0759) 025:(0.0737) 045:(0.0734) 100:(0.097) 101:(0.0862) \n",
      "\t\tProto:42 001:(0.1047) 002:(0.0787) 003:(0.1136) 023:(0.0833) 024:(0.0946) 025:(0.0848) 045:(0.122) 100:(0.0523) 101:(0.0528) \n",
      "\t\tProto:43 001:(0.1288) 002:(0.1359) 003:(0.1088) 023:(0.0948) 024:(0.1212) 025:(0.1168) 045:(0.0593) 100:(0.0619) 101:(0.1064) \n",
      "\t\tProto:44 001:(0.083) 002:(0.1033) 003:(0.1141) 023:(0.0818) 024:(0.0964) 025:(0.0759) 045:(0.0606) 100:(0.1036) 101:(0.1023) \n",
      "\t\tProto:45 001:(0.0931) 002:(0.1159) 003:(0.0755) 023:(0.0745) 024:(0.0468) 025:(0.0712) 045:(0.1209) 100:(0.0697) 101:(0.0357) \n",
      "\t\tProto:50 001:(0.1222) 002:(0.1164) 003:(0.0975) 023:(0.1279) 024:(0.1035) 025:(0.115) 045:(0.0877) 100:(0.0568) 101:(0.0674) \n",
      "\t\tProto:51 001:(0.1263) 002:(0.1549) 003:(0.0774) 023:(0.1155) 024:(0.1085) 025:(0.1195) 045:(0.0714) 100:(0.0391) 101:(0.1033) \n",
      "\t\tProto:53 001:(0.08) 002:(0.1113) 003:(0.0895) 023:(0.0784) 024:(0.1039) 025:(0.0903) 045:(0.0898) 100:(0.102) 101:(0.0978) \n",
      "\t\tProto:54 001:(0.102) 002:(0.0652) 003:(0.0905) 023:(0.0867) 024:(0.0927) 025:(0.0751) 045:(0.092) 100:(0.0884) 101:(0.0868) \n",
      "\t\tProto:56 001:(0.08) 002:(0.0764) 003:(0.0972) 023:(0.0983) 024:(0.1095) 025:(0.1227) 045:(0.1153) 100:(0.103) 101:(0.1012) \n",
      "\t\tProto:59 001:(0.0769) 002:(0.1119) 003:(0.091) 023:(0.1061) 024:(0.092) 025:(0.1077) 045:(0.1168) 100:(0.0961) 101:(0.0921) \n",
      "\t\tProto:60 001:(0.1307) 002:(0.1279) 003:(0.1959) 023:(0.1175) 024:(0.1173) 025:(0.1145) 045:(0.1465) 100:(0.1794) 101:(0.2122) \n",
      "\t\tProto:62 001:(0.1109) 002:(0.1103) 003:(0.0959) 023:(0.0902) 024:(0.0888) 025:(0.0853) 045:(0.0892) 100:(0.055) 101:(0.0409) \n",
      "\t\tProto:63 001:(0.0664) 002:(0.0792) 003:(0.1652) 023:(0.106) 024:(0.1009) 025:(0.097) 045:(0.1405) 100:(0.107) 101:(0.1126) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 42.79it/s]   \n",
      "Collecting topk: 90it [00:02, 33.35it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 033+031 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(0.2712) 033:(0.2724) \n",
      "\t\tProto:1 031:(0.317) 033:(0.3015) \n",
      "\t\tProto:2 031:(0.2077) 033:(0.2363) \n",
      "\t\tProto:3 031:(0.472) 033:(0.4356) \n",
      "\t\tProto:4 031:(0.4987) 033:(0.5033) \n",
      "\t\tProto:5 031:(0.3761) 033:(0.3594) \n",
      "\t\tProto:6 031:(0.3954) 033:(0.3725) \n",
      "\t\tProto:7 031:(0.5382) 033:(0.4736) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 63.41it/s]\n",
      "Collecting topk: 270it [00:05, 52.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+003 {0, 1, 3, 4, 7, 8, 12, 15, 16, 18, 20, 21, 23} --------------------\n",
      "-------------------- 101+023 {0, 2, 3, 4, 8, 9, 14, 15, 16, 17, 18, 19, 22, 23, 25, 28, 30} --------------------\n",
      "-------------------- 045+003 {2, 5, 6, 9, 10, 11, 13, 14, 17, 19, 22} --------------------\n",
      "-------------------- 101+023 {1, 5, 6, 7, 10, 11, 12, 13, 20, 21, 24, 26, 27, 29, 31} --------------------\n",
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:0 001:(0.3147) 002:(0.3705) 003:(0.2707) 045:(0.301) \n",
      "\t\tProto:1 001:(0.0669) 002:(0.1104) 003:(0.0714) 045:(0.087) \n",
      "\t\tProto:3 001:(0.27) 002:(0.191) 003:(0.3155) 045:(0.3384) \n",
      "\t\tProto:4 001:(0.2585) 002:(0.2732) 003:(0.3136) 045:(0.2488) \n",
      "\t\tProto:7 001:(0.307) 002:(0.3212) 003:(0.2062) 045:(0.3111) \n",
      "\t\tProto:8 001:(0.171) 002:(0.0932) 003:(0.1838) 045:(0.1799) \n",
      "\t\tProto:12 001:(0.2767) 002:(0.2208) 003:(0.2858) 045:(0.2342) \n",
      "\t\tProto:15 001:(0.2616) 002:(0.2782) 003:(0.2881) 045:(0.2588) \n",
      "\t\tProto:16 001:(0.0908) 002:(0.0888) 003:(0.1138) 045:(0.1057) \n",
      "\t\tProto:18 001:(0.0922) 002:(0.106) 003:(0.1046) 045:(0.0874) \n",
      "\t\tProto:20 001:(0.1449) 002:(0.1562) 003:(0.1816) 045:(0.0717) \n",
      "\t\tProto:21 001:(0.1669) 002:(0.1137) 003:(0.1732) 045:(0.1765) \n",
      "\t\tProto:23 001:(0.1445) 002:(0.0965) 003:(0.1682) 045:(0.1374) \n",
      "\t Child: 101+023\n",
      "\t\tProto:0 023:(0.1129) 024:(0.1001) 025:(0.1004) 100:(0.1037) 101:(0.1044) \n",
      "\t\tProto:2 023:(0.1358) 024:(0.1451) 025:(0.1557) 100:(0.1195) 101:(0.1151) \n",
      "\t\tProto:3 023:(0.2084) 024:(0.2527) 025:(0.1945) 100:(0.2837) 101:(0.2863) \n",
      "\t\tProto:4 023:(0.1083) 024:(0.1782) 025:(0.1312) 100:(0.1443) 101:(0.1317) \n",
      "\t\tProto:8 023:(0.2444) 024:(0.2331) 025:(0.2521) 100:(0.2481) 101:(0.245) \n",
      "\t\tProto:9 023:(0.0958) 024:(0.0819) 025:(0.0938) 100:(0.1745) 101:(0.187) \n",
      "\t\tProto:14 023:(0.1321) 024:(0.0888) 025:(0.1336) 100:(0.072) 101:(0.1017) \n",
      "\t\tProto:15 023:(0.1374) 024:(0.178) 025:(0.1074) 100:(0.1866) 101:(0.1765) \n",
      "\t\tProto:16 023:(0.1559) 024:(0.2003) 025:(0.1618) 100:(0.2335) 101:(0.2526) \n",
      "\t\tProto:17 023:(0.1078) 024:(0.0752) 025:(0.1148) 100:(0.1221) 101:(0.1084) \n",
      "\t\tProto:18 023:(0.1933) 024:(0.257) 025:(0.1893) 100:(0.2101) 101:(0.2186) \n",
      "\t\tProto:19 023:(0.1421) 024:(0.1873) 025:(0.1601) 100:(0.1547) 101:(0.1569) \n",
      "\t\tProto:22 023:(0.1546) 024:(0.2267) 025:(0.2336) 100:(0.1805) 101:(0.1738) \n",
      "\t\tProto:23 023:(0.1411) 024:(0.1402) 025:(0.1002) 100:(0.0995) 101:(0.1004) \n",
      "\t\tProto:25 023:(0.1482) 024:(0.1565) 025:(0.1227) 100:(0.2067) 101:(0.1921) \n",
      "\t\tProto:28 023:(0.2156) 024:(0.3375) 025:(0.2318) 100:(0.3298) 101:(0.3085) \n",
      "\t\tProto:30 023:(0.1103) 024:(0.1013) 025:(0.1117) 100:(0.1106) 101:(0.0972) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 56.80it/s]  \n",
      "Collecting topk: 120it [00:03, 35.54it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 003+002 {0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15} --------------------\n",
      "-------------------- 003+002 {10, 3} --------------------\n",
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:0 001:(0.3028) 002:(0.3084) 003:(0.3648) \n",
      "\t\tProto:1 001:(0.1505) 002:(0.1261) 003:(0.177) \n",
      "\t\tProto:2 001:(0.5042) 002:(0.5208) 003:(0.4685) \n",
      "\t\tProto:4 001:(0.2533) 002:(0.2053) 003:(0.1917) \n",
      "\t\tProto:5 001:(0.1631) 002:(0.1917) 003:(0.198) \n",
      "\t\tProto:6 001:(0.2858) 002:(0.2974) 003:(0.3613) \n",
      "\t\tProto:7 001:(0.2562) 002:(0.2734) 003:(0.2436) \n",
      "\t\tProto:8 001:(0.3637) 002:(0.4024) 003:(0.3232) \n",
      "\t\tProto:9 001:(0.3752) 002:(0.3699) 003:(0.3156) \n",
      "\t\tProto:11 001:(0.2262) 002:(0.2257) 003:(0.1721) \n",
      "\t\tProto:12 001:(0.3038) 002:(0.2953) 003:(0.2286) \n",
      "\t\tProto:13 001:(0.061) 002:(0.0594) 003:(0.0588) \n",
      "\t\tProto:14 001:(0.3737) 002:(0.3852) 003:(0.385) \n",
      "\t\tProto:15 001:(0.1039) 002:(0.1336) 003:(0.1712) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:02, 50.66it/s]\n",
      "Collecting topk: 150it [00:03, 45.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 101+100 {0, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 023+025 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15} --------------------\n",
      "-------------------- 101+100 {1} --------------------\n",
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 100:(0.3484) 101:(0.3393) \n",
      "\t\tProto:2 100:(0.4537) 101:(0.4409) \n",
      "\t\tProto:3 100:(0.1882) 101:(0.2216) \n",
      "\t\tProto:4 100:(0.1349) 101:(0.1309) \n",
      "\t\tProto:5 100:(0.3607) 101:(0.3604) \n",
      "\t\tProto:6 100:(0.6033) 101:(0.6122) \n",
      "\t\tProto:7 100:(0.5145) 101:(0.5059) \n",
      "\t Child: 023+025\n",
      "\t\tProto:0 023:(0.4021) 024:(0.429) 025:(0.3951) \n",
      "\t\tProto:1 023:(0.0742) 024:(0.1135) 025:(0.0892) \n",
      "\t\tProto:2 023:(0.3214) 024:(0.2936) 025:(0.3174) \n",
      "\t\tProto:3 023:(0.181) 024:(0.1892) 025:(0.1712) \n",
      "\t\tProto:4 023:(0.1324) 024:(0.1568) 025:(0.1256) \n",
      "\t\tProto:5 023:(0.379) 024:(0.4195) 025:(0.3753) \n",
      "\t\tProto:6 023:(0.1426) 024:(0.1535) 025:(0.1252) \n",
      "\t\tProto:7 023:(0.2169) 024:(0.2839) 025:(0.2049) \n",
      "\t\tProto:8 023:(0.0985) 024:(0.1631) 025:(0.1043) \n",
      "\t\tProto:9 023:(0.0905) 024:(0.1481) 025:(0.1303) \n",
      "\t\tProto:10 023:(0.1168) 024:(0.1311) 025:(0.1078) \n",
      "\t\tProto:11 023:(0.0842) 024:(0.0752) 025:(0.0543) \n",
      "\t\tProto:12 023:(0.187) 024:(0.2161) 025:(0.1979) \n",
      "\t\tProto:13 023:(0.2662) 024:(0.2915) 025:(0.2461) \n",
      "\t\tProto:14 023:(0.0925) 024:(0.1414) 025:(0.1218) \n",
      "\t\tProto:15 023:(0.1272) 024:(0.1152) 025:(0.1467) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 45.60it/s]   \n",
      "Collecting topk: 90it [00:02, 32.62it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 002+001 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 001:(0.3646) 002:(0.3203) \n",
      "\t\tProto:1 001:(0.1896) 002:(0.1307) \n",
      "\t\tProto:2 001:(0.4698) 002:(0.4896) \n",
      "\t\tProto:3 001:(0.2519) 002:(0.1338) \n",
      "\t\tProto:4 001:(0.295) 002:(0.2186) \n",
      "\t\tProto:5 001:(0.5624) 002:(0.6117) \n",
      "\t\tProto:6 001:(0.0939) 002:(0.0987) \n",
      "\t\tProto:7 001:(0.7247) 002:(0.7253) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.68it/s]   \n",
      "Collecting topk: 90it [00:02, 31.59it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 025+024 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 024:(0.1927) 025:(0.1015) \n",
      "\t\tProto:1 024:(0.6212) 025:(0.5528) \n",
      "\t\tProto:2 024:(0.6922) 025:(0.5023) \n",
      "\t\tProto:3 024:(0.3868) 025:(0.2855) \n",
      "\t\tProto:4 024:(0.3179) 025:(0.3275) \n",
      "\t\tProto:5 024:(0.3436) 025:(0.3672) \n",
      "\t\tProto:6 024:(0.2117) 025:(0.2408) \n",
      "\t\tProto:7 024:(0.233) 025:(0.2451) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "# overlayed_image_np = get_heatmap(latent_activation, xs)\n",
    "# Image.fromarray(overlayed_image_np).show()\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            if coarse_label2name[ys.item()] != child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                _, softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written\n",
    "                    if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                        continue\n",
    "                        \n",
    "                    h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes_of_child_node.shape, patchsize, skip, h_idx, w_idx)\n",
    "                    latent_activation = softmaxes_of_child_node[:, p, :, :]\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) > topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                         (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "#                         bbox_coords = torch.tensor([[w_coor_min, h_coor_min, w_coor_max, h_coor_max]])\n",
    "#                         bb_image = torchvision.utils.draw_bounding_boxes((img_tensor * 255).type(torch.uint8), bbox_coords, colors='red') / 255\n",
    "#                         pdb.set_trace()\n",
    "                        patches.append(overlayed_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_heatmap_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_heatmap_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images after using UNIT-SPHERE with INTGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:03, 139.30it/s]\n",
      "Collecting topk: 540it [00:10, 52.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 052+053 {18, 11, 20, 13} --------------------\n",
      "-------------------- 004+086 {96, 1, 2, 39, 80, 83, 20, 53, 84, 30} --------------------\n",
      "-------------------- 052+053 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 19, 21, 22, 23} --------------------\n",
      "-------------------- 004+086 {0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103} --------------------\n",
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:18 050:(0.3252) 051:(0.5353) 052:(0.2734) 053:(0.6168) \n",
      "\t\tProto:11 050:(0.6663) 051:(0.6605) 052:(0.6597) 053:(0.3921) \n",
      "\t\tProto:20 050:(0.4929) 051:(0.5261) 052:(0.5124) 053:(0.2639) \n",
      "\t\tProto:13 050:(0.6151) 051:(0.601) 052:(0.5769) 053:(0.4078) \n",
      "\t Child: 004+086\n",
      "\t\tProto:96 001:(0.5186) 002:(0.5554) 003:(0.537) 004:(0.5865) 023:(0.5001) 024:(0.4837) 025:(0.5356) 031:(0.5793) 032:(0.5618) 033:(0.5359) 045:(0.5403) 086:(0.53) 100:(0.5318) 101:(0.5261) \n",
      "\t\tProto:1 001:(0.1845) 002:(0.1996) 003:(0.2003) 004:(0.2244) 023:(0.1933) 024:(0.1213) 025:(0.1735) 031:(0.2169) 032:(0.2157) 033:(0.208) 045:(0.175) 086:(0.162) 100:(0.1473) 101:(0.1277) \n",
      "\t\tProto:2 001:(0.3513) 002:(0.3484) 003:(0.2397) 004:(0.2627) 023:(0.3064) 024:(0.3176) 025:(0.2993) 031:(0.2784) 032:(0.1522) 033:(0.2109) 045:(0.2752) 086:(0.2481) 100:(0.3324) 101:(0.2867) \n",
      "\t\tProto:39 001:(0.1867) 002:(0.1941) 003:(0.2253) 004:(0.2522) 023:(0.1892) 024:(0.1348) 025:(0.1735) 031:(0.2374) 032:(0.2351) 033:(0.2591) 045:(0.178) 086:(0.1455) 100:(0.1725) 101:(0.1997) \n",
      "\t\tProto:80 001:(0.1435) 002:(0.1307) 003:(0.1606) 004:(0.1074) 023:(0.1337) 024:(0.1004) 025:(0.0952) 031:(0.1061) 032:(0.1088) 033:(0.1111) 045:(0.1606) 086:(0.1118) 100:(0.1074) 101:(0.114) \n",
      "\t\tProto:83 001:(0.2174) 002:(0.2176) 003:(0.2721) 004:(0.1713) 023:(0.2462) 024:(0.1456) 025:(0.1639) 031:(0.1787) 032:(0.173) 033:(0.1934) 045:(0.219) 086:(0.2074) 100:(0.1642) 101:(0.2054) \n",
      "\t\tProto:20 001:(0.371) 002:(0.3656) 003:(0.2691) 004:(0.3406) 023:(0.3008) 024:(0.3335) 025:(0.3132) 031:(0.2921) 032:(0.2883) 033:(0.3033) 045:(0.1861) 086:(0.2028) 100:(0.2771) 101:(0.1769) \n",
      "\t\tProto:53 001:(0.2871) 002:(0.2986) 003:(0.3536) 004:(0.4686) 023:(0.4287) 024:(0.4803) 025:(0.4827) 031:(0.3948) 032:(0.3632) 033:(0.3782) 045:(0.3457) 086:(0.2282) 100:(0.4699) 101:(0.3062) \n",
      "\t\tProto:84 001:(0.1401) 002:(0.1497) 003:(0.1278) 004:(0.1541) 023:(0.1643) 024:(0.1494) 025:(0.1617) 031:(0.1423) 032:(0.1003) 033:(0.1333) 045:(0.1396) 086:(0.1456) 100:(0.1332) 101:(0.1215) \n",
      "\t\tProto:30 001:(0.1312) 002:(0.1523) 003:(0.1409) 004:(0.1378) 023:(0.1285) 024:(0.0909) 025:(0.0899) 031:(0.1457) 032:(0.1384) 033:(0.142) 045:(0.1171) 086:(0.0991) 100:(0.1048) 101:(0.0996) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 67.10it/s]  \n",
      "Collecting topk: 120it [00:02, 40.47it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 053+050 {0, 4, 5, 7, 12} --------------------\n",
      "-------------------- 053+050 {1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:0 050:(0.6047) 051:(0.6608) 053:(0.497) \n",
      "\t\tProto:4 050:(0.7026) 051:(0.7391) 053:(0.7525) \n",
      "\t\tProto:5 050:(0.7816) 051:(0.8258) 053:(0.8018) \n",
      "\t\tProto:7 050:(0.3984) 051:(0.4429) 053:(0.4351) \n",
      "\t\tProto:12 050:(0.2848) 051:(0.3119) 053:(0.3928) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:03, 116.20it/s]\n",
      "Collecting topk: 420it [00:07, 57.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 004+032 {3, 6, 12, 19, 20} --------------------\n",
      "-------------------- 086+045 {33, 66, 6, 70, 22, 55, 29} --------------------\n",
      "-------------------- 004+032 {0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 23} --------------------\n",
      "-------------------- 086+045 {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71} --------------------\n",
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:3 004:(0.2836) 031:(0.3807) 032:(0.3586) 033:(0.401) \n",
      "\t\tProto:6 004:(0.3789) 031:(0.3858) 032:(0.3293) 033:(0.3943) \n",
      "\t\tProto:12 004:(0.6587) 031:(0.5948) 032:(0.5652) 033:(0.622) \n",
      "\t\tProto:19 004:(0.2785) 031:(0.4442) 032:(0.3468) 033:(0.444) \n",
      "\t\tProto:20 004:(0.443) 031:(0.6363) 032:(0.6039) 033:(0.6255) \n",
      "\t Child: 086+045\n",
      "\t\tProto:33 001:(0.2015) 002:(0.1894) 003:(0.2164) 023:(0.4279) 024:(0.4215) 025:(0.4418) 045:(0.1976) 086:(0.3946) 100:(0.235) 101:(0.2387) \n",
      "\t\tProto:66 001:(0.1454) 002:(0.1542) 003:(0.145) 023:(0.134) 024:(0.1393) 025:(0.1462) 045:(0.1903) 086:(0.1662) 100:(0.0983) 101:(0.1647) \n",
      "\t\tProto:6 001:(0.6476) 002:(0.6028) 003:(0.6048) 023:(0.5373) 024:(0.4772) 025:(0.5356) 045:(0.6097) 086:(0.5781) 100:(0.5748) 101:(0.5864) \n",
      "\t\tProto:70 001:(0.5572) 002:(0.5296) 003:(0.5298) 023:(0.4622) 024:(0.4249) 025:(0.4729) 045:(0.5301) 086:(0.4766) 100:(0.5149) 101:(0.5199) \n",
      "\t\tProto:22 001:(0.2772) 002:(0.2229) 003:(0.2409) 023:(0.2354) 024:(0.1885) 025:(0.2596) 045:(0.234) 086:(0.2801) 100:(0.2655) 101:(0.2613) \n",
      "\t\tProto:55 001:(0.2148) 002:(0.1423) 003:(0.1546) 023:(0.0786) 024:(0.0972) 025:(0.0629) 045:(0.1594) 086:(0.1622) 100:(0.1365) 101:(0.1361) \n",
      "\t\tProto:29 001:(0.1802) 002:(0.13) 003:(0.1375) 023:(0.177) 024:(0.184) 025:(0.1882) 045:(0.1345) 086:(0.2894) 100:(0.218) 101:(0.1694) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 56.86it/s]   \n",
      "Collecting topk: 90it [00:02, 36.29it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 050+051 {0, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 050+051 {1} --------------------\n",
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 050:(0.6674) 051:(0.7778) \n",
      "\t\tProto:2 050:(0.5409) 051:(0.5996) \n",
      "\t\tProto:3 050:(0.2594) 051:(0.1519) \n",
      "\t\tProto:4 050:(0.4809) 051:(0.4492) \n",
      "\t\tProto:5 050:(0.4087) 051:(0.2888) \n",
      "\t\tProto:6 050:(0.2898) 051:(0.3113) \n",
      "\t\tProto:7 050:(0.697) 051:(0.7704) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 66.84it/s]  \n",
      "Collecting topk: 120it [00:03, 39.48it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 032+033 {1, 3, 4, 7, 8, 12, 13, 15} --------------------\n",
      "-------------------- 032+033 {0, 2, 5, 6, 9, 10, 11, 14} --------------------\n",
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:1 031:(0.5949) 032:(0.6005) 033:(0.572) \n",
      "\t\tProto:3 031:(0.6483) 032:(0.5824) 033:(0.5745) \n",
      "\t\tProto:4 031:(0.2155) 032:(0.1376) 033:(0.226) \n",
      "\t\tProto:7 031:(0.3777) 032:(0.3478) 033:(0.3973) \n",
      "\t\tProto:8 031:(0.3584) 032:(0.3095) 033:(0.3489) \n",
      "\t\tProto:12 031:(0.5948) 032:(0.5497) 033:(0.5869) \n",
      "\t\tProto:13 031:(0.3872) 032:(0.2731) 033:(0.4023) \n",
      "\t\tProto:15 031:(0.411) 032:(0.372) 033:(0.3598) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:01, 173.03it/s] \n",
      "Collecting topk: 300it [00:07, 40.07it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+101 {4, 5, 9, 10, 17, 18, 19, 24, 25, 26, 27, 28, 31, 32, 34, 39, 41, 44, 45, 49, 50, 51, 58, 59, 60, 63} --------------------\n",
      "-------------------- 045+101 {0, 1, 2, 3, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 29, 30, 33, 35, 36, 37, 38, 40, 42, 43, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62} --------------------\n",
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:4 001:(0.1589) 002:(0.186) 003:(0.1694) 023:(0.1542) 024:(0.1969) 025:(0.1824) 045:(0.1522) 100:(0.2369) 101:(0.2297) \n",
      "\t\tProto:5 001:(0.1494) 002:(0.1391) 003:(0.1762) 023:(0.1863) 024:(0.2087) 025:(0.1885) 045:(0.1265) 100:(0.2072) 101:(0.1212) \n",
      "\t\tProto:9 001:(0.256) 002:(0.262) 003:(0.2457) 023:(0.2511) 024:(0.2622) 025:(0.2516) 045:(0.251) 100:(0.2718) 101:(0.2629) \n",
      "\t\tProto:10 001:(0.2107) 002:(0.2178) 003:(0.232) 023:(0.2316) 024:(0.2357) 025:(0.2214) 045:(0.2081) 100:(0.2348) 101:(0.2061) \n",
      "\t\tProto:17 001:(0.1937) 002:(0.1928) 003:(0.1941) 023:(0.194) 024:(0.1932) 025:(0.1918) 045:(0.1939) 100:(0.1923) 101:(0.1894) \n",
      "\t\tProto:18 001:(0.275) 002:(0.2834) 003:(0.2771) 023:(0.2841) 024:(0.2977) 025:(0.2752) 045:(0.2547) 100:(0.2892) 101:(0.2669) \n",
      "\t\tProto:19 001:(0.1337) 002:(0.1215) 003:(0.142) 023:(0.1678) 024:(0.1835) 025:(0.1704) 045:(0.1251) 100:(0.1883) 101:(0.1258) \n",
      "\t\tProto:24 001:(0.114) 002:(0.1215) 003:(0.1177) 023:(0.1184) 024:(0.1516) 025:(0.1144) 045:(0.1126) 100:(0.1739) 101:(0.1619) \n",
      "\t\tProto:25 001:(0.1349) 002:(0.1373) 003:(0.1361) 023:(0.1491) 024:(0.1937) 025:(0.1574) 045:(0.1475) 100:(0.1457) 101:(0.1352) \n",
      "\t\tProto:26 001:(0.2344) 002:(0.2658) 003:(0.2424) 023:(0.1632) 024:(0.1591) 025:(0.1563) 045:(0.2658) 100:(0.1191) 101:(0.2188) \n",
      "\t\tProto:27 001:(0.214) 002:(0.2118) 003:(0.2167) 023:(0.216) 024:(0.2114) 025:(0.2069) 045:(0.2164) 100:(0.2093) 101:(0.2075) \n",
      "\t\tProto:28 001:(0.1505) 002:(0.1968) 003:(0.2358) 023:(0.2494) 024:(0.2778) 025:(0.2522) 045:(0.1271) 100:(0.2821) 101:(0.1802) \n",
      "\t\tProto:31 001:(0.1677) 002:(0.1662) 003:(0.1741) 023:(0.1682) 024:(0.173) 025:(0.1626) 045:(0.1557) 100:(0.1752) 101:(0.1653) \n",
      "\t\tProto:32 001:(0.1242) 002:(0.1149) 003:(0.1224) 023:(0.1603) 024:(0.1713) 025:(0.1659) 045:(0.1187) 100:(0.1305) 101:(0.1125) \n",
      "\t\tProto:34 001:(0.1257) 002:(0.1397) 003:(0.1468) 023:(0.1595) 024:(0.1626) 025:(0.1377) 045:(0.1022) 100:(0.158) 101:(0.0869) \n",
      "\t\tProto:39 001:(0.1452) 002:(0.1431) 003:(0.1456) 023:(0.1235) 024:(0.0996) 025:(0.1055) 045:(0.1334) 100:(0.1847) 101:(0.1943) \n",
      "\t\tProto:41 001:(0.192) 002:(0.1915) 003:(0.2117) 023:(0.2024) 024:(0.2156) 025:(0.2033) 045:(0.1569) 100:(0.2043) 101:(0.1444) \n",
      "\t\tProto:44 001:(0.0992) 002:(0.0946) 003:(0.1384) 023:(0.1883) 024:(0.1939) 025:(0.1761) 045:(0.0906) 100:(0.2725) 101:(0.2586) \n",
      "\t\tProto:45 001:(0.1217) 002:(0.1189) 003:(0.1126) 023:(0.12) 024:(0.1146) 025:(0.1095) 045:(0.0962) 100:(0.1162) 101:(0.1119) \n",
      "\t\tProto:49 001:(0.1669) 002:(0.1555) 003:(0.1196) 023:(0.1199) 024:(0.1411) 025:(0.1056) 045:(0.0847) 100:(0.1884) 101:(0.1738) \n",
      "\t\tProto:50 001:(0.2135) 002:(0.2082) 003:(0.2042) 023:(0.2131) 024:(0.2257) 025:(0.2081) 045:(0.206) 100:(0.2331) 101:(0.2053) \n",
      "\t\tProto:51 001:(0.2632) 002:(0.2352) 003:(0.2921) 023:(0.3311) 024:(0.3562) 025:(0.3152) 045:(0.1829) 100:(0.3254) 101:(0.2207) \n",
      "\t\tProto:58 001:(0.1623) 002:(0.1429) 003:(0.1435) 023:(0.1478) 024:(0.1667) 025:(0.1464) 045:(0.1497) 100:(0.1697) 101:(0.1694) \n",
      "\t\tProto:59 001:(0.19) 002:(0.1911) 003:(0.1854) 023:(0.1818) 024:(0.1904) 025:(0.1874) 045:(0.1857) 100:(0.1913) 101:(0.1873) \n",
      "\t\tProto:60 001:(0.2125) 002:(0.193) 003:(0.2379) 023:(0.2547) 024:(0.2564) 025:(0.1987) 045:(0.1527) 100:(0.2522) 101:(0.1755) \n",
      "\t\tProto:63 001:(0.3816) 002:(0.3861) 003:(0.3746) 023:(0.3757) 024:(0.3978) 025:(0.3795) 045:(0.373) 100:(0.4077) 101:(0.3873) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 54.71it/s]   \n",
      "Collecting topk: 90it [00:02, 36.45it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 033+031 {0, 2, 3, 4, 6} --------------------\n",
      "-------------------- 033+031 {1, 5, 7} --------------------\n",
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(0.4821) 033:(0.4657) \n",
      "\t\tProto:2 031:(0.877) 033:(0.8533) \n",
      "\t\tProto:3 031:(0.476) 033:(0.4541) \n",
      "\t\tProto:4 031:(0.6427) 033:(0.6106) \n",
      "\t\tProto:6 031:(0.778) 033:(0.7333) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:03, 73.97it/s]\n",
      "Collecting topk: 270it [00:04, 63.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+003 {2, 5, 8, 12, 14, 19} --------------------\n",
      "-------------------- 101+023 {4, 10, 16, 17, 18, 19, 28, 31} --------------------\n",
      "-------------------- 045+003 {0, 1, 3, 4, 6, 7, 9, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23} --------------------\n",
      "-------------------- 101+023 {0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30} --------------------\n",
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:2 001:(0.5596) 002:(0.5588) 003:(0.5632) 045:(0.5319) \n",
      "\t\tProto:5 001:(0.5105) 002:(0.5156) 003:(0.502) 045:(0.5146) \n",
      "\t\tProto:8 001:(0.3184) 002:(0.3117) 003:(0.3185) 045:(0.3157) \n",
      "\t\tProto:12 001:(0.4434) 002:(0.4419) 003:(0.4425) 045:(0.4245) \n",
      "\t\tProto:14 001:(0.5768) 002:(0.6344) 003:(0.5285) 045:(0.6534) \n",
      "\t\tProto:19 001:(0.6378) 002:(0.6402) 003:(0.6384) 045:(0.6585) \n",
      "\t Child: 101+023\n",
      "\t\tProto:4 023:(0.5292) 024:(0.5859) 025:(0.4831) 100:(0.7277) 101:(0.7226) \n",
      "\t\tProto:10 023:(0.2665) 024:(0.2643) 025:(0.2599) 100:(0.3563) 101:(0.3485) \n",
      "\t\tProto:16 023:(0.582) 024:(0.5716) 025:(0.5917) 100:(0.3794) 101:(0.3221) \n",
      "\t\tProto:17 023:(0.3074) 024:(0.3229) 025:(0.3237) 100:(0.2917) 101:(0.2726) \n",
      "\t\tProto:18 023:(0.2331) 024:(0.2622) 025:(0.25) 100:(0.2687) 101:(0.2239) \n",
      "\t\tProto:19 023:(0.2899) 024:(0.3111) 025:(0.3092) 100:(0.4103) 101:(0.4207) \n",
      "\t\tProto:28 023:(0.2479) 024:(0.2577) 025:(0.255) 100:(0.0953) 101:(0.0942) \n",
      "\t\tProto:31 023:(0.1985) 024:(0.1925) 025:(0.1904) 100:(0.1559) 101:(0.1724) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 70.25it/s]  \n",
      "Collecting topk: 120it [00:03, 39.70it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 003+002 {0, 8, 14, 7} --------------------\n",
      "-------------------- 003+002 {1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15} --------------------\n",
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:0 001:(0.8339) 002:(0.8155) 003:(0.8298) \n",
      "\t\tProto:8 001:(0.6134) 002:(0.6258) 003:(0.6797) \n",
      "\t\tProto:14 001:(0.6222) 002:(0.6239) 003:(0.5564) \n",
      "\t\tProto:7 001:(0.7661) 002:(0.7521) 003:(0.7208) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:02, 57.17it/s]\n",
      "Collecting topk: 150it [00:03, 49.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 101+100 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 023+025 {2, 3, 4, 6, 12} --------------------\n",
      "-------------------- 023+025 {0, 1, 5, 7, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 100:(0.2876) 101:(0.3614) \n",
      "\t\tProto:1 100:(0.7379) 101:(0.7317) \n",
      "\t\tProto:2 100:(0.7684) 101:(0.7555) \n",
      "\t\tProto:3 100:(0.2336) 101:(0.2127) \n",
      "\t\tProto:4 100:(0.4767) 101:(0.4516) \n",
      "\t\tProto:5 100:(0.5537) 101:(0.5466) \n",
      "\t\tProto:6 100:(0.7228) 101:(0.7082) \n",
      "\t\tProto:7 100:(0.2817) 101:(0.3799) \n",
      "\t Child: 023+025\n",
      "\t\tProto:2 023:(0.7737) 024:(0.7581) 025:(0.7624) \n",
      "\t\tProto:3 023:(0.4728) 024:(0.5089) 025:(0.4773) \n",
      "\t\tProto:4 023:(0.3758) 024:(0.4067) 025:(0.3565) \n",
      "\t\tProto:6 023:(0.4754) 024:(0.5072) 025:(0.4805) \n",
      "\t\tProto:12 023:(0.5061) 024:(0.5009) 025:(0.5033) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 50.58it/s]   \n",
      "Collecting topk: 90it [00:02, 35.60it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 002+001 {0, 1, 2, 3, 7} --------------------\n",
      "-------------------- 002+001 {4, 5, 6} --------------------\n",
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 001:(0.5638) 002:(0.562) \n",
      "\t\tProto:1 001:(0.4708) 002:(0.4649) \n",
      "\t\tProto:2 001:(0.7616) 002:(0.7513) \n",
      "\t\tProto:3 001:(0.2725) 002:(0.2667) \n",
      "\t\tProto:7 001:(0.8984) 002:(0.9141) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 54.36it/s]   \n",
      "Collecting topk: 90it [00:02, 37.54it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 025+024 {0, 1, 3, 4, 5, 7} --------------------\n",
      "-------------------- 025+024 {2, 6} --------------------\n",
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 024:(0.5906) 025:(0.626) \n",
      "\t\tProto:1 024:(0.2673) 025:(0.2632) \n",
      "\t\tProto:3 024:(0.8024) 025:(0.5746) \n",
      "\t\tProto:4 024:(0.6648) 025:(0.5593) \n",
      "\t\tProto:5 024:(0.4814) 025:(0.4915) \n",
      "\t\tProto:7 024:(0.855) 025:(0.7984) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "from captum.attr import (\n",
    "    GradientShap,\n",
    "    DeepLift,\n",
    "    DeepLiftShap,\n",
    "    IntegratedGradients,\n",
    "    LayerConductance,\n",
    "    NeuronConductance,\n",
    "    NoiseTunnel,\n",
    ")\n",
    "\n",
    "class TempModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, model, node_name, child_name, proto_idx):\n",
    "        super().__init__()\n",
    "        self.node_name = node_name\n",
    "        self.child_name = child_name\n",
    "        self.proto_idx = proto_idx\n",
    "        self.temp_model = model\n",
    "        \n",
    "    def forward(self, input):\n",
    "        _, softmaxes, pooled, _ = self.temp_model(input, inference=False)\n",
    "        pooled = pooled[self.node_name][self.child_name]#.squeeze(0)\n",
    "        return pooled[:, self.proto_idx]\n",
    "\n",
    "def get_intgrad(model, node_name, child_name, proto_idx, input_image):\n",
    "    tempModel = TempModel(model, node.name, child_name, proto_idx=proto_idx)\n",
    "    baseline = torch.zeros_like(input_image)\n",
    "    ig = IntegratedGradients(tempModel)\n",
    "    attributions = ig.attribute(input_image, baseline, target=None, return_convergence_delta=False, n_steps=50)\n",
    "    cum_attributions = attributions.sum(dim=1, keepdim=True)\n",
    "    cum_attributions = cum_attributions.repeat(1, 3, 1, 1)\n",
    "    pos_attribution = cum_attributions.abs()\n",
    "    pos_attribution = (pos_attribution - pos_attribution.min()) / (pos_attribution.max() - pos_attribution.min())\n",
    "    pos_attribution_np = (pos_attribution.squeeze(0).permute(1, 2, 0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    return pos_attribution_np\n",
    "\n",
    "\n",
    "# overlayed_image_np = get_heatmap(latent_activation, xs)\n",
    "# Image.fromarray(overlayed_image_np).show()\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            if coarse_label2name[ys.item()] != child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                _, softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written\n",
    "                    if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                        continue\n",
    "                        \n",
    "                    h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes_of_child_node.shape, patchsize, skip, h_idx, w_idx)\n",
    "                    latent_activation = softmaxes_of_child_node[:, p, :, :]\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation, xs))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                         (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation, xs))\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 # 3x the width of a patch\n",
    "#                 pdb.set_trace()\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation, img_tensor = ele\n",
    "                        \n",
    "                        attribution = get_intgrad(net, node.name, child_classname, p, img_tensor)\n",
    "                        attribution = torch.tensor(attribution).permute(2, 0, 1).float() / 255.\n",
    "                        img_tensor = (img_tensor - img_tensor.min()) / (img_tensor.max() - img_tensor.min())\n",
    "                        patches.append(img_tensor.detach().cpu().squeeze())\n",
    "                        patches.append(attribution.detach().cpu())\n",
    "#                         pdb.set_trace()\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=(2*topk), padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_intgrad2_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_intgrad2_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "print('Elapsed time', int(elapsed_time // 60), 'mins', int(elapsed_time % 60), 'secs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images after using UNIT-SPHERE with HEAT MAPS using TESTLOADER(CROPPED IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 511it [00:08, 59.57it/s]\n",
      "Collecting topk: 511it [00:09, 51.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 052+053 {18, 11, 20, 13} --------------------\n",
      "-------------------- 004+086 {96, 1, 2, 39, 80, 83, 20, 53, 84, 30} --------------------\n",
      "-------------------- 052+053 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 19, 21, 22, 23} --------------------\n",
      "-------------------- 004+086 {0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103} --------------------\n",
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:18 050:(0.4618) 051:(0.5204) 052:(0.3459) 053:(0.6431) \n",
      "\t\tProto:11 050:(0.7271) 051:(0.7194) 052:(0.7297) 053:(0.6985) \n",
      "\t\tProto:20 050:(0.6863) 051:(0.6889) 052:(0.6938) 053:(0.6065) \n",
      "\t\tProto:13 050:(0.678) 051:(0.6777) 052:(0.6856) 053:(0.6566) \n",
      "\t Child: 004+086\n",
      "\t\tProto:96 001:(0.5838) 002:(0.5599) 003:(0.5794) 004:(0.6281) 023:(0.5187) 024:(0.5051) 025:(0.5527) 031:(0.6018) 032:(0.5655) 033:(0.5712) 045:(0.5965) 086:(0.5716) 100:(0.5695) 101:(0.4969) \n",
      "\t\tProto:1 001:(0.2276) 002:(0.2105) 003:(0.2251) 004:(0.2353) 023:(0.1753) 024:(0.1551) 025:(0.1883) 031:(0.2248) 032:(0.2217) 033:(0.2299) 045:(0.1769) 086:(0.1749) 100:(0.1826) 101:(0.1293) \n",
      "\t\tProto:2 001:(0.3527) 002:(0.3504) 003:(0.2293) 004:(0.3033) 023:(0.3129) 024:(0.3014) 025:(0.3452) 031:(0.2355) 032:(0.2461) 033:(0.2582) 045:(0.3094) 086:(0.2951) 100:(0.3405) 101:(0.3101) \n",
      "\t\tProto:39 001:(0.2005) 002:(0.1943) 003:(0.2524) 004:(0.24) 023:(0.183) 024:(0.1256) 025:(0.1943) 031:(0.2648) 032:(0.2049) 033:(0.243) 045:(0.2048) 086:(0.1503) 100:(0.2067) 101:(0.2193) \n",
      "\t\tProto:80 001:(0.1409) 002:(0.1439) 003:(0.157) 004:(0.1102) 023:(0.1331) 024:(0.0983) 025:(0.1059) 031:(0.1138) 032:(0.0983) 033:(0.1149) 045:(0.1628) 086:(0.1213) 100:(0.1167) 101:(0.109) \n",
      "\t\tProto:83 001:(0.2367) 002:(0.24) 003:(0.2726) 004:(0.1697) 023:(0.216) 024:(0.1479) 025:(0.1657) 031:(0.1787) 032:(0.1454) 033:(0.1683) 045:(0.2425) 086:(0.2299) 100:(0.2132) 101:(0.2074) \n",
      "\t\tProto:20 001:(0.3614) 002:(0.3642) 003:(0.2682) 004:(0.3475) 023:(0.2909) 024:(0.3002) 025:(0.3272) 031:(0.3091) 032:(0.323) 033:(0.3397) 045:(0.2248) 086:(0.2164) 100:(0.2823) 101:(0.1724) \n",
      "\t\tProto:53 001:(0.3899) 002:(0.3949) 003:(0.3827) 004:(0.4669) 023:(0.4392) 024:(0.4503) 025:(0.475) 031:(0.4045) 032:(0.3778) 033:(0.4199) 045:(0.3881) 086:(0.3067) 100:(0.4665) 101:(0.2375) \n",
      "\t\tProto:84 001:(0.1423) 002:(0.1432) 003:(0.1483) 004:(0.1492) 023:(0.1408) 024:(0.1304) 025:(0.1623) 031:(0.1369) 032:(0.1237) 033:(0.1269) 045:(0.1494) 086:(0.1498) 100:(0.1528) 101:(0.1064) \n",
      "\t\tProto:30 001:(0.1455) 002:(0.155) 003:(0.1504) 004:(0.1485) 023:(0.1206) 024:(0.1062) 025:(0.1204) 031:(0.1565) 032:(0.1413) 033:(0.1567) 045:(0.1302) 086:(0.1164) 100:(0.1202) 101:(0.1039) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 69.57it/s]  \n",
      "Collecting topk: 120it [00:03, 39.36it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 053+050 {0, 4, 5, 7, 12} --------------------\n",
      "-------------------- 053+050 {1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:0 050:(0.6791) 051:(0.6777) 053:(0.6484) \n",
      "\t\tProto:4 050:(0.7826) 051:(0.7892) 053:(0.7844) \n",
      "\t\tProto:5 050:(0.8235) 051:(0.8266) 053:(0.8328) \n",
      "\t\tProto:7 050:(0.4925) 051:(0.491) 053:(0.4968) \n",
      "\t\tProto:12 050:(0.2689) 051:(0.2873) 053:(0.3726) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 391it [00:03, 109.12it/s]\n",
      "Collecting topk: 391it [00:06, 56.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 004+032 {3, 6, 12, 19, 20} --------------------\n",
      "-------------------- 086+045 {33, 66, 6, 70, 22, 55, 29} --------------------\n",
      "-------------------- 004+032 {0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 23} --------------------\n",
      "-------------------- 086+045 {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71} --------------------\n",
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:3 004:(0.3251) 031:(0.4058) 032:(0.382) 033:(0.4083) \n",
      "\t\tProto:6 004:(0.4143) 031:(0.4059) 032:(0.3932) 033:(0.4148) \n",
      "\t\tProto:12 004:(0.7041) 031:(0.6118) 032:(0.6323) 033:(0.6462) \n",
      "\t\tProto:19 004:(0.3293) 031:(0.4534) 032:(0.4261) 033:(0.4699) \n",
      "\t\tProto:20 004:(0.4916) 031:(0.6235) 032:(0.6342) 033:(0.6234) \n",
      "\t Child: 086+045\n",
      "\t\tProto:33 001:(0.2491) 002:(0.2267) 003:(0.2567) 023:(0.4481) 024:(0.4277) 025:(0.4451) 045:(0.2582) 086:(0.3702) 100:(0.2485) 101:(0.2449) \n",
      "\t\tProto:66 001:(0.1433) 002:(0.1762) 003:(0.1753) 023:(0.1417) 024:(0.1205) 025:(0.1406) 045:(0.1975) 086:(0.1809) 100:(0.126) 101:(0.1853) \n",
      "\t\tProto:6 001:(0.6391) 002:(0.643) 003:(0.633) 023:(0.5949) 024:(0.5129) 025:(0.5756) 045:(0.6428) 086:(0.6082) 100:(0.6169) 101:(0.6084) \n",
      "\t\tProto:70 001:(0.5648) 002:(0.5568) 003:(0.5542) 023:(0.5137) 024:(0.4631) 025:(0.5097) 045:(0.5541) 086:(0.5076) 100:(0.5404) 101:(0.5445) \n",
      "\t\tProto:22 001:(0.2801) 002:(0.2502) 003:(0.2694) 023:(0.2897) 024:(0.2107) 025:(0.2704) 045:(0.2742) 086:(0.3132) 100:(0.2902) 101:(0.2902) \n",
      "\t\tProto:55 001:(0.1975) 002:(0.1577) 003:(0.1666) 023:(0.1501) 024:(0.0951) 025:(0.1129) 045:(0.1928) 086:(0.2062) 100:(0.1653) 101:(0.1462) \n",
      "\t\tProto:29 001:(0.1481) 002:(0.1493) 003:(0.144) 023:(0.2269) 024:(0.1778) 025:(0.1939) 045:(0.174) 086:(0.3027) 100:(0.2354) 101:(0.1809) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 52.44it/s]   \n",
      "Collecting topk: 90it [00:02, 36.80it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 050+051 {0, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 050+051 {1} --------------------\n",
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 050:(0.8348) 051:(0.8364) \n",
      "\t\tProto:2 050:(0.6577) 051:(0.656) \n",
      "\t\tProto:3 050:(0.3862) 051:(0.3707) \n",
      "\t\tProto:4 050:(0.5644) 051:(0.5372) \n",
      "\t\tProto:5 050:(0.4896) 051:(0.4815) \n",
      "\t\tProto:6 050:(0.3676) 051:(0.3613) \n",
      "\t\tProto:7 050:(0.7988) 051:(0.7947) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 112it [00:01, 69.74it/s]  \n",
      "Collecting topk: 112it [00:02, 38.44it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 032+033 {1, 3, 4, 7, 8, 12, 13, 15} --------------------\n",
      "-------------------- 032+033 {0, 2, 5, 6, 9, 10, 11, 14} --------------------\n",
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:1 031:(0.6114) 032:(0.5936) 033:(0.586) \n",
      "\t\tProto:3 031:(0.6392) 032:(0.6139) 033:(0.5689) \n",
      "\t\tProto:4 031:(0.2147) 032:(0.1706) 033:(0.2282) \n",
      "\t\tProto:7 031:(0.3888) 032:(0.3991) 033:(0.3902) \n",
      "\t\tProto:8 031:(0.3568) 032:(0.3329) 033:(0.3483) \n",
      "\t\tProto:12 031:(0.5962) 032:(0.5996) 033:(0.5912) \n",
      "\t\tProto:13 031:(0.3974) 032:(0.3179) 033:(0.3922) \n",
      "\t\tProto:15 031:(0.4199) 032:(0.388) 033:(0.3779) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 279it [00:01, 155.95it/s] \n",
      "Collecting topk: 279it [00:06, 40.57it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+101 {4, 5, 9, 10, 17, 18, 19, 24, 25, 26, 27, 28, 31, 32, 34, 39, 41, 44, 45, 49, 50, 51, 58, 59, 60, 63} --------------------\n",
      "-------------------- 045+101 {0, 1, 2, 3, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 29, 30, 33, 35, 36, 37, 38, 40, 42, 43, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62} --------------------\n",
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:4 001:(0.1774) 002:(0.188) 003:(0.1754) 023:(0.1716) 024:(0.1778) 025:(0.1977) 045:(0.1742) 100:(0.2529) 101:(0.2276) \n",
      "\t\tProto:5 001:(0.1832) 002:(0.1905) 003:(0.1878) 023:(0.2073) 024:(0.2163) 025:(0.2441) 045:(0.1608) 100:(0.2171) 101:(0.1204) \n",
      "\t\tProto:9 001:(0.2488) 002:(0.2416) 003:(0.2422) 023:(0.2666) 024:(0.2641) 025:(0.2605) 045:(0.2169) 100:(0.2409) 101:(0.2188) \n",
      "\t\tProto:10 001:(0.2131) 002:(0.2182) 003:(0.2267) 023:(0.2403) 024:(0.2333) 025:(0.2447) 045:(0.2058) 100:(0.247) 101:(0.1487) \n",
      "\t\tProto:17 001:(0.1893) 002:(0.1851) 003:(0.1904) 023:(0.1742) 024:(0.1731) 025:(0.1706) 045:(0.1733) 100:(0.1633) 101:(0.1244) \n",
      "\t\tProto:18 001:(0.2682) 002:(0.2894) 003:(0.2643) 023:(0.2836) 024:(0.2861) 025:(0.2907) 045:(0.2328) 100:(0.2466) 101:(0.1916) \n",
      "\t\tProto:19 001:(0.1306) 002:(0.1291) 003:(0.1358) 023:(0.1624) 024:(0.1684) 025:(0.1886) 045:(0.1324) 100:(0.184) 101:(0.1133) \n",
      "\t\tProto:24 001:(0.1126) 002:(0.1127) 003:(0.1165) 023:(0.1133) 024:(0.1504) 025:(0.1373) 045:(0.1066) 100:(0.177) 101:(0.1784) \n",
      "\t\tProto:25 001:(0.1577) 002:(0.1513) 003:(0.1541) 023:(0.1492) 024:(0.1813) 025:(0.1691) 045:(0.1735) 100:(0.1559) 101:(0.1384) \n",
      "\t\tProto:26 001:(0.2628) 002:(0.2991) 003:(0.3013) 023:(0.1843) 024:(0.1646) 025:(0.1708) 045:(0.3182) 100:(0.1549) 101:(0.2477) \n",
      "\t\tProto:27 001:(0.2062) 002:(0.1959) 003:(0.2096) 023:(0.1757) 024:(0.1709) 025:(0.177) 045:(0.1861) 100:(0.1712) 101:(0.1431) \n",
      "\t\tProto:28 001:(0.2776) 002:(0.2736) 003:(0.2838) 023:(0.2912) 024:(0.2891) 025:(0.3059) 045:(0.2538) 100:(0.3071) 101:(0.1798) \n",
      "\t\tProto:31 001:(0.1478) 002:(0.1371) 003:(0.1527) 023:(0.1601) 024:(0.167) 025:(0.177) 045:(0.1464) 100:(0.1658) 101:(0.1276) \n",
      "\t\tProto:32 001:(0.166) 002:(0.1592) 003:(0.1474) 023:(0.1728) 024:(0.1734) 025:(0.1715) 045:(0.1455) 100:(0.1383) 101:(0.1043) \n",
      "\t\tProto:34 001:(0.1509) 002:(0.1453) 003:(0.1502) 023:(0.1623) 024:(0.1548) 025:(0.1725) 045:(0.1256) 100:(0.1616) 101:(0.0801) \n",
      "\t\tProto:39 001:(0.1554) 002:(0.1499) 003:(0.1642) 023:(0.129) 024:(0.1036) 025:(0.131) 045:(0.1443) 100:(0.1927) 101:(0.2076) \n",
      "\t\tProto:41 001:(0.2237) 002:(0.2049) 003:(0.2254) 023:(0.2) 024:(0.2112) 025:(0.2069) 045:(0.1957) 100:(0.2072) 101:(0.1492) \n",
      "\t\tProto:44 001:(0.1413) 002:(0.1381) 003:(0.1569) 023:(0.1995) 024:(0.2018) 025:(0.2052) 045:(0.1366) 100:(0.272) 101:(0.2552) \n",
      "\t\tProto:45 001:(0.1217) 002:(0.127) 003:(0.1265) 023:(0.1172) 024:(0.1171) 025:(0.1241) 045:(0.1197) 100:(0.1196) 101:(0.1095) \n",
      "\t\tProto:49 001:(0.1633) 002:(0.1524) 003:(0.121) 023:(0.1083) 024:(0.1393) 025:(0.1322) 045:(0.0981) 100:(0.1885) 101:(0.1852) \n",
      "\t\tProto:50 001:(0.2252) 002:(0.2241) 003:(0.2101) 023:(0.2362) 024:(0.2321) 025:(0.2269) 045:(0.196) 100:(0.2144) 101:(0.1731) \n",
      "\t\tProto:51 001:(0.3285) 002:(0.2932) 003:(0.3392) 023:(0.3363) 024:(0.3479) 025:(0.3586) 045:(0.2578) 100:(0.3356) 101:(0.2304) \n",
      "\t\tProto:58 001:(0.1809) 002:(0.1767) 003:(0.1724) 023:(0.1756) 024:(0.1639) 025:(0.1806) 045:(0.1599) 100:(0.1825) 101:(0.1777) \n",
      "\t\tProto:59 001:(0.1852) 002:(0.1773) 003:(0.1808) 023:(0.183) 024:(0.181) 025:(0.1746) 045:(0.1698) 100:(0.1717) 101:(0.1501) \n",
      "\t\tProto:60 001:(0.2557) 002:(0.2535) 003:(0.2627) 023:(0.2713) 024:(0.2666) 025:(0.2706) 045:(0.2111) 100:(0.2835) 101:(0.1854) \n",
      "\t\tProto:63 001:(0.3765) 002:(0.3814) 003:(0.3524) 023:(0.394) 024:(0.4009) 025:(0.394) 045:(0.3247) 100:(0.3512) 101:(0.3026) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 82it [00:01, 49.34it/s]   \n",
      "Collecting topk: 82it [00:02, 32.90it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 033+031 {0, 2, 3, 4, 6} --------------------\n",
      "-------------------- 033+031 {1, 5, 7} --------------------\n",
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(0.4852) 033:(0.4863) \n",
      "\t\tProto:2 031:(0.8887) 033:(0.8873) \n",
      "\t\tProto:3 031:(0.4811) 033:(0.4613) \n",
      "\t\tProto:4 031:(0.6527) 033:(0.6378) \n",
      "\t\tProto:6 031:(0.802) 033:(0.7598) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 249it [00:03, 69.04it/s]\n",
      "Collecting topk: 249it [00:03, 64.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+003 {2, 5, 8, 12, 14, 19} --------------------\n",
      "-------------------- 101+023 {4, 10, 16, 17, 18, 19, 28, 31} --------------------\n",
      "-------------------- 045+003 {0, 1, 3, 4, 6, 7, 9, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23} --------------------\n",
      "-------------------- 101+023 {0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30} --------------------\n",
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:2 001:(0.5795) 002:(0.5885) 003:(0.5975) 045:(0.5992) \n",
      "\t\tProto:5 001:(0.5147) 002:(0.5196) 003:(0.5127) 045:(0.5291) \n",
      "\t\tProto:8 001:(0.3262) 002:(0.3191) 003:(0.3297) 045:(0.339) \n",
      "\t\tProto:12 001:(0.4582) 002:(0.4517) 003:(0.463) 045:(0.4572) \n",
      "\t\tProto:14 001:(0.5994) 002:(0.6803) 003:(0.5729) 045:(0.6781) \n",
      "\t\tProto:19 001:(0.6477) 002:(0.6367) 003:(0.6452) 045:(0.6611) \n",
      "\t Child: 101+023\n",
      "\t\tProto:4 023:(0.5377) 024:(0.5882) 025:(0.5179) 100:(0.72) 101:(0.7124) \n",
      "\t\tProto:10 023:(0.2621) 024:(0.263) 025:(0.2704) 100:(0.3515) 101:(0.347) \n",
      "\t\tProto:16 023:(0.5871) 024:(0.5698) 025:(0.5829) 100:(0.3833) 101:(0.3098) \n",
      "\t\tProto:17 023:(0.3164) 024:(0.3239) 025:(0.3304) 100:(0.2917) 101:(0.2739) \n",
      "\t\tProto:18 023:(0.2438) 024:(0.2503) 025:(0.2787) 100:(0.2605) 101:(0.1953) \n",
      "\t\tProto:19 023:(0.2996) 024:(0.2921) 025:(0.3525) 100:(0.4057) 101:(0.4069) \n",
      "\t\tProto:28 023:(0.2469) 024:(0.2466) 025:(0.2493) 100:(0.1041) 101:(0.0933) \n",
      "\t\tProto:31 023:(0.2005) 024:(0.1984) 025:(0.203) 100:(0.1612) 101:(0.1667) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 118it [00:01, 66.76it/s]  \n",
      "Collecting topk: 118it [00:03, 37.38it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 003+002 {0, 8, 14, 7} --------------------\n",
      "-------------------- 003+002 {1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15} --------------------\n",
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:0 001:(0.8434) 002:(0.8354) 003:(0.8422) \n",
      "\t\tProto:8 001:(0.6671) 002:(0.6606) 003:(0.7073) \n",
      "\t\tProto:14 001:(0.6186) 002:(0.6222) 003:(0.5863) \n",
      "\t\tProto:7 001:(0.7726) 002:(0.761) 003:(0.7391) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 131it [00:02, 54.44it/s]\n",
      "Collecting topk: 131it [00:02, 47.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 101+100 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 023+025 {2, 3, 4, 6, 12} --------------------\n",
      "-------------------- 023+025 {0, 1, 5, 7, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 100:(0.3725) 101:(0.3737) \n",
      "\t\tProto:1 100:(0.7456) 101:(0.7412) \n",
      "\t\tProto:2 100:(0.7728) 101:(0.762) \n",
      "\t\tProto:3 100:(0.2321) 101:(0.2167) \n",
      "\t\tProto:4 100:(0.4949) 101:(0.4492) \n",
      "\t\tProto:5 100:(0.5602) 101:(0.5552) \n",
      "\t\tProto:6 100:(0.7284) 101:(0.7083) \n",
      "\t\tProto:7 100:(0.3563) 101:(0.4221) \n",
      "\t Child: 023+025\n",
      "\t\tProto:2 023:(0.7905) 024:(0.7754) 025:(0.7816) \n",
      "\t\tProto:3 023:(0.4759) 024:(0.5121) 025:(0.4969) \n",
      "\t\tProto:4 023:(0.3612) 024:(0.3981) 025:(0.4054) \n",
      "\t\tProto:6 023:(0.4742) 024:(0.5026) 025:(0.4846) \n",
      "\t\tProto:12 023:(0.496) 024:(0.4914) 025:(0.5119) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 88it [00:01, 50.79it/s]   \n",
      "Collecting topk: 88it [00:02, 36.46it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 002+001 {0, 1, 2, 3, 7} --------------------\n",
      "-------------------- 002+001 {4, 5, 6} --------------------\n",
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 001:(0.5676) 002:(0.5899) \n",
      "\t\tProto:1 001:(0.4638) 002:(0.4658) \n",
      "\t\tProto:2 001:(0.7494) 002:(0.7361) \n",
      "\t\tProto:3 001:(0.2789) 002:(0.2585) \n",
      "\t\tProto:7 001:(0.91) 002:(0.9191) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 81it [00:01, 50.07it/s]   \n",
      "Collecting topk: 81it [00:02, 34.90it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 025+024 {0, 1, 3, 4, 5, 7} --------------------\n",
      "-------------------- 025+024 {2, 6} --------------------\n",
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 024:(0.5469) 025:(0.5799) \n",
      "\t\tProto:1 024:(0.2375) 025:(0.2304) \n",
      "\t\tProto:3 024:(0.8022) 025:(0.56) \n",
      "\t\tProto:4 024:(0.6653) 025:(0.5663) \n",
      "\t\tProto:5 024:(0.422) 025:(0.4565) \n",
      "\t\tProto:7 024:(0.8476) 025:(0.8011) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "# overlayed_image_np = get_heatmap(latent_activation, xs)\n",
    "# Image.fromarray(overlayed_image_np).show()\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = testloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(testloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            if coarse_label2name[ys.item()] != child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                _, softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written\n",
    "                    if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                        continue\n",
    "                        \n",
    "                    h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes_of_child_node.shape, patchsize, skip, h_idx, w_idx)\n",
    "                    latent_activation = softmaxes_of_child_node[:, p, :, :]\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) > topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                         (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "#                         bbox_coords = torch.tensor([[w_coor_min, h_coor_min, w_coor_max, h_coor_max]])\n",
    "#                         bb_image = torchvision.utils.draw_bounding_boxes((img_tensor * 255).type(torch.uint8), bbox_coords, colors='red') / 255\n",
    "#                         pdb.set_trace()\n",
    "                        patches.append(overlayed_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_heatmap_testloader_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_heatmap_testloader_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on NON leaf descendents - topk images after using UNIT-SPHERE with HEAT MAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:10, 52.03it/s]\n",
      "Collecting topk: 540it [00:04, 111.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 052+053 {1, 3, 5, 7, 10, 13, 14, 20, 21} --------------------\n",
      "-------------------- 004+086 {0, 3, 6, 10, 12, 16, 21, 22, 23, 27, 28, 29, 32, 36, 43, 48, 50, 51, 52, 53, 55, 56, 59, 69, 72, 74, 80, 81, 83, 84, 86, 89, 90, 91, 97, 98, 99, 101} --------------------\n",
      "-------------------- 052+053 {0, 2, 4, 6, 8, 9, 11, 12, 15, 16, 17, 18, 19, 22, 23} --------------------\n",
      "-------------------- 004+086 {1, 2, 4, 5, 7, 8, 9, 11, 13, 14, 15, 17, 18, 19, 20, 24, 25, 26, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 54, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 73, 75, 76, 77, 78, 79, 82, 85, 87, 88, 92, 93, 94, 95, 96, 100, 102, 103} --------------------\n",
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:1 001:(0.0176) 002:(0.0048) 003:(0.0124) 004:(-0.0249) 023:(0.0009) 024:(-0.0002) 025:(0.0005) 031:(0.0142) 032:(0.0149) 033:(0.0354) 045:(-0.0014) 086:(0.0411) 100:(0.0022) 101:(0.016) \n",
      "\t\tProto:3 001:(0.0315) 002:(0.0498) 003:(0.034) 004:(0.0423) 023:(0.0171) 024:(0.0842) 025:(0.0768) 031:(0.0183) 032:(0.0657) 033:(0.0339) 045:(0.0285) 086:(0.0215) 100:(0.0512) 101:(0.0423) \n",
      "\t\tProto:5 001:(0.0067) 002:(-0.0056) 003:(0.0346) 004:(0.0098) 023:(0.0135) 024:(0.0162) 025:(0.0059) 031:(0.009) 032:(0.0141) 033:(0.0181) 045:(0.0213) 086:(0.0215) 100:(0.0037) 101:(0.0439) \n",
      "\t\tProto:7 001:(0.0166) 002:(0.0055) 003:(0.0053) 004:(0.0362) 023:(-0.0052) 024:(-0.0034) 025:(-0.002) 031:(0.0096) 032:(0.0013) 033:(0.0278) 045:(0.0044) 086:(0.0085) 100:(0.0102) 101:(0.0128) \n",
      "\t\tProto:10 001:(0.0147) 002:(-0.0075) 003:(-0.0191) 004:(0.0087) 023:(0.0201) 024:(0.0143) 025:(0.0234) 031:(0.0086) 032:(0.0085) 033:(0.0317) 045:(-0.0102) 086:(0.0142) 100:(0.0091) 101:(0.0192) \n",
      "\t\tProto:13 001:(0.0586) 002:(0.0482) 003:(0.0376) 004:(0.0201) 023:(0.0408) 024:(0.029) 025:(0.0281) 031:(0.0249) 032:(0.0102) 033:(0.0236) 045:(0.0299) 086:(0.0201) 100:(0.0313) 101:(0.0308) \n",
      "\t\tProto:14 001:(0.0056) 002:(0.0042) 003:(0.0207) 004:(0.0022) 023:(0.0259) 024:(0.025) 025:(0.0233) 031:(0.0183) 032:(0.0035) 033:(0.0148) 045:(0.0124) 086:(0.0145) 100:(-0.0019) 101:(0.0325) \n",
      "\t\tProto:20 001:(0.0392) 002:(0.0715) 003:(0.0499) 004:(0.0533) 023:(0.0383) 024:(0.0427) 025:(0.0263) 031:(0.0286) 032:(0.0201) 033:(0.0334) 045:(0.0389) 086:(0.0458) 100:(0.0157) 101:(0.0349) \n",
      "\t\tProto:21 001:(0.0166) 002:(0.0095) 003:(-0.0033) 004:(0.0207) 023:(0.0277) 024:(0.0169) 025:(0.0234) 031:(0.0278) 032:(0.0364) 033:(0.044) 045:(0.0194) 086:(0.0049) 100:(0.0384) 101:(0.0215) \n",
      "\t Child: 004+086\n",
      "\t\tProto:0 050:(0.0498) 051:(0.0345) 052:(0.0417) 053:(0.0194) \n",
      "\t\tProto:3 050:(0.0638) 051:(0.0569) 052:(0.0527) 053:(0.028) \n",
      "\t\tProto:6 050:(0.0641) 051:(0.0731) 052:(0.0467) 053:(0.0614) \n",
      "\t\tProto:10 050:(0.0568) 051:(0.0565) 052:(0.0283) 053:(-0.0312) \n",
      "\t\tProto:12 050:(0.0472) 051:(0.0371) 052:(0.058) 053:(0.0393) \n",
      "\t\tProto:16 050:(0.0485) 051:(0.0383) 052:(0.0331) 053:(0.0157) \n",
      "\t\tProto:21 050:(0.0428) 051:(0.0269) 052:(0.0387) 053:(-0.0024) \n",
      "\t\tProto:22 050:(0.0427) 051:(0.0355) 052:(0.0212) 053:(0.0134) \n",
      "\t\tProto:23 050:(0.0835) 051:(0.0575) 052:(0.0584) 053:(0.0354) \n",
      "\t\tProto:27 050:(0.0596) 051:(0.0457) 052:(0.0335) 053:(0.0157) \n",
      "\t\tProto:28 050:(0.0341) 051:(0.0477) 052:(0.0122) 053:(0.0168) \n",
      "\t\tProto:29 050:(0.0268) 051:(0.0119) 052:(-0.0027) 053:(-0.0006) \n",
      "\t\tProto:32 050:(0.0709) 051:(0.0778) 052:(0.0406) 053:(0.0684) \n",
      "\t\tProto:36 050:(0.0315) 051:(0.0489) 052:(0.0551) 053:(0.0249) \n",
      "\t\tProto:43 050:(0.0657) 051:(0.0511) 052:(0.0699) 053:(0.0243) \n",
      "\t\tProto:48 050:(0.0442) 051:(0.0422) 052:(0.0395) 053:(0.0431) \n",
      "\t\tProto:50 050:(0.0318) 051:(0.053) 052:(0.0171) 053:(0.0515) \n",
      "\t\tProto:51 050:(0.068) 051:(0.0415) 052:(0.0431) 053:(0.0029) \n",
      "\t\tProto:52 050:(0.0701) 051:(0.0549) 052:(0.0489) 053:(0.0535) \n",
      "\t\tProto:53 050:(0.0391) 051:(0.0474) 052:(0.0347) 053:(0.0229) \n",
      "\t\tProto:55 050:(0.0851) 051:(0.0542) 052:(0.0573) 053:(0.0322) \n",
      "\t\tProto:56 050:(0.0416) 051:(0.0511) 052:(0.0446) 053:(0.0594) \n",
      "\t\tProto:59 050:(0.0316) 051:(0.026) 052:(0.0202) 053:(0.0135) \n",
      "\t\tProto:69 050:(0.0269) 051:(0.0366) 052:(0.0229) 053:(0.0064) \n",
      "\t\tProto:72 050:(0.0704) 051:(0.0635) 052:(0.037) 053:(0.0243) \n",
      "\t\tProto:74 050:(0.0595) 051:(0.047) 052:(0.0547) 053:(0.0483) \n",
      "\t\tProto:80 050:(0.0547) 051:(0.0869) 052:(0.063) 053:(0.0778) \n",
      "\t\tProto:81 050:(0.0564) 051:(0.0663) 052:(0.0651) 053:(0.0303) \n",
      "\t\tProto:83 050:(0.0682) 051:(0.0627) 052:(0.0716) 053:(0.0651) \n",
      "\t\tProto:84 050:(0.078) 051:(0.0768) 052:(0.0603) 053:(0.0641) \n",
      "\t\tProto:86 050:(0.078) 051:(0.082) 052:(0.0487) 053:(0.0061) \n",
      "\t\tProto:89 050:(0.0617) 051:(0.0465) 052:(0.0509) 053:(0.0388) \n",
      "\t\tProto:90 050:(0.0584) 051:(0.0426) 052:(0.0286) 053:(0.0239) \n",
      "\t\tProto:91 050:(0.0572) 051:(0.0594) 052:(0.0271) 053:(0.0393) \n",
      "\t\tProto:97 050:(0.0258) 051:(0.0064) 052:(0.014) 053:(0.0126) \n",
      "\t\tProto:98 050:(0.0233) 051:(0.0224) 052:(0.02) 053:(0.0143) \n",
      "\t\tProto:99 050:(0.0995) 051:(0.0867) 052:(0.0785) 053:(0.0725) \n",
      "\t\tProto:101 050:(0.0637) 051:(0.0515) 052:(0.0332) 053:(0.0313) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 33.86it/s]  \n",
      "Collecting topk: 120it [00:01, 67.71it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:07, 53.48it/s]\n",
      "Collecting topk: 420it [00:05, 79.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 004+032 {0, 2, 4, 6, 9, 10, 14, 15, 17, 18, 19, 21, 22} --------------------\n",
      "-------------------- 086+045 {3, 6, 8, 12, 13, 15, 16, 17, 21, 26, 28, 30, 33, 34, 37, 40, 42, 44, 46, 49, 50, 52, 53, 54, 55, 57, 58, 60, 61, 62, 63, 66, 70, 71} --------------------\n",
      "-------------------- 004+032 {1, 3, 5, 7, 8, 11, 12, 13, 16, 20, 23} --------------------\n",
      "-------------------- 086+045 {0, 1, 2, 4, 5, 7, 9, 10, 11, 14, 18, 19, 20, 22, 23, 24, 25, 27, 29, 31, 32, 35, 36, 38, 39, 41, 43, 45, 47, 48, 51, 56, 59, 64, 65, 67, 68, 69} --------------------\n",
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:0 001:(0.0129) 002:(-0.0048) 003:(-0.0012) 023:(-0.0218) 024:(-0.0148) 025:(-0.0256) 045:(-0.0154) 086:(-0.0078) 100:(-0.012) 101:(-0.0042) \n",
      "\t\tProto:2 001:(0.0598) 002:(0.0567) 003:(0.0713) 023:(0.0917) 024:(0.0865) 025:(0.0767) 045:(0.0538) 086:(0.0532) 100:(0.0656) 101:(0.0719) \n",
      "\t\tProto:4 001:(-0.0091) 002:(0.0006) 003:(-0.0048) 023:(-0.0072) 024:(-0.0197) 025:(-0.0097) 045:(0.0192) 086:(-0.0008) 100:(-0.0146) 101:(-0.0083) \n",
      "\t\tProto:6 001:(-0.0145) 002:(-0.0293) 003:(-0.0182) 023:(-0.007) 024:(-0.0248) 025:(-0.0028) 045:(-0.0197) 086:(0.0243) 100:(-0.0012) 101:(-0.0075) \n",
      "\t\tProto:9 001:(0.045) 002:(0.0591) 003:(0.0212) 023:(0.0301) 024:(0.0448) 025:(0.0304) 045:(0.084) 086:(0.0116) 100:(0.0549) 101:(0.0508) \n",
      "\t\tProto:10 001:(-0.0045) 002:(0.0056) 003:(0.0037) 023:(0.0072) 024:(0.0213) 025:(0.0105) 045:(-0.0354) 086:(-0.0218) 100:(-0.0047) 101:(0.0042) \n",
      "\t\tProto:14 001:(0.0557) 002:(0.0497) 003:(0.0516) 023:(0.0502) 024:(0.073) 025:(0.0735) 045:(0.0472) 086:(0.0389) 100:(0.0456) 101:(0.0373) \n",
      "\t\tProto:15 001:(0.0365) 002:(0.0173) 003:(0.0496) 023:(0.0121) 024:(0.0248) 025:(0.042) 045:(0.041) 086:(0.0183) 100:(0.029) 101:(0.0271) \n",
      "\t\tProto:17 001:(0.0259) 002:(0.0444) 003:(0.0337) 023:(0.0648) 024:(0.0467) 025:(0.0222) 045:(0.0142) 086:(-0.0004) 100:(0.0166) 101:(0.0279) \n",
      "\t\tProto:18 001:(0.032) 002:(0.0068) 003:(0.0307) 023:(0.0405) 024:(0.0068) 025:(0.001) 045:(0.0364) 086:(0.024) 100:(0.0151) 101:(0.0078) \n",
      "\t\tProto:19 001:(0.0244) 002:(0.0037) 003:(0.0184) 023:(0.0273) 024:(0.0278) 025:(0.0315) 045:(0.0144) 086:(0.038) 100:(0.0155) 101:(0.0222) \n",
      "\t\tProto:21 001:(0.023) 002:(0.0375) 003:(0.0231) 023:(0.0284) 024:(0.0465) 025:(0.0359) 045:(0.0155) 086:(0.0237) 100:(0.0627) 101:(0.0199) \n",
      "\t\tProto:22 001:(0.0401) 002:(0.0611) 003:(0.0469) 023:(0.0405) 024:(0.0245) 025:(0.0481) 045:(0.0227) 086:(0.0257) 100:(0.0267) 101:(0.0199) \n",
      "\t Child: 086+045\n",
      "\t\tProto:3 004:(0.0565) 031:(0.0587) 032:(0.0417) 033:(0.0549) \n",
      "\t\tProto:6 004:(0.033) 031:(0.0366) 032:(0.0395) 033:(0.0378) \n",
      "\t\tProto:8 004:(0.0457) 031:(0.0439) 032:(0.0232) 033:(0.0239) \n",
      "\t\tProto:12 004:(0.0276) 031:(0.0229) 032:(0.0135) 033:(0.0262) \n",
      "\t\tProto:13 004:(0.0115) 031:(0.0269) 032:(-0.0058) 033:(0.0272) \n",
      "\t\tProto:15 004:(0.02) 031:(0.0125) 032:(0.0109) 033:(0.0292) \n",
      "\t\tProto:16 004:(0.0443) 031:(0.0018) 032:(0.0198) 033:(0.0094) \n",
      "\t\tProto:17 004:(0.0628) 031:(0.0657) 032:(0.1) 033:(0.0654) \n",
      "\t\tProto:21 004:(0.0115) 031:(-0.0269) 032:(-0.0094) 033:(-0.0075) \n",
      "\t\tProto:26 004:(0.0124) 031:(0.0418) 032:(0.0241) 033:(0.0091) \n",
      "\t\tProto:28 004:(0.0018) 031:(0.0531) 032:(0.0063) 033:(0.0424) \n",
      "\t\tProto:30 004:(0.0024) 031:(-0.0017) 032:(0.0114) 033:(0.0064) \n",
      "\t\tProto:33 004:(-0.0084) 031:(-0.0374) 032:(-0.0332) 033:(-0.0261) \n",
      "\t\tProto:34 004:(0.0331) 031:(0.0484) 032:(0.0642) 033:(0.0403) \n",
      "\t\tProto:37 004:(0.0283) 031:(0.0249) 032:(0.0146) 033:(0.0202) \n",
      "\t\tProto:40 004:(0.0065) 031:(0.0028) 032:(-0.0036) 033:(0.0076) \n",
      "\t\tProto:42 004:(-0.0004) 031:(0.0355) 032:(0.0154) 033:(0.0241) \n",
      "\t\tProto:44 004:(0.0258) 031:(0.0411) 032:(0.0178) 033:(0.0258) \n",
      "\t\tProto:46 004:(0.0881) 031:(0.0695) 032:(0.0455) 033:(0.0714) \n",
      "\t\tProto:49 004:(0.026) 031:(0.03) 032:(0.0253) 033:(0.0276) \n",
      "\t\tProto:50 004:(0.0064) 031:(-0.0114) 032:(0.0034) 033:(-0.0019) \n",
      "\t\tProto:52 004:(0.0287) 031:(0.0184) 032:(0.0509) 033:(0.0217) \n",
      "\t\tProto:53 004:(0.0549) 031:(0.038) 032:(0.0482) 033:(0.0192) \n",
      "\t\tProto:54 004:(0.05) 031:(0.0481) 032:(0.0459) 033:(0.05) \n",
      "\t\tProto:55 004:(0.013) 031:(0.0215) 032:(0.0259) 033:(0.0227) \n",
      "\t\tProto:57 004:(0.0237) 031:(0.0049) 032:(-0.0035) 033:(0.0077) \n",
      "\t\tProto:58 004:(0.0955) 031:(0.0792) 032:(0.0717) 033:(0.0834) \n",
      "\t\tProto:60 004:(0.0365) 031:(-0.0009) 032:(0.0047) 033:(0.0214) \n",
      "\t\tProto:61 004:(0.0805) 031:(0.0548) 032:(0.0541) 033:(0.0519) \n",
      "\t\tProto:62 004:(0.0424) 031:(0.0305) 032:(0.019) 033:(0.0235) \n",
      "\t\tProto:63 004:(0.026) 031:(0.0155) 032:(0.0237) 033:(-0.0014) \n",
      "\t\tProto:66 004:(-0.015) 031:(-0.0061) 032:(-0.011) 033:(-0.0046) \n",
      "\t\tProto:70 004:(0.0306) 031:(0.0451) 032:(0.0294) 033:(0.038) \n",
      "\t\tProto:71 004:(0.0725) 031:(0.0621) 032:(0.0464) 033:(0.0559) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 31.93it/s]   \n",
      "Collecting topk: 90it [00:01, 51.70it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 36.14it/s]  \n",
      "Collecting topk: 120it [00:01, 64.89it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:05, 50.64it/s]  \n",
      "Collecting topk: 300it [00:02, 145.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- cub_086_Pacific_Loon {2} --------------------\n",
      "Node 086+045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 31.21it/s]   \n",
      "Collecting topk: 90it [00:01, 51.35it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:05, 53.48it/s]\n",
      "Collecting topk: 270it [00:04, 59.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+003 {0, 1, 3, 4, 7, 8, 12, 15, 16, 18, 20, 21, 23} --------------------\n",
      "-------------------- 101+023 {0, 2, 3, 4, 8, 9, 14, 15, 16, 17, 18, 19, 22, 23, 25, 28, 30} --------------------\n",
      "-------------------- 045+003 {2, 5, 6, 9, 10, 11, 13, 14, 17, 19, 22} --------------------\n",
      "-------------------- 101+023 {1, 5, 6, 7, 10, 11, 12, 13, 20, 21, 24, 26, 27, 29, 31} --------------------\n",
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:0 023:(0.0001) 024:(-0.0156) 025:(-0.0005) 100:(-0.0138) 101:(-0.0188) \n",
      "\t\tProto:1 023:(0.0559) 024:(0.0153) 025:(0.0273) 100:(0.0516) 101:(0.0492) \n",
      "\t\tProto:3 023:(-0.0139) 024:(-0.0131) 025:(-0.0104) 100:(0.0014) 101:(0.0039) \n",
      "\t\tProto:4 023:(0.0288) 024:(0.0204) 025:(0.0219) 100:(0.02) 101:(0.0232) \n",
      "\t\tProto:7 023:(-0.0011) 024:(0.0026) 025:(0.015) 100:(0.0006) 101:(0.0047) \n",
      "\t\tProto:8 023:(0.0543) 024:(0.0388) 025:(0.0385) 100:(0.0087) 101:(0.0093) \n",
      "\t\tProto:12 023:(0.0128) 024:(-0.0068) 025:(0.0192) 100:(0.0228) 101:(0.0143) \n",
      "\t\tProto:15 023:(0.0197) 024:(0.0108) 025:(0.0166) 100:(0.0164) 101:(0.0109) \n",
      "\t\tProto:16 023:(0.0037) 024:(0.0164) 025:(0.0104) 100:(0.0197) 101:(0.0096) \n",
      "\t\tProto:18 023:(0.0182) 024:(0.0175) 025:(0.0105) 100:(0.0227) 101:(0.0312) \n",
      "\t\tProto:20 023:(0.0418) 024:(0.0373) 025:(0.0374) 100:(0.0743) 101:(0.0334) \n",
      "\t\tProto:21 023:(0.0201) 024:(0.0368) 025:(0.0158) 100:(0.012) 101:(0.0042) \n",
      "\t\tProto:23 023:(0.0308) 024:(0.0505) 025:(0.0674) 100:(0.033) 101:(0.0394) \n",
      "\t Child: 101+023\n",
      "\t\tProto:0 001:(0.0541) 002:(0.0385) 003:(0.0251) 045:(0.0357) \n",
      "\t\tProto:2 001:(0.075) 002:(0.0724) 003:(0.0758) 045:(0.1222) \n",
      "\t\tProto:3 001:(0.0013) 002:(-0.0267) 003:(-0.0033) 045:(-0.0241) \n",
      "\t\tProto:4 001:(0.0405) 002:(0.0212) 003:(0.0305) 045:(0.0232) \n",
      "\t\tProto:8 001:(0.0115) 002:(-0.0012) 003:(0.0157) 045:(0.0087) \n",
      "\t\tProto:9 001:(0.02) 002:(0.0139) 003:(-0.003) 045:(0.0243) \n",
      "\t\tProto:14 001:(0.0423) 002:(0.046) 003:(0.0375) 045:(0.0402) \n",
      "\t\tProto:15 001:(0.0106) 002:(0.0005) 003:(-0.0018) 045:(0.0126) \n",
      "\t\tProto:16 001:(-0.0036) 002:(-0.0153) 003:(0.0004) 045:(-0.0091) \n",
      "\t\tProto:17 001:(0.0732) 002:(0.0392) 003:(0.0337) 045:(0.0528) \n",
      "\t\tProto:18 001:(0.0311) 002:(0.0184) 003:(0.0327) 045:(0.0161) \n",
      "\t\tProto:19 001:(0.0535) 002:(0.0572) 003:(0.0541) 045:(0.0762) \n",
      "\t\tProto:22 001:(0.0211) 002:(0.0333) 003:(0.0144) 045:(0.0219) \n",
      "\t\tProto:23 001:(0.0305) 002:(0.0244) 003:(0.0164) 045:(0.0186) \n",
      "\t\tProto:25 001:(0.0212) 002:(0.0161) 003:(0.0123) 045:(0.0159) \n",
      "\t\tProto:28 001:(-0.0077) 002:(-0.0052) 003:(-0.0031) 045:(-0.0156) \n",
      "\t\tProto:30 001:(0.03) 002:(0.002) 003:(0.0376) 045:(0.0381) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:03, 34.44it/s]  \n",
      "Collecting topk: 120it [00:01, 64.05it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 41.41it/s]\n",
      "Collecting topk: 150it [00:03, 49.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 101+100 {0, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 023+025 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15} --------------------\n",
      "-------------------- 101+100 {1} --------------------\n",
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 023:(0.0526) 024:(0.023) 025:(0.0242) \n",
      "\t\tProto:2 023:(0.0078) 024:(0.0094) 025:(0.0235) \n",
      "\t\tProto:3 023:(0.0094) 024:(0.0164) 025:(0.0298) \n",
      "\t\tProto:4 023:(0.0077) 024:(0.0101) 025:(0.0134) \n",
      "\t\tProto:5 023:(0.0127) 024:(0.025) 025:(0.0137) \n",
      "\t\tProto:6 023:(-0.0045) 024:(0.0099) 025:(0.0065) \n",
      "\t\tProto:7 023:(-0.0118) 024:(-0.0079) 025:(-0.0119) \n",
      "\t Child: 023+025\n",
      "\t\tProto:0 100:(-0.0182) 101:(-0.019) \n",
      "\t\tProto:1 100:(0.0829) 101:(0.0586) \n",
      "\t\tProto:2 100:(0.0269) 101:(0.0177) \n",
      "\t\tProto:3 100:(0.0497) 101:(0.0423) \n",
      "\t\tProto:4 100:(0.0242) 101:(0.0166) \n",
      "\t\tProto:5 100:(-0.0156) 101:(-0.0282) \n",
      "\t\tProto:6 100:(0.0417) 101:(0.0341) \n",
      "\t\tProto:7 100:(-0.0027) 101:(-0.0006) \n",
      "\t\tProto:8 100:(0.0282) 101:(0.0171) \n",
      "\t\tProto:9 100:(0.0394) 101:(0.0492) \n",
      "\t\tProto:10 100:(0.0353) 101:(0.0343) \n",
      "\t\tProto:11 100:(0.0333) 101:(0.0316) \n",
      "\t\tProto:12 100:(0.0168) 101:(0.0261) \n",
      "\t\tProto:13 100:(0.0182) 101:(-0.0005) \n",
      "\t\tProto:14 100:(0.052) 101:(0.0654) \n",
      "\t\tProto:15 100:(0.0498) 101:(0.0423) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 32.12it/s]   \n",
      "Collecting topk: 90it [00:01, 51.25it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 34.43it/s]   \n",
      "Collecting topk: 90it [00:01, 52.01it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "Done !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "# overlayed_image_np = get_heatmap(latent_activation, xs)\n",
    "# Image.fromarray(overlayed_image_np).show()\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            if coarse_label2name[ys.item()] == child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                _, softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written\n",
    "                    if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                        continue\n",
    "                        \n",
    "                    h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes_of_child_node.shape, patchsize, skip, h_idx, w_idx)\n",
    "                    latent_activation = softmaxes_of_child_node[:, p, :, :]\n",
    "                    if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) > topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                         (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "#                         bbox_coords = torch.tensor([[w_coor_min, h_coor_min, w_coor_max, h_coor_max]])\n",
    "#                         bb_image = torchvision.utils.draw_bounding_boxes((img_tensor * 255).type(torch.uint8), bbox_coords, colors='red') / 255\n",
    "#                         pdb.set_trace()\n",
    "                        patches.append(overlayed_image)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'non_descendent_specific_topk_heatmap_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'non_descendent_specific_topk_heatmap_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images after using unit-sphere & tanh-desc WITH bounding boxes of all the patches greater than a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 540it [00:04, 130.36it/s]\n",
      "Collecting topk: 540it [00:11, 45.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 052+053 {18, 11, 20, 13} --------------------\n",
      "-------------------- 004+086 {96, 1, 2, 39, 80, 83, 20, 53, 84, 30} --------------------\n",
      "-------------------- 052+053 {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 19, 21, 22, 23} --------------------\n",
      "-------------------- 004+086 {0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103} --------------------\n",
      "Node root\n",
      "\t Child: 052+053\n",
      "\t\tProto:18 050:(0.3224) 051:(0.5289) 052:(0.2688) 053:(0.6115) \n",
      "\t\tProto:11 050:(0.6517) 051:(0.6445) 052:(0.6527) 053:(0.3735) \n",
      "\t\tProto:20 050:(0.4741) 051:(0.5075) 052:(0.5022) 053:(0.2589) \n",
      "\t\tProto:13 050:(0.6036) 051:(0.5833) 052:(0.5662) 053:(0.3894) \n",
      "\t Child: 004+086\n",
      "\t\tProto:96 001:(0.5111) 002:(0.5501) 003:(0.5323) 004:(0.5836) 023:(0.4943) 024:(0.4769) 025:(0.5284) 031:(0.5764) 032:(0.5585) 033:(0.5312) 045:(0.534) 086:(0.5197) 100:(0.5268) 101:(0.5216) \n",
      "\t\tProto:1 001:(0.1821) 002:(0.1959) 003:(0.1979) 004:(0.2218) 023:(0.1907) 024:(0.1184) 025:(0.1717) 031:(0.215) 032:(0.2137) 033:(0.2063) 045:(0.1728) 086:(0.1593) 100:(0.1421) 101:(0.124) \n",
      "\t\tProto:2 001:(0.3508) 002:(0.3477) 003:(0.2319) 004:(0.2603) 023:(0.303) 024:(0.3151) 025:(0.2953) 031:(0.2709) 032:(0.15) 033:(0.2073) 045:(0.2716) 086:(0.2373) 100:(0.3307) 101:(0.2845) \n",
      "\t\tProto:39 001:(0.1836) 002:(0.1912) 003:(0.2224) 004:(0.2492) 023:(0.1876) 024:(0.1307) 025:(0.1703) 031:(0.2351) 032:(0.2322) 033:(0.2564) 045:(0.1754) 086:(0.1438) 100:(0.1708) 101:(0.1959) \n",
      "\t\tProto:80 001:(0.1416) 002:(0.1287) 003:(0.159) 004:(0.1065) 023:(0.1326) 024:(0.0992) 025:(0.0937) 031:(0.1055) 032:(0.1076) 033:(0.1096) 045:(0.1591) 086:(0.1103) 100:(0.1063) 101:(0.1129) \n",
      "\t\tProto:83 001:(0.2142) 002:(0.2136) 003:(0.2698) 004:(0.1688) 023:(0.2411) 024:(0.1444) 025:(0.1618) 031:(0.1762) 032:(0.1705) 033:(0.1897) 045:(0.2148) 086:(0.2046) 100:(0.1628) 101:(0.2014) \n",
      "\t\tProto:20 001:(0.3689) 002:(0.3607) 003:(0.264) 004:(0.3371) 023:(0.2967) 024:(0.332) 025:(0.3081) 031:(0.2863) 032:(0.2824) 033:(0.3005) 045:(0.1826) 086:(0.1979) 100:(0.2734) 101:(0.174) \n",
      "\t\tProto:53 001:(0.2774) 002:(0.2925) 003:(0.3464) 004:(0.4645) 023:(0.4219) 024:(0.4766) 025:(0.4793) 031:(0.3893) 032:(0.3592) 033:(0.3744) 045:(0.3408) 086:(0.2234) 100:(0.4674) 101:(0.2955) \n",
      "\t\tProto:84 001:(0.1393) 002:(0.1483) 003:(0.1263) 004:(0.1529) 023:(0.16) 024:(0.1471) 025:(0.1594) 031:(0.1408) 032:(0.0992) 033:(0.1323) 045:(0.1374) 086:(0.143) 100:(0.1302) 101:(0.1192) \n",
      "\t\tProto:30 001:(0.1302) 002:(0.151) 003:(0.1383) 004:(0.1363) 023:(0.1271) 024:(0.0901) 025:(0.0888) 031:(0.1445) 032:(0.1374) 033:(0.1392) 045:(0.1155) 086:(0.0975) 100:(0.1041) 101:(0.0982) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 59.39it/s]  \n",
      "Collecting topk: 120it [00:03, 36.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 053+050 {0, 4, 5, 7, 12} --------------------\n",
      "-------------------- 053+050 {1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:0 050:(0.6018) 051:(0.6573) 053:(0.4821) \n",
      "\t\tProto:4 050:(0.6982) 051:(0.7354) 053:(0.7513) \n",
      "\t\tProto:5 050:(0.7782) 051:(0.8249) 053:(0.7996) \n",
      "\t\tProto:7 050:(0.3938) 051:(0.4381) 053:(0.4319) \n",
      "\t\tProto:12 050:(0.2812) 051:(0.3068) 053:(0.3904) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:04, 100.49it/s]\n",
      "Collecting topk: 420it [00:08, 50.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 004+032 {3, 6, 12, 19, 20} --------------------\n",
      "-------------------- 086+045 {33, 66, 6, 70, 22, 55, 29} --------------------\n",
      "-------------------- 004+032 {0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 23} --------------------\n",
      "-------------------- 086+045 {0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71} --------------------\n",
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:3 004:(0.2749) 031:(0.3765) 032:(0.3545) 033:(0.3979) \n",
      "\t\tProto:6 004:(0.3775) 031:(0.3835) 032:(0.3265) 033:(0.3926) \n",
      "\t\tProto:12 004:(0.656) 031:(0.5929) 032:(0.5623) 033:(0.6189) \n",
      "\t\tProto:19 004:(0.2689) 031:(0.44) 032:(0.3415) 033:(0.4406) \n",
      "\t\tProto:20 004:(0.4277) 031:(0.6322) 032:(0.5991) 033:(0.6219) \n",
      "\t Child: 086+045\n",
      "\t\tProto:33 001:(0.1989) 002:(0.1869) 003:(0.2129) 023:(0.4262) 024:(0.4197) 025:(0.4387) 045:(0.1953) 086:(0.3889) 100:(0.2343) 101:(0.2375) \n",
      "\t\tProto:66 001:(0.1443) 002:(0.1516) 003:(0.1438) 023:(0.1331) 024:(0.1375) 025:(0.1449) 045:(0.1883) 086:(0.1648) 100:(0.0977) 101:(0.164) \n",
      "\t\tProto:6 001:(0.6457) 002:(0.5974) 003:(0.6025) 023:(0.5345) 024:(0.4713) 025:(0.5332) 045:(0.606) 086:(0.5751) 100:(0.5726) 101:(0.5841) \n",
      "\t\tProto:70 001:(0.5566) 002:(0.5244) 003:(0.5271) 023:(0.4602) 024:(0.4198) 025:(0.4706) 045:(0.5269) 086:(0.4724) 100:(0.5131) 101:(0.5179) \n",
      "\t\tProto:22 001:(0.2746) 002:(0.2188) 003:(0.2395) 023:(0.2327) 024:(0.1857) 025:(0.2566) 045:(0.2312) 086:(0.2758) 100:(0.2633) 101:(0.2604) \n",
      "\t\tProto:55 001:(0.2109) 002:(0.1403) 003:(0.1532) 023:(0.0766) 024:(0.0969) 025:(0.0622) 045:(0.1575) 086:(0.16) 100:(0.1359) 101:(0.1355) \n",
      "\t\tProto:29 001:(0.1767) 002:(0.1281) 003:(0.1364) 023:(0.1748) 024:(0.1836) 025:(0.1861) 045:(0.1337) 086:(0.2874) 100:(0.2168) 101:(0.1684) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 45.17it/s]   \n",
      "Collecting topk: 90it [00:02, 32.86it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 050+051 {0, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 050+051 {1} --------------------\n",
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 050:(0.6595) 051:(0.773) \n",
      "\t\tProto:2 050:(0.5292) 051:(0.596) \n",
      "\t\tProto:3 050:(0.2493) 051:(0.1498) \n",
      "\t\tProto:4 050:(0.4782) 051:(0.4411) \n",
      "\t\tProto:5 050:(0.403) 051:(0.2806) \n",
      "\t\tProto:6 050:(0.2847) 051:(0.3088) \n",
      "\t\tProto:7 050:(0.6833) 051:(0.7682) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 63.48it/s]  \n",
      "Collecting topk: 120it [00:03, 34.42it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 032+033 {1, 3, 4, 7, 8, 12, 13, 15} --------------------\n",
      "-------------------- 032+033 {0, 2, 5, 6, 9, 10, 11, 14} --------------------\n",
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:1 031:(0.5933) 032:(0.5973) 033:(0.5693) \n",
      "\t\tProto:3 031:(0.6457) 032:(0.5805) 033:(0.571) \n",
      "\t\tProto:4 031:(0.214) 032:(0.1365) 033:(0.2244) \n",
      "\t\tProto:7 031:(0.3754) 032:(0.3439) 033:(0.3951) \n",
      "\t\tProto:8 031:(0.3565) 032:(0.3079) 033:(0.3477) \n",
      "\t\tProto:12 031:(0.5921) 032:(0.5478) 033:(0.5841) \n",
      "\t\tProto:13 031:(0.3858) 032:(0.2704) 033:(0.4004) \n",
      "\t\tProto:15 031:(0.4102) 032:(0.371) 033:(0.3568) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:02, 146.07it/s] \n",
      "Collecting topk: 300it [00:09, 31.47it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+101 {4, 5, 9, 10, 17, 18, 19, 24, 25, 26, 27, 28, 31, 32, 34, 39, 41, 44, 45, 49, 50, 51, 58, 59, 60, 63} --------------------\n",
      "-------------------- 045+101 {0, 1, 2, 3, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 29, 30, 33, 35, 36, 37, 38, 40, 42, 43, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62} --------------------\n",
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:4 001:(0.1567) 002:(0.1822) 003:(0.1681) 023:(0.1522) 024:(0.1955) 025:(0.1807) 045:(0.1498) 100:(0.2344) 101:(0.2268) \n",
      "\t\tProto:5 001:(0.1477) 002:(0.1367) 003:(0.1737) 023:(0.1846) 024:(0.2069) 025:(0.1864) 045:(0.1252) 100:(0.2062) 101:(0.1185) \n",
      "\t\tProto:9 001:(0.2545) 002:(0.2588) 003:(0.2427) 023:(0.2479) 024:(0.2601) 025:(0.2498) 045:(0.2492) 100:(0.2702) 101:(0.2609) \n",
      "\t\tProto:10 001:(0.2098) 002:(0.2168) 003:(0.2308) 023:(0.2301) 024:(0.2344) 025:(0.2199) 045:(0.2074) 100:(0.2335) 101:(0.2056) \n",
      "\t\tProto:17 001:(0.1932) 002:(0.1924) 003:(0.194) 023:(0.1935) 024:(0.1928) 025:(0.1914) 045:(0.1936) 100:(0.192) 101:(0.1889) \n",
      "\t\tProto:18 001:(0.2721) 002:(0.282) 003:(0.2756) 023:(0.282) 024:(0.2942) 025:(0.2734) 045:(0.2522) 100:(0.2874) 101:(0.2652) \n",
      "\t\tProto:19 001:(0.1326) 002:(0.1208) 003:(0.1398) 023:(0.1645) 024:(0.1817) 025:(0.1676) 045:(0.1245) 100:(0.1877) 101:(0.1254) \n",
      "\t\tProto:24 001:(0.1132) 002:(0.1203) 003:(0.1168) 023:(0.1173) 024:(0.151) 025:(0.1137) 045:(0.1119) 100:(0.1732) 101:(0.16) \n",
      "\t\tProto:25 001:(0.1337) 002:(0.1361) 003:(0.1353) 023:(0.148) 024:(0.1929) 025:(0.1567) 045:(0.1448) 100:(0.1451) 101:(0.1348) \n",
      "\t\tProto:26 001:(0.2315) 002:(0.262) 003:(0.2395) 023:(0.161) 024:(0.158) 025:(0.1549) 045:(0.2617) 100:(0.1175) 101:(0.2163) \n",
      "\t\tProto:27 001:(0.2131) 002:(0.211) 003:(0.2161) 023:(0.2146) 024:(0.2092) 025:(0.205) 045:(0.2156) 100:(0.2072) 101:(0.2061) \n",
      "\t\tProto:28 001:(0.1458) 002:(0.1921) 003:(0.2289) 023:(0.2431) 024:(0.2746) 025:(0.2444) 045:(0.1252) 100:(0.2777) 101:(0.1765) \n",
      "\t\tProto:31 001:(0.165) 002:(0.1648) 003:(0.1728) 023:(0.1666) 024:(0.172) 025:(0.1606) 045:(0.153) 100:(0.1742) 101:(0.1628) \n",
      "\t\tProto:32 001:(0.1231) 002:(0.1129) 003:(0.1216) 023:(0.1585) 024:(0.1706) 025:(0.1641) 045:(0.1178) 100:(0.1286) 101:(0.1113) \n",
      "\t\tProto:34 001:(0.1252) 002:(0.1381) 003:(0.1451) 023:(0.1571) 024:(0.1608) 025:(0.1363) 045:(0.101) 100:(0.1567) 101:(0.0857) \n",
      "\t\tProto:39 001:(0.1424) 002:(0.1403) 003:(0.1441) 023:(0.1223) 024:(0.0986) 025:(0.1041) 045:(0.1308) 100:(0.183) 101:(0.1913) \n",
      "\t\tProto:41 001:(0.1874) 002:(0.1873) 003:(0.2083) 023:(0.2001) 024:(0.2142) 025:(0.2018) 045:(0.1528) 100:(0.203) 101:(0.1431) \n",
      "\t\tProto:44 001:(0.0981) 002:(0.0938) 003:(0.1347) 023:(0.1864) 024:(0.1929) 025:(0.1726) 045:(0.0892) 100:(0.2721) 101:(0.2575) \n",
      "\t\tProto:45 001:(0.1203) 002:(0.1175) 003:(0.1113) 023:(0.1176) 024:(0.1127) 025:(0.1077) 045:(0.0953) 100:(0.115) 101:(0.1114) \n",
      "\t\tProto:49 001:(0.1657) 002:(0.1541) 003:(0.1185) 023:(0.1181) 024:(0.14) 025:(0.1039) 045:(0.0841) 100:(0.1869) 101:(0.1729) \n",
      "\t\tProto:50 001:(0.2115) 002:(0.2049) 003:(0.2011) 023:(0.2116) 024:(0.2234) 025:(0.2066) 045:(0.2047) 100:(0.2313) 101:(0.2037) \n",
      "\t\tProto:51 001:(0.2565) 002:(0.2295) 003:(0.2884) 023:(0.3266) 024:(0.3511) 025:(0.311) 045:(0.1807) 100:(0.3212) 101:(0.2186) \n",
      "\t\tProto:58 001:(0.1616) 002:(0.141) 003:(0.1421) 023:(0.146) 024:(0.1634) 025:(0.1451) 045:(0.1479) 100:(0.1676) 101:(0.1664) \n",
      "\t\tProto:59 001:(0.1892) 002:(0.1903) 003:(0.1846) 023:(0.1804) 024:(0.1894) 025:(0.1866) 045:(0.185) 100:(0.1903) 101:(0.1864) \n",
      "\t\tProto:60 001:(0.2071) 002:(0.1906) 003:(0.2327) 023:(0.2496) 024:(0.2543) 025:(0.1947) 045:(0.151) 100:(0.2499) 101:(0.1725) \n",
      "\t\tProto:63 001:(0.3799) 002:(0.3823) 003:(0.3703) 023:(0.3713) 024:(0.3958) 025:(0.3767) 045:(0.3706) 100:(0.4063) 101:(0.3851) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 45.10it/s]   \n",
      "Collecting topk: 90it [00:02, 32.62it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 033+031 {0, 2, 3, 4, 6} --------------------\n",
      "-------------------- 033+031 {1, 5, 7} --------------------\n",
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 031:(0.4807) 033:(0.4616) \n",
      "\t\tProto:2 031:(0.8752) 033:(0.8493) \n",
      "\t\tProto:3 031:(0.4735) 033:(0.4492) \n",
      "\t\tProto:4 031:(0.6412) 033:(0.6034) \n",
      "\t\tProto:6 031:(0.7761) 033:(0.7219) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 66.45it/s]\n",
      "Collecting topk: 270it [00:04, 56.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 045+003 {2, 5, 8, 12, 14, 19} --------------------\n",
      "-------------------- 101+023 {4, 10, 16, 17, 18, 19, 28, 31} --------------------\n",
      "-------------------- 045+003 {0, 1, 3, 4, 6, 7, 9, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23} --------------------\n",
      "-------------------- 101+023 {0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30} --------------------\n",
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:2 001:(0.5555) 002:(0.5532) 003:(0.5581) 045:(0.5252) \n",
      "\t\tProto:5 001:(0.5084) 002:(0.5138) 003:(0.501) 045:(0.5132) \n",
      "\t\tProto:8 001:(0.3175) 002:(0.3091) 003:(0.3163) 045:(0.3117) \n",
      "\t\tProto:12 001:(0.4407) 002:(0.4386) 003:(0.4393) 045:(0.4195) \n",
      "\t\tProto:14 001:(0.573) 002:(0.63) 003:(0.5254) 045:(0.6495) \n",
      "\t\tProto:19 001:(0.6359) 002:(0.6387) 003:(0.6375) 045:(0.6567) \n",
      "\t Child: 101+023\n",
      "\t\tProto:4 023:(0.5267) 024:(0.5849) 025:(0.4806) 100:(0.7271) 101:(0.7219) \n",
      "\t\tProto:10 023:(0.2657) 024:(0.2619) 025:(0.2585) 100:(0.3557) 101:(0.3481) \n",
      "\t\tProto:16 023:(0.5802) 024:(0.5681) 025:(0.5893) 100:(0.3766) 101:(0.321) \n",
      "\t\tProto:17 023:(0.3033) 024:(0.3205) 025:(0.322) 100:(0.291) 101:(0.272) \n",
      "\t\tProto:18 023:(0.2274) 024:(0.2599) 025:(0.2447) 100:(0.2682) 101:(0.2234) \n",
      "\t\tProto:19 023:(0.285) 024:(0.3073) 025:(0.306) 100:(0.4096) 101:(0.4198) \n",
      "\t\tProto:28 023:(0.2468) 024:(0.2565) 025:(0.2539) 100:(0.0941) 101:(0.0929) \n",
      "\t\tProto:31 023:(0.1977) 024:(0.1917) 025:(0.1892) 100:(0.1552) 101:(0.1715) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:01, 61.56it/s]  \n",
      "Collecting topk: 120it [00:03, 35.61it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 003+002 {0, 8, 14, 7} --------------------\n",
      "-------------------- 003+002 {1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15} --------------------\n",
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:0 001:(0.8316) 002:(0.8128) 003:(0.8287) \n",
      "\t\tProto:8 001:(0.6097) 002:(0.6205) 003:(0.6777) \n",
      "\t\tProto:14 001:(0.6213) 002:(0.6221) 003:(0.5518) \n",
      "\t\tProto:7 001:(0.7652) 002:(0.7501) 003:(0.7189) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:02, 50.04it/s]\n",
      "Collecting topk: 150it [00:03, 44.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 101+100 {0, 1, 2, 3, 4, 5, 6, 7} --------------------\n",
      "-------------------- 023+025 {2, 3, 4, 6, 12} --------------------\n",
      "-------------------- 023+025 {0, 1, 5, 7, 8, 9, 10, 11, 13, 14, 15} --------------------\n",
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:0 100:(0.2837) 101:(0.3593) \n",
      "\t\tProto:1 100:(0.7365) 101:(0.7306) \n",
      "\t\tProto:2 100:(0.7673) 101:(0.7536) \n",
      "\t\tProto:3 100:(0.2328) 101:(0.212) \n",
      "\t\tProto:4 100:(0.4729) 101:(0.445) \n",
      "\t\tProto:5 100:(0.5522) 101:(0.5454) \n",
      "\t\tProto:6 100:(0.7209) 101:(0.7072) \n",
      "\t\tProto:7 100:(0.2771) 101:(0.3756) \n",
      "\t Child: 023+025\n",
      "\t\tProto:2 023:(0.7714) 024:(0.756) 025:(0.7596) \n",
      "\t\tProto:3 023:(0.4703) 024:(0.5075) 025:(0.4745) \n",
      "\t\tProto:4 023:(0.3722) 024:(0.4047) 025:(0.3518) \n",
      "\t\tProto:6 023:(0.4741) 024:(0.5056) 025:(0.4779) \n",
      "\t\tProto:12 023:(0.505) 024:(0.4987) 025:(0.5021) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 44.86it/s]   \n",
      "Collecting topk: 90it [00:02, 33.54it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 002+001 {0, 1, 2, 3, 7} --------------------\n",
      "-------------------- 002+001 {4, 5, 6} --------------------\n",
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 001:(0.5614) 002:(0.5602) \n",
      "\t\tProto:1 001:(0.4688) 002:(0.4623) \n",
      "\t\tProto:2 001:(0.7611) 002:(0.7502) \n",
      "\t\tProto:3 001:(0.2713) 002:(0.2649) \n",
      "\t\tProto:7 001:(0.8971) 002:(0.9128) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.65it/s]   \n",
      "Collecting topk: 90it [00:02, 32.35it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 025+024 {0, 1, 3, 4, 5, 7} --------------------\n",
      "-------------------- 025+024 {2, 6} --------------------\n",
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 024:(0.5855) 025:(0.6178) \n",
      "\t\tProto:1 024:(0.2654) 025:(0.2592) \n",
      "\t\tProto:3 024:(0.8018) 025:(0.5688) \n",
      "\t\tProto:4 024:(0.6614) 025:(0.5576) \n",
      "\t\tProto:5 024:(0.4765) 025:(0.4864) \n",
      "\t\tProto:7 024:(0.8539) 025:(0.7967) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw as D\n",
    "import torchvision\n",
    "\n",
    "topk = 10\n",
    "save_images = True\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "#     img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "#                     total=len(modifiedLabelLoader),\n",
    "#                     mininterval=50.,\n",
    "#                     desc='Collecting topk',\n",
    "#                     ncols=0)\n",
    "    \n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps class names to the prototypes that DON'T have strong connection to classification\n",
    "    class_and_non_relevant_prototypes = defaultdict(set)\n",
    "    \n",
    "    # maps child_class_name -> proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(lambda: defaultdict(get_heap)))\n",
    "    \n",
    "    for child_node in node.children:\n",
    "        classification_weights = getattr(net.module, '_'+node.name+'_'+child_node.name+'_classification').weight\n",
    "        \n",
    "#         if all([grand_child.is_leaf() for grand_child in child_node]):\n",
    "#             continue\n",
    "\n",
    "        img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "        \n",
    "        for i, (xs, orig_y, ys) in img_iter:\n",
    "            \n",
    "            if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "                continue\n",
    "                \n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            \n",
    "            if coarse_label2name[ys.item()] != child_node.name:\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # pooled is dict of dict, mapping [node.name][child_node.name] to correspoding pooled tensor\n",
    "                # softmaxes is dict, mapping [node.name] to tensor that is produced after concatenating the output\n",
    "                # of add_ons of each child node and doing softmax on them\n",
    "                _, softmaxes, pooled, _ = net(xs, inference=False)\n",
    "                pooled = pooled[node.name][child_node.name].squeeze(0)\n",
    "                softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "                softmaxes_split = torch.split(softmaxes, [node.num_protos_per_child[child_node.name] for child_node in node.children], dim=1)\n",
    "                idx = [temp_child_node.name for temp_child_node in node.children].index(child_node.name)\n",
    "                softmaxes_of_child_node = softmaxes_split[idx]\n",
    "                \n",
    "                for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                    c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "#                     relevant_proto_class_names = child_node.descendents # names of all descendants of the child_node\n",
    "                    if c_weight < 1e-3:\n",
    "                        class_and_non_relevant_prototypes[child_node.name].add(p)\n",
    "                        continue\n",
    "                    relevant_proto_class_names = [child_node.name]\n",
    "                    \n",
    "                    # Take the max per prototype.                             \n",
    "                    max_per_prototype, max_idx_per_prototype = torch.max(softmaxes_of_child_node, dim=0)\n",
    "                    max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                    max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                    \n",
    "                    h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                    w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                    # if prototype not relevant # never happens\n",
    "                    if len(relevant_proto_class_names) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # might happen but can be better written\n",
    "                    if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                        continue\n",
    "                    \n",
    "                    latent_activation = softmaxes_of_child_node[:, p, :, :]\n",
    "                    threshold = np.percentile(latent_activation.squeeze().cpu().numpy(), 99)\n",
    "                    indices = np.where(latent_activation.squeeze().cpu().numpy() > threshold)\n",
    "                    indices = [x.tolist() for x in indices]\n",
    "                    indices = [_ for _ in zip(*indices)]\n",
    "                    bboxes = []\n",
    "                    for _h_idx, _w_idx in indices:\n",
    "                        h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes_of_child_node.shape, patchsize, skip, _h_idx, _w_idx)\n",
    "                        bboxes.append((h_coor_min, h_coor_max, w_coor_min, w_coor_max))\n",
    "                    \n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "#                         child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[child_node.name][p][leaf_descendent]) > topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[child_node.name][p][leaf_descendent], (pooled[p].item(), img_to_open, bboxes))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[child_node.name][p][leaf_descendent], (pooled[p].item(), img_to_open, bboxes))\n",
    "#                     pdb.set_trace()\n",
    "                    class_and_prototypes[child_node.name].add(p)\n",
    "    \n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('-'*20, child_classname, class_and_prototypes[child_classname], '-'*20)\n",
    "    for child_classname in class_and_non_relevant_prototypes:\n",
    "        print('-'*20, child_classname, class_and_non_relevant_prototypes[child_classname], '-'*20)\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            for leaf_descendent in proto_mean_activations[child_classname][p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[child_classname][p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n",
    "            \n",
    "            if save_images:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 7 # 7x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[child_classname][p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[child_classname][p][leaf_descendent]]), 4)\n",
    "                    for ele in heap:\n",
    "                        activation, img_to_open, bboxes = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        \n",
    "                        for (h_coor_min, h_coor_max, w_coor_min, w_coor_max) in bboxes:\n",
    "                            bbox_coords = torch.tensor([[w_coor_min, h_coor_min, w_coor_max, h_coor_max]])\n",
    "                            img_tensor = torchvision.utils.draw_bounding_boxes((img_tensor * 255).type(torch.uint8), bbox_coords, colors='red') / 255\n",
    "                        patches.append(img_tensor)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk+1, padding=1)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=1)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "#                 pdb.set_trace()\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((5, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\")\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "\n",
    "                os.makedirs(os.path.join(run_path, f'descendent_specific_topk_multi_bb_ep={epoch}', node.name), exist_ok=True)\n",
    "                torchvision.utils.save_image(grid, os.path.join(run_path, f'descendent_specific_topk_multi_bb_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "            \n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - plot all activations of one particular prototype from one node, consider all descendant images of that prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:05, 71.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 086+045\n",
      "\t Child: 004+032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - plot all activations of one particular prototype from one node, consider all descendant images of that prototype\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "topk = None\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    \n",
    "    if node.name != '004+086':\n",
    "        continue\n",
    "        \n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pfs, pooled, _ = net(xs, inference=False)\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            pfs = pfs[node.name].squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                \n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) > topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent], pooled[p].item())\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent], pooled[p].item())\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    activations = []\n",
    "    activations_not_desc = []\n",
    "    p = 17\n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        if p in class_and_prototypes[child_classname]:\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                activations += [round(_, 4) for _ in proto_mean_activations[p][leaf_descendent]]\n",
    "    activations = sorted(activations)\n",
    "    plt.plot(activations)\n",
    "    plt.title('activations of descendants')\n",
    "    plt.show()\n",
    "                \n",
    "#         for p in class_and_prototypes[child_classname]:\n",
    "#             logstr = '\\t'*2 + f'Proto:{p} '\n",
    "#             if p != 17:\n",
    "#                 continue\n",
    "#             activations = []\n",
    "#             for leaf_descendent in proto_mean_activations[p]:\n",
    "#                 mean_activation = round(np.mean(proto_mean_activations[p][leaf_descendent]), 4)\n",
    "#                 activations += [round(_, 4) for _ in proto_mean_activations[p][leaf_descendent]]\n",
    "#                 num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "#                 logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "#             print(logstr)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9853\n",
      "values above 66% 103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aab9fdd80d0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJw0lEQVR4nO3de1xUdf4/8NfMwFzkGoLAIHdJvAWGQJhZbhSppZntmj83WaotN7WMXQ3yWuaXrqapm23tbi50sdZLt13Q8JYbiqJWal4Qk4sCojLD/TLn8/uDHJtEYxQ4zMzr+XjM4xFnPufM+xyTefk5n8/nKIQQAkREREQ2Til3AURERESdgaGGiIiI7AJDDREREdkFhhoiIiKyCww1REREZBcYaoiIiMguMNQQERGRXWCoISIiIrvgJHcB3UWSJJw+fRpubm5QKBRyl0NEREQdIIRATU0N9Ho9lMqr98U4TKg5ffo0AgMD5S6DiIiIrkFJSQn69u171TYOE2rc3NwAtF0Ud3d3mashIiKijjAajQgMDDR/j1+Nw4Sai7ec3N3dGWqIiIhsTEeGjnCgMBEREdkFhhoiIiKyCww1REREZBcYaoiIiMguMNQQERGRXWCoISIiIrvAUENERER2gaGGiIiI7AJDDREREdkFq0PNjh07cN9990Gv10OhUGDjxo2/us+2bdtw8803Q6PRoF+/fnjvvfcua7Nq1SqEhIRAq9UiPj4e+fn5Fu83NjZi+vTp6N27N1xdXTFx4kRUVFRYWz4RERHZKatDTV1dHaKiorBq1aoOtT958iTGjh2LUaNG4cCBA5g1axYee+wx5OTkmNusXbsWqampWLhwIfbt24eoqCgkJSWhsrLS3OaZZ57B559/jk8++QTbt2/H6dOn8cADD1hbPhEREdkphRBCXPPOCgU2bNiA+++//4ptnn32WXz55Zc4ePCgedtDDz2E6upqZGdnAwDi4+MRGxuLlStXAgAkSUJgYCBmzpyJtLQ0GAwG+Pj44IMPPsCDDz4IADhy5AgGDBiAvLw83HLLLb9aq9FohIeHBwwGA5/9REREZCOs+f7u8gda5uXlITEx0WJbUlISZs2aBQBobm5GQUEB0tPTze8rlUokJiYiLy8PAFBQUICWlhaL40RGRiIoKOiKoaapqQlNTU3mn41GY2eeFhERUY/S2GLCJ3tLUFRVJ1sNTkoF5o4dKN/nd/UHlJeXw9fX12Kbr68vjEYjGhoacOHCBZhMpnbbHDlyxHwMtVoNT0/Py9qUl5e3+7kZGRl4/vnnO+9EiIiIeqDmVgkf7SnGyi2FqKxp+vUdupDaSWnfoUYu6enpSE1NNf9sNBoRGBgoY0VERGRLhBA4dNqIc3XNcpdyRaUX6vHXrSdQVt0AAAjw1OHeKH84KRWy1KNSyjupustDjZ+f32WzlCoqKuDu7g6dTgeVSgWVStVuGz8/P/MxmpubUV1dbdFb8/M2v6TRaKDRaDr3ZIiIyCHs+fE8Xs05ivyT5+UupUP6uGkw8zf9MCk2CGonx12tpctDTUJCAv7zn/9YbNu8eTMSEhIAAGq1GjExMcjNzTUPOJYkCbm5uZgxYwYAICYmBs7OzsjNzcXEiRMBAEePHkVxcbH5OERERNfr25JqvL75GHYcOwug7XZKPx9XKOTp+PhVziolxg7xx8MJwdA6q+QuR3ZWh5ra2loUFhaafz558iQOHDgALy8vBAUFIT09HWVlZfjXv/4FAJg2bRpWrlyJOXPm4JFHHsGWLVvw8ccf48svvzQfIzU1FcnJyRg2bBji4uKwbNky1NXVISUlBQDg4eGBRx99FKmpqfDy8oK7uztmzpyJhISEDs18IiIiuqjVJGH9vjKs2laI4vP1Fu9dnA/spFRgUmwgZvymH/w9dDJUSdfC6lCzd+9ejBo1yvzzxXErycnJeO+993DmzBkUFxeb3w8NDcWXX36JZ555BsuXL0ffvn3x7rvvIikpydxm0qRJOHv2LBYsWIDy8nJER0cjOzvbYvDwG2+8AaVSiYkTJ6KpqQlJSUn461//ek0nTUREjkeSBD7/7jSWfXUcJ68wQ0ipACYM7Yun74xAUO9e3VwhXa/rWqfGlnCdGiIi23O8ogbvfn0SlTWN132sU+frUXS2Lcx4uajx5B3huC9KD+XP7i3p1Cq4aux2Do1N6lHr1BAREVnrx6o6LM89jo0HytCZ//R20zrhiZFhSLk1FC4ML3aHf6JERGS1orO1+F9hFaQu6Os/fNqIf+8rhemng48e7IdRkX1wvWN11U5K3HFjH3j0cr7+IqlHYqghIqIOKzlfj+W5x7F+X2mXBJqfu6O/D/58V38M6evRtR9EdoOhhojIwTW2mFBhvPqYlcYWCf/K+xFr95Sg9ac0c0uYF3q7dP56YDq1Cg/FBmJYiFenH5vsG0MNEZGDqm9uxT//9yP+tqMIhoaWDu93W4Q3/nx3f0QHenZdcUTXgKGGiMjBNLaY8P7uYry1rRBVtW2PANA4KX91af2b+nri6cQI3BLWuzvKJLIaQw0RkR0QQiDnUDne/fokzv/Ks4ou1DfjQn1bz0xw716YlRiBcVEBUMn0vCCizsJQQ0Rkw4QQ2HbsLF7fdBQHy4wd3s/fQ4un7ozAgzF94axy3GcFkX1hqCEisgF1Ta34eG/JZcv6f1dqQMGpCwAAF7UKj44IxYgIn6s+q0ilVGCQ3h0aJz4riOwLQw0RUQ/W3viXX9I4KZE8PATTbg+Hl4u6mysk6jkYaoiIupihvgXflVVbva7LqXN1+OvWEyj/abp1cO9eGD3YHz+/W+SiccKDN/dFH3dtJ1ZMZJsYaoiIuoixsQXvfn0S/9h5ErVNrdd8HI5/IeoYhhoiok5W39yK9775EW9vv7T+S98bdPDQWbc8v9pJiXFRekyOC4LWmeNfiH4NQw0RUSdpb/xLvz6u+PNdNyJpkB+UnDJN1KUYaoiIrlNzq4RPCkqwIrfQPP4lyKsXnrmL678QdSeGGiKidlxc/+WTvSVoaDZdte3xylqUXmgA0Db+ZeZvIvDbYRz/QtTdGGqIiH4h78Q5vL7pKPb+tP5LR3i7ajB9VDjHvxDJiKGGiOgn+4ovYOmmY9hZWAWgbf2X398SjEg/t6vup1Or8JvIPuil5q9UIjnxbyARObxDpw1YuukYco9UAgCcVQpMjgvCjFH9uP4LkQ1hqCEihyBJAmXVDZDEpRXwqutb8LcdRfjy+zMA2h4fMPHmADx1ZwT63tBLrlKJ6Box1BCRXZMkgf8eLMfSzUdx4mxdu20UCmBclB5P3xmBMB/Xbq6QiDoLQw0R2SUhBHJ/qMTrm4/hhzNtT692Vimg/tmMJKVCgVv7eWPWXRGI9HOXq1Qi6iQMNURkd+qbW/HIe3uwq+g8AMBV44THbgvFIyNC4a61blVfIrIdDDVEZHeWbjqGXUXnoXVW4g/DQ/HEyDDcwKdXE9k9hhoisivfllTjH/87CQB4a0oMRkX2kbkiIuouXO6SiOxGc6uEZ9d9B0kA46P1DDREDoahhojsxtvbT+BIeQ1u6OWMBfcOlLscIupmDDVEZBcKK2uwYkshAGDhfYPQ21Ujc0VE1N0YaojI5kmSQNq679FsknBHfx+Mj9bLXRIRyYADhYnIphWfq8erPz180kWtwpIJQ6BQKOQui4hkwFBDRDbpjKEBK7cUYu2eErRKbY8+mH/vQAR46mSujIjkwlBDRDalqrYJb207gcxdp9DcKgEAbovwxl/u7o+oQE95iyMiWTHUEJFNMNS34O0dJ/DeNz+ivtkEAIgNuQF/ubs/4sN6y1wdEfUEDDVEJJvmVgmbDpfjXG3zVdtVGBuRuesUahpbAQA39fXAn+/uj5ER3hw/Q0RmDDVE1O1aTRI2HjiN5bnHUHK+ocP7Rfq5IfWuG3HXQF+GGSK6zDWFmlWrVuHVV19FeXk5oqKisGLFCsTFxbXbtqWlBRkZGVizZg3KysrQv39/vPzyy7jnnnvMbWpqajB//nxs2LABlZWVGDp0KJYvX47Y2Fhzm9raWqSlpWHjxo04d+4cQkND8dRTT2HatGnXcgpEdJ2aWk0oNzRavd93pQa88dUxFJ2tAwB4u2oQF3oDFLhySFEpFUgc6It7h/hDqWSYIaL2WR1q1q5di9TUVKxevRrx8fFYtmwZkpKScPToUfTpc/mS5PPmzUNWVhbeeecdREZGIicnBxMmTMA333yDoUOHAgAee+wxHDx4EJmZmdDr9cjKykJiYiIOHz6MgIAAAEBqaiq2bNmCrKwshISEYNOmTXjyySeh1+sxbty467wMRNRRjS0mZO06hbe2ncC5uqvfNroaz17OmHZ7OJITQqBTqzqxQiJyVAohhLBmh/j4eMTGxmLlypUAAEmSEBgYiJkzZyItLe2y9nq9HnPnzsX06dPN2yZOnAidToesrCw0NDTAzc0Nn376KcaOHWtuExMTg9GjR+PFF18EAAwePBiTJk3C/Pnzr9jmaoxGIzw8PGAwGODu7m7NKRMR2sa/fLy3BCu3FKLc2NZDo3ZSwtnKnhMXjROmxAfjkREhcNM6d0WpRGRHrPn+tqqnprm5GQUFBUhPTzdvUyqVSExMRF5eXrv7NDU1QavVWmzT6XTYuXMnAKC1tRUmk+mqbQBg+PDh+Oyzz/DII49Ar9dj27ZtOHbsGN54440rfm5TU5P5Z6PRaM2pEtFP2hv/ovfQ4qk7IzAxpi+cVVyYnIh6BqtCTVVVFUwmE3x9fS22+/r64siRI+3uk5SUhKVLl2LkyJEIDw9Hbm4u1q9fD5OpbUqmm5sbEhISsHjxYgwYMAC+vr748MMPkZeXh379+pmPs2LFCjz++OPo27cvnJycoFQq8c4772DkyJHtfm5GRgaef/55a06PiH5GkgS+/P7MZeNfZowKx+T4IGiceMuIiHqWLv8n1vLlyxEREYHIyEio1WrMmDEDKSkpUCovfXRmZiaEEAgICIBGo8Gbb76JyZMnW7RZsWIFdu3ahc8++wwFBQV4/fXXMX36dHz11Vftfm56ejoMBoP5VVJS0tWnSmQXhBDYfLgCY978GjM/3I+is3Xw7OWM9NGR2DHnDvzh1lAGGiLqkazqqfH29oZKpUJFRYXF9oqKCvj5+bW7j4+PDzZu3IjGxkacO3cOer0eaWlpCAsLM7cJDw/H9u3bUVdXB6PRCH9/f0yaNMncpqGhAc899xw2bNhgHndz00034cCBA3jttdeQmJh42edqNBpoNHxKL1FHCSGws7AKr206hm9LqgEAbhonPHZbGMe/EJFNsCrUqNVqxMTEIDc3F/fffz+AtoHCubm5mDFjxlX31Wq1CAgIQEtLC9atW4ff/e53l7VxcXGBi4sLLly4gJycHLzyyisA2qaFt7S0WPTcAIBKpYIkSdacAhG1Y8+P5/FqzlHknzwPANA5q/CHW0PwxMgwePZSy1wdEVHHWD2lOzU1FcnJyRg2bBji4uKwbNky1NXVISUlBQAwdepUBAQEICMjAwCwe/dulJWVITo6GmVlZVi0aBEkScKcOXPMx8zJyYEQAv3790dhYSFmz56NyMhI8zHd3d1x++23Y/bs2dDpdAgODsb27dvxr3/9C0uXLu2M60DkkL4rrcbrm45h+7GzANpmM/0+Phh/uiMcPm7s6SQi22J1qJk0aRLOnj2LBQsWoLy8HNHR0cjOzjYPHi4uLrboUWlsbMS8efNQVFQEV1dXjBkzBpmZmfD09DS3MRgMSE9PR2lpKby8vDBx4kQsWbIEzs6Xurs/+ugjpKenY8qUKTh//jyCg4OxZMkSLr5HdA2OlBvxxuZjyDnUdivZSanAb4cFYuZv+kHPp1wTkY2yep0aW8V1asjRSJLA59+dxoothThxttbivYt/65UK4P6hAZh1540I6t1LhiqJiK6uy9apIaKeTwiBnEMVeGPzMRytqLliu7FD/PHMXRHo18etG6sjIuo6DDVENuzjvSXIPliOn3e4nq5uNIcZN60TnhgZhokxfeH0s9vCWmclZzMRkd1hqCGyUX/bcQL/95/2F73spVbhkVtD8cfbwuDRi+GFiBwDQw2RDVrzzY/mQPOH4SEYpL90n9lZpcSICG94u3L2EhE5FoYaIhvzYX4xFn52CAAwY1Q//CWpv8wVERH1DHwSHZENWb+vFM9t+B4A8MfbQvHnu2+UuSIiop6DPTVENqD4XD2W5R7Dhv1lEAKYmhCM58YMgEKhkLs0IqIeg6GGqAc7Y2jAii2F+HhPCVqlthlOUxOCsei+QQw0RES/wFBD1EP9u6DtVlNza9vzzUbe6IM/33UjogI95S2MiKiHYqgh6oGMjS144fNDaG6VEBfihb8k9UdcqJfcZRER9WgMNUQ9UGbeKRgbW9Gvjys+evwWKJW81URE9Gs4+4moh6lvbsXfd54EAEwfFc5AQ0TUQQw1RD3Mh/klOF/XjCCvXrjvJr3c5RAR2QyGGqIepLHFhL/tOAEA+NMd4XBS8a8oEVFH8TcmUQ/y74JSVBib4O+hxQM3B8hdDhGRTWGoIeohWkwSVm9v66V5YmQYNE4qmSsiIrItDDVEPcSnB06j9EIDvF3VeCguSO5yiIhsDkMNUQ9w6lwdVm45DgD4421h0Dqzl4aIyFpcp4ZIRqer2x6D8MnetscgeLmoMeWWYLnLIiKySQw1RDKoa2rFqzlH8cHuYjSb2h6DcPuNPnhuzAC4avjXkojoWvC3J5EMnv/8ED7eWwoAiA9tewxCbAgfg0BEdD0Yaoi6Wcn5eqzfVwYAWP37m5E0yI9P3CYi6gQMNUTd7O0dJ9AqCdwW4Y17BvvLXQ4Rkd3g7CeiblRhbMTHe9puO80Y1U/maoiI7AtDDVE3+tuOIjSbJMSFeCE+rLfc5RAR2RWGGqJucq62Ce/vPgUAmP4b9tIQEXU2hhqibvKP/51EY4uEm/p6YGSEt9zlEBHZHYYaom5gqG/Bmm/aemlmjOrH2U5ERF2AoYaoG6zJ+xG1Ta2I9HND4gBfucshIrJLDDVEXez7UgP+tqMIAPDkqH5QKtlLQ0TUFRhqiLrQD2eM+P3fd6O2qRXxoV4YO4Tr0hARdRWGGqIuUlhZg9+/uxuGhhYMDfLE3/8QCxV7aYiIugxDDVEXOFlVh//3zm6cq2vG4AB3vJcSxwdVEhF1MYYaok6Wd+IcpryzC5U1TYj0c0PmI/Hw0DnLXRYRkd3jPx2JOsm+4gt4fdNR/K/wHAAg3McFmY/G4wYXtcyVERE5hmvqqVm1ahVCQkKg1WoRHx+P/Pz8K7ZtaWnBCy+8gPDwcGi1WkRFRSE7O9uiTU1NDWbNmoXg4GDodDoMHz4ce/bsuexYP/zwA8aNGwcPDw+4uLggNjYWxcXF13IKRNdECIGtRyqx5psfza/3/ncSj7y3Bw/89Rv8r/AcnFUKTE0IxsdPJMDHTSN3yUREDsPqnpq1a9ciNTUVq1evRnx8PJYtW4akpCQcPXoUffr0uaz9vHnzkJWVhXfeeQeRkZHIycnBhAkT8M0332Do0KEAgMceewwHDx5EZmYm9Ho9srKykJiYiMOHDyMgIAAAcOLECYwYMQKPPvoonn/+ebi7u+PQoUPQarXXeQmIOkYIgZf+ewRv/zQ9+5dUSgUevLkvZt7ZD31v6NXN1RERkUIIIazZIT4+HrGxsVi5ciUAQJIkBAYGYubMmUhLS7usvV6vx9y5czF9+nTztokTJ0Kn0yErKwsNDQ1wc3PDp59+irFjx5rbxMTEYPTo0XjxxRcBAA899BCcnZ2RmZl5TSdqNBrh4eEBg8EAd3f3azoGObalm4/hzdzjAIDEAX2gcVKZ3+vtqsYfhocgzMdVrvKIiOySNd/fVvXUNDc3o6CgAOnp6eZtSqUSiYmJyMvLa3efpqamy3pTdDoddu7cCQBobW2FyWS6ahtJkvDll19izpw5SEpKwv79+xEaGor09HTcf//9V/zcpqYm889Go9GaUyWysGproTnQLLxvIFJuDZW5IiIi+iWrxtRUVVXBZDLB19dymXdfX1+Ul5e3u09SUhKWLl2K48ePQ5IkbN68GevXr8eZM2cAAG5ubkhISMDixYtx+vRpmEwmZGVlIS8vz9ymsrIStbW1eOmll3DPPfdg06ZNmDBhAh544AFs37693c/NyMiAh4eH+RUYGGjNqRKZvft1EV7NOQoASBsdyUBDRNRDdfmU7uXLlyMiIgKRkZFQq9WYMWMGUlJSoFRe+ujMzEwIIRAQEACNRoM333wTkydPNreRJAkAMH78eDzzzDOIjo5GWloa7r33Xqxevbrdz01PT4fBYDC/SkpKuvpUyc5cqGvGi18cxotf/gAAmJUYgWm3h8tcFRERXYlVocbb2xsqlQoVFRUW2ysqKuDn59fuPj4+Pti4cSPq6upw6tQpHDlyBK6urggLCzO3CQ8Px/bt21FbW4uSkhLk5+ejpaXF3Mbb2xtOTk4YOHCgxbEHDBhwxdlPGo0G7u7uFi+ijjA2tuCNzcdw2ytb8e7OkwCAP90RjqfvjJC5MiIiuhqrQo1arUZMTAxyc3PN2yRJQm5uLhISEq66r1arRUBAAFpbW7Fu3TqMHz/+sjYuLi7w9/fHhQsXkJOTY26jVqsRGxuLo0ePWrQ/duwYgoODrTkFoqvK2nUKI1/ZiuW5x1Hb1IoB/u54d+owzEnqD4WCjzggIurJrJ7SnZqaiuTkZAwbNgxxcXFYtmwZ6urqkJKSAgCYOnUqAgICkJGRAQDYvXs3ysrKEB0djbKyMixatAiSJGHOnDnmY+bk5EAIgf79+6OwsBCzZ89GZGSk+ZgAMHv2bEyaNAkjR47EqFGjkJ2djc8//xzbtm27zktA1GZf8QXM23gQQNvCeal39cfowX58qjYRkY2wOtRMmjQJZ8+exYIFC1BeXo7o6GhkZ2ebBw8XFxdbjJdpbGzEvHnzUFRUBFdXV4wZMwaZmZnw9PQ0tzEYDEhPT0dpaSm8vLwwceJELFmyBM7Ol5aWnzBhAlavXo2MjAw89dRT6N+/P9atW4cRI0Zcx+kTXbJqSyEAYFyUHm9MiubDJ4mIbIzV69TYKq5TQ1dzsMyAe1fshFIBfJV6O9ebISLqIaz5/uYDLYkA/HVbWy/NvTfpGWiIiGwUQw05vMLKGvz3YNs6S9NH9ZO5GiIiulYMNeTw/rr1BIQA7h7oi/5+bnKXQ0RE14ihhhzaqXN1+PTb0wCAGb9hLw0RkS1jqCGHtnr7CZgkgdtv9MFNfT3lLoeIiK4DQw05rNPVDfh3QSkAYCZ7aYiIbB5DDTmk+uZWPP3RfrSYBOJDvTAsxEvukoiI6Dox1JDDaWwx4bE1e7Hnxwtw0zph4X2D5C6JiIg6AUMNOZSmVhOmZRXgmxPn4KJWYc0jcRio52KMRET2gKGGHEaLScKMD/Zj29Gz0Dor8Y8/xOLmoBvkLouIiDqJ1c9+IrIFlcZGPPn+PpyvazZva2gx4YyhEWonJd6dGov4sN4yVkhERJ2NoYbs0mffnsbeUxcu265WKbH69zdjRIS3DFUREVFXYqghu3SgpBoA8PAtwRgXrTdvD+7dC33ctDJVRUREXYmhhuzSxVBzz2A/xHK6NhGRQ+BAYbI7VbVNKL3QAIUCuKmvh9zlEBFRN2GoIbtzoLgaANDPxxVuWmd5iyEiom7DUEN25+Ktp+hAT1nrICKi7sVQQ3bHHGqCPGWtg4iIuhdDDdkVSRL4lj01REQOiaGG7EpRVS1qmlqhc1ahv6+b3OUQEVE3Yqghu7L/p0HCQwI84KTi/95ERI6Ev/XJrnA8DRGR42KoIbvCmU9ERI6LoYbsRkOzCUfKawAw1BAROSKGGrIbB08bYJIE+rhp4O/B5zsRETkahhqyG/uL257KHR3oCYVCIXM1RETU3RhqyG5wkDARkWNjqCG7cfGZTxxPQ0TkmBhqyC5UGhtx2tD405O5PeUuh4iIZMBQQ3Zh/0+3nm7s4wZXjZO8xRARkSz4259s0vGKGpw2NJp/zj5YDgAYyvE0REQOi6GGbM7eH89j0t92wSSJy97jeBoiIsfFUEM2pbHFhGfXfQeTJBDgqYNnL2fzez5uGowe4i9jdUREJCeGGrIpq7YW4sTZOvi4afCfp26Dx89CDRERObZrGii8atUqhISEQKvVIj4+Hvn5+Vds29LSghdeeAHh4eHQarWIiopCdna2RZuamhrMmjULwcHB0Ol0GD58OPbs2XPFY06bNg0KhQLLli27lvLJRv1wxoi3tp0AALwwbhADDRERWbA61KxduxapqalYuHAh9u3bh6ioKCQlJaGysrLd9vPmzcPbb7+NFStW4PDhw5g2bRomTJiA/fv3m9s89thj2Lx5MzIzM/H999/j7rvvRmJiIsrKyi473oYNG7Br1y7o9XprSycbZpIE0tZ9h1ZJIGmQL28zERHR5YSV4uLixPTp080/m0wmodfrRUZGRrvt/f39xcqVKy22PfDAA2LKlClCCCHq6+uFSqUSX3zxhUWbm2++WcydO9diW2lpqQgICBAHDx4UwcHB4o033uhw3QaDQQAQBoOhw/tQz/HOjhMi+NkvxOCF2aLc0CB3OURE1E2s+f62qqemubkZBQUFSExMNG9TKpVITExEXl5eu/s0NTVBq7V8uKBOp8POnTsBAK2trTCZTFdtAwCSJOHhhx/G7NmzMWjQIGvKJhtXfK4er206CgCYO2YAfN35sEoiIrqcVaGmqqoKJpMJvr6+Ftt9fX1RXl7e7j5JSUlYunQpjh8/DkmSsHnzZqxfvx5nzpwBALi5uSEhIQGLFy/G6dOnYTKZkJWVhby8PHMbAHj55Zfh5OSEp556qkO1NjU1wWg0WrzINq3YchyNLRISwnpjUmyg3OUQEVEP1eUrCi9fvhwRERGIjIyEWq3GjBkzkJKSAqXy0kdnZmZCCIGAgABoNBq8+eabmDx5srlNQUEBli9fjvfee6/DT1/OyMiAh4eH+RUYyC9DW9RikrDpcAUAYFZiBJ++TUREV2RVqPH29oZKpUJFRYXF9oqKCvj5+bW7j4+PDzZu3Ii6ujqcOnUKR44cgaurK8LCwsxtwsPDsX37dtTW1qKkpAT5+floaWkxt/n6669RWVmJoKAgODk5wcnJCadOncKf//xnhISEtPu56enpMBgM5ldJSYk1p0o9xK6iczA0tMDbVY1hIV5yl0NERD2YVaFGrVYjJiYGubm55m2SJCE3NxcJCQlX3Ver1SIgIACtra1Yt24dxo8ff1kbFxcX+Pv748KFC8jJyTG3efjhh/Hdd9/hwIED5pder8fs2bORk5PT7udpNBq4u7tbvMj2/Penxx/cPcgPKiV7aYiI6MqsXnwvNTUVycnJGDZsGOLi4rBs2TLU1dUhJSUFADB16lQEBAQgIyMDALB7926UlZUhOjoaZWVlWLRoESRJwpw5c8zHzMnJgRAC/fv3R2FhIWbPno3IyEjzMXv37o3evXtb1OHs7Aw/Pz/079//mk+eejaTJLDpUFuv4D2D2u8JJCIiusjqUDNp0iScPXsWCxYsQHl5OaKjo5GdnW0ePFxcXGwxXqaxsRHz5s1DUVERXF1dMWbMGGRmZsLT09PcxmAwID09HaWlpfDy8sLEiROxZMkSODtzcTVHVnDqAqpqm+CudcItYb1/fQciInJoCiHE5U8FtENGoxEeHh4wGAy8FWUjXvj8MP7xv5N44OYALP1dtNzlEBGRDKz5/u7y2U9E10IIgZxDbeNpeOuJiIg6gqGGeqTvSg0oq25AL7UKI2/0kbscIiKyAQw11CNl/9RLM6p/H2idVTJXQ0REtoChhnocIQSyf5rKfc9g3noiIqKOYaihHudYRS1OVtVB7aTEqMg+cpdDREQ2gqGGepz/Hmx75tfICG+4aqxedYCIiBwUQw31KJIk8N/v2249JXHWExERWYGhhnoMIQTmbjyIoxU10DgpkTjA99d3IiIi+glDDfUIQgg8//lhfJhfDKUCePW3UbjBRS13WUREZEMYakh2Qgi89N8jeO+bHwEArzwYhXFRenmLIiIim8NRmNStJEmg9EIDBC49neOTvaV4e0cRAGDJhMF4MKavXOUREZENY6ihbnOhrhnJ/8zHd6WGdt9fcO9ATIkP7uaqiIjIXjDUULcwNLRg6j/y8X2ZAU5KBTROl+58ap1VmPGbfki5NVTGComIyNYx1FCXq21qRco/2wJNbxc1Pnr8FkT4usldFhER2RkOFKYu1dBswiPv7cG+4mp46JyR+Wg8Aw0REXUJhhrqMpU1jfjjv/Yi/+R5uGmckPloHAbq3eUui4iI7BRvP1Gnu1DXjNU7TmDNNz+isUVCL7UK7z0Si5v6espdGhER2TGGGuqQVpOEfcXVaGgxXbXdvlMX8PedJ1Hb1AoAGBrkiUX3DUJUoGc3VElERI6MoYY65O0dRXg152iH2w/0d8dfkm7EqP59oFAourAyIiKiNgw11CEXn5wd0rsXXK7y5Gw3rROmJoTgnkF+UCoZZoiIqPsw1NCvOlfbhINlRgDAx9MS0MdNK3NFREREl+PsJ/pVOwurAAAD/N0ZaIiIqMdiqKFftf3YWQDAyBu9Za6EiIjoyhhq6KqEEPj6eFtPze0RPjJXQ0REdGUMNXRVR8prcLamCTpnFWJCbpC7HCIioitiqKGr2vHTradbwrygcVLJXA0REdGVMdTQVe04fnE8DW89ERFRz8ZQQ1dU39yKPScvAGCoISKino+hhq5o98nzaDZJCPDUIczbRe5yiIiIroqhhq5ox8+mcvNRB0RE1NMx1NAVmUMNp3ITEZENYKihdpVVN+DE2TooFcDwflx0j4iIej6GGmrX1z/10kQHesJD5yxzNURERL+OoYbaxancRERka/iUbrJQVt2AlVuOI+dQBQCGGiIish3X1FOzatUqhISEQKvVIj4+Hvn5+Vds29LSghdeeAHh4eHQarWIiopCdna2RZuamhrMmjULwcHB0Ol0GD58OPbs2WNxjGeffRZDhgyBi4sL9Ho9pk6ditOnT19L+dSOyppGLPrsEEa9ug0f5pfAJAlMGBqA6L6ecpdGRETUIVaHmrVr1yI1NRULFy7Evn37EBUVhaSkJFRWVrbbft68eXj77bexYsUKHD58GNOmTcOECROwf/9+c5vHHnsMmzdvRmZmJr7//nvcfffdSExMRFlZGQCgvr4e+/btw/z587Fv3z6sX78eR48exbhx467xtOnnjlfUYNSr2/DeNz+i2SThljAv/HtaAt6YFA2lklO5iYjINiiEEMKaHeLj4xEbG4uVK1cCACRJQmBgIGbOnIm0tLTL2uv1esydOxfTp083b5s4cSJ0Oh2ysrLQ0NAANzc3fPrppxg7dqy5TUxMDEaPHo0XX3yx3Tr27NmDuLg4nDp1CkFBQb9at9FohIeHBwwGA9zd3a05ZbuX8Z8f8PaOIkT0ccWicYMwPLw316UhIqIewZrvb6t6apqbm1FQUIDExMRLB1AqkZiYiLy8vHb3aWpqglartdim0+mwc+dOAEBraytMJtNV27THYDBAoVDA09Pzip9rNBotXtS+/B/PAwCm3R6OW/txoT0iIrJNVoWaqqoqmEwm+Pr6Wmz39fVFeXl5u/skJSVh6dKlOH78OCRJwubNm7F+/XqcOXMGAODm5oaEhAQsXrwYp0+fhslkQlZWFvLy8sxtfqmxsRHPPvssJk+efMXUlpGRAQ8PD/MrMDDQmlN1GPXNrfi+1AAAiAv1krkaIiKia9flU7qXL1+OiIgIREZGQq1WY8aMGUhJSYFSeemjMzMzIYRAQEAANBoN3nzzTUyePNmizUUtLS343e9+ByEE3nrrrSt+bnp6OgwGg/lVUlLSJedn6/YXV6NVEtB7aNH3Bp3c5RAREV0zq0KNt7c3VCoVKioqLLZXVFTAz8+v3X18fHywceNG1NXV4dSpUzhy5AhcXV0RFhZmbhMeHo7t27ejtrYWJSUlyM/PR0tLi0Ub4FKgOXXqFDZv3nzVe2sajQbu7u4WL7rc7pNtt57iQr1424mIiGyaVaFGrVYjJiYGubm55m2SJCE3NxcJCQlX3Ver1SIgIACtra1Yt24dxo8ff1kbFxcX+Pv748KFC8jJybFoczHQHD9+HF999RV69+5tTel0BfknzwEA4kJ5PYmIyLZZvfheamoqkpOTMWzYMMTFxWHZsmWoq6tDSkoKAGDq1KkICAhARkYGAGD37t0oKytDdHQ0ysrKsGjRIkiShDlz5piPmZOTAyEE+vfvj8LCQsyePRuRkZHmY7a0tODBBx/Evn378MUXX8BkMpnH8Hh5eUGtVl/3hXBETa0m7C+uBsDxNEREZPusDjWTJk3C2bNnsWDBApSXlyM6OhrZ2dnmwcPFxcUWY2EaGxsxb948FBUVwdXVFWPGjEFmZqbFrCWDwYD09HSUlpbCy8sLEydOxJIlS+Ds3PbMobKyMnz22WcAgOjoaIt6tm7dijvuuMPa0yAA35ca0NQqobeLGuE+LnKXQ0REdF2sXqfGVnGdmsut2lqIV3OOYvRgP7z1+xi5yyEiIrpMl61TQ/Zlz4+XBgkTERHZOoYaB2WSBPb+eAEAQw0REdkHhhoH9cMZI2qbWuGmdUKkH2/HERGR7WOocVAX16eJDfGCig+tJCIiO8BQ46AurU/DW09ERGQfGGockBAC+T/rqSEiIrIHDDUOqLCyFhfqW6B1VmJIgIfc5RAREXUKhhoHdHE8zc1BN0DtxP8FiIjIPvAbzQFxfRoiIrJHDDUOxiQJ7DxeBQCI50MsiYjIjjDUOJg9P57HubpmePZyxrCQG+Quh4iIqNMw1DiY7INtTze/a4AvnFX84yciIvvBbzUHIknCHGruGewnczVERESdi6HGgXxbWo1yYyNc1Crc2s9b7nKIiIg6FUONA8k+1NZL85sBvtA6q2SuhoiIqHMx1DgIIX5262kQbz0REZH9YahxED+cqcGpc/XQOClxR38fucshIiLqdAw1DuLiraeRN/rAReMkczVERESdj6HGQWQfPAMAGM1ZT0REZKcYahzAibO1OFZRCyelAndG+spdDhERUZdgqHEAFwcID+/nDY9ezjJXQ0RE1DUYahxAziHOeiIiIvvHUGPnTlbV4btSAxQK4O5BvPVERET2i6HGjgkhMH/jQQDA7Tf6wNtVI3NFREREXYehxo79u6AUOwuroHFSYuF9g+Quh4iIqEsx1NipszVNePHLHwAAz9x1I0K9XWSuiIiIqGsx1NipRZ8dgqGhBYMD3PHYiFC5yyEiIupyDDV2aNOhcnz5/RmolAq8PPEmOKn4x0xERPaP33Z2xtjYgvmftg0OfnxkGAbpPWSuiIiIqHsw1NiZv249gQpjE0K9XfD0nRFyl0NERNRtGGrsTMGp8wCAGaP6QeuskrkaIiKi7sNQY2dOVtUBAPr7uclcCRERUfdiqLEjhoYWVNU2AwBCOIWbiIgcDEONHfnxp16aPm4auGqcZK6GiIioezHU2JGLt5640B4RETmiawo1q1atQkhICLRaLeLj45Gfn3/Fti0tLXjhhRcQHh4OrVaLqKgoZGdnW7SpqanBrFmzEBwcDJ1Oh+HDh2PPnj0WbYQQWLBgAfz9/aHT6ZCYmIjjx49fS/l2q+inUBPmw1BDRESOx+pQs3btWqSmpmLhwoXYt28foqKikJSUhMrKynbbz5s3D2+//TZWrFiBw4cPY9q0aZgwYQL2799vbvPYY49h8+bNyMzMxPfff4+7774biYmJKCsrM7d55ZVX8Oabb2L16tXYvXs3XFxckJSUhMbGxms4bfvEnhoiInJowkpxcXFi+vTp5p9NJpPQ6/UiIyOj3fb+/v5i5cqVFtseeOABMWXKFCGEEPX19UKlUokvvvjCos3NN98s5s6dK4QQQpIk4efnJ1599VXz+9XV1UKj0YgPP/ywQ3UbDAYBQBgMhg61t0Vjlu8Qwc9+ITYdKpe7FCIiok5hzfe3VT01zc3NKCgoQGJionmbUqlEYmIi8vLy2t2nqakJWq3WYptOp8POnTsBAK2trTCZTFdtc/LkSZSXl1t8roeHB+Lj46/6uUaj0eJlz4QQ7KkhIiKHZlWoqaqqgslkgq+vr8V2X19flJeXt7tPUlISli5diuPHj0OSJGzevBnr16/HmTNnAABubm5ISEjA4sWLcfr0aZhMJmRlZSEvL8/c5uKxrfncjIwMeHh4mF+BgYHWnKrNqaxpQn2zCUoFEOTVS+5yiIiIul2Xz35avnw5IiIiEBkZCbVajRkzZiAlJQVK5aWPzszMhBACAQEB0Gg0ePPNNzF58mSLNtZKT0+HwWAwv0pKSjrjdHqsorNtvTSBXr2gduKkNiIicjxWfft5e3tDpVKhoqLCYntFRQX8/Pza3cfHxwcbN25EXV0dTp06hSNHjsDV1RVhYWHmNuHh4di+fTtqa2tRUlKC/Px8tLS0mNtcPLY1n6vRaODu7m7xsme89URERI7OqlCjVqsRExOD3Nxc8zZJkpCbm4uEhISr7qvVahEQEIDW1lasW7cO48ePv6yNi4sL/P39ceHCBeTk5JjbhIaGws/Pz+JzjUYjdu/e/auf6yhOVtUCYKghIiLHZfWys6mpqUhOTsawYcMQFxeHZcuWoa6uDikpKQCAqVOnIiAgABkZGQCA3bt3o6ysDNHR0SgrK8OiRYsgSRLmzJljPmZOTg6EEOjfvz8KCwsxe/ZsREZGmo+pUCgwa9YsvPjii4iIiEBoaCjmz58PvV6P+++/vxMug+272FMTxlBDREQOyupQM2nSJJw9exYLFixAeXk5oqOjkZ2dbR7EW1xcbDEWprGxEfPmzUNRURFcXV0xZswYZGZmwtPT09zGYDAgPT0dpaWl8PLywsSJE7FkyRI4Ozub28yZMwd1dXV4/PHHUV1djREjRiA7O/uyWVOO6tLCe64yV0JERCQPhRBCyF1EdzAajfDw8IDBYLC78TWtJgmR87PRKgl8k/Yb6D11cpdERETUKaz5/uY0GTtQeqEBrZKA1lkJP3f2XBERkWNiqLEDF8fThPR2gVKpkLkaIiIieTDU2AE+yJKIiIihxi4UneV0biIiIoYaO3Bp4T3OfCIiIsfFUGMHuJowERERQ43Nq29uxRlDIwAuvEdERI6NocbG/VhVDwDw7OWMG1zUMldDREQkH4YaG8dbT0RERG0YamwcH2RJRETUhqHGxhXxQZZEREQAGGpsHqdzExERtWGosXEcU0NERNSGocaGXahrRnV9CwAgxLuXzNUQERHJi6HGhhWfb5vO7eOmQS+1k8zVEBERyYuhxoaVXGgLNYE36GSuhIiISH4MNTas5HwDACDQi7eeiIiIGGps2KWeGoYaIiIihhobVvLTmJpAL95+IiIiYqixYaUXfrr9xJ4aIiIihhpbJUkCZRc4poaIiOgihhobVVHTiGaTBJVSAX8PrdzlEBERyY6hxkZdnPnk76GFk4p/jERERPw2tFEXBwkH8dYTERERAIYam8Xp3ERERJYYamzUpYX3OJ2biIgIYKixWeaeGt5+IiIiAsBQY7NKfxpT05e3n4iIiAAw1Nik5lYJZ4yNAHj7iYiI6CKGGht0uroBQgBaZyV8XDVyl0NERNQjMNTYoIvjafre0AsKhULmaoiIiHoGhhobZJ75dANvPREREV3EUGODOPOJiIjocgw1NujiasJceI+IiOgShhobVHKBC+8RERH90jWFmlWrViEkJARarRbx8fHIz8+/YtuWlha88MILCA8Ph1arRVRUFLKzsy3amEwmzJ8/H6GhodDpdAgPD8fixYshhDC3qa2txYwZM9C3b1/odDoMHDgQq1evvpbybR7XqCEiIrqck7U7rF27FqmpqVi9ejXi4+OxbNkyJCUl4ejRo+jTp89l7efNm4esrCy88847iIyMRE5ODiZMmIBvvvkGQ4cOBQC8/PLLeOutt7BmzRoMGjQIe/fuRUpKCjw8PPDUU08BAFJTU7FlyxZkZWUhJCQEmzZtwpNPPgm9Xo9x48Zd52WwHXVNrThX1wyAY2qIiIh+TiF+3h3SAfHx8YiNjcXKlSsBAJIkITAwEDNnzkRaWtpl7fV6PebOnYvp06ebt02cOBE6nQ5ZWVkAgHvvvRe+vr74+9//fsU2gwcPxqRJkzB//nxzm5iYGIwePRovvvjir9ZtNBrh4eEBg8EAd3d3a065RzlaXoOkZTvgrnXCd4uS5C6HiIioS1nz/W3V7afm5mYUFBQgMTHx0gGUSiQmJiIvL6/dfZqamqDVai226XQ67Ny50/zz8OHDkZubi2PHjgEAvv32W+zcuROjR4+2aPPZZ5+hrKwMQghs3boVx44dw913333FzzUajRYve2AeJMxeGiIiIgtW3X6qqqqCyWSCr6+vxXZfX18cOXKk3X2SkpKwdOlSjBw5EuHh4cjNzcX69ethMpnMbdLS0mA0GhEZGQmVSgWTyYQlS5ZgypQp5jYrVqzA448/jr59+8LJyQlKpRLvvPMORo4c2e7nZmRk4Pnnn7fm9GyCeTo3x9MQERFZ6PLZT8uXL0dERAQiIyOhVqsxY8YMpKSkQKm89NEff/wx3n//fXzwwQfYt28f1qxZg9deew1r1qwxt1mxYgV27dqFzz77DAUFBXj99dcxffp0fPXVV+1+bnp6OgwGg/lVUlLS1afaLcwL73HmExERkQWremq8vb2hUqlQUVFhsb2iogJ+fn7t7uPj44ONGzeisbER586dg16vR1paGsLCwsxtZs+ejbS0NDz00EMAgCFDhuDUqVPIyMhAcnIyGhoa8Nxzz2HDhg0YO3YsAOCmm27CgQMH8Nprr1ncDrtIo9FAo7G/5yJx4T0iIqL2WdVTo1arERMTg9zcXPM2SZKQm5uLhISEq+6r1WoREBCA1tZWrFu3DuPHjze/V19fb9FzAwAqlQqSJAFomxbe0tJy1TaOggvvERERtc/qKd2pqalITk7GsGHDEBcXh2XLlqGurg4pKSkAgKlTpyIgIAAZGRkAgN27d6OsrAzR0dEoKyvDokWLIEkS5syZYz7mfffdhyVLliAoKAiDBg3C/v37sXTpUjzyyCMAAHd3d9x+++2YPXs2dDodgoODsX37dvzrX//C0qVLO+M62AQhBEq58B4REVG7rA41kyZNwtmzZ7FgwQKUl5cjOjoa2dnZ5sHDxcXFFj0qjY2NmDdvHoqKiuDq6ooxY8YgMzMTnp6e5jYrVqzA/Pnz8eSTT6KyshJ6vR5PPPEEFixYYG7z0UcfIT09HVOmTMH58+cRHByMJUuWYNq0addx+ralur4FtU2tALjwHhER0S9ZvU6NrbKHdWq+K63GuJX/g4+bBnvmXj6OiIiIyN5Y8/1tdU8NdR1DfQuqG5qv+P63JdUAgMAbeOuJiIjolxhqeoj1+0qRtu57NJt+feAzZz4RERFdjqGmB/j829P4yyffQhKAzlkFpeLKbXVqFcZF6buvOCIiIhvBUCOznEPlmLX2ACQBPBQbiP+bMATKq6UaIiIialeXryhMV7b1SCVmfLAPJknggaEBWMJAQ0REdM0YamSSd+IcnsgqQItJYOwQf7zy4E1QMdAQERFdM4YamSz5z2E0t0q4a6Avlj0UDScV/yiIiIiuB79JZXC2pgkHy4wAgIwHhsCZgYaIiOi68dtUBl8fPwsAGKR3h7er/T10k4iISA4MNTL4+ngVAGDkjT4yV0JERGQ/GGq6mSQJc0/NyAiGGiIios7CUNPNDp8xoqq2Gb3UKsQE3yB3OURERHaDoaab7fiplyYhrDfUTrz8REREnYXfqt3s62McT0NERNQVGGq6UV1TK/aeOg+AoYaIiKizMdR0o11F59BiEgj00iGkN5+0TURE1JkYarrRjmOXZj0pFHwkAhERUWdiqOlGF9enuY1TuYmIiDodQ003KTlfj6KqOqiUCgzv11vucoiIiOwOQ003uTiV++YgT7hrnWWuhoiIyP4w1HSTn4+nISIios7HUNMNWkwSvik8BwC4jVO5iYiIugRDTReTJIF5Gw6ipqkVXi5qDAnwkLskIiIiu8RQ04WEEFj42SGs3VsCpQJ48f7BUCk5lZuIiKgrMNR0ESEElnz5AzJ3nYJCAbz+uyiMGeIvd1lERER2i6Gmi7y+6Rje3XkSAJAxYQgmDO0rc0VERET2jaGmC/y7oBQrtxYCAJ4fNwgPxQXJXBEREZH9Y6jpAtkHywEAT4wMQ/LwEHmLISIichAMNV2gsLIGAHA7p28TERF1G4aaTtbYYkLx+XoAQL8+rjJXQ0RE5DgYajrZj+fqIAnATesEHzeN3OUQERE5DIaaTlZYWQsAiOjjCoWCa9IQERF1F4aaTna8oi3U8NYTERFR92Ko6WSFZxlqiIiI5HBNoWbVqlUICQmBVqtFfHw88vPzr9i2paUFL7zwAsLDw6HVahEVFYXs7GyLNiaTCfPnz0doaCh0Oh3Cw8OxePFiCCEs2v3www8YN24cPDw84OLigtjYWBQXF1/LKXSZE5UMNURERHKwOtSsXbsWqampWLhwIfbt24eoqCgkJSWhsrKy3fbz5s3D22+/jRUrVuDw4cOYNm0aJkyYgP3795vbvPzyy3jrrbewcuVK/PDDD3j55ZfxyiuvYMWKFeY2J06cwIgRIxAZGYlt27bhu+++w/z586HVaq/htLtGq0lCUVUdACCij5vM1RARETkWhfhld8iviI+PR2xsLFauXAkAkCQJgYGBmDlzJtLS0i5rr9frMXfuXEyfPt28beLEidDpdMjKygIA3HvvvfD19cXf//73K7Z56KGH4OzsjMzMTOvPEoDRaISHhwcMBgPc3d2v6Ri/5mRVHUa9tg1aZyUOP38PlHx4JRER0XWx5vvbqp6a5uZmFBQUIDEx8dIBlEokJiYiLy+v3X2ampou603R6XTYuXOn+efhw4cjNzcXx44dAwB8++232LlzJ0aPHg2gLTh9+eWXuPHGG5GUlIQ+ffogPj4eGzduvGKtTU1NMBqNFq+udnHmU5i3KwMNERFRN7Mq1FRVVcFkMsHX19diu6+vL8rLy9vdJykpCUuXLsXx48chSRI2b96M9evX48yZM+Y2aWlpeOihhxAZGQlnZ2cMHToUs2bNwpQpUwAAlZWVqK2txUsvvYR77rkHmzZtwoQJE/DAAw9g+/bt7X5uRkYGPDw8zK/AwEBrTvWaFHI8DRERkWy6fPbT8uXLERERgcjISKjVasyYMQMpKSlQKi999Mcff4z3338fH3zwAfbt24c1a9bgtddew5o1awC09dQAwPjx4/HMM88gOjoaaWlpuPfee7F69ep2Pzc9PR0Gg8H8Kikp6epTtVijhoiIiLqXkzWNvb29oVKpUFFRYbG9oqICfn5+7e7j4+ODjRs3orGxEefOnYNer0daWhrCwsLMbWbPnm3urQGAIUOG4NSpU8jIyEBycjK8vb3h5OSEgQMHWhx7wIABFrexfk6j0UCj6d4VfS8+84k9NURERN3Pqp4atVqNmJgY5ObmmrdJkoTc3FwkJCRcdV+tVouAgAC0trZi3bp1GD9+vPm9+vp6i54bAFCpVOYeGrVajdjYWBw9etSizbFjxxAcHGzNKXQZIQROnG2b+cRQQ0RE1P2s6qkBgNTUVCQnJ2PYsGGIi4vDsmXLUFdXh5SUFADA1KlTERAQgIyMDADA7t27UVZWhujoaJSVlWHRokWQJAlz5swxH/O+++7DkiVLEBQUhEGDBmH//v1YunQpHnnkEXOb2bNnY9KkSRg5ciRGjRqF7OxsfP7559i2bdt1XoLOUW5sRG1TK5yUCgT3dpG7HCIiIodjdaiZNGkSzp49iwULFqC8vBzR0dHIzs42Dx4uLi626HVpbGzEvHnzUFRUBFdXV4wZMwaZmZnw9PQ0t1mxYgXmz5+PJ598EpWVldDr9XjiiSewYMECc5sJEyZg9erVyMjIwFNPPYX+/ftj3bp1GDFixHWcfue5OJ4muHcvqJ24UDMREVF3s3qdGlvV1evU/GPnSbzwxWEkDfLF2w8P6/TjExEROaIuW6eGrozPfCIiIpIXQ00nuTSdm49HICIikgNDTSfhgyyJiIjkxVDTCc7XNeNcXTMAIMyHM5+IiIjkwFDTCS7eegrw1KGX2uoJZURERNQJGGo6gXk8jS9vPREREcmFoaYTmB9k6cNQQ0REJBeGmk5wnM98IiIikh1DTSc4wdtPREREsmOouU51Ta04bWgEAPTz4Ro1REREcuFUneskCYG5YwbgtKEBHr2c5S6HiIjIYTHUXCc3rTP+ODJM7jKIiIgcHm8/ERERkV1gqCEiIiK7wFBDREREdoGhhoiIiOwCQw0RERHZBYYaIiIisgsMNURERGQXGGqIiIjILjDUEBERkV1gqCEiIiK7wFBDREREdoGhhoiIiOwCQw0RERHZBYd5SrcQAgBgNBplroSIiIg66uL39sXv8atxmFBTU1MDAAgMDJS5EiIiIrJWTU0NPDw8rtpGIToSfeyAJEk4ffo03NzcoFAoOvXYRqMRgYGBKCkpgbu7e6cem3h9uwOvcdfi9e16vMZdS87rK4RATU0N9Ho9lMqrj5pxmJ4apVKJvn37dulnuLu78y9TF+L17Xq8xl2L17fr8Rp3Lbmu76/10FzEgcJERERkFxhqiIiIyC4w1HQCjUaDhQsXQqPRyF2KXeL17Xq8xl2L17fr8Rp3LVu5vg4zUJiIiIjsG3tqiIiIyC4w1BAREZFdYKghIiIiu8BQQ0RERHaBoaYTrFq1CiEhIdBqtYiPj0d+fr7cJdmkjIwMxMbGws3NDX369MH999+Po0ePWrRpbGzE9OnT0bt3b7i6umLixImoqKiQqWLb9tJLL0GhUGDWrFnmbby+16esrAy///3v0bt3b+h0OgwZMgR79+41vy+EwIIFC+Dv7w+dTofExEQcP35cxopti8lkwvz58xEaGgqdTofw8HAsXrzY4plAvMYdt2PHDtx3333Q6/VQKBTYuHGjxfsduZbnz5/HlClT4O7uDk9PTzz66KOora3txrP4BUHX5aOPPhJqtVr84x//EIcOHRJ//OMfhaenp6ioqJC7NJuTlJQk/vnPf4qDBw+KAwcOiDFjxoigoCBRW1trbjNt2jQRGBgocnNzxd69e8Utt9wihg8fLmPVtik/P1+EhISIm266STz99NPm7by+1+78+fMiODhY/OEPfxC7d+8WRUVFIicnRxQWFprbvPTSS8LDw0Ns3LhRfPvtt2LcuHEiNDRUNDQ0yFi57ViyZIno3bu3+OKLL8TJkyfFJ598IlxdXcXy5cvNbXiNO+4///mPmDt3rli/fr0AIDZs2GDxfkeu5T333COioqLErl27xNdffy369esnJk+e3M1ncglDzXWKi4sT06dPN/9sMpmEXq8XGRkZMlZlHyorKwUAsX37diGEENXV1cLZ2Vl88skn5jY//PCDACDy8vLkKtPm1NTUiIiICLF582Zx++23m0MNr+/1efbZZ8WIESOu+L4kScLPz0+8+uqr5m3V1dVCo9GIDz/8sDtKtHljx44VjzzyiMW2Bx54QEyZMkUIwWt8PX4ZajpyLQ8fPiwAiD179pjb/Pe//xUKhUKUlZV1W+0/x9tP16G5uRkFBQVITEw0b1MqlUhMTEReXp6MldkHg8EAAPDy8gIAFBQUoKWlxeJ6R0ZGIigoiNfbCtOnT8fYsWMtriPA63u9PvvsMwwbNgy//e1v0adPHwwdOhTvvPOO+f2TJ0+ivLzc4vp6eHggPj6e17eDhg8fjtzcXBw7dgwA8O2332Lnzp0YPXo0AF7jztSRa5mXlwdPT08MGzbM3CYxMRFKpRK7d+/u9poBB3qgZVeoqqqCyWSCr6+vxXZfX18cOXJEpqrsgyRJmDVrFm699VYMHjwYAFBeXg61Wg1PT0+Ltr6+vigvL5ehStvz0UcfYd++fdizZ89l7/H6Xp+ioiK89dZbSE1NxXPPPYc9e/bgqaeeglqtRnJysvkatvf7gte3Y9LS0mA0GhEZGQmVSgWTyYQlS5ZgypQpAMBr3Ik6ci3Ly8vRp08fi/ednJzg5eUl2/VmqKEeafr06Th48CB27twpdyl2o6SkBE8//TQ2b94MrVYrdzl2R5IkDBs2DP/3f/8HABg6dCgOHjyI1atXIzk5Webq7MPHH3+M999/Hx988AEGDRqEAwcOYNasWdDr9bzGBICzn66Lt7c3VCrVZbNDKioq4OfnJ1NVtm/GjBn44osvsHXrVvTt29e83c/PD83NzaiurrZoz+vdMQUFBaisrMTNN98MJycnODk5Yfv27XjzzTfh5OQEX19fXt/r4O/vj4EDB1psGzBgAIqLiwHAfA35++LazZ49G2lpaXjooYcwZMgQPPzww3jmmWeQkZEBgNe4M3XkWvr5+aGystLi/dbWVpw/f162681Qcx3UajViYmKQm5tr3iZJEnJzc5GQkCBjZbZJCIEZM2Zgw4YN2LJlC0JDQy3ej4mJgbOzs8X1Pnr0KIqLi3m9O+DOO+/E999/jwMHDphfw4YNw5QpU8z/zet77W699dbLliA4duwYgoODAQChoaHw8/OzuL5GoxG7d+/m9e2g+vp6KJWWX1sqlQqSJAHgNe5MHbmWCQkJqK6uRkFBgbnNli1bIEkS4uPju71mAJzSfb0++ugjodFoxHvvvScOHz4sHn/8ceHp6SnKy8vlLs3m/OlPfxIeHh5i27Zt4syZM+ZXfX29uc20adNEUFCQ2LJli9i7d69ISEgQCQkJMlZt234++0kIXt/rkZ+fL5ycnMSSJUvE8ePHxfvvvy969eolsrKyzG1eeukl4enpKT799FPx3XffifHjx3O6sRWSk5NFQECAeUr3+vXrhbe3t5gzZ465Da9xx9XU1Ij9+/eL/fv3CwBi6dKlYv/+/eLUqVNCiI5dy3vuuUcMHTpU7N69W+zcuVNERERwSretW7FihQgKChJqtVrExcWJXbt2yV2STQLQ7uuf//ynuU1DQ4N48sknxQ033CB69eolJkyYIM6cOSNf0Tbul6GG1/f6fP7552Lw4MFCo9GIyMhI8be//c3ifUmSxPz584Wvr6/QaDTizjvvFEePHpWpWttjNBrF008/LYKCgoRWqxVhYWFi7ty5oqmpydyG17jjtm7d2u7v3OTkZCFEx67luXPnxOTJk4Wrq6twd3cXKSkpoqamRoazaaMQ4mdLMRIRERHZKI6pISIiIrvAUENERER2gaGGiIiI7AJDDREREdkFhhoiIiKyCww1REREZBcYaoiIiMguMNQQERGRXWCoISIiIrvAUENERER2gaGGiIiI7AJDDREREdmF/w+pQRFhApMaIwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "percentile = 66\n",
    "closest_val = np.percentile(activations, percentile, method='closest_observation')\n",
    "print(closest_val)\n",
    "idx_closest_val = np.where(np.array(activations, np.float64) == closest_val)[0][0]\n",
    "print(f'values above {percentile}%', len(activations) - idx_closest_val)\n",
    "# print(idx_closest_val)\n",
    "plt.plot(activations[idx_closest_val:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 44.03it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "\t Child: 053+050\n",
      "\t\tProto:3 tensor([0.0000, 2.7507], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:4 tensor([0.0000, 2.0495], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:9 tensor([0.0000, 2.8243], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:13 tensor([0.0000, 1.7485], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:16 tensor([0.0000, 3.2713], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:17 tensor([0.0000, 1.2852], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:19 tensor([0.0000, 4.1273], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 420it [00:05, 73.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 086+045\n",
      "\t\tProto:1 tensor([0.0000, 4.3319], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:18 tensor([0.0000, 2.5111], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:11 tensor([0.0000, 3.2857], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:17 tensor([0.0000, 4.8782], device='cuda:0', requires_grad=True)\n",
      "\t Child: 004+032\n",
      "\t\tProto:3 tensor([3.1388, 0.0000], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:6 tensor([0.0577, 0.0000], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:8 tensor([0.2559, 0.0000], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:9 tensor([3.9704, 0.0000], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:14 tensor([2.7296, 0.0000], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 42.75it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "\t Child: 050+051\n",
      "\t\tProto:0 tensor([0.0000, 2.3671], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:3 tensor([0.0000, 3.1122], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:6 tensor([0.0000, 3.3047], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:16 tensor([0.0000, 2.3511], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:18 tensor([0.0000, 0.1159], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:19 tensor([0.0000, 3.7443], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 51.88it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "\t Child: 032+033\n",
      "\t\tProto:0 tensor([0.0000, 1.0593], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:2 tensor([0.0000, 0.7110], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:4 tensor([0.0000, 3.3837], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:6 tensor([0.0000, 3.5011], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:8 tensor([0.0000, 1.4647], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:12 tensor([0.0000, 2.8666], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:18 tensor([0.0000, 2.7044], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:19 tensor([0.0000, 3.4991], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 300it [00:04, 67.28it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "\t Child: 045+101\n",
      "\t\tProto:1 tensor([0.0000, 2.3559], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:3 tensor([0.0000, 2.6002], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:5 tensor([0.0000, 3.9472], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:7 tensor([0.0000, 1.0077], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:8 tensor([0.0000, 3.2147], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:10 tensor([0.0000, 3.7773], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:12 tensor([0.0000, 2.1987], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:13 tensor([0.0000, 3.0346], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:14 tensor([0.0000, 3.2442], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:15 tensor([0.0000, 3.1790], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:16 tensor([0.0000, 2.2836], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:18 tensor([0.0000, 2.4896], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:19 tensor([0.0000, 2.7937], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 46.10it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "\t Child: 033+031\n",
      "\t\tProto:0 tensor([0.0000, 3.0051], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:1 tensor([0.0000, 1.2554], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:3 tensor([0.0000, 3.8950], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:19 tensor([0.0000, 2.1860], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 270it [00:04, 62.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "\t Child: 101+023\n",
      "\t\tProto:1 tensor([0.0000, 3.1944], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:2 tensor([0.0000, 2.2051], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:6 tensor([0.0000, 3.7047], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:7 tensor([0.0000, 0.1995], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:8 tensor([0.0000, 3.2273], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:19 tensor([0.0000, 1.4763], device='cuda:0', requires_grad=True)\n",
      "\t Child: 045+003\n",
      "\t\tProto:5 tensor([3.2268, 0.0000], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:9 tensor([2.2783, 0.0000], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:10 tensor([2.4777, 0.0000], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:13 tensor([3.1175, 0.0000], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:16 tensor([1.4063, 0.0000], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 53.06it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "\t Child: 003+002\n",
      "\t\tProto:1 tensor([0.0000, 1.6834], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:2 tensor([0.0000, 1.8176], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:6 tensor([0.0000, 0.5305], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:7 tensor([0.0000, 0.1318], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:9 tensor([0.0000, 2.0412], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:11 tensor([0.0000, 2.0561], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:13 tensor([0.0000, 2.5633], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:17 tensor([0.0000, 4.3478], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:18 tensor([0.0000, 2.5620], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 150it [00:03, 49.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "\t Child: 023+025\n",
      "\t\tProto:4 tensor([0.0000, 2.0026], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:9 tensor([0.0000, 1.5009], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:10 tensor([0.0000, 1.4211], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:11 tensor([0.0000, 2.6654], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:12 tensor([0.0000, 0.1736], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:13 tensor([0.0000, 2.9452], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:18 tensor([0.0000, 3.3243], device='cuda:0', requires_grad=True)\n",
      "\t Child: 101+100\n",
      "\t\tProto:15 tensor([2.0474, 0.0000], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:5 tensor([1.4804, 0.0000], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:6 tensor([3.6834, 0.0000], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:7 tensor([3.7679, 0.0000], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 43.46it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "\t Child: 002+001\n",
      "\t\tProto:0 tensor([0.0000, 3.2075], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:9 tensor([0.0000, 0.2022], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:12 tensor([0.0000, 3.6557], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:13 tensor([0.0000, 3.5591], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:17 tensor([0.0000, 2.4840], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:01, 45.62it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "\t Child: 025+024\n",
      "\t\tProto:0 tensor([0.0000, 0.8786], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:6 tensor([0.0000, 0.5805], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:7 tensor([0.0000, 2.4203], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:9 tensor([0.0000, 2.9682], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:10 tensor([0.0000, 1.6679], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:11 tensor([0.0000, 1.7539], device='cuda:0', requires_grad=True)\n",
      "\t\tProto:14 tensor([0.0000, 2.6830], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - relevant weights of each prototype\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "\n",
    "topk = 10\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    if node.name == 'root':\n",
    "        continue\n",
    "    non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "    if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "        continue\n",
    "\n",
    "    name2label = projectloader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(projectloader, node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "    \n",
    "    # maps proto_number -> classification weights\n",
    "    proto_classification_weights = {}\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "        if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "            continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pfs, pooled, _ = net(xs, inference=False)\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            pfs = pfs[node.name].squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                proto_classification_weights[p] = classification_weights[:,p]\n",
    "                \n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "                    continue\n",
    "                \n",
    "                if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                    child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                    leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                    if topk and (len(proto_mean_activations[p][leaf_descendent]) > topk):\n",
    "                        heapq.heappushpop(proto_mean_activations[p][leaf_descendent], pooled[p].item())\n",
    "                    else:\n",
    "                        heapq.heappush(proto_mean_activations[p][leaf_descendent], pooled[p].item())\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    \n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            logstr += str(proto_classification_weights[p])\n",
    "#             for leaf_descendent in proto_mean_activations[p]:\n",
    "#                 mean_activation = round(np.mean(proto_mean_activations[p][leaf_descendent]), 4)\n",
    "#                 num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "#                 logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "            print(logstr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17 in class_and_prototypes['086+045']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
