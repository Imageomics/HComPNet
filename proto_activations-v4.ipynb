{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/154-PruningNaiveHPIPNet_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/158-PruningNaiveHPIPNetExpWeightPruning_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/159-PruningNaiveHPIPNetMaskL1=1.0_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/160-PruningNaiveHPIPNetMaskL1=0.5_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/161-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15eps_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "run_path = \"/projects/ml4science/harishbabu/projects/PIPNet/162-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/163-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.2MinCont=0.1_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/projects/ml4science/harishbabu/projects/PIPNet/164-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/167-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext26_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/178-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "try:\n",
    "    sys.path.remove('/home/harishbabu/projects/PIPNet')\n",
    "except:\n",
    "    pass\n",
    "sys.path.insert(0, os.path.join(run_path, 'source_clone'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/ml4science/harishbabu/projects/PIPNet/162-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\n"
     ]
    }
   ],
   "source": [
    "print(run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import sys, os\n",
    "import random\n",
    "import numpy as np\n",
    "from shutil import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "# from skimage.filters import threshold_local, gaussian\n",
    "import ntpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/ml4science/harishbabu/projects/PIPNet/162-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20/source_clone\n"
     ]
    }
   ],
   "source": [
    "print(sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/ml4science/harishbabu/projects/PIPNet/162-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20/source_clone/util/node.py\n"
     ]
    }
   ],
   "source": [
    "# import pipnet.pipnet\n",
    "# from pipnet.pipnet import PIPNet, get_network\n",
    "# # from pipnet import pipnet\n",
    "# print(pipnet.__file__)\n",
    "from util import node\n",
    "print(node.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmaps showing where a prototype is found will not be generated because OpenCV is not installed.\n"
     ]
    }
   ],
   "source": [
    "from pipnet.pipnet import PIPNet, get_network\n",
    "from util.log import Log\n",
    "from util.args import get_args, save_args, get_optimizer_nn\n",
    "from util.data import get_dataloaders\n",
    "from util.func import init_weights_xavier\n",
    "from pipnet.train import train_pipnet, test_pipnet\n",
    "# from pipnet.test import eval_pipnet, get_thresholds, eval_ood\n",
    "from util.eval_cub_csv import eval_prototypes_cub_parts_csv, get_topk_cub, get_proto_patches_cub\n",
    "from util.vis_pipnet import visualize, visualize_topk\n",
    "from util.visualize_prediction import vis_pred, vis_pred_experiments\n",
    "from util.node import Node\n",
    "from util.phylo_utils import construct_phylo_tree, construct_discretized_phylo_tree\n",
    "from util.func import get_patch_size\n",
    "from util.data import ModifiedLabelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "def get_bb_gaussian_threshold(latent_activation, sigma=1.0, percentile=97, extend_h=0, extend_w=0):\n",
    "    # latent_activation -> []\n",
    "    upscaled_similarity = get_upscaled_activation_uninterpolated(latent_activation, \\\n",
    "                                                                 image_size=(args.image_size, args.image_size))\n",
    "    upscaled_similarity = minmaxscale(upscaled_similarity)\n",
    "    upscaled_similarity = gaussian(upscaled_similarity, sigma=sigma)\n",
    "    upscaled_similarity = threshold_local(upscaled_similarity, block_size=15, method='mean')\n",
    "    h_min, h_max, w_min, w_max = find_top_percentile_bbox(upscaled_similarity ,percentile=97)\n",
    "    h_min = max(0, h_min-extend_h)\n",
    "    h_max = min(upscaled_similarity.shape[0], h_max+extend_h)\n",
    "    w_min = max(0, w_min-extend_w)\n",
    "    w_max = min(upscaled_similarity.shape[1], w_max+extend_w)\n",
    "    return h_min, h_max, w_min, w_max\n",
    "\n",
    "\n",
    "def minmaxscale(tensor):\n",
    "    return (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def unshuffle_dataloader(dataloader):\n",
    "    if type(dataloader.dataset) == ImageFolder:\n",
    "        dataset = dataloader.dataset\n",
    "    else:\n",
    "        dataset = dataloader.dataset.dataset.dataset\n",
    "    new_dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=dataloader.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=dataloader.num_workers,\n",
    "        pin_memory=dataloader.pin_memory,\n",
    "        drop_last=dataloader.drop_last,\n",
    "        timeout=dataloader.timeout,\n",
    "        worker_init_fn=dataloader.worker_init_fn,\n",
    "        multiprocessing_context=dataloader.multiprocessing_context,\n",
    "        generator=dataloader.generator,\n",
    "        prefetch_factor=dataloader.prefetch_factor,\n",
    "        persistent_workers=dataloader.persistent_workers\n",
    "    )\n",
    "    return new_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- No discretization -------------------------\n"
     ]
    }
   ],
   "source": [
    "args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "args = pickle.load(args_file)\n",
    "\n",
    "if args.phylo_config:\n",
    "    phylo_config = OmegaConf.load(args.phylo_config)\n",
    "\n",
    "if args.phylo_config:\n",
    "    # construct the phylo tree\n",
    "    if phylo_config.phyloDistances_string == 'None':\n",
    "        if '031' in run_path: # this run uses a different phylogeny file that had an extra root node which is a mistake\n",
    "            root = construct_phylo_tree('/home/harishbabu/data/phlyogenyCUB/18Species-with-extra-root-node/1_tree-consensus-Hacket-18Species-modified_cub-names_v1.phy')\n",
    "        else:\n",
    "            root = construct_phylo_tree(phylo_config.phylogeny_path)\n",
    "        print('-'*25 + ' No discretization ' + '-'*25)\n",
    "    else:\n",
    "        root = construct_discretized_phylo_tree(phylo_config.phylogeny_path, phylo_config.phyloDistances_string)\n",
    "        print('-'*25 + ' Discretized ' + '-'*25)\n",
    "else:\n",
    "    # construct the tree (original hierarchy as described in the paper)\n",
    "    root = Node(\"root\")\n",
    "    root.add_children(['animal','vehicle','everyday_object','weapon','scuba_diver'])\n",
    "    root.add_children_to('animal',['non_primate','primate'])\n",
    "    root.add_children_to('non_primate',['African_elephant','giant_panda','lion'])\n",
    "    root.add_children_to('primate',['capuchin','gibbon','orangutan'])\n",
    "    root.add_children_to('vehicle',['ambulance','pickup','sports_car'])\n",
    "    root.add_children_to('everyday_object',['laptop','sandal','wine_bottle'])\n",
    "    root.add_children_to('weapon',['assault_rifle','rifle'])\n",
    "    # flat root\n",
    "    # root.add_children(['scuba_diver','African_elephant','giant_panda','lion','capuchin','gibbon','orangutan','ambulance','pickup','sports_car','laptop','sandal','wine_bottle','assault_rifle','rifle'])\n",
    "root.assign_all_descendents()\n",
    "\n",
    "exp_no = int(os.path.basename(run_path)[:3])\n",
    "\n",
    "if exp_no < 77:\n",
    "    if ('num_protos_per_descendant' in args) and (args.num_protos_per_descendant > 0):\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(args.num_protos_per_descendant)\n",
    "if exp_no == 77:\n",
    "    # update num of protos per node based on num_protos_per_descendant\n",
    "    if args.num_features == 0 and args.num_protos_per_descendant == 0:\n",
    "        raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "    for node in root.nodes_with_children():\n",
    "        node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                                            min_protos=args.num_features)\n",
    "else:\n",
    "    if ('num_protos_per_descendant' in args):\n",
    "        # update num of protos per node based on num_protos_per_descendant\n",
    "        if args.num_features == 0 and args.num_protos_per_descendant == 0:\n",
    "            raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                min_protos=args.num_features,\\\n",
    "                                split_protos=('protopool' in args) and (args.protopool == 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/.conda/envs/hpnet4/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "CUB-18-imgnet-224\n"
     ]
    }
   ],
   "source": [
    "args.batch_size = 1\n",
    "\n",
    "print(args.batch_size)\n",
    "print(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 samples from trainloader\n",
      "Dropping 0 samples from trainloader_normal\n",
      "Dropping 0 samples from trainloader_normal_augment\n",
      "Num classes (k) =  18 ['cub_001_Black_footed_Albatross', 'cub_002_Laysan_Albatross', 'cub_003_Sooty_Albatross', 'cub_004_Groove_billed_Ani', 'cub_023_Brandt_Cormorant'] etc.\n",
      "1 1\n",
      "Classes:  {'cub_001_Black_footed_Albatross': 0, 'cub_002_Laysan_Albatross': 1, 'cub_003_Sooty_Albatross': 2, 'cub_004_Groove_billed_Ani': 3, 'cub_023_Brandt_Cormorant': 4, 'cub_024_Red_faced_Cormorant': 5, 'cub_025_Pelagic_Cormorant': 6, 'cub_031_Black_billed_Cuckoo': 7, 'cub_032_Mangrove_Cuckoo': 8, 'cub_033_Yellow_billed_Cuckoo': 9, 'cub_045_Northern_Fulmar': 10, 'cub_050_Eared_Grebe': 11, 'cub_051_Horned_Grebe': 12, 'cub_052_Pied_billed_Grebe': 13, 'cub_053_Western_Grebe': 14, 'cub_086_Pacific_Loon': 15, 'cub_100_Brown_Pelican': 16, 'cub_101_White_Pelican': 17}\n",
      "Number of prototypes:  20\n",
      "----------Prototypes per descendant: 0----------\n",
      "Assigned 20 protos to node root\n",
      "Assigned 20 protos to node 052+053\n",
      "Assigned 20 protos to node 004+086\n",
      "Assigned 20 protos to node 053+050\n",
      "Assigned 20 protos to node 004+032\n",
      "Assigned 20 protos to node 086+045\n",
      "Assigned 20 protos to node 050+051\n",
      "Assigned 20 protos to node 032+033\n",
      "Assigned 20 protos to node 045+101\n",
      "Assigned 20 protos to node 033+031\n",
      "Assigned 20 protos to node 045+003\n",
      "Assigned 20 protos to node 101+023\n",
      "Assigned 20 protos to node 003+002\n",
      "Assigned 20 protos to node 101+100\n",
      "Assigned 20 protos to node 023+025\n",
      "Assigned 20 protos to node 002+001\n",
      "Assigned 20 protos to node 025+024\n",
      "Output shape:  torch.Size([1, 20, 13, 13])\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    device_ids = [torch.cuda.current_device()]\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    device_ids = []\n",
    "\n",
    "# args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "# args = pickle.load(args_file)\n",
    "\n",
    "# ckpt_file_name = 'net_overspecific_pruned_replaced_thresh=0.5_last'\n",
    "# ckpt_file_name = 'net_trained_30'\n",
    "# ckpt_file_name = 'net_trained_10'\n",
    "# ckpt_file_name = 'net_pretrained'\n",
    "ckpt_file_name = 'net_trained_last'\n",
    "epoch = ckpt_file_name.split('_')[-1]\n",
    "\n",
    "ckpt_path = os.path.join(run_path, 'checkpoints', ckpt_file_name)\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "if ckpt_file_name != 'net_trained_last':\n",
    "    print('\\n', (10*'-')+'WARNING: Not using the final trained model'+(10*'-'), '\\n')\n",
    "\n",
    "# Obtain the dataset and dataloaders\n",
    "trainloader, trainloader_pretraining, trainloader_normal, trainloader_normal_augment, projectloader, testloader, test_projectloader, classes = get_dataloaders(args, device)\n",
    "\n",
    "print(args.batch_size, trainloader.batch_size)\n",
    "\n",
    "if len(classes)<=20:\n",
    "    if args.validation_size == 0.:\n",
    "        print(\"Classes: \", testloader.dataset.class_to_idx, flush=True)\n",
    "    else:\n",
    "        print(\"Classes: \", str(classes), flush=True)\n",
    "\n",
    "# Create a convolutional network based on arguments and add 1x1 conv layer\n",
    "feature_net, add_on_layers, pool_layer, classification_layers, num_prototypes = get_network(len(classes), args, root=root)\n",
    "   \n",
    "# Create a PIP-Net\n",
    "net = PIPNet(num_classes=len(classes),\n",
    "                    num_prototypes=num_prototypes,\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "\n",
    "# Create a PIP-Net\n",
    "if ('byol' in args) and (args.byol == 'y'):\n",
    "    from pipnet.pipnet import PIPNetBYOL\n",
    "    net = PIPNetBYOL(num_classes=len(classes),\n",
    "                        num_prototypes=num_prototypes,\n",
    "                        feature_net = feature_net,\n",
    "                        args = args,\n",
    "                        add_on_layers = add_on_layers,\n",
    "                        pool_layer = pool_layer,\n",
    "                        classification_layers = classification_layers,\n",
    "                        num_parent_nodes = len(root.nodes_with_children()),\n",
    "                        root = root\n",
    "                        )\n",
    "else:\n",
    "    net = PIPNet(num_classes=len(classes),\n",
    "                    num_prototypes=num_prototypes,\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "        \n",
    "net = net.to(device=device)\n",
    "net = nn.DataParallel(net, device_ids = device_ids)    \n",
    "net.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "# print(net.eval())\n",
    "criterion = nn.NLLLoss(reduction='mean').to(device)\n",
    "\n",
    "# Forward one batch through the backbone to get the latent output size\n",
    "with torch.no_grad():\n",
    "    xs1, _, _ = next(iter(trainloader))\n",
    "    xs1 = xs1.to(device)\n",
    "    _, proto_features, _, _ = net(xs1)\n",
    "    wshape = proto_features['root'].shape[-1]\n",
    "    args.wshape = wshape #needed for calculating image patch size\n",
    "    print(\"Output shape: \", proto_features['root'].shape, flush=True)\n",
    "    \n",
    "print(args.wshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0000, 1.5260, 0.0000, 4.2201, 3.0667, 0.0000, 0.0000, 0.0000, 0.9793,\n",
       "         0.2637, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 4.8590, 5.3766, 3.5659, 3.8348, 1.9277, 0.0000, 1.0251, 0.0000,\n",
       "         4.9522, 4.4730]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.module._root_classification.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find subtree root - only for finding does not affect the run, use the value found here in the visualization block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "024+051\n"
     ]
    }
   ],
   "source": [
    "leaf_descendents = set(['cub_052_Pied_billed_Grebe', 'cub_004_Groove_billed_Ani'])\n",
    "subtree_root = root\n",
    "for node in root.nodes_with_children():\n",
    "    if leaf_descendents.issubset(node.leaf_descendents) and (len(node.leaf_descendents) < len(subtree_root.leaf_descendents)):\n",
    "        subtree_root = node\n",
    "\n",
    "# root.get_node('053+004')\n",
    "\n",
    "print(subtree_root.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images using  NAIVE-HPIPNET with HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping node root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 41.97it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "\t Child: cub_052_Pied_billed_Grebe\n",
      "\t\tProto:0 052:(1.0) \n",
      "\t\tProto:1 052:(0.9999) \n",
      "\t\tProto:3 052:(0.9941) \n",
      "\t\tProto:5 052:(1.0) \n",
      "\t\tProto:8 052:(0.9999) \n",
      "\t\tProto:9 052:(0.9999) \n",
      "\t Child: 053+050\n",
      "\t\tProto:11 050:(0.9742) 051:(0.9487) 053:(0.9999) \n",
      "\t\tProto:12 050:(0.9914) 051:(0.9665) 053:(0.9934) \n",
      "\t\tProto:13 050:(0.9979) 051:(0.996) 053:(0.9683) \n",
      "\t\tProto:14 050:(0.9423) 051:(0.9799) 053:(0.9611) \n",
      "\t\tProto:15 050:(0.9994) 051:(0.9998) 053:(0.9997) \n",
      "\t\tProto:16 050:(0.9657) 051:(0.9985) 053:(0.9991) \n",
      "\t\tProto:17 050:(0.9813) 051:(0.9835) 053:(0.9991) \n",
      "\t\tProto:18 050:(0.9997) 051:(1.0) 053:(0.9997) \n",
      "\t\tProto:19 050:(0.9999) 051:(0.9983) 053:(0.9854) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 391it [00:06, 58.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:2 004:(0.276) 031:(0.9932) 032:(0.9893) 033:(0.9859) \n",
      "\t\tProto:3 004:(0.999) 031:(0.9944) 032:(0.9942) 033:(0.995) \n",
      "\t\tProto:5 004:(0.9996) 031:(0.9976) 032:(0.9997) 033:(0.9996) \n",
      "\t\tProto:6 004:(0.9618) 031:(0.9996) 032:(0.9956) 033:(0.9987) \n",
      "\t\tProto:8 004:(0.9998) 031:(0.9965) 032:(0.9985) 033:(0.9819) \n",
      "\t Child: 086+045\n",
      "\t\tProto:10 001:(0.9717) 002:(0.9774) 003:(0.9002) 023:(0.7999) 024:(0.7553) 025:(0.8124) 045:(0.9369) 086:(0.8811) 100:(0.8805) 101:(0.9553) \n",
      "\t\tProto:11 001:(0.9929) 002:(0.9669) 003:(0.9773) 023:(0.999) 024:(0.9991) 025:(0.9997) 045:(0.9843) 086:(0.9989) 100:(0.9977) 101:(0.9644) \n",
      "\t\tProto:12 001:(0.9814) 002:(0.9951) 003:(0.8337) 023:(0.9356) 024:(0.9046) 025:(0.8427) 045:(0.8591) 086:(0.9624) 100:(0.9883) 101:(0.7244) \n",
      "\t\tProto:13 001:(0.9669) 002:(0.8866) 003:(0.9298) 023:(0.798) 024:(0.3903) 025:(0.8725) 045:(0.7464) 086:(0.9415) 100:(0.779) 101:(0.7211) \n",
      "\t\tProto:14 001:(0.9973) 002:(0.9963) 003:(0.9966) 023:(0.9998) 024:(0.9991) 025:(0.9994) 045:(0.9795) 086:(0.9952) 100:(1.0) 101:(0.9995) \n",
      "\t\tProto:15 001:(0.9962) 002:(0.9773) 003:(0.9981) 023:(0.5761) 024:(0.4098) 025:(0.735) 045:(0.7397) 086:(0.7888) 100:(0.6718) 101:(0.4469) \n",
      "\t\tProto:16 001:(0.6655) 002:(0.7205) 003:(0.8241) 023:(0.8295) 024:(0.6831) 025:(0.6474) 045:(0.628) 086:(0.6476) 100:(0.7824) 101:(0.6656) \n",
      "\t\tProto:17 001:(0.9993) 002:(0.9999) 003:(0.9996) 023:(0.9994) 024:(0.9956) 025:(0.9901) 045:(0.9991) 086:(0.9962) 100:(0.9991) 101:(0.9988) \n",
      "\t\tProto:18 001:(0.941) 002:(0.9549) 003:(0.9117) 023:(0.8577) 024:(0.9583) 025:(0.9495) 045:(0.5271) 086:(0.9001) 100:(0.9439) 101:(0.9829) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 40.59it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "\t Child: cub_053_Western_Grebe\n",
      "\t\tProto:0 053:(0.9998) \n",
      "\t\tProto:4 053:(0.9999) \n",
      "\t\tProto:5 053:(1.0) \n",
      "\t\tProto:7 053:(1.0) \n",
      "\t\tProto:8 053:(0.9999) \n",
      "\t\tProto:9 053:(0.9999) \n",
      "\t Child: 050+051\n",
      "\t\tProto:10 050:(0.9951) 051:(0.9949) \n",
      "\t\tProto:11 050:(0.9993) 051:(0.9519) \n",
      "\t\tProto:13 050:(0.9997) 051:(0.9998) \n",
      "\t\tProto:14 050:(0.9996) 051:(0.9961) \n",
      "\t\tProto:15 050:(0.9995) 051:(0.9969) \n",
      "\t\tProto:16 050:(0.9987) 051:(0.9951) \n",
      "\t\tProto:17 050:(0.9999) 051:(0.9997) \n",
      "\t\tProto:18 050:(0.9844) 051:(0.9969) \n",
      "\t\tProto:19 050:(0.9998) 051:(0.9999) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 112it [00:02, 41.99it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "\t Child: cub_004_Groove_billed_Ani\n",
      "\t\tProto:0 004:(0.9976) \n",
      "\t\tProto:3 004:(0.9998) \n",
      "\t\tProto:4 004:(0.9988) \n",
      "\t\tProto:5 004:(1.0) \n",
      "\t\tProto:6 004:(1.0) \n",
      "\t Child: 032+033\n",
      "\t\tProto:10 031:(0.9991) 032:(0.997) 033:(0.9995) \n",
      "\t\tProto:11 031:(0.9993) 032:(0.9444) 033:(0.9611) \n",
      "\t\tProto:12 031:(0.9996) 032:(0.9744) 033:(0.9949) \n",
      "\t\tProto:13 031:(0.9965) 032:(0.9987) 033:(0.9998) \n",
      "\t\tProto:14 031:(0.9988) 032:(0.9981) 033:(0.9999) \n",
      "\t\tProto:15 031:(0.9848) 032:(0.9998) 033:(1.0) \n",
      "\t\tProto:16 031:(0.9968) 032:(0.9899) 033:(0.8485) \n",
      "\t\tProto:17 031:(0.9675) 032:(0.7277) 033:(0.823) \n",
      "\t\tProto:18 031:(0.9958) 032:(0.9926) 033:(0.9994) \n",
      "\t\tProto:19 031:(0.9975) 032:(0.9476) 033:(0.9987) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 279it [00:05, 52.56it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "\t Child: cub_086_Pacific_Loon\n",
      "\t\tProto:9 086:(0.9955) \n",
      "\t\tProto:2 086:(0.9995) \n",
      "\t\tProto:6 086:(0.9989) \n",
      "\t\tProto:7 086:(0.9993) \n",
      "\t Child: 045+101\n",
      "\t\tProto:10 001:(0.4477) 002:(0.8593) 003:(0.8521) 023:(0.9649) 024:(0.7236) 025:(0.981) 045:(0.8766) 100:(0.7389) 101:(0.5672) \n",
      "\t\tProto:11 001:(0.99) 002:(0.9906) 003:(0.993) 023:(0.5569) 024:(0.8512) 025:(0.4961) 045:(0.9518) 100:(0.9619) 101:(0.944) \n",
      "\t\tProto:12 001:(0.9453) 002:(0.9941) 003:(0.9738) 023:(0.6233) 024:(0.9291) 025:(0.4428) 045:(0.9889) 100:(0.602) 101:(0.8334) \n",
      "\t\tProto:13 001:(0.9833) 002:(0.9911) 003:(0.9203) 023:(0.9788) 024:(0.9972) 025:(0.9984) 045:(0.9684) 100:(0.9644) 101:(0.9518) \n",
      "\t\tProto:14 001:(0.9978) 002:(0.9813) 003:(0.9857) 023:(0.8979) 024:(0.7089) 025:(0.9848) 045:(0.9455) 100:(0.7716) 101:(0.1763) \n",
      "\t\tProto:15 001:(0.7639) 002:(0.8437) 003:(0.855) 023:(0.9787) 024:(0.8192) 025:(0.5535) 045:(0.654) 100:(0.9916) 101:(0.9907) \n",
      "\t\tProto:16 001:(0.9945) 002:(0.992) 003:(0.9168) 023:(0.8806) 024:(0.993) 025:(0.9814) 045:(0.9476) 100:(0.9878) 101:(0.9986) \n",
      "\t\tProto:17 001:(0.869) 002:(0.8328) 003:(0.7051) 023:(0.8968) 024:(0.9757) 025:(0.969) 045:(0.9825) 100:(0.8305) 101:(0.6936) \n",
      "\t\tProto:18 001:(0.9557) 002:(0.9952) 003:(0.9986) 023:(0.9858) 024:(0.9932) 025:(0.9673) 045:(0.7338) 100:(0.9986) 101:(0.9917) \n",
      "\t\tProto:19 001:(0.9968) 002:(0.9984) 003:(0.8806) 023:(0.8323) 024:(0.7796) 025:(0.8404) 045:(0.9994) 100:(0.4516) 101:(0.7509) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 31.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 050+051\n",
      "\t Child: cub_050_Eared_Grebe\n",
      "\t\tProto:0 050:(0.9992) \n",
      "\t\tProto:2 050:(0.9999) \n",
      "\t\tProto:3 050:(0.9976) \n",
      "\t\tProto:4 050:(0.9979) \n",
      "\t\tProto:7 050:(0.9999) \n",
      "\t\tProto:9 050:(0.9994) \n",
      "\t Child: cub_051_Horned_Grebe\n",
      "\t\tProto:11 051:(1.0) \n",
      "\t\tProto:13 051:(0.9953) \n",
      "\t\tProto:15 051:(1.0) \n",
      "\t\tProto:16 051:(0.9995) \n",
      "\t\tProto:17 051:(1.0) \n",
      "\t\tProto:18 051:(0.9733) \n",
      "\t\tProto:19 051:(0.9939) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 82it [00:02, 40.14it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "\t Child: cub_032_Mangrove_Cuckoo\n",
      "\t\tProto:3 032:(0.9827) \n",
      "\t\tProto:4 032:(0.9995) \n",
      "\t\tProto:5 032:(0.9999) \n",
      "\t\tProto:6 032:(1.0) \n",
      "\t\tProto:7 032:(1.0) \n",
      "\t\tProto:8 032:(0.9978) \n",
      "\t Child: 033+031\n",
      "\t\tProto:10 031:(0.9996) 033:(0.9843) \n",
      "\t\tProto:11 031:(0.9996) 033:(0.9737) \n",
      "\t\tProto:12 031:(0.9999) 033:(0.983) \n",
      "\t\tProto:13 031:(0.9922) 033:(0.9607) \n",
      "\t\tProto:15 031:(1.0) 033:(0.999) \n",
      "\t\tProto:16 031:(0.9998) 033:(0.9926) \n",
      "\t\tProto:17 031:(0.9987) 033:(0.9993) \n",
      "\t\tProto:18 031:(0.9999) 033:(0.9929) \n",
      "\t\tProto:19 031:(1.0) 033:(0.999) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 249it [00:04, 54.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:2 001:(0.9115) 002:(0.9308) 003:(0.9942) 045:(0.9892) \n",
      "\t\tProto:3 001:(0.7015) 002:(0.5192) 003:(0.9305) 045:(0.9413) \n",
      "\t\tProto:6 001:(0.9973) 002:(0.9988) 003:(0.9998) 045:(0.9974) \n",
      "\t\tProto:7 001:(0.9993) 002:(0.9986) 003:(0.997) 045:(0.9966) \n",
      "\t\tProto:9 001:(1.0) 002:(1.0) 003:(0.9997) 045:(0.9999) \n",
      "\t Child: 101+023\n",
      "\t\tProto:18 023:(0.9997) 024:(0.9992) 025:(0.9989) 100:(0.9993) 101:(0.9992) \n",
      "\t\tProto:11 023:(0.9803) 024:(0.991) 025:(0.9984) 100:(0.9124) 101:(0.9421) \n",
      "\t\tProto:12 023:(0.932) 024:(0.9261) 025:(0.9708) 100:(0.9781) 101:(0.6788) \n",
      "\t\tProto:14 023:(0.9995) 024:(0.997) 025:(0.9936) 100:(0.999) 101:(0.9957) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 59/59 [00:01<00:00, 31.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 033+031\n",
      "\t Child: cub_033_Yellow_billed_Cuckoo\n",
      "\t\tProto:1 033:(0.9999) \n",
      "\t\tProto:2 033:(1.0) \n",
      "\t\tProto:3 033:(0.9999) \n",
      "\t\tProto:4 033:(0.999) \n",
      "\t\tProto:5 033:(0.9977) \n",
      "\t\tProto:6 033:(1.0) \n",
      "\t\tProto:9 033:(1.0) \n",
      "\t Child: cub_031_Black_billed_Cuckoo\n",
      "\t\tProto:10 031:(0.9566) \n",
      "\t\tProto:11 031:(0.9973) \n",
      "\t\tProto:14 031:(0.985) \n",
      "\t\tProto:15 031:(0.9998) \n",
      "\t\tProto:16 031:(0.9992) \n",
      "\t\tProto:18 031:(0.9994) \n",
      "\t\tProto:19 031:(0.9889) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 118it [00:02, 44.04it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "\t Child: cub_045_Northern_Fulmar\n",
      "\t\tProto:1 045:(0.9997) \n",
      "\t\tProto:3 045:(1.0) \n",
      "\t\tProto:4 045:(0.9995) \n",
      "\t\tProto:6 045:(0.9975) \n",
      "\t\tProto:7 045:(0.9989) \n",
      "\t\tProto:8 045:(0.9971) \n",
      "\t\tProto:9 045:(0.9991) \n",
      "\t Child: 003+002\n",
      "\t\tProto:10 001:(0.9641) 002:(0.8363) 003:(0.7883) \n",
      "\t\tProto:11 001:(0.9989) 002:(0.974) 003:(0.9989) \n",
      "\t\tProto:12 001:(0.9869) 002:(0.9993) 003:(0.9988) \n",
      "\t\tProto:13 001:(0.9891) 002:(0.9967) 003:(0.9834) \n",
      "\t\tProto:14 001:(0.9961) 002:(0.9988) 003:(0.9944) \n",
      "\t\tProto:15 001:(1.0) 002:(0.9999) 003:(0.9999) \n",
      "\t\tProto:16 001:(0.9959) 002:(0.9624) 003:(0.9986) \n",
      "\t\tProto:17 001:(0.9996) 002:(1.0) 003:(0.9999) \n",
      "\t\tProto:18 001:(0.9998) 002:(1.0) 003:(0.9993) \n",
      "\t\tProto:19 001:(0.9901) 002:(0.9855) 003:(0.9656) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 131it [00:02, 46.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:1 100:(0.9947) 101:(0.9979) \n",
      "\t\tProto:3 100:(0.9995) 101:(0.9852) \n",
      "\t\tProto:4 100:(0.9998) 101:(0.9998) \n",
      "\t\tProto:5 100:(0.9999) 101:(0.9995) \n",
      "\t\tProto:6 100:(0.9985) 101:(0.9907) \n",
      "\t\tProto:7 100:(0.9999) 101:(0.9999) \n",
      "\t\tProto:8 100:(0.9878) 101:(0.9802) \n",
      "\t\tProto:9 100:(0.9967) 101:(0.9979) \n",
      "\t Child: 023+025\n",
      "\t\tProto:10 023:(0.9993) 024:(0.9999) 025:(0.9998) \n",
      "\t\tProto:11 023:(0.9993) 024:(0.9969) 025:(0.9982) \n",
      "\t\tProto:13 023:(0.9866) 024:(0.969) 025:(0.9994) \n",
      "\t\tProto:14 023:(0.997) 024:(0.9867) 025:(0.998) \n",
      "\t\tProto:15 023:(0.9997) 024:(1.0) 025:(1.0) \n",
      "\t\tProto:16 023:(0.9994) 024:(0.9999) 025:(0.9999) \n",
      "\t\tProto:19 023:(0.9994) 024:(0.9993) 025:(0.9997) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 88it [00:02, 38.71it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "\t Child: cub_003_Sooty_Albatross\n",
      "\t\tProto:3 003:(1.0) \n",
      "\t\tProto:5 003:(0.9994) \n",
      "\t\tProto:6 003:(0.9999) \n",
      "\t\tProto:7 003:(0.9993) \n",
      "\t\tProto:8 003:(0.9998) \n",
      "\t\tProto:9 003:(0.9991) \n",
      "\t Child: 002+001\n",
      "\t\tProto:10 001:(0.996) 002:(0.9984) \n",
      "\t\tProto:11 001:(0.9852) 002:(0.9971) \n",
      "\t\tProto:12 001:(0.9959) 002:(0.9878) \n",
      "\t\tProto:13 001:(0.9956) 002:(0.9934) \n",
      "\t\tProto:14 001:(0.9947) 002:(0.9996) \n",
      "\t\tProto:15 001:(0.9971) 002:(0.9999) \n",
      "\t\tProto:16 001:(0.9994) 002:(0.997) \n",
      "\t\tProto:17 001:(0.9999) 002:(0.9999) \n",
      "\t\tProto:18 001:(0.9997) 002:(0.9997) \n",
      "\t\tProto:19 001:(0.9995) 002:(0.9999) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 50/50 [00:01<00:00, 31.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+100\n",
      "\t Child: cub_101_White_Pelican\n",
      "\t\tProto:0 101:(1.0) \n",
      "\t\tProto:1 101:(0.9979) \n",
      "\t\tProto:2 101:(0.9971) \n",
      "\t\tProto:4 101:(0.9986) \n",
      "\t\tProto:5 101:(0.9961) \n",
      "\t\tProto:6 101:(0.9978) \n",
      "\t\tProto:8 101:(0.9977) \n",
      "\t\tProto:9 101:(0.9999) \n",
      "\t Child: cub_100_Brown_Pelican\n",
      "\t\tProto:10 100:(0.9997) \n",
      "\t\tProto:11 100:(0.9998) \n",
      "\t\tProto:12 100:(1.0) \n",
      "\t\tProto:13 100:(1.0) \n",
      "\t\tProto:16 100:(0.9999) \n",
      "\t\tProto:17 100:(1.0) \n",
      "\t\tProto:19 100:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 81it [00:02, 37.33it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "\t Child: cub_023_Brandt_Cormorant\n",
      "\t\tProto:0 023:(1.0) \n",
      "\t\tProto:1 023:(0.9966) \n",
      "\t\tProto:2 023:(0.9979) \n",
      "\t\tProto:6 023:(0.9996) \n",
      "\t\tProto:8 023:(1.0) \n",
      "\t Child: 025+024\n",
      "\t\tProto:10 024:(0.9956) 025:(0.9989) \n",
      "\t\tProto:11 024:(0.94) 025:(0.9976) \n",
      "\t\tProto:12 024:(0.9961) 025:(0.9926) \n",
      "\t\tProto:13 024:(0.985) 025:(0.9993) \n",
      "\t\tProto:14 024:(0.9924) 025:(0.9983) \n",
      "\t\tProto:15 024:(0.9992) 025:(0.9996) \n",
      "\t\tProto:16 024:(0.9967) 025:(0.8939) \n",
      "\t\tProto:17 024:(0.9306) 025:(0.9962) \n",
      "\t\tProto:18 024:(0.998) 025:(0.9962) \n",
      "\t\tProto:19 024:(0.986) 025:(0.9249) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 34.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 002+001\n",
      "\t Child: cub_002_Laysan_Albatross\n",
      "\t\tProto:0 002:(1.0) \n",
      "\t\tProto:1 002:(0.9984) \n",
      "\t\tProto:2 002:(0.9961) \n",
      "\t\tProto:3 002:(0.9999) \n",
      "\t\tProto:6 002:(0.9992) \n",
      "\t\tProto:7 002:(0.9996) \n",
      "\t Child: cub_001_Black_footed_Albatross\n",
      "\t\tProto:10 001:(0.9999) \n",
      "\t\tProto:12 001:(0.9996) \n",
      "\t\tProto:13 001:(0.9999) \n",
      "\t\tProto:15 001:(0.9969) \n",
      "\t\tProto:17 001:(0.9998) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 52/52 [00:01<00:00, 31.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 025+024\n",
      "\t Child: cub_025_Pelagic_Cormorant\n",
      "\t\tProto:1 025:(0.9998) \n",
      "\t\tProto:3 025:(0.9999) \n",
      "\t\tProto:4 025:(0.9471) \n",
      "\t\tProto:8 025:(1.0) \n",
      "\t\tProto:9 025:(0.9961) \n",
      "\t Child: cub_024_Red_faced_Cormorant\n",
      "\t\tProto:10 024:(0.999) \n",
      "\t\tProto:15 024:(0.9986) \n",
      "\t\tProto:16 024:(0.9994) \n",
      "\t\tProto:17 024:(0.9996) \n",
      "\t\tProto:18 024:(1.0) \n",
      "\t\tProto:19 024:(0.999) \n",
      "Done !!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "txt_file.write('\\n')\n",
    "\n",
    "vizloader_name = 'testloader' # projectloader\n",
    "find_non_descendants = False # True, False # param\n",
    "topk = 6\n",
    "save_images = False # True, False\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "save_activation_as_npy_path = None # 'activation_as_npy'\n",
    "if (save_activation_as_npy_path is not None):\n",
    "    save_activation_as_npy_path = '_'.join(['activation_as_npy', vizloader_name])  # activation_as_npy, added for NUMPY SAVING\n",
    "if find_non_descendants and (save_activation_as_npy_path is not None):\n",
    "    save_activation_as_npy_path = save_activation_as_npy_path + '_non_desc'\n",
    "plot_overspecificity_score = True\n",
    "subtree_root = root#.get_node('024+051')\n",
    "\n",
    "from datetime import datetime\n",
    "txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "txt_file.write('\\n')\n",
    "\n",
    "def write_num_proto_details(proto_mean_activations, node_name, net, threshold, txt_file, args):\n",
    "    \n",
    "    rand_input = torch.randn((1, 3, args.image_size, args.image_size))\n",
    "    with torch.no_grad():\n",
    "        *_, pooled, out = net(rand_input)\n",
    "    num_protos = pooled[node_name].shape[1]\n",
    "    used_protos = len(proto_mean_activations)\n",
    "    non_overspecific = 0\n",
    "    for p in proto_mean_activations:\n",
    "        logstr = '\\t'*2 + f'Proto:{p} '\n",
    "        protos_mean_for_all_leaf_descedants = []\n",
    "        for leaf_descendent in proto_mean_activations[p]:\n",
    "            mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "            protos_mean_for_all_leaf_descedants.append(mean_activation)\n",
    "            \n",
    "        if all([(mean_activation>0.2) for mean_activation in protos_mean_for_all_leaf_descedants]):\n",
    "            non_overspecific += 1\n",
    "            \n",
    "    txt_file.write(f\"Node:{node_name},Total:{num_protos},Used:{used_protos},Good:{non_overspecific},threshold={threshold}\\n\")\n",
    "\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "\n",
    "vizloader_dict = {'trainloader': trainloader,\n",
    "                 'projectloader': projectloader,\n",
    "                 'testloader': testloader,\n",
    "                 'test_projectloader': test_projectloader}\n",
    "vizloader_dict[vizloader_name] = unshuffle_dataloader(vizloader_dict[vizloader_name])\n",
    "\n",
    "\n",
    "if type(vizloader_dict[vizloader_name].dataset) == ImageFolder:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "else:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.dataset.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    \n",
    "overspecificity_score_and_proto_mask = []\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "#     non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "#     if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "#         continue\n",
    "\n",
    "    if node.name not in subtree_root.descendents:\n",
    "        print('Skipping node', node.name)\n",
    "        continue\n",
    "        \n",
    "    name2label = vizloader_dict[vizloader_name].dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(vizloader_dict[vizloader_name], node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "#         if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "#             continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = net(xs, inference=False)\n",
    "            if len(model_output) == 3:\n",
    "                softmaxes, pooled, _ = model_output\n",
    "            elif len(model_output) == 4:\n",
    "                _, softmaxes, pooled, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "#                 if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "#                     continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                \n",
    "                if not find_non_descendants:\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                else:\n",
    "                    if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()][4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    # write_num_proto_details(proto_mean_activations, node.name, net, threshold=0.2, txt_file=txt_file, args=args)\n",
    "\n",
    "    if plot_overspecificity_score:\n",
    "        for child_classname in class_and_prototypes:\n",
    "            for p in class_and_prototypes[child_classname]:\n",
    "                mean_activation_of_every_leaf = []\n",
    "                for leaf_descendent in proto_mean_activations[p]:\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    mean_activation_of_every_leaf.append(mean_activation)\n",
    "\n",
    "                overspecificity_score = 1\n",
    "                for mean_act in mean_activation_of_every_leaf:\n",
    "                    overspecificity_score *= mean_act * 1.0\n",
    "                proto_presence = getattr(net.module, '_'+node.name+'_proto_presence')\n",
    "                proto_presence = F.gumbel_softmax(proto_presence, tau=0.5, hard=True, dim=-1)\n",
    "                proto_mask = proto_presence[p, 1].item()\n",
    "                overspecificity_score_and_proto_mask.append((overspecificity_score, len(mean_activation_of_every_leaf), proto_mask))\n",
    "\n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            mean_activation_of_every_leaf = []\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "                mean_activation_of_every_leaf.append(mean_activation)\n",
    "            print(logstr)\n",
    "            \n",
    "            # # if the mean_activation is less for all leaf descendants skip the node\n",
    "            # if all([mean_act < 0.2 for mean_act in mean_activation_of_every_leaf]):\n",
    "            #     if find_non_descendants:\n",
    "            #         print('\\t'*2 + f'Not skipping proto {p} of {node.name} coz of find_non_descendants')\n",
    "            #     else:\n",
    "            #         print('\\t'*2 + f'Skipping proto {p} of {node.name}')\n",
    "            #         continue\n",
    "            \n",
    "            # have this for NON descendants\n",
    "            if len(proto_mean_activations[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images or save_activation_as_npy_path:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 # 3x the width of a patch\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    for rank, ele in enumerate(heap):\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "                        patches.append(overlayed_image)\n",
    "                        \n",
    "                        # added for NUMPY SAVING\n",
    "                        \n",
    "                        if save_activation_as_npy_path:\n",
    "#                             upscaled_similarity_interpolated = get_upscaled_activation_interpolated(latent_activation,\n",
    "#                                                                                        image_size=(args.image_size, args.image_size))\n",
    "                            latent_activation_npy = latent_activation.squeeze().cpu().numpy()\n",
    "                            data = {'node_name': node.name,\n",
    "                                    'proto_num': p,\n",
    "                                    'child_name': child_classname,\n",
    "                                    'leaf_desc': leaf_descendent,\n",
    "                                     'rank': rank,\n",
    "                                     'img_path': img_to_open,\n",
    "                                     'img_filename': ntpath.basename(img_to_open),\n",
    "                                     'activation': latent_activation_npy,\n",
    "                                     'max_activation': activation,\n",
    "                                     'model_type': 'NAIVE-HPIPNET'}\n",
    "                            filename = str(rank)+ '-' + ntpath.basename(img_to_open) + '.npy'\n",
    "                            save_path = os.path.join(run_path, save_activation_as_npy_path, \\\n",
    "                                                     node.name, str(p), leaf_descendent,\n",
    "                                                     filename)\n",
    "                            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                            np.save(save_path, data, allow_pickle=True)\n",
    "\n",
    "                    # description on the right hand side\n",
    "                    text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (0, 0, 0))\n",
    "                    draw = D.Draw(txtimage)\n",
    "                    draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "                    \n",
    "                # weird thing padding should be zero for non descendants else it raises some error # change\n",
    "                if find_non_descendants or (len(patches) == topk): # (len(patches) == topk) means there is only one leaf descendant\n",
    "                    padding = 0\n",
    "                else:\n",
    "                    padding = 1\n",
    "\n",
    "                grid = torchvision.utils.make_grid(patches, nrow=topk, padding=padding)\n",
    "                grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=padding)\n",
    "\n",
    "                # merging right description with the grid of images\n",
    "                grid = torch.cat([grid, grid_right_descriptions], dim=-1)\n",
    "\n",
    "                # description on the top\n",
    "                text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                draw = D.Draw(txtimage)\n",
    "                draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                grid = torch.cat([grid, txttensor], dim=1)\n",
    "                \n",
    "                if save_images:\n",
    "                    prefix = 'non_' if find_non_descendants else ''\n",
    "                    os.makedirs(os.path.join(run_path, prefix+f'descendent_specific_topk_heatmap_ep={epoch}', node.name), exist_ok=True)\n",
    "                    torchvision.utils.save_image(grid, os.path.join(run_path, prefix+f'descendent_specific_topk_heatmap_ep={epoch}', node.name, f'{child_classname}-p{p}.png'))\n",
    "\n",
    "txt_file.write('\\n')\n",
    "txt_file.close()\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proto activations on leaf descendents - topk images using  NAIVE-HPIPNET with HEATMAP (clean visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping node root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 120it [00:02, 43.11it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 052+053\n",
      "\t Child: cub_052_Pied_billed_Grebe\n",
      "\t\tProto:0 cub_052_Pied_billed_Grebe:(1.0) \n",
      "\t\tProto:5 cub_052_Pied_billed_Grebe:(0.9994) \n",
      "\t\tProto:7 cub_052_Pied_billed_Grebe:(1.0) \n",
      "\t\tProto:8 cub_052_Pied_billed_Grebe:(1.0) \n",
      "\t\tProto:9 cub_052_Pied_billed_Grebe:(1.0) \n",
      "\t Child: 053+050\n",
      "\t\tProto:11 cub_050_Eared_Grebe:(0.9816) cub_051_Horned_Grebe:(0.983) cub_053_Western_Grebe:(0.9958) \n",
      "\t\tProto:12 cub_050_Eared_Grebe:(0.9628) cub_051_Horned_Grebe:(0.8874) cub_053_Western_Grebe:(0.9951) \n",
      "\t\tProto:13 cub_050_Eared_Grebe:(0.9591) cub_051_Horned_Grebe:(0.9968) cub_053_Western_Grebe:(0.9981) \n",
      "\t\tProto:14 cub_050_Eared_Grebe:(0.8981) cub_051_Horned_Grebe:(0.9973) cub_053_Western_Grebe:(0.3038) \n",
      "\t\tProto:15 cub_050_Eared_Grebe:(0.9961) cub_051_Horned_Grebe:(0.8548) cub_053_Western_Grebe:(0.99) \n",
      "\t\tProto:16 cub_050_Eared_Grebe:(0.999) cub_051_Horned_Grebe:(0.9972) cub_053_Western_Grebe:(0.9998) \n",
      "\t\tProto:17 cub_050_Eared_Grebe:(0.9503) cub_051_Horned_Grebe:(0.999) cub_053_Western_Grebe:(0.6412) \n",
      "\t\tProto:18 cub_050_Eared_Grebe:(0.9893) cub_051_Horned_Grebe:(0.9929) cub_053_Western_Grebe:(0.9884) \n",
      "\t\tProto:19 cub_050_Eared_Grebe:(0.9934) cub_051_Horned_Grebe:(0.9865) cub_053_Western_Grebe:(1.0) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 391it [00:06, 58.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+086\n",
      "\t Child: 004+032\n",
      "\t\tProto:2 cub_004_Groove_billed_Ani:(0.0727) cub_031_Black_billed_Cuckoo:(0.9839) cub_032_Mangrove_Cuckoo:(0.9675) cub_033_Yellow_billed_Cuckoo:(0.9544) \n",
      "\t\tProto:3 cub_004_Groove_billed_Ani:(0.0023) cub_031_Black_billed_Cuckoo:(0.998) cub_032_Mangrove_Cuckoo:(0.998) cub_033_Yellow_billed_Cuckoo:(0.991) \n",
      "\t\tProto:5 cub_004_Groove_billed_Ani:(0.8323) cub_031_Black_billed_Cuckoo:(0.9366) cub_032_Mangrove_Cuckoo:(0.9033) cub_033_Yellow_billed_Cuckoo:(0.9415) \n",
      "\t\tProto:6 cub_004_Groove_billed_Ani:(0.9998) cub_031_Black_billed_Cuckoo:(0.9991) cub_032_Mangrove_Cuckoo:(0.9932) cub_033_Yellow_billed_Cuckoo:(0.9961) \n",
      "\t\tProto:8 cub_004_Groove_billed_Ani:(1.0) cub_031_Black_billed_Cuckoo:(0.0788) cub_032_Mangrove_Cuckoo:(0.0851) cub_033_Yellow_billed_Cuckoo:(0.0156) \n",
      "\t Child: 086+045\n",
      "\t\tProto:10 cub_001_Black_footed_Albatross:(0.9998) cub_002_Laysan_Albatross:(0.9998) cub_003_Sooty_Albatross:(0.9995) cub_023_Brandt_Cormorant:(0.9994) cub_024_Red_faced_Cormorant:(0.9933) cub_025_Pelagic_Cormorant:(0.9894) cub_045_Northern_Fulmar:(0.9889) cub_086_Pacific_Loon:(0.989) cub_100_Brown_Pelican:(0.997) cub_101_White_Pelican:(0.9909) \n",
      "\t\tProto:11 cub_001_Black_footed_Albatross:(0.9607) cub_002_Laysan_Albatross:(0.9692) cub_003_Sooty_Albatross:(0.517) cub_023_Brandt_Cormorant:(0.9995) cub_024_Red_faced_Cormorant:(0.9995) cub_025_Pelagic_Cormorant:(0.9991) cub_045_Northern_Fulmar:(0.9704) cub_086_Pacific_Loon:(0.9986) cub_100_Brown_Pelican:(0.9998) cub_101_White_Pelican:(0.9999) \n",
      "\t\tProto:14 cub_001_Black_footed_Albatross:(0.7882) cub_002_Laysan_Albatross:(0.7304) cub_003_Sooty_Albatross:(0.7751) cub_023_Brandt_Cormorant:(0.9929) cub_024_Red_faced_Cormorant:(0.9855) cub_025_Pelagic_Cormorant:(0.9713) cub_045_Northern_Fulmar:(0.0901) cub_086_Pacific_Loon:(0.9961) cub_100_Brown_Pelican:(0.1869) cub_101_White_Pelican:(0.0578) \n",
      "\t\tProto:16 cub_001_Black_footed_Albatross:(0.8961) cub_002_Laysan_Albatross:(0.6526) cub_003_Sooty_Albatross:(0.9784) cub_023_Brandt_Cormorant:(0.3332) cub_024_Red_faced_Cormorant:(0.1786) cub_025_Pelagic_Cormorant:(0.4185) cub_045_Northern_Fulmar:(0.896) cub_086_Pacific_Loon:(0.2914) cub_100_Brown_Pelican:(0.3479) cub_101_White_Pelican:(0.0662) \n",
      "\t\tProto:17 cub_001_Black_footed_Albatross:(0.9655) cub_002_Laysan_Albatross:(0.9994) cub_003_Sooty_Albatross:(0.9991) cub_023_Brandt_Cormorant:(0.2241) cub_024_Red_faced_Cormorant:(0.0415) cub_025_Pelagic_Cormorant:(0.0466) cub_045_Northern_Fulmar:(0.9935) cub_086_Pacific_Loon:(0.7914) cub_100_Brown_Pelican:(0.9989) cub_101_White_Pelican:(0.9999) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 90it [00:02, 38.19it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 053+050\n",
      "\t Child: cub_053_Western_Grebe\n",
      "\t\tProto:2 cub_053_Western_Grebe:(0.9996) \n",
      "\t\tProto:3 cub_053_Western_Grebe:(0.9999) \n",
      "\t\tProto:5 cub_053_Western_Grebe:(0.9995) \n",
      "\t\tProto:7 cub_053_Western_Grebe:(1.0) \n",
      "\t\tProto:8 cub_053_Western_Grebe:(0.9991) \n",
      "\t\tProto:9 cub_053_Western_Grebe:(0.9998) \n",
      "\t Child: 050+051\n",
      "\t\tProto:10 cub_050_Eared_Grebe:(0.9998) cub_051_Horned_Grebe:(0.9993) \n",
      "\t\tProto:11 cub_050_Eared_Grebe:(0.996) cub_051_Horned_Grebe:(0.9847) \n",
      "\t\tProto:13 cub_050_Eared_Grebe:(0.9999) cub_051_Horned_Grebe:(0.9998) \n",
      "\t\tProto:14 cub_050_Eared_Grebe:(0.9997) cub_051_Horned_Grebe:(0.9994) \n",
      "\t\tProto:15 cub_050_Eared_Grebe:(0.9971) cub_051_Horned_Grebe:(0.9838) \n",
      "\t\tProto:16 cub_050_Eared_Grebe:(0.9879) cub_051_Horned_Grebe:(0.9841) \n",
      "\t\tProto:17 cub_050_Eared_Grebe:(0.9985) cub_051_Horned_Grebe:(0.9901) \n",
      "\t\tProto:18 cub_050_Eared_Grebe:(0.9996) cub_051_Horned_Grebe:(0.9505) \n",
      "\t\tProto:19 cub_050_Eared_Grebe:(0.9991) cub_051_Horned_Grebe:(0.9973) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 112it [00:02, 43.44it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 004+032\n",
      "\t Child: cub_004_Groove_billed_Ani\n",
      "\t\tProto:3 cub_004_Groove_billed_Ani:(0.9999) \n",
      "\t\tProto:4 cub_004_Groove_billed_Ani:(0.9999) \n",
      "\t\tProto:5 cub_004_Groove_billed_Ani:(1.0) \n",
      "\t\tProto:6 cub_004_Groove_billed_Ani:(1.0) \n",
      "\t Child: 032+033\n",
      "\t\tProto:10 cub_031_Black_billed_Cuckoo:(0.9969) cub_032_Mangrove_Cuckoo:(0.9742) cub_033_Yellow_billed_Cuckoo:(0.9973) \n",
      "\t\tProto:11 cub_031_Black_billed_Cuckoo:(0.4068) cub_032_Mangrove_Cuckoo:(0.6322) cub_033_Yellow_billed_Cuckoo:(0.6595) \n",
      "\t\tProto:12 cub_031_Black_billed_Cuckoo:(0.9917) cub_032_Mangrove_Cuckoo:(0.9142) cub_033_Yellow_billed_Cuckoo:(0.9716) \n",
      "\t\tProto:13 cub_031_Black_billed_Cuckoo:(0.8648) cub_032_Mangrove_Cuckoo:(0.9839) cub_033_Yellow_billed_Cuckoo:(0.9903) \n",
      "\t\tProto:14 cub_031_Black_billed_Cuckoo:(0.9742) cub_032_Mangrove_Cuckoo:(0.5963) cub_033_Yellow_billed_Cuckoo:(0.9877) \n",
      "\t\tProto:15 cub_031_Black_billed_Cuckoo:(0.7864) cub_032_Mangrove_Cuckoo:(0.7792) cub_033_Yellow_billed_Cuckoo:(0.8476) \n",
      "\t\tProto:16 cub_031_Black_billed_Cuckoo:(0.9933) cub_032_Mangrove_Cuckoo:(0.9734) cub_033_Yellow_billed_Cuckoo:(0.9142) \n",
      "\t\tProto:17 cub_031_Black_billed_Cuckoo:(0.9704) cub_032_Mangrove_Cuckoo:(0.7041) cub_033_Yellow_billed_Cuckoo:(0.6277) \n",
      "\t\tProto:18 cub_031_Black_billed_Cuckoo:(0.8934) cub_032_Mangrove_Cuckoo:(0.1384) cub_033_Yellow_billed_Cuckoo:(0.508) \n",
      "\t\tProto:19 cub_031_Black_billed_Cuckoo:(0.9979) cub_032_Mangrove_Cuckoo:(0.9989) cub_033_Yellow_billed_Cuckoo:(0.9996) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 279it [00:05, 51.34it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 086+045\n",
      "\t Child: cub_086_Pacific_Loon\n",
      "\t\tProto:8 cub_086_Pacific_Loon:(0.999) \n",
      "\t\tProto:9 cub_086_Pacific_Loon:(0.9937) \n",
      "\t\tProto:2 cub_086_Pacific_Loon:(0.9995) \n",
      "\t\tProto:7 cub_086_Pacific_Loon:(0.9949) \n",
      "\t Child: 045+101\n",
      "\t\tProto:10 cub_001_Black_footed_Albatross:(0.9998) cub_002_Laysan_Albatross:(0.9887) cub_003_Sooty_Albatross:(0.996) cub_023_Brandt_Cormorant:(0.8884) cub_024_Red_faced_Cormorant:(0.5018) cub_025_Pelagic_Cormorant:(0.1332) cub_045_Northern_Fulmar:(0.997) cub_100_Brown_Pelican:(0.0914) cub_101_White_Pelican:(0.0906) \n",
      "\t\tProto:11 cub_001_Black_footed_Albatross:(0.8821) cub_002_Laysan_Albatross:(0.942) cub_003_Sooty_Albatross:(0.952) cub_023_Brandt_Cormorant:(0.114) cub_024_Red_faced_Cormorant:(0.0502) cub_025_Pelagic_Cormorant:(0.0585) cub_045_Northern_Fulmar:(0.9962) cub_100_Brown_Pelican:(0.1314) cub_101_White_Pelican:(0.1525) \n",
      "\t\tProto:12 cub_001_Black_footed_Albatross:(0.9515) cub_002_Laysan_Albatross:(0.9387) cub_003_Sooty_Albatross:(0.8424) cub_023_Brandt_Cormorant:(0.7468) cub_024_Red_faced_Cormorant:(0.9872) cub_025_Pelagic_Cormorant:(0.9231) cub_045_Northern_Fulmar:(0.0629) cub_100_Brown_Pelican:(0.1941) cub_101_White_Pelican:(0.053) \n",
      "\t\tProto:13 cub_001_Black_footed_Albatross:(0.4118) cub_002_Laysan_Albatross:(0.1326) cub_003_Sooty_Albatross:(0.0259) cub_023_Brandt_Cormorant:(0.9981) cub_024_Red_faced_Cormorant:(0.9876) cub_025_Pelagic_Cormorant:(1.0) cub_045_Northern_Fulmar:(0.0168) cub_100_Brown_Pelican:(0.9963) cub_101_White_Pelican:(0.4608) \n",
      "\t\tProto:14 cub_001_Black_footed_Albatross:(0.1024) cub_002_Laysan_Albatross:(0.9546) cub_003_Sooty_Albatross:(0.0369) cub_023_Brandt_Cormorant:(0.0815) cub_024_Red_faced_Cormorant:(0.9339) cub_025_Pelagic_Cormorant:(0.1503) cub_045_Northern_Fulmar:(0.2719) cub_100_Brown_Pelican:(0.6285) cub_101_White_Pelican:(0.9937) \n",
      "\t\tProto:15 cub_001_Black_footed_Albatross:(0.9934) cub_002_Laysan_Albatross:(0.9994) cub_003_Sooty_Albatross:(0.9999) cub_023_Brandt_Cormorant:(0.1181) cub_024_Red_faced_Cormorant:(0.0542) cub_025_Pelagic_Cormorant:(0.0094) cub_045_Northern_Fulmar:(0.9966) cub_100_Brown_Pelican:(0.9909) cub_101_White_Pelican:(0.9986) \n",
      "\t\tProto:16 cub_001_Black_footed_Albatross:(0.96) cub_002_Laysan_Albatross:(0.9935) cub_003_Sooty_Albatross:(0.9388) cub_023_Brandt_Cormorant:(0.8289) cub_024_Red_faced_Cormorant:(0.9961) cub_025_Pelagic_Cormorant:(0.946) cub_045_Northern_Fulmar:(0.3219) cub_100_Brown_Pelican:(0.2885) cub_101_White_Pelican:(0.3137) \n",
      "\t\tProto:17 cub_001_Black_footed_Albatross:(0.2569) cub_002_Laysan_Albatross:(0.2703) cub_003_Sooty_Albatross:(0.3314) cub_023_Brandt_Cormorant:(0.9764) cub_024_Red_faced_Cormorant:(0.8817) cub_025_Pelagic_Cormorant:(0.9924) cub_045_Northern_Fulmar:(0.2066) cub_100_Brown_Pelican:(0.3128) cub_101_White_Pelican:(0.0199) \n",
      "\t\tProto:18 cub_001_Black_footed_Albatross:(0.2034) cub_002_Laysan_Albatross:(0.5717) cub_003_Sooty_Albatross:(0.4077) cub_023_Brandt_Cormorant:(0.8317) cub_024_Red_faced_Cormorant:(0.976) cub_025_Pelagic_Cormorant:(0.8753) cub_045_Northern_Fulmar:(0.191) cub_100_Brown_Pelican:(0.9966) cub_101_White_Pelican:(0.9733) \n",
      "\t\tProto:19 cub_001_Black_footed_Albatross:(0.1507) cub_002_Laysan_Albatross:(0.2092) cub_003_Sooty_Albatross:(0.0271) cub_023_Brandt_Cormorant:(0.9981) cub_024_Red_faced_Cormorant:(0.9985) cub_025_Pelagic_Cormorant:(0.9986) cub_045_Northern_Fulmar:(0.0571) cub_100_Brown_Pelican:(0.9935) cub_101_White_Pelican:(0.9646) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 32.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 050+051\n",
      "\t Child: cub_050_Eared_Grebe\n",
      "\t\tProto:0 cub_050_Eared_Grebe:(0.9997) \n",
      "\t\tProto:1 cub_050_Eared_Grebe:(0.9994) \n",
      "\t\tProto:6 cub_050_Eared_Grebe:(0.9974) \n",
      "\t\tProto:7 cub_050_Eared_Grebe:(0.9996) \n",
      "\t\tProto:8 cub_050_Eared_Grebe:(0.9997) \n",
      "\t\tProto:9 cub_050_Eared_Grebe:(0.9957) \n",
      "\t Child: cub_051_Horned_Grebe\n",
      "\t\tProto:11 cub_051_Horned_Grebe:(0.9999) \n",
      "\t\tProto:13 cub_051_Horned_Grebe:(0.997) \n",
      "\t\tProto:15 cub_051_Horned_Grebe:(0.9944) \n",
      "\t\tProto:16 cub_051_Horned_Grebe:(0.9996) \n",
      "\t\tProto:17 cub_051_Horned_Grebe:(0.9943) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 82it [00:02, 37.37it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 032+033\n",
      "\t Child: cub_032_Mangrove_Cuckoo\n",
      "\t\tProto:1 cub_032_Mangrove_Cuckoo:(0.9791) \n",
      "\t\tProto:2 cub_032_Mangrove_Cuckoo:(0.9991) \n",
      "\t\tProto:3 cub_032_Mangrove_Cuckoo:(0.9997) \n",
      "\t\tProto:6 cub_032_Mangrove_Cuckoo:(0.9922) \n",
      "\t\tProto:7 cub_032_Mangrove_Cuckoo:(0.9997) \n",
      "\t\tProto:8 cub_032_Mangrove_Cuckoo:(0.9995) \n",
      "\t\tProto:9 cub_032_Mangrove_Cuckoo:(0.8958) \n",
      "\t Child: 033+031\n",
      "\t\tProto:10 cub_031_Black_billed_Cuckoo:(0.9962) cub_033_Yellow_billed_Cuckoo:(0.9542) \n",
      "\t\tProto:12 cub_031_Black_billed_Cuckoo:(0.9889) cub_033_Yellow_billed_Cuckoo:(0.7411) \n",
      "\t\tProto:13 cub_031_Black_billed_Cuckoo:(0.9977) cub_033_Yellow_billed_Cuckoo:(0.9609) \n",
      "\t\tProto:15 cub_031_Black_billed_Cuckoo:(1.0) cub_033_Yellow_billed_Cuckoo:(0.9942) \n",
      "\t\tProto:16 cub_031_Black_billed_Cuckoo:(0.9747) cub_033_Yellow_billed_Cuckoo:(0.8776) \n",
      "\t\tProto:17 cub_031_Black_billed_Cuckoo:(0.9969) cub_033_Yellow_billed_Cuckoo:(0.9964) \n",
      "\t\tProto:18 cub_031_Black_billed_Cuckoo:(0.9986) cub_033_Yellow_billed_Cuckoo:(0.6769) \n",
      "\t\tProto:19 cub_031_Black_billed_Cuckoo:(0.9936) cub_033_Yellow_billed_Cuckoo:(0.9682) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 249it [00:04, 50.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+101\n",
      "\t Child: 045+003\n",
      "\t\tProto:3 cub_001_Black_footed_Albatross:(0.5511) cub_002_Laysan_Albatross:(0.3919) cub_003_Sooty_Albatross:(0.8507) cub_045_Northern_Fulmar:(0.8254) \n",
      "\t\tProto:4 cub_001_Black_footed_Albatross:(0.9632) cub_002_Laysan_Albatross:(0.9871) cub_003_Sooty_Albatross:(0.9788) cub_045_Northern_Fulmar:(0.9565) \n",
      "\t\tProto:7 cub_001_Black_footed_Albatross:(0.9888) cub_002_Laysan_Albatross:(0.8499) cub_003_Sooty_Albatross:(0.9849) cub_045_Northern_Fulmar:(0.9816) \n",
      "\t\tProto:8 cub_001_Black_footed_Albatross:(0.9971) cub_002_Laysan_Albatross:(0.9351) cub_003_Sooty_Albatross:(0.9964) cub_045_Northern_Fulmar:(0.9966) \n",
      "\t\tProto:9 cub_001_Black_footed_Albatross:(0.9975) cub_002_Laysan_Albatross:(0.9981) cub_003_Sooty_Albatross:(0.9935) cub_045_Northern_Fulmar:(0.9954) \n",
      "\t Child: 101+023\n",
      "\t\tProto:18 cub_023_Brandt_Cormorant:(0.9885) cub_024_Red_faced_Cormorant:(0.9994) cub_025_Pelagic_Cormorant:(0.9998) cub_100_Brown_Pelican:(0.9999) cub_101_White_Pelican:(0.9994) \n",
      "\t\tProto:11 cub_023_Brandt_Cormorant:(0.9998) cub_024_Red_faced_Cormorant:(1.0) cub_025_Pelagic_Cormorant:(0.9994) cub_100_Brown_Pelican:(0.9998) cub_101_White_Pelican:(0.9999) \n",
      "\t\tProto:13 cub_023_Brandt_Cormorant:(0.9962) cub_024_Red_faced_Cormorant:(0.9931) cub_025_Pelagic_Cormorant:(0.9985) cub_100_Brown_Pelican:(0.9839) cub_101_White_Pelican:(0.2171) \n",
      "\t\tProto:14 cub_023_Brandt_Cormorant:(0.9328) cub_024_Red_faced_Cormorant:(0.9929) cub_025_Pelagic_Cormorant:(0.9925) cub_100_Brown_Pelican:(0.2471) cub_101_White_Pelican:(0.0436) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 59/59 [00:01<00:00, 30.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 033+031\n",
      "\t Child: cub_033_Yellow_billed_Cuckoo\n",
      "\t\tProto:1 cub_033_Yellow_billed_Cuckoo:(0.999) \n",
      "\t\tProto:2 cub_033_Yellow_billed_Cuckoo:(0.9809) \n",
      "\t\tProto:4 cub_033_Yellow_billed_Cuckoo:(0.9993) \n",
      "\t\tProto:5 cub_033_Yellow_billed_Cuckoo:(0.9994) \n",
      "\t\tProto:6 cub_033_Yellow_billed_Cuckoo:(0.9999) \n",
      "\t\tProto:8 cub_033_Yellow_billed_Cuckoo:(1.0) \n",
      "\t Child: cub_031_Black_billed_Cuckoo\n",
      "\t\tProto:10 cub_031_Black_billed_Cuckoo:(0.9663) \n",
      "\t\tProto:11 cub_031_Black_billed_Cuckoo:(0.9572) \n",
      "\t\tProto:12 cub_031_Black_billed_Cuckoo:(0.9987) \n",
      "\t\tProto:15 cub_031_Black_billed_Cuckoo:(0.9997) \n",
      "\t\tProto:16 cub_031_Black_billed_Cuckoo:(0.9972) \n",
      "\t\tProto:17 cub_031_Black_billed_Cuckoo:(0.9999) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 118it [00:02, 41.31it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 045+003\n",
      "\t Child: cub_045_Northern_Fulmar\n",
      "\t\tProto:9 cub_045_Northern_Fulmar:(1.0) \n",
      "\t\tProto:2 cub_045_Northern_Fulmar:(0.9992) \n",
      "\t\tProto:3 cub_045_Northern_Fulmar:(0.9991) \n",
      "\t\tProto:6 cub_045_Northern_Fulmar:(0.9979) \n",
      "\t Child: 003+002\n",
      "\t\tProto:10 cub_001_Black_footed_Albatross:(0.9877) cub_002_Laysan_Albatross:(0.9991) cub_003_Sooty_Albatross:(0.5244) \n",
      "\t\tProto:11 cub_001_Black_footed_Albatross:(0.9973) cub_002_Laysan_Albatross:(0.9988) cub_003_Sooty_Albatross:(0.9981) \n",
      "\t\tProto:12 cub_001_Black_footed_Albatross:(0.9418) cub_002_Laysan_Albatross:(0.4407) cub_003_Sooty_Albatross:(0.9766) \n",
      "\t\tProto:13 cub_001_Black_footed_Albatross:(0.9993) cub_002_Laysan_Albatross:(1.0) cub_003_Sooty_Albatross:(0.9882) \n",
      "\t\tProto:14 cub_001_Black_footed_Albatross:(0.9954) cub_002_Laysan_Albatross:(0.9847) cub_003_Sooty_Albatross:(0.9996) \n",
      "\t\tProto:15 cub_001_Black_footed_Albatross:(0.9637) cub_002_Laysan_Albatross:(0.8515) cub_003_Sooty_Albatross:(0.9988) \n",
      "\t\tProto:16 cub_001_Black_footed_Albatross:(0.9968) cub_002_Laysan_Albatross:(0.9992) cub_003_Sooty_Albatross:(0.9962) \n",
      "\t\tProto:17 cub_001_Black_footed_Albatross:(0.9938) cub_002_Laysan_Albatross:(0.9971) cub_003_Sooty_Albatross:(0.9967) \n",
      "\t\tProto:18 cub_001_Black_footed_Albatross:(0.9789) cub_002_Laysan_Albatross:(0.9946) cub_003_Sooty_Albatross:(0.9996) \n",
      "\t\tProto:19 cub_001_Black_footed_Albatross:(0.9701) cub_002_Laysan_Albatross:(0.9848) cub_003_Sooty_Albatross:(0.9191) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 131it [00:03, 43.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+023\n",
      "\t Child: 101+100\n",
      "\t\tProto:4 cub_100_Brown_Pelican:(0.8828) cub_101_White_Pelican:(0.8417) \n",
      "\t\tProto:5 cub_100_Brown_Pelican:(1.0) cub_101_White_Pelican:(0.999) \n",
      "\t\tProto:6 cub_100_Brown_Pelican:(0.9988) cub_101_White_Pelican:(0.9991) \n",
      "\t\tProto:7 cub_100_Brown_Pelican:(1.0) cub_101_White_Pelican:(0.9997) \n",
      "\t\tProto:8 cub_100_Brown_Pelican:(0.9997) cub_101_White_Pelican:(0.9992) \n",
      "\t\tProto:9 cub_100_Brown_Pelican:(0.9429) cub_101_White_Pelican:(0.9969) \n",
      "\t Child: 023+025\n",
      "\t\tProto:10 cub_023_Brandt_Cormorant:(0.9998) cub_024_Red_faced_Cormorant:(0.9998) cub_025_Pelagic_Cormorant:(0.9995) \n",
      "\t\tProto:11 cub_023_Brandt_Cormorant:(0.9444) cub_024_Red_faced_Cormorant:(0.9985) cub_025_Pelagic_Cormorant:(0.9914) \n",
      "\t\tProto:13 cub_023_Brandt_Cormorant:(0.995) cub_024_Red_faced_Cormorant:(0.7494) cub_025_Pelagic_Cormorant:(0.8109) \n",
      "\t\tProto:14 cub_023_Brandt_Cormorant:(0.9975) cub_024_Red_faced_Cormorant:(0.683) cub_025_Pelagic_Cormorant:(0.9824) \n",
      "\t\tProto:15 cub_023_Brandt_Cormorant:(0.9546) cub_024_Red_faced_Cormorant:(0.9985) cub_025_Pelagic_Cormorant:(0.9996) \n",
      "\t\tProto:16 cub_023_Brandt_Cormorant:(0.9738) cub_024_Red_faced_Cormorant:(0.9974) cub_025_Pelagic_Cormorant:(0.9989) \n",
      "\t\tProto:19 cub_023_Brandt_Cormorant:(0.9635) cub_024_Red_faced_Cormorant:(0.8086) cub_025_Pelagic_Cormorant:(0.9919) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 88it [00:02, 37.30it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 003+002\n",
      "\t Child: cub_003_Sooty_Albatross\n",
      "\t\tProto:9 cub_003_Sooty_Albatross:(0.9793) \n",
      "\t\tProto:2 cub_003_Sooty_Albatross:(0.9998) \n",
      "\t\tProto:5 cub_003_Sooty_Albatross:(0.9947) \n",
      "\t\tProto:7 cub_003_Sooty_Albatross:(0.9958) \n",
      "\t Child: 002+001\n",
      "\t\tProto:10 cub_001_Black_footed_Albatross:(0.9402) cub_002_Laysan_Albatross:(0.9995) \n",
      "\t\tProto:11 cub_001_Black_footed_Albatross:(0.9563) cub_002_Laysan_Albatross:(0.9526) \n",
      "\t\tProto:12 cub_001_Black_footed_Albatross:(0.8524) cub_002_Laysan_Albatross:(0.9912) \n",
      "\t\tProto:13 cub_001_Black_footed_Albatross:(0.9992) cub_002_Laysan_Albatross:(0.999) \n",
      "\t\tProto:16 cub_001_Black_footed_Albatross:(0.9794) cub_002_Laysan_Albatross:(0.9717) \n",
      "\t\tProto:17 cub_001_Black_footed_Albatross:(0.9941) cub_002_Laysan_Albatross:(0.9891) \n",
      "\t\tProto:18 cub_001_Black_footed_Albatross:(0.992) cub_002_Laysan_Albatross:(0.9987) \n",
      "\t\tProto:19 cub_001_Black_footed_Albatross:(0.9823) cub_002_Laysan_Albatross:(0.9889) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 50/50 [00:01<00:00, 31.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 101+100\n",
      "\t Child: cub_101_White_Pelican\n",
      "\t\tProto:1 cub_101_White_Pelican:(0.9478) \n",
      "\t\tProto:2 cub_101_White_Pelican:(0.9407) \n",
      "\t\tProto:4 cub_101_White_Pelican:(0.9931) \n",
      "\t\tProto:5 cub_101_White_Pelican:(0.9985) \n",
      "\t\tProto:6 cub_101_White_Pelican:(0.9961) \n",
      "\t\tProto:7 cub_101_White_Pelican:(0.9908) \n",
      "\t\tProto:8 cub_101_White_Pelican:(0.6824) \n",
      "\t Child: cub_100_Brown_Pelican\n",
      "\t\tProto:10 cub_100_Brown_Pelican:(1.0) \n",
      "\t\tProto:13 cub_100_Brown_Pelican:(0.9992) \n",
      "\t\tProto:14 cub_100_Brown_Pelican:(0.9896) \n",
      "\t\tProto:15 cub_100_Brown_Pelican:(0.9603) \n",
      "\t\tProto:17 cub_100_Brown_Pelican:(0.9991) \n",
      "\t\tProto:18 cub_100_Brown_Pelican:(0.9991) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 81it [00:02, 37.17it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 023+025\n",
      "\t Child: cub_023_Brandt_Cormorant\n",
      "\t\tProto:0 cub_023_Brandt_Cormorant:(0.9996) \n",
      "\t\tProto:8 cub_023_Brandt_Cormorant:(0.9999) \n",
      "\t\tProto:6 cub_023_Brandt_Cormorant:(0.9994) \n",
      "\t\tProto:9 cub_023_Brandt_Cormorant:(0.997) \n",
      "\t Child: 025+024\n",
      "\t\tProto:10 cub_024_Red_faced_Cormorant:(0.9929) cub_025_Pelagic_Cormorant:(0.9968) \n",
      "\t\tProto:11 cub_024_Red_faced_Cormorant:(0.9086) cub_025_Pelagic_Cormorant:(0.9956) \n",
      "\t\tProto:12 cub_024_Red_faced_Cormorant:(0.9986) cub_025_Pelagic_Cormorant:(0.9923) \n",
      "\t\tProto:13 cub_024_Red_faced_Cormorant:(0.9886) cub_025_Pelagic_Cormorant:(0.9065) \n",
      "\t\tProto:14 cub_024_Red_faced_Cormorant:(0.9782) cub_025_Pelagic_Cormorant:(0.8948) \n",
      "\t\tProto:15 cub_024_Red_faced_Cormorant:(0.994) cub_025_Pelagic_Cormorant:(0.9183) \n",
      "\t\tProto:16 cub_024_Red_faced_Cormorant:(0.9977) cub_025_Pelagic_Cormorant:(0.8357) \n",
      "\t\tProto:17 cub_024_Red_faced_Cormorant:(0.9498) cub_025_Pelagic_Cormorant:(0.9741) \n",
      "\t\tProto:18 cub_024_Red_faced_Cormorant:(0.9929) cub_025_Pelagic_Cormorant:(0.7482) \n",
      "\t\tProto:19 cub_024_Red_faced_Cormorant:(0.9408) cub_025_Pelagic_Cormorant:(0.8281) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 60/60 [00:01<00:00, 35.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 002+001\n",
      "\t Child: cub_002_Laysan_Albatross\n",
      "\t\tProto:1 cub_002_Laysan_Albatross:(0.9994) \n",
      "\t\tProto:2 cub_002_Laysan_Albatross:(0.9984) \n",
      "\t\tProto:3 cub_002_Laysan_Albatross:(0.9992) \n",
      "\t\tProto:7 cub_002_Laysan_Albatross:(0.9996) \n",
      "\t\tProto:9 cub_002_Laysan_Albatross:(0.9965) \n",
      "\t Child: cub_001_Black_footed_Albatross\n",
      "\t\tProto:10 cub_001_Black_footed_Albatross:(0.9916) \n",
      "\t\tProto:13 cub_001_Black_footed_Albatross:(0.9988) \n",
      "\t\tProto:14 cub_001_Black_footed_Albatross:(0.999) \n",
      "\t\tProto:17 cub_001_Black_footed_Albatross:(0.9998) \n",
      "\t\tProto:18 cub_001_Black_footed_Albatross:(0.9993) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting topk: 100% 52/52 [00:01<00:00, 32.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 025+024\n",
      "\t Child: cub_025_Pelagic_Cormorant\n",
      "\t\tProto:1 cub_025_Pelagic_Cormorant:(0.999) \n",
      "\t\tProto:3 cub_025_Pelagic_Cormorant:(0.9999) \n",
      "\t\tProto:4 cub_025_Pelagic_Cormorant:(0.9949) \n",
      "\t\tProto:5 cub_025_Pelagic_Cormorant:(0.9999) \n",
      "\t\tProto:9 cub_025_Pelagic_Cormorant:(0.8138) \n",
      "\t Child: cub_024_Red_faced_Cormorant\n",
      "\t\tProto:11 cub_024_Red_faced_Cormorant:(0.9989) \n",
      "\t\tProto:12 cub_024_Red_faced_Cormorant:(0.9413) \n",
      "\t\tProto:13 cub_024_Red_faced_Cormorant:(0.8116) \n",
      "\t\tProto:15 cub_024_Red_faced_Cormorant:(0.9981) \n",
      "\t\tProto:16 cub_024_Red_faced_Cormorant:(0.9972) \n",
      "\t\tProto:17 cub_024_Red_faced_Cormorant:(0.9885) \n",
      "\t\tProto:18 cub_024_Red_faced_Cormorant:(0.9998) \n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "# Proto activations on leaf descendents - topk images\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    # input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "from util.data import ModifiedLabelLoader\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pdb\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import math\n",
    "# txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "# txt_file.write('\\n')\n",
    "\n",
    "vizloader_name = 'testloader' # projectloader\n",
    "find_non_descendants = False # True, False # param\n",
    "topk = 10\n",
    "save_images = True # True, False\n",
    "font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "save_activation_as_npy_path = None # 'activation_as_npy'\n",
    "if (save_activation_as_npy_path is not None):\n",
    "    save_activation_as_npy_path = '_'.join(['activation_as_npy', vizloader_name])  # activation_as_npy, added for NUMPY SAVING\n",
    "if find_non_descendants and (save_activation_as_npy_path is not None):\n",
    "    save_activation_as_npy_path = save_activation_as_npy_path + '_non_desc'\n",
    "plot_overspecificity_score = True\n",
    "subtree_root = root#.get_node('024+051')\n",
    "    \n",
    "from datetime import datetime\n",
    "# txt_file = open(os.path.join(run_path, \"num_proto_details_\"+datetime.now().strftime(\"%m:%d:%H:%M:%S\")+\".txt\"), \"a\")\n",
    "# txt_file.write('\\n')\n",
    "\n",
    "def write_num_proto_details(proto_mean_activations, node_name, net, threshold, txt_file, args):\n",
    "    \n",
    "    rand_input = torch.randn((1, 3, args.image_size, args.image_size))\n",
    "    with torch.no_grad():\n",
    "        *_, pooled, out = net(rand_input)\n",
    "    num_protos = pooled[node_name].shape[1]\n",
    "    used_protos = len(proto_mean_activations)\n",
    "    non_overspecific = 0\n",
    "    for p in proto_mean_activations:\n",
    "        logstr = '\\t'*2 + f'Proto:{p} '\n",
    "        protos_mean_for_all_leaf_descedants = []\n",
    "        for leaf_descendent in proto_mean_activations[p]:\n",
    "            mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "            protos_mean_for_all_leaf_descedants.append(mean_activation)\n",
    "            \n",
    "        if all([(mean_activation>0.2) for mean_activation in protos_mean_for_all_leaf_descedants]):\n",
    "            non_overspecific += 1\n",
    "            \n",
    "    txt_file.write(f\"Node:{node_name},Total:{num_protos},Used:{used_protos},Good:{non_overspecific},threshold={threshold}\\n\")\n",
    "\n",
    "\n",
    "def get_heap():\n",
    "    list_ = []\n",
    "    heapq.heapify(list_)\n",
    "    return list_\n",
    "\n",
    "patchsize, skip = get_patch_size(args)\n",
    "\n",
    "\n",
    "vizloader_dict = {'trainloader': trainloader,\n",
    "                 'projectloader': projectloader,\n",
    "                 'testloader': testloader,\n",
    "                 'test_projectloader': test_projectloader}\n",
    "vizloader_dict[vizloader_name] = unshuffle_dataloader(vizloader_dict[vizloader_name])\n",
    "\n",
    "\n",
    "if type(vizloader_dict[vizloader_name].dataset) == ImageFolder:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "else:\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.dataset.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    \n",
    "overspecificity_score_and_proto_mask = []\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "#     if node.name == 'root':\n",
    "#         continue\n",
    "#     non_leaf_children_names = [child.name for child in node.children if not child.is_leaf()]\n",
    "#     if len(non_leaf_children_names) == 0: # if all the children are leaf nodes then skip this node\n",
    "#         continue\n",
    "\n",
    "    if node.name not in subtree_root.descendents:\n",
    "        print('Skipping node', node.name)\n",
    "        continue\n",
    "\n",
    "    name2label = vizloader_dict[vizloader_name].dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    modifiedLabelLoader = ModifiedLabelLoader(vizloader_dict[vizloader_name], node)\n",
    "    coarse_label2name = modifiedLabelLoader.modifiedlabel2name\n",
    "    node_label_to_children = {label: name for name, label in node.children_to_labels.items()}\n",
    "    \n",
    "    imgs = modifiedLabelLoader.filtered_imgs\n",
    "\n",
    "    img_iter = tqdm(enumerate(modifiedLabelLoader),\n",
    "                    total=len(modifiedLabelLoader),\n",
    "                    mininterval=50.,\n",
    "                    desc='Collecting topk',\n",
    "                    ncols=0)\n",
    "\n",
    "    classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "    \n",
    "    # maps proto_number -> grand_child_name (or descendant leaf name) -> list of top-k activations\n",
    "    proto_mean_activations = defaultdict(lambda: defaultdict(get_heap))\n",
    "\n",
    "    # maps class names to the prototypes that belong to that\n",
    "    class_and_prototypes = defaultdict(set)\n",
    "\n",
    "    for i, (xs, orig_y, ys) in img_iter:\n",
    "#         if coarse_label2name[ys.item()] not in non_leaf_children_names:\n",
    "#             continue\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = net(xs, inference=False)\n",
    "            if len(model_output) == 3:\n",
    "                softmaxes, pooled, _ = model_output\n",
    "            elif len(model_output) == 4:\n",
    "                _, softmaxes, pooled, _ = model_output\n",
    "            pooled = pooled[node.name].squeeze(0) \n",
    "            softmaxes = softmaxes[node.name]#.squeeze(0)\n",
    "\n",
    "            for p in range(pooled.shape[0]): # pooled.shape -> [768] (== num of prototypes)\n",
    "                c_weight = torch.max(classification_weights[:,p]) # classification_weights[:,p].shape -> [200] (== num of classes)\n",
    "                relevant_proto_classes = torch.nonzero(classification_weights[:, p] > 1e-3)\n",
    "                relevant_proto_class_names = [node_label_to_children[class_idx.item()] for class_idx in relevant_proto_classes]\n",
    "                \n",
    "                # Take the max per prototype.                             \n",
    "                max_per_prototype, max_idx_per_prototype = torch.max(softmaxes, dim=0)\n",
    "                max_per_prototype_h, max_idx_per_prototype_h = torch.max(max_per_prototype, dim=1)\n",
    "                max_per_prototype_w, max_idx_per_prototype_w = torch.max(max_per_prototype_h, dim=1) #shape (num_prototypes)\n",
    "                \n",
    "                h_idx = max_idx_per_prototype_h[p, max_idx_per_prototype_w[p]]\n",
    "                w_idx = max_idx_per_prototype_w[p]\n",
    "\n",
    "                if len(relevant_proto_class_names) == 0:\n",
    "                    continue\n",
    "                \n",
    "#                 if (len(relevant_proto_class_names) == 1) and (relevant_proto_class_names[0] not in non_leaf_children_names):\n",
    "#                     continue\n",
    "                \n",
    "                h_coor_min, h_coor_max, w_coor_min, w_coor_max = get_img_coordinates(args.image_size, softmaxes.shape, patchsize, skip, h_idx, w_idx)\n",
    "                latent_activation = softmaxes[:, p, :, :]\n",
    "                \n",
    "                if not find_non_descendants:\n",
    "                    if (coarse_label2name[ys.item()] in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()]#[4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                else:\n",
    "                    if (coarse_label2name[ys.item()] not in relevant_proto_class_names):\n",
    "                        child_node = root.get_node(coarse_label2name[ys.item()])\n",
    "                        leaf_descendent = label2name[orig_y.item()]#[4:7]\n",
    "                        img_to_open = imgs[i][0] # it is a tuple of (path to image, lable)\n",
    "                        if topk and (len(proto_mean_activations[p][leaf_descendent]) >= topk):\n",
    "                            heapq.heappushpop(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                              (pooled[p].item(), img_to_open,\\\n",
    "                                               (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "                        else:\n",
    "                            heapq.heappush(proto_mean_activations[p][leaf_descendent],\\\n",
    "                                           (pooled[p].item(), img_to_open,\\\n",
    "                                            (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation))\n",
    "\n",
    "                class_and_prototypes[', '.join(relevant_proto_class_names)].add(p)\n",
    "\n",
    "    # write_num_proto_details(proto_mean_activations, node.name, net, threshold=0.2, txt_file=txt_file, args=args)\n",
    "\n",
    "    if plot_overspecificity_score:\n",
    "        for child_classname in class_and_prototypes:\n",
    "            for p in class_and_prototypes[child_classname]:\n",
    "                mean_activation_of_every_leaf = []\n",
    "                for leaf_descendent in proto_mean_activations[p]:\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    mean_activation_of_every_leaf.append(mean_activation)\n",
    "\n",
    "                overspecificity_score = 1\n",
    "                for mean_act in mean_activation_of_every_leaf:\n",
    "                    overspecificity_score *= mean_act * 1.0\n",
    "                proto_presence = getattr(net.module, '_'+node.name+'_proto_presence')\n",
    "                proto_presence = F.gumbel_softmax(proto_presence, tau=0.5, hard=True, dim=-1)\n",
    "                proto_mask = proto_presence[p, 1].item()\n",
    "                overspecificity_score_and_proto_mask.append((overspecificity_score, len(mean_activation_of_every_leaf), proto_mask))\n",
    "\n",
    "    print('Node', node.name)\n",
    "    for child_classname in class_and_prototypes:\n",
    "        \n",
    "        print('\\t'*1, 'Child:', child_classname)\n",
    "        for p in class_and_prototypes[child_classname]:\n",
    "            \n",
    "            logstr = '\\t'*2 + f'Proto:{p} '\n",
    "            mean_activation_of_every_leaf = []\n",
    "            for leaf_descendent in proto_mean_activations[p]:\n",
    "                mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                num_images = len(proto_mean_activations[p][leaf_descendent])\n",
    "                logstr += f'{leaf_descendent}:({mean_activation}) '\n",
    "                mean_activation_of_every_leaf.append(mean_activation)\n",
    "            print(logstr)\n",
    "            \n",
    "            # # if the mean_activation is less for all leaf descendants skip the node\n",
    "            # if all([mean_act < 0.2 for mean_act in mean_activation_of_every_leaf]):\n",
    "            #     if find_non_descendants:\n",
    "            #         print('\\t'*2 + f'Not skipping proto {p} of {node.name} coz of find_non_descendants')\n",
    "            #     else:\n",
    "            #         print('\\t'*2 + f'Skipping proto {p} of {node.name}')\n",
    "            #         continue\n",
    "            \n",
    "            # have this for NON descendants\n",
    "            if len(proto_mean_activations[p]) == 0:\n",
    "                continue\n",
    "            \n",
    "            if save_images or save_activation_as_npy_path:\n",
    "                patches = []\n",
    "                right_descriptions = []\n",
    "                text_region_width = 3 # 3x the width of a patch\n",
    "\n",
    "                font_size = 40\n",
    "                fnt = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "                max_width = ImageDraw.Draw(Image.new(\"RGB\", (100, 100), (255, 0, 0))).textlength('-', font=fnt)\n",
    "                \n",
    "                for leaf_descendent in proto_mean_activations[p]:\n",
    "                    for word in leaf_descendent.split('_')[2:]:\n",
    "                        width_of_word = ImageDraw.Draw(Image.new(\"RGB\", (100, 100), (255, 0, 0))).textlength(word, font=fnt)\n",
    "                        max_width = max(max_width, width_of_word)\n",
    "\n",
    "                for leaf_descendent, heap in proto_mean_activations[p].items():\n",
    "                    species_name = ' '.join(leaf_descendent.split('_')[2:])\n",
    "                    heap = sorted(heap)[::-1]\n",
    "                    mean_activation = round(np.mean([activation for activation, *_ in proto_mean_activations[p][leaf_descendent]]), 4)\n",
    "                    for rank, ele in enumerate(heap):\n",
    "                        activation, img_to_open, (h_coor_min, h_coor_max, w_coor_min, w_coor_max), latent_activation = ele\n",
    "                        image = transforms.Resize(size=(args.image_size, args.image_size))(Image.open(img_to_open))\n",
    "                        img_tensor = transforms.ToTensor()(image)#.unsqueeze_(0) #shape (1, 3, h, w)\n",
    "                        img_tensor_patch = img_tensor[:, h_coor_min:h_coor_max, w_coor_min:w_coor_max]\n",
    "                        # latent_activation[latent_activation < torch.quantile(latent_activation, 0.75).item()] = 0.\n",
    "                        # latent_activation[latent_activation < 1.5] = 0.\n",
    "                        # pdb.set_trace()\n",
    "                        overlayed_image_np = get_heatmap(latent_activation, img_tensor)\n",
    "                        overlayed_image = torch.tensor(overlayed_image_np).permute(2, 0, 1).float() / 255.\n",
    "                        # overlayed_image = img_tensor\n",
    "                        patches.append(overlayed_image)\n",
    "                        \n",
    "                        # added for NUMPY SAVING\n",
    "                        \n",
    "                        if save_activation_as_npy_path:\n",
    "#                             upscaled_similarity_interpolated = get_upscaled_activation_interpolated(latent_activation,\n",
    "#                                                                                        image_size=(args.image_size, args.image_size))\n",
    "                            latent_activation_npy = latent_activation.squeeze().cpu().numpy()\n",
    "                            data = {'node_name': node.name,\n",
    "                                    'proto_num': p,\n",
    "                                    'child_name': child_classname,\n",
    "                                    'leaf_desc': leaf_descendent,\n",
    "                                     'rank': rank,\n",
    "                                     'img_path': img_to_open,\n",
    "                                     'img_filename': ntpath.basename(img_to_open),\n",
    "                                     'activation': latent_activation_npy,\n",
    "                                     'max_activation': activation,\n",
    "                                     'model_type': 'NAIVE-HPIPNET'}\n",
    "                            filename = str(rank)+ '-' + ntpath.basename(img_to_open) + '.npy'\n",
    "                            save_path = os.path.join(run_path, save_activation_as_npy_path, \\\n",
    "                                                     node.name, str(p), leaf_descendent,\n",
    "                                                     filename)\n",
    "                            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                            np.save(save_path, data, allow_pickle=True)\n",
    "\n",
    "                    # # description on the right hand side\n",
    "                    # text = f'{mean_activation}, {leaf_descendent}'\n",
    "                    # txtimage = Image.new(\"RGB\", (patches[0].shape[-2]*text_region_width,patches[0].shape[-1]), (255, 255, 255))\n",
    "                    # draw = D.Draw(txtimage)\n",
    "                    # draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"black\", font=font)\n",
    "                    # pdb.set_trace()\n",
    "                    # txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    # right_descriptions.append(txttensor)\n",
    "\n",
    "                    text = '\\n'.join(species_name.split(' '))\n",
    "                    \n",
    "                    image_size = (math.ceil(max_width) + 10, patches[0].shape[-1])\n",
    "                    txtimage = Image.new(\"RGB\", image_size, (255, 255, 255))\n",
    "                    d = ImageDraw.Draw(txtimage)\n",
    "                    d.multiline_text((image_size[0]/2, image_size[1]/2), text, font=fnt, fill=(0, 0, 0), align =\"center\", anchor=\"mm\")\n",
    "                    txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "                    right_descriptions.append(txttensor)\n",
    "                    \n",
    "\n",
    "                padding = 0\n",
    "\n",
    "                # grid = torchvision.utils.make_grid(patches, nrow=topk, padding=padding, border=0)\n",
    "                # grid_right_descriptions = torchvision.utils.make_grid(right_descriptions, nrow=1, padding=padding, border=0)\n",
    "                # grid = torch.cat([grid_right_descriptions, grid], dim=-1)\n",
    "\n",
    "                grid_rows = []\n",
    "                for k in range(len(proto_mean_activations[p])):\n",
    "                    grid_row = torchvision.utils.make_grid(patches[k*topk:(k+1)*topk], nrow=topk, padding=padding, border=0)\n",
    "                    grid_right_description = torchvision.utils.make_grid(right_descriptions[k], nrow=1, padding=padding, border=0)\n",
    "                    grid_row = torch.cat([grid_right_description, grid_row], dim=-1)\n",
    "                    grid_rows.append(grid_row)\n",
    "                # grid = torch.cat(grid_rows, dim=0)\n",
    "                grid = torchvision.utils.make_grid(grid_rows, nrow=1, padding=5, pad_value=1.)\n",
    "                    \n",
    "                # # description on the top\n",
    "                # text = f'Node:{node.name}, p{p}, Child:{child_classname}'\n",
    "                # txtimage = Image.new(\"RGB\", (grid.shape[-1], args.wshape), (0, 0, 0))\n",
    "                # draw = D.Draw(txtimage)\n",
    "                # draw.text((150, patches[0].shape[1]//2), text, anchor='mm', fill=\"white\", font=font)\n",
    "                # txttensor = transforms.ToTensor()(txtimage)#.unsqueeze_(0)\n",
    "\n",
    "                # merging top description with the grid of images\n",
    "                # grid = torch.cat([grid, txttensor], dim=1)\n",
    "                \n",
    "                if save_images:\n",
    "                    prefix = 'non_' if find_non_descendants else ''\n",
    "                    os.makedirs(os.path.join(run_path, prefix+f'descendent_specific_topk_heatmap_clean_ep={epoch}', node.name), exist_ok=True)\n",
    "                    torchvision.utils.save_image(grid, os.path.join(run_path, prefix+f'descendent_specific_topk_heatmap_clean_ep={epoch}', node.name, f'{child_classname}-p{p}.png'), border=0) # , border_color=(255, 255, 255), border=10\n",
    "\n",
    "# txt_file.write('\\n')\n",
    "# txt_file.close()\n",
    "print('Done !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=207x224>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from PIL import Image, ImageDraw, ImageFont\n",
    "# import math\n",
    "\n",
    "# text = \"Hello\\nWorld\\nWoWWW\\nWoWWW!!!\"\n",
    "# font_size = 40\n",
    "# fnt = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "# image_size = (224, 224)\n",
    "# biggest_word = sorted(text.split('\\n'), key = lambda x: len(x))[-1]\n",
    "# max_width = ImageDraw.Draw(Image.new(\"RGB\", (100, 100), (255, 0, 0))).textlength(biggest_word, font=fnt)\n",
    "# image_size = (math.ceil(max_width), 224)\n",
    "# out = Image.new(\"RGB\", image_size, (255, 255, 255))\n",
    "# d = ImageDraw.Draw(out)\n",
    "# d.multiline_text((image_size[0]/2, image_size[1]/2), text, font=fnt, fill=(0, 0, 0), align =\"center\", anchor=\"mm\")\n",
    "\n",
    "# out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example list of tuples\n",
    "data = overspecificity_score_and_proto_mask\n",
    "\n",
    "# Separate the data based on the second value\n",
    "x_0 = [x for x, y, z in data if z == 0]  # First values where the second value is 0\n",
    "x_1 = [x for x, y, z in data if z == 1]  # First values where the second value is 1\n",
    "\n",
    "# Create a dummy y-axis value since this is a one-dimensional scatter plot\n",
    "# y_0 = [y for x, y, z in data if z == 0]  # Dummy y values for blue points\n",
    "# y_1 = [y for x, y, z in data if z == 1]  # Dummy y values for red points\n",
    "\n",
    "# y_0 = [1]*len(x_0)\n",
    "# y_1 = [1.5]*len(x_1)\n",
    "\n",
    "y_0 = [1]*len(x_0)\n",
    "y_1 = [1]*len(x_1)\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(x_1, y_1, color='red', label='Value 1', s=4)   # Plot points with second value 1 in red\n",
    "plt.scatter(x_0, y_0, color='blue', label='Value 0', s=4)  # Plot points with second value 0 in blue\n",
    "\n",
    "\n",
    "# Additional plot formatting\n",
    "plt.xlabel('Overspecificity score')\n",
    "# plt.ylabel('Num descendants')  # Hide y-axis ticks since it's a one-dimensional plot\n",
    "plt.yticks([])\n",
    "# plt.legend(loc='best')\n",
    "# plt.title('One-dimensional Scatter Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: cairosvg\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip show cairosvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
