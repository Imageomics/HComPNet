{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/home/harishbabu/.conda/envs/hpnet1/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from pipnet.pipnet import PIPNet, get_network\n",
    "from util.data import get_dataloaders\n",
    "from util.vis_pipnet import get_img_coordinates\n",
    "from util.func import get_patch_size\n",
    "from util.eval_cub_csv import get_topk_cub\n",
    "from PIL import ImageFont, Image, ImageDraw as D\n",
    "from pipnet.train import test_pipnet, train_pipnet\n",
    "from omegaconf import OmegaConf\n",
    "from util.phylo_utils import construct_phylo_tree, construct_discretized_phylo_tree\n",
    "from util.args import get_args, save_args, get_optimizer_nn\n",
    "import wandb\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "import pdb\n",
    "import math\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/004-CUB-27-imgnet_cnext26_img=224_nprotos=200'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/005-CUB-27-imgnet_cnext26_img=224_nprotos=50'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/007-CUB-27-imgnet_cnext26_img=224_nprotos=50'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/009-CUB-27-imgnet_cnext26_img=224_nprotos=50'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/010-CUB-27-imgnet_OOD_cnext26_img=224_nprotos=20'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/012-CUB-27-imgnet_OOD_cnext26_img=224_nprotos=20'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/013-CUB-27-imgnet_OOD_cnext26_img=224_nprotos=20'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/022-CUB-27-imgnet_OOD_cnext26_img=224_nprotos=20'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/022-CUB-27-imgnet_cnext26_img=224_nprotos=20'\n",
    "run_path = '/home/harishbabu/projects/PIPNet/runs/035-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    device_ids = [torch.cuda.current_device()]\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    device_ids = []\n",
    "\n",
    "args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "args = pickle.load(args_file)\n",
    "args.OOD_dataset = 'CUB-163-OOD-imgnet-224'\n",
    "\n",
    "ckpt_path = os.path.join(run_path, 'checkpoints', 'net_trained_last')\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- No discretization -------------------------\n"
     ]
    }
   ],
   "source": [
    "if args.phylo_config:\n",
    "    phylo_config = OmegaConf.load(args.phylo_config)\n",
    "\n",
    "if args.phylo_config:\n",
    "    # construct the phylo tree\n",
    "    if phylo_config.phyloDistances_string == 'None':\n",
    "        root = construct_phylo_tree(phylo_config.phylogeny_path)\n",
    "        print('-'*25 + ' No discretization ' + '-'*25)\n",
    "    else:\n",
    "        root = construct_discretized_phylo_tree(phylo_config.phylogeny_path, phylo_config.phyloDistances_string)\n",
    "        print('-'*25 + ' Discretized ' + '-'*25)\n",
    "else:\n",
    "    # construct the tree (original hierarchy as described in the paper)\n",
    "    root = Node(\"root\")\n",
    "    root.add_children(['animal','vehicle','everyday_object','weapon','scuba_diver'])\n",
    "    root.add_children_to('animal',['non_primate','primate'])\n",
    "    root.add_children_to('non_primate',['African_elephant','giant_panda','lion'])\n",
    "    root.add_children_to('primate',['capuchin','gibbon','orangutan'])\n",
    "    root.add_children_to('vehicle',['ambulance','pickup','sports_car'])\n",
    "    root.add_children_to('everyday_object',['laptop','sandal','wine_bottle'])\n",
    "    root.add_children_to('weapon',['assault_rifle','rifle'])\n",
    "    # flat root\n",
    "    # root.add_children(['scuba_diver','African_elephant','giant_panda','lion','capuchin','gibbon','orangutan','ambulance','pickup','sports_car','laptop','sandal','wine_bottle','assault_rifle','rifle'])\n",
    "root.assign_all_descendents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes (k) =  18 ['cub_001_Black_footed_Albatross', 'cub_002_Laysan_Albatross', 'cub_003_Sooty_Albatross', 'cub_004_Groove_billed_Ani', 'cub_023_Brandt_Cormorant'] etc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/.conda/envs/hpnet1/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 21 samples from trainloader_pretraining\n",
      "Num classes (k) =  163 ['cub_002_Laysan_Albatross', 'cub_003_Sooty_Albatross', 'cub_004_Groove_billed_Ani', 'cub_005_Crested_Auklet', 'cub_006_Least_Auklet'] etc.\n"
     ]
    }
   ],
   "source": [
    "trainloader, trainloader_pretraining, trainloader_normal, trainloader_normal_augment, projectloader, testloader, test_projectloader, classes = get_dataloaders(args, device, OOD=False)\n",
    "trainloader_OOD, trainloader_pretraining_OOD, trainloader_normal_OOD, trainloader_normal_augment_OOD, projectloader_OOD, testloader_OOD, test_projectloader_OOD, _ = get_dataloaders(args, device, OOD=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prototypes:  20\n"
     ]
    }
   ],
   "source": [
    "# Create a convolutional network based on arguments and add 1x1 conv layer\n",
    "feature_net, add_on_layers, pool_layer, classification_layers, num_prototypes = get_network(len(classes), args, root=root)\n",
    "   \n",
    "# Create a PIP-Net\n",
    "net = PIPNet(num_classes=len(classes),\n",
    "                    num_prototypes=num_prototypes,\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "net = net.to(device=device)\n",
    "net = nn.DataParallel(net, device_ids = device_ids)    \n",
    "net.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "criterion = nn.NLLLoss(reduction='mean').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- root -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/.conda/envs/hpnet1/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/harishbabu/.conda/envs/hpnet1/lib/python3.8/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/harishbabu/.conda/envs/hpnet1/lib/python3.8/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/harishbabu/.conda/envs/hpnet1/lib/python3.8/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/harishbabu/.conda/envs/hpnet1/lib/python3.8/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_child_confidences mean: nan std: nan\n",
      "OOD_confidences mean: 0.5553259209621172 std: 0.1453424249454944\n",
      "ID_confidences mean: 0.8781609270307753 std: 0.18097744498511775\n",
      "\n",
      "\n",
      "------------------------- 052+053 -------------------------\n",
      "non_child_confidences mean: 0.5271810420921871 std: 0.0963297127864586\n",
      "OOD_confidences mean: 0.5202414623798768 std: 0.08590184667103448\n",
      "ID_confidences mean: 0.9863733500242233 std: 0.006437726390970147\n",
      "\n",
      "\n",
      "------------------------- 004+086 -------------------------\n",
      "non_child_confidences mean: 0.5000443160533905 std: 6.723966003276683e-05\n",
      "OOD_confidences mean: 0.5573485621645407 std: 0.15105458840247646\n",
      "ID_confidences mean: 0.962884681565421 std: 0.05807802391728871\n",
      "\n",
      "\n",
      "------------------------- 053+050 -------------------------\n",
      "non_child_confidences mean: 0.5354722301165263 std: 0.08092726706809839\n",
      "OOD_confidences mean: 0.5142108958923012 std: 0.06895337005009712\n",
      "ID_confidences mean: 0.9838799039522806 std: 0.006761266181520603\n",
      "\n",
      "\n",
      "------------------------- 004+032 -------------------------\n",
      "non_child_confidences mean: 0.5001602343150547 std: 0.00018606813491109996\n",
      "OOD_confidences mean: 0.5151177586221988 std: 0.07731570189225292\n",
      "ID_confidences mean: 0.8233921825885773 std: 0.1911658201289055\n",
      "\n",
      "\n",
      "------------------------- 086+045 -------------------------\n",
      "non_child_confidences mean: 0.5442953854799271 std: 0.10850427844785894\n",
      "OOD_confidences mean: 0.5357196491920143 std: 0.11808840854385372\n",
      "ID_confidences mean: 0.8914702415466309 std: 0.1756902155854099\n",
      "\n",
      "\n",
      "------------------------- 050+051 -------------------------\n",
      "non_child_confidences mean: 0.5176775008440018 std: 0.040297202376082336\n",
      "OOD_confidences mean: 0.5100759169075386 std: 0.05558920207961557\n",
      "ID_confidences mean: 0.9759393036365509 std: 0.001781851053237915\n",
      "\n",
      "\n",
      "------------------------- 032+033 -------------------------\n",
      "non_child_confidences mean: 0.5013955434163412 std: 0.0014735455092371843\n",
      "OOD_confidences mean: 0.5179417283257093 std: 0.07577939111331583\n",
      "ID_confidences mean: 0.9822535117467245 std: 0.007666244613467541\n",
      "\n",
      "\n",
      "------------------------- 045+101 -------------------------\n",
      "non_child_confidences mean: 0.5391563110881381 std: 0.11042513208538716\n",
      "OOD_confidences mean: 0.5242206483530852 std: 0.09806609342658368\n",
      "ID_confidences mean: 0.9439358512560526 std: 0.13402263258672012\n",
      "\n",
      "\n",
      "------------------------- 033+031 -------------------------\n",
      "non_child_confidences mean: 0.5259496420621872 std: 0.09752754543227156\n",
      "OOD_confidences mean: 0.5169855049051391 std: 0.07013215141412972\n",
      "ID_confidences mean: 0.8268711268901825 std: 0.11650308966636658\n",
      "\n",
      "\n",
      "------------------------- 045+003 -------------------------\n",
      "non_child_confidences mean: 0.5057814930166517 std: 0.008612250895045923\n",
      "OOD_confidences mean: 0.528492990812641 std: 0.0944904234798783\n",
      "ID_confidences mean: 0.9729456752538681 std: 0.013993000283287892\n",
      "\n",
      "\n",
      "------------------------- 101+023 -------------------------\n",
      "non_child_confidences mean: 0.5089017427884616 std: 0.026054841514821094\n",
      "OOD_confidences mean: 0.5205359422356073 std: 0.08683569560750687\n",
      "ID_confidences mean: 0.8936861991882324 std: 0.19681586516474744\n",
      "\n",
      "\n",
      "------------------------- 003+002 -------------------------\n",
      "non_child_confidences mean: 0.5352851907412212 std: 0.11286584765469154\n",
      "OOD_confidences mean: 0.5148770004693716 std: 0.06893118911067148\n",
      "ID_confidences mean: 0.8826567331949869 std: 0.11803976638056685\n",
      "\n",
      "\n",
      "------------------------- 101+100 -------------------------\n",
      "non_child_confidences mean: 0.5292292647063732 std: 0.1083889487552325\n",
      "OOD_confidences mean: 0.5137973424115795 std: 0.06914369773934018\n",
      "ID_confidences mean: 0.9743017554283142 std: 0.008524835109710693\n",
      "\n",
      "\n",
      "------------------------- 023+025 -------------------------\n",
      "non_child_confidences mean: 0.5168885866800944 std: 0.03757000827944081\n",
      "OOD_confidences mean: 0.5160047942144008 std: 0.05635627527496128\n",
      "ID_confidences mean: 0.8419354359308878 std: 0.1473435145573821\n",
      "\n",
      "\n",
      "------------------------- 002+001 -------------------------\n",
      "non_child_confidences mean: 0.5029496029019356 std: 0.003970206898308762\n",
      "OOD_confidences mean: 0.5064274416379402 std: 0.04305497148262645\n",
      "ID_confidences mean: 0.9682855606079102 std: 0.0036463141441345215\n",
      "\n",
      "\n",
      "------------------------- 025+024 -------------------------\n",
      "non_child_confidences mean: 0.5596935302019119 std: 0.10795386306530752\n",
      "OOD_confidences mean: 0.5191117287413475 std: 0.07119535226933398\n",
      "ID_confidences mean: 0.9796229004859924 std: 0.001949012279510498\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader = testloader\n",
    "data_loader_OOD = testloader_OOD\n",
    "# data_loader = trainloader_normal\n",
    "data_loader.shuffle = False\n",
    "data_loader_OOD.shuffle = False\n",
    "\n",
    "net.eval()\n",
    "\n",
    "dataset = data_loader.dataset\n",
    "while type(dataset) != ImageFolder:\n",
    "    dataset = dataset.dataset\n",
    "name2label = dataset.class_to_idx\n",
    "label2name = {label:name for name, label in name2label.items()}\n",
    "\n",
    "def confidences(node):\n",
    "    print('-'*25, node.name, '-'*25)\n",
    "    with torch.no_grad():\n",
    "        non_child_images = {}\n",
    "        ID_images = {}\n",
    "        for xs, ys1 in data_loader:        \n",
    "            for i in range(ys1.shape[0]):\n",
    "                y = ys1[i].item()\n",
    "                if (label2name[y] not in node.descendents) and (y not in non_child_images):\n",
    "                    non_child_images[y] = xs[i]\n",
    "                if (label2name[y] in node.descendents) and (y not in ID_images):\n",
    "                    ID_images[y] = xs[i]\n",
    "\n",
    "        OOD_images = {}\n",
    "        for xs, ys1 in data_loader_OOD:\n",
    "            for i in range(ys1.shape[0]):\n",
    "                y = ys1[i].item()\n",
    "                if (y not in OOD_images):\n",
    "                    OOD_images[y] = xs[i]\n",
    "\n",
    "        non_child_confidences = []\n",
    "        for y, image in non_child_images.items():\n",
    "            proto_features, pooled, out = net(image.unsqueeze(0))\n",
    "            node_logits = out[node.name]\n",
    "            normalized_score = torch.log1p(node_logits**net.module._multiplier)\n",
    "            prob = torch.nn.functional.softmax(normalized_score,1)\n",
    "            non_child_confidences.append(torch.max(prob).item())\n",
    "        # print('non_child_confidences', non_child_confidences, '\\n')\n",
    "        print('non_child_confidences', 'mean:', np.mean(non_child_confidences), 'std:', np.std(non_child_confidences))\n",
    "\n",
    "        OOD_confidences = []\n",
    "        for y, image in OOD_images.items():\n",
    "            proto_features, pooled, out = net(image.unsqueeze(0))\n",
    "            node_logits = out[node.name]\n",
    "            normalized_score = torch.log1p(node_logits**net.module._multiplier)\n",
    "            prob = torch.nn.functional.softmax(normalized_score,1)\n",
    "            OOD_confidences.append(torch.max(prob).item())\n",
    "        # print('OOD_confidences', OOD_confidences, '\\n')\n",
    "        print('OOD_confidences', 'mean:', np.mean(OOD_confidences), 'std:', np.std(OOD_confidences))\n",
    "\n",
    "        ID_confidences = []\n",
    "        for y, image in ID_images.items():\n",
    "            proto_features, pooled, out = net(image.unsqueeze(0))\n",
    "            node_logits = out[node.name]\n",
    "            normalized_score = torch.log1p(node_logits**net.module._multiplier)\n",
    "            prob = torch.nn.functional.softmax(normalized_score,1)\n",
    "            ID_confidences.append(torch.max(prob).item())\n",
    "        # print('ID_confidences', ID_confidences, '\\n')\n",
    "        print('ID_confidences', 'mean:', np.mean(ID_confidences), 'std:', np.std(ID_confidences))\n",
    "        \n",
    "        print('\\n')\n",
    "                \n",
    "\n",
    "# node = root.get_node('113+011')\n",
    "for node in root.nodes_with_children():\n",
    "    confidences(node)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- root -------------------------\n",
      "non_child_max_logits mean: nan std: nan\n",
      "OOD_max_logits mean: 0.6082209549682498 std: 1.592678779783133\n",
      "ID_max_logits mean: 6.032765225265865 std: 4.764022885239978\n",
      "\n",
      "\n",
      "------------------------- 113+001+068 -------------------------\n",
      "non_child_max_logits mean: 0.0005412555183283985 std: 0.0\n",
      "OOD_max_logits mean: 1.0353187390026761 std: 2.5701152959573905\n",
      "ID_max_logits mean: 9.50496085258559 std: 6.211165565225364\n",
      "\n",
      "\n",
      "------------------------- 113+060 -------------------------\n",
      "non_child_max_logits mean: 0.025293122371658684 std: 0.04379857865999187\n",
      "OOD_max_logits mean: 0.6131174176409298 std: 1.7258463005296325\n",
      "ID_max_logits mean: 6.395429765572771 std: 5.211234176376284\n",
      "\n",
      "\n",
      "------------------------- 001+052 -------------------------\n",
      "non_child_max_logits mean: 0.10528445018765827 std: 0.1596867377259321\n",
      "OOD_max_logits mean: 0.23528782221948602 std: 0.838539883743166\n",
      "ID_max_logits mean: 10.873497009277344 std: 3.2598831119939735\n",
      "\n",
      "\n",
      "------------------------- 113+187 -------------------------\n",
      "non_child_max_logits mean: 0.026163264192291535 std: 0.04621843504208935\n",
      "OOD_max_logits mean: 0.2973504055435505 std: 1.17525218507854\n",
      "ID_max_logits mean: 8.027530444013935 std: 6.519885672752644\n",
      "\n",
      "\n",
      "------------------------- 060+071 -------------------------\n",
      "non_child_max_logits mean: 0.11147768304605658 std: 0.14603402630830856\n",
      "OOD_max_logits mean: 0.8288130894306178 std: 2.338467209214641\n",
      "ID_max_logits mean: 7.677426755428314 std: 5.00727742957816\n",
      "\n",
      "\n",
      "------------------------- 001+033 -------------------------\n",
      "non_child_max_logits mean: 0.2702887935936451 std: 0.38943854577751646\n",
      "OOD_max_logits mean: 0.2721688615163914 std: 0.4735717267682818\n",
      "ID_max_logits mean: 7.2054502964019775 std: 1.3823497295379639\n",
      "\n",
      "\n",
      "------------------------- 113+037 -------------------------\n",
      "non_child_max_logits mean: 0.011101355458959006 std: 0.014675174957536919\n",
      "OOD_max_logits mean: 0.3061563984313362 std: 1.3446994984784322\n",
      "ID_max_logits mean: 7.966047215261771 std: 6.1137524496292555\n",
      "\n",
      "\n",
      "------------------------- 187+079 -------------------------\n",
      "non_child_max_logits mean: 0.1365001518651843 std: 0.14509675255973495\n",
      "OOD_max_logits mean: 0.286081539414126 std: 0.7025505879560846\n",
      "ID_max_logits mean: 7.918936252593994 std: 0.21030855178833008\n",
      "\n",
      "\n",
      "------------------------- 060+143 -------------------------\n",
      "non_child_max_logits mean: 0.20375650018453598 std: 0.1486992579703549\n",
      "OOD_max_logits mean: 0.6709960022929804 std: 1.6524987607631447\n",
      "ID_max_logits mean: 6.985604286193848 std: 1.0290956497192383\n",
      "\n",
      "\n",
      "------------------------- 113+030 -------------------------\n",
      "non_child_max_logits mean: 0.18342959957954008 std: 0.5777743069352206\n",
      "OOD_max_logits mean: 0.22057347906113495 std: 0.8395276181216184\n",
      "ID_max_logits mean: 8.422977861389517 std: 7.298968442072403\n",
      "\n",
      "\n",
      "------------------------- 037+077 -------------------------\n",
      "non_child_max_logits mean: 0.3184915741533041 std: 0.3643011204605416\n",
      "OOD_max_logits mean: 0.6342021962684905 std: 1.1718071016035594\n",
      "ID_max_logits mean: 7.296678781509399 std: 0.021521806716918945\n",
      "\n",
      "\n",
      "------------------------- 113+085 -------------------------\n",
      "non_child_max_logits mean: 0.12120192688806648 std: 0.4055805154364682\n",
      "OOD_max_logits mean: 0.07475033912134922 std: 0.5722773890130749\n",
      "ID_max_logits mean: 12.10277642066089 std: 6.667525234729596\n",
      "\n",
      "\n",
      "------------------------- 030+156 -------------------------\n",
      "non_child_max_logits mean: 0.41562899082899096 std: 0.31155473396128736\n",
      "OOD_max_logits mean: 0.5855035616736288 std: 1.015555955437853\n",
      "ID_max_logits mean: 7.6762919425964355 std: 0.19303178787231445\n",
      "\n",
      "\n",
      "------------------------- 113+194 -------------------------\n",
      "non_child_max_logits mean: 0.02841111321079855 std: 0.08583760247160463\n",
      "OOD_max_logits mean: 0.09622251199832632 std: 0.4896392445396868\n",
      "ID_max_logits mean: 5.789841304009315 std: 6.735523992365377\n",
      "\n",
      "\n",
      "------------------------- 113+118 -------------------------\n",
      "non_child_max_logits mean: 0.04122717910692753 std: 0.08752964083476769\n",
      "OOD_max_logits mean: 0.16106414603738278 std: 0.7556390173627678\n",
      "ID_max_logits mean: 11.641858333582059 std: 7.633930619427026\n",
      "\n",
      "\n",
      "------------------------- 194+019 -------------------------\n",
      "non_child_max_logits mean: 0.29199944227933883 std: 0.25088341410973714\n",
      "OOD_max_logits mean: 0.4179621117583767 std: 0.8021911340572127\n",
      "ID_max_logits mean: 4.11330309510231 std: 3.995917409658432\n",
      "\n",
      "\n",
      "------------------------- 113+034 -------------------------\n",
      "non_child_max_logits mean: 0.02167609319197557 std: 0.05223505879980343\n",
      "OOD_max_logits mean: 0.06243678245034949 std: 0.3297640965741265\n",
      "ID_max_logits mean: 12.9039642545912 std: 6.372951729192805\n",
      "\n",
      "\n",
      "------------------------- 113+016 -------------------------\n",
      "non_child_max_logits mean: 0.09722133102753248 std: 0.26917144145179206\n",
      "OOD_max_logits mean: 0.10300972248981792 std: 0.48071922254997573\n",
      "ID_max_logits mean: 12.746373474597931 std: 6.09534193722655\n",
      "\n",
      "\n",
      "------------------------- 113+165 -------------------------\n",
      "non_child_max_logits mean: 0.07243207173014525 std: 0.1390461567869278\n",
      "OOD_max_logits mean: 0.10656827870459815 std: 0.7168874929561042\n",
      "ID_max_logits mean: 9.184569173625537 std: 5.246180490287\n",
      "\n",
      "\n",
      "------------------------- 113+011 -------------------------\n",
      "non_child_max_logits mean: 0.21013999944704626 std: 0.5318147046569545\n",
      "OOD_max_logits mean: 0.21042616719553572 std: 0.8504083531501385\n",
      "ID_max_logits mean: 7.543302864767611 std: 4.425514561378373\n",
      "\n",
      "\n",
      "------------------------- 165+181 -------------------------\n",
      "non_child_max_logits mean: 0.10084029093074302 std: 0.1159603596548107\n",
      "OOD_max_logits mean: 0.17260521156013447 std: 0.6889921818190191\n",
      "ID_max_logits mean: 13.037033398946127 std: 5.236647441584429\n",
      "\n",
      "\n",
      "------------------------- 113+122 -------------------------\n",
      "non_child_max_logits mean: 0.09905968866776675 std: 0.16043451896461564\n",
      "OOD_max_logits mean: 0.18767370460940627 std: 0.8088698369382009\n",
      "ID_max_logits mean: 2.479538142681122 std: 1.7489364743232727\n",
      "\n",
      "\n",
      "------------------------- 011+097 -------------------------\n",
      "non_child_max_logits mean: 0.2139031939394772 std: 0.28152279922615253\n",
      "OOD_max_logits mean: 0.2819596161048836 std: 0.6405190997114777\n",
      "ID_max_logits mean: 3.2561376988887787 std: 3.1812545359134674\n",
      "\n",
      "\n",
      "------------------------- 165+161 -------------------------\n",
      "non_child_max_logits mean: 0.3017024881765246 std: 0.24836504964300316\n",
      "OOD_max_logits mean: 0.34182078166196317 std: 0.5599627411720955\n",
      "ID_max_logits mean: 7.705671310424805 std: 0.6672382354736328\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader = testloader\n",
    "data_loader_OOD = testloader_OOD\n",
    "# data_loader = trainloader_normal\n",
    "data_loader.shuffle = False\n",
    "data_loader_OOD.shuffle = False\n",
    "\n",
    "net.eval()\n",
    "\n",
    "dataset = data_loader.dataset\n",
    "while type(dataset) != ImageFolder:\n",
    "    dataset = dataset.dataset\n",
    "name2label = dataset.class_to_idx\n",
    "label2name = {label:name for name, label in name2label.items()}\n",
    "\n",
    "def confidences(node):\n",
    "    print('-'*25, node.name, '-'*25)\n",
    "    with torch.no_grad():\n",
    "        non_child_images = {}\n",
    "        ID_images = {}\n",
    "        for xs, ys1 in data_loader:        \n",
    "            for i in range(ys1.shape[0]):\n",
    "                y = ys1[i].item()\n",
    "                if (label2name[y] not in node.descendents) and (y not in non_child_images):\n",
    "                    non_child_images[y] = xs[i]\n",
    "                if (label2name[y] in node.descendents) and (y not in ID_images):\n",
    "                    ID_images[y] = xs[i]\n",
    "\n",
    "        OOD_images = {}\n",
    "        for xs, ys1 in data_loader_OOD:\n",
    "            for i in range(ys1.shape[0]):\n",
    "                y = ys1[i].item()\n",
    "                if (y not in OOD_images):\n",
    "                    OOD_images[y] = xs[i]\n",
    "\n",
    "        non_child_confidences = []\n",
    "        for y, image in non_child_images.items():\n",
    "            proto_features, pooled, out = net(image.unsqueeze(0))\n",
    "            node_logits = out[node.name]\n",
    "#             normalized_score = torch.log1p(node_logits**net.module._multiplier)\n",
    "#             prob = torch.nn.functional.softmax(normalized_score,1)\n",
    "            non_child_confidences.append(torch.max(node_logits).item())\n",
    "        # print('non_child_confidences', non_child_confidences, '\\n')\n",
    "        print('non_child_max_logits', 'mean:', np.mean(non_child_confidences), 'std:', np.std(non_child_confidences))\n",
    "\n",
    "        OOD_confidences = []\n",
    "        for y, image in OOD_images.items():\n",
    "            proto_features, pooled, out = net(image.unsqueeze(0))\n",
    "            node_logits = out[node.name]\n",
    "#             normalized_score = torch.log1p(node_logits**net.module._multiplier)\n",
    "#             prob = torch.nn.functional.softmax(normalized_score,1)\n",
    "            OOD_confidences.append(torch.max(node_logits).item())\n",
    "        # print('OOD_confidences', OOD_confidences, '\\n')\n",
    "        print('OOD_max_logits', 'mean:', np.mean(OOD_confidences), 'std:', np.std(OOD_confidences))\n",
    "\n",
    "        ID_confidences = []\n",
    "        for y, image in ID_images.items():\n",
    "            proto_features, pooled, out = net(image.unsqueeze(0))\n",
    "            node_logits = out[node.name]\n",
    "#             normalized_score = torch.log1p(node_logits**net.module._multiplier)\n",
    "#             prob = torch.nn.functional.softmax(normalized_score,1)\n",
    "            ID_confidences.append(torch.max(node_logits).item())\n",
    "        # print('ID_confidences', ID_confidences, '\\n')\n",
    "        print('ID_max_logits', 'mean:', np.mean(ID_confidences), 'std:', np.std(ID_confidences))\n",
    "        \n",
    "        print('\\n')\n",
    "                \n",
    "\n",
    "# node = root.get_node('113+011')\n",
    "for node in root.nodes_with_children():\n",
    "    confidences(node)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(getattr(net.module, \"_113+165_classification\").bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    device_ids = [torch.cuda.current_device()]\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    device_ids = []\n",
    "    \n",
    "model = torchvision.models.resnet18()\n",
    "    \n",
    "model = model.to(device=device)\n",
    "model = nn.DataParallel(model, device_ids = device_ids)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.layer2[0].downsample[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n",
    "model.module.layer2[0].downsample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n",
    "# model.module.layer1#[0].conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
