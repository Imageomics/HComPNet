{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48090c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "import sys, os\n",
    "import random\n",
    "import numpy as np\n",
    "from shutil import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cebc9a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/010-CUB-27-imgnet_OOD_cnext26_img=224_nprotos=20'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/031-CUB-18-imgnet_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/032-CUB-18-imgnet_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/035-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "\n",
    "# run_path = '/home/harishbabu/projects/PIPNet/runs/043-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel'\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/036-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel_uniformity\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/041-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/042-035_clone-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20_orth-on-rel\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/044-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=20-or-4per-desc_orth-on-rel\"\n",
    "\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/046-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=10per-desc_orth-on-rel\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/047-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=5per-desc_tanh-desc\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/048-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=5per-desc_tanh-desc_unit-sphere\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/051-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_tanh-desc_unit-sphere_AW=5-TW=2-UW=2-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/052-CUB-18-imgnet_OOD_cnext26_img=224_nprotos=4per-desc_tanh-desc_unit-sphere_AW=5-TW=2-UW=2-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/055-CUB-18_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/056-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/057-CUB-18-imgnet_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/058-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2\"\n",
    "\n",
    "# with unit sphere\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/059-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# unit sphere with softmax\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/065-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# original hpipnet with 20 protos per node no KO, no OOD, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/062-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD\"\n",
    "\n",
    "# original hpipnet with 20 protos per node no KO, no OOD, WITH tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/063-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=20_no-KO_no-OOD_tanh-desc\"\n",
    "\n",
    "# with unit sphere but no AL+UNI\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/066-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere_finetune=5_no-meanpool_no-softmax_no-align_no-uni_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, with softmax, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/067-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, with softmax, no tanh-desc, INCORRECT\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/067-incorrect-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# with unit sphere, protopool, no softmax, no tanh-desc\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/068-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_no-softmax_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 071 with bias\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/071-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_with-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 072 gumbel softmax, tau=0.5\n",
    "# run_path = \"/home/harishbabu/projects/PIPNet/runs/072-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-gumbel-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "# 074 multiply_cs_softmax\n",
    "run_path = \"/home/harishbabu/projects/PIPNet/runs/074-CUB-18-imgnet_with-equalize-aug_cnext26_img=224_nprotos=4per-desc_unit-sphere-protopool_finetune=5_no-meanpool_with-softmax_multi-cs-softmax_no-addon-bias_AW=3-TW=2-UW=3-CW=2_batch=20\"\n",
    "\n",
    "try:\n",
    "    sys.path.remove('/home/harishbabu/projects/PIPNet')\n",
    "except:\n",
    "    pass\n",
    "sys.path.insert(0, os.path.join(run_path, 'source_clone'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c9fc894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmaps showing where a prototype is found will not be generated because OpenCV is not installed.\n"
     ]
    }
   ],
   "source": [
    "from pipnet.pipnet import PIPNet, get_network\n",
    "from util.log import Log\n",
    "from util.args import get_args, save_args, get_optimizer_nn\n",
    "from util.data import get_dataloaders\n",
    "from util.func import init_weights_xavier\n",
    "from pipnet.train import train_pipnet, test_pipnet\n",
    "# from pipnet.test import eval_pipnet, get_thresholds, eval_ood\n",
    "from util.eval_cub_csv import eval_prototypes_cub_parts_csv, get_topk_cub, get_proto_patches_cub\n",
    "from util.vis_pipnet import visualize, visualize_topk\n",
    "from util.visualize_prediction import vis_pred, vis_pred_experiments\n",
    "from util.node import Node\n",
    "from util.phylo_utils import construct_phylo_tree, construct_discretized_phylo_tree\n",
    "from util.func import get_patch_size\n",
    "from util.data import ModifiedLabelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44caaec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    ## Load Model\n",
    "    return np.array(result_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32a4405",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e77cd933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- No discretization -------------------------\n"
     ]
    }
   ],
   "source": [
    "args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "args = pickle.load(args_file)\n",
    "\n",
    "if args.phylo_config:\n",
    "    phylo_config = OmegaConf.load(args.phylo_config)\n",
    "\n",
    "if args.phylo_config:\n",
    "    # construct the phylo tree\n",
    "    if phylo_config.phyloDistances_string == 'None':\n",
    "        if '031' in run_path: # this run uses a different phylogeny file that had an extra root node which is a mistake\n",
    "            root = construct_phylo_tree('/home/harishbabu/data/phlyogenyCUB/18Species-with-extra-root-node/1_tree-consensus-Hacket-18Species-modified_cub-names_v1.phy')\n",
    "        else:\n",
    "            root = construct_phylo_tree(phylo_config.phylogeny_path)\n",
    "        print('-'*25 + ' No discretization ' + '-'*25)\n",
    "    else:\n",
    "        root = construct_discretized_phylo_tree(phylo_config.phylogeny_path, phylo_config.phyloDistances_string)\n",
    "        print('-'*25 + ' Discretized ' + '-'*25)\n",
    "else:\n",
    "    # construct the tree (original hierarchy as described in the paper)\n",
    "    root = Node(\"root\")\n",
    "    root.add_children(['animal','vehicle','everyday_object','weapon','scuba_diver'])\n",
    "    root.add_children_to('animal',['non_primate','primate'])\n",
    "    root.add_children_to('non_primate',['African_elephant','giant_panda','lion'])\n",
    "    root.add_children_to('primate',['capuchin','gibbon','orangutan'])\n",
    "    root.add_children_to('vehicle',['ambulance','pickup','sports_car'])\n",
    "    root.add_children_to('everyday_object',['laptop','sandal','wine_bottle'])\n",
    "    root.add_children_to('weapon',['assault_rifle','rifle'])\n",
    "    # flat root\n",
    "    # root.add_children(['scuba_diver','African_elephant','giant_panda','lion','capuchin','gibbon','orangutan','ambulance','pickup','sports_car','laptop','sandal','wine_bottle','assault_rifle','rifle'])\n",
    "root.assign_all_descendents()\n",
    "\n",
    "if ('num_protos_per_descendant' in args) and (args.num_protos_per_descendant > 0):\n",
    "    for node in root.nodes_with_children():\n",
    "        node.set_num_protos(args.num_protos_per_descendant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a58e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 samples from trainloader\n",
      "Dropping 0 samples from trainloader_pretraining\n",
      "Dropping 0 samples from trainloader_normal\n",
      "Dropping 0 samples from trainloader_normal_augment\n",
      "Num classes (k) =  18 ['cub_001_Black_footed_Albatross', 'cub_002_Laysan_Albatross', 'cub_003_Sooty_Albatross', 'cub_004_Groove_billed_Ani', 'cub_023_Brandt_Cormorant'] etc.\n",
      "Classes:  {'cub_001_Black_footed_Albatross': 0, 'cub_002_Laysan_Albatross': 1, 'cub_003_Sooty_Albatross': 2, 'cub_004_Groove_billed_Ani': 3, 'cub_023_Brandt_Cormorant': 4, 'cub_024_Red_faced_Cormorant': 5, 'cub_025_Pelagic_Cormorant': 6, 'cub_031_Black_billed_Cuckoo': 7, 'cub_032_Mangrove_Cuckoo': 8, 'cub_033_Yellow_billed_Cuckoo': 9, 'cub_045_Northern_Fulmar': 10, 'cub_050_Eared_Grebe': 11, 'cub_051_Horned_Grebe': 12, 'cub_052_Pied_billed_Grebe': 13, 'cub_053_Western_Grebe': 14, 'cub_086_Pacific_Loon': 15, 'cub_100_Brown_Pelican': 16, 'cub_101_White_Pelican': 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/.conda/envs/hpnet1/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prototypes:  20\n",
      "----------Prototypes per descendant: 4----------\n",
      "Assigned 136 protos to node root\n",
      "Assigned 24 protos to node 052+053\n",
      "Assigned 104 protos to node 004+086\n",
      "Assigned 16 protos to node 053+050\n",
      "Assigned 24 protos to node 004+032\n",
      "Assigned 72 protos to node 086+045\n",
      "Assigned 8 protos to node 050+051\n",
      "Assigned 16 protos to node 032+033\n",
      "Assigned 64 protos to node 045+101\n",
      "Assigned 8 protos to node 033+031\n",
      "Assigned 24 protos to node 045+003\n",
      "Assigned 32 protos to node 101+023\n",
      "Assigned 16 protos to node 003+002\n",
      "Assigned 8 protos to node 101+100\n",
      "Assigned 16 protos to node 023+025\n",
      "Assigned 8 protos to node 002+001\n",
      "Assigned 8 protos to node 025+024\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    device_ids = [torch.cuda.current_device()]\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    device_ids = []\n",
    "\n",
    "args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "args = pickle.load(args_file)\n",
    "\n",
    "# ckpt_file_name = 'net_overspecific_pruned_replaced_thresh=0.5_last'\n",
    "ckpt_file_name = 'net_trained_last'\n",
    "# ckpt_file_name = 'net_trained_10'\n",
    "# ckpt_file_name = 'net_pretrained'\n",
    "epoch = ckpt_file_name.split('_')[-1]\n",
    "\n",
    "ckpt_path = os.path.join(run_path, 'checkpoints', ckpt_file_name)\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "if ckpt_file_name != 'net_trained_last':\n",
    "    print('\\n', (10*'-')+'WARNING: Not using the final trained model'+(10*'-'), '\\n')\n",
    "\n",
    "# Obtain the dataset and dataloaders\n",
    "trainloader, trainloader_pretraining, trainloader_normal, trainloader_normal_augment, projectloader, testloader, test_projectloader, classes = get_dataloaders(args, device)\n",
    "if len(classes)<=20:\n",
    "    if args.validation_size == 0.:\n",
    "        print(\"Classes: \", testloader.dataset.class_to_idx, flush=True)\n",
    "    else:\n",
    "        print(\"Classes: \", str(classes), flush=True)\n",
    "\n",
    "# Create a convolutional network based on arguments and add 1x1 conv layer\n",
    "feature_net, add_on_layers, pool_layer, classification_layers, num_prototypes = get_network(len(classes), args, root=root)\n",
    "   \n",
    "# Create a PIP-Net\n",
    "net = PIPNet(num_classes=len(classes),\n",
    "                    num_prototypes=num_prototypes,\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "net = net.to(device=device)\n",
    "net = nn.DataParallel(net, device_ids = device_ids)    \n",
    "net.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "net.eval()\n",
    "criterion = nn.NLLLoss(reduction='mean').to(device)\n",
    "\n",
    "# Forward one batch through the backbone to get the latent output size\n",
    "# with torch.no_grad():\n",
    "#     xs1, _, _ = next(iter(trainloader))\n",
    "#     xs1 = xs1.to(device)\n",
    "#     proto_features, _, _ = net(xs1)\n",
    "#     wshape = proto_features['root'].shape[-1]\n",
    "#     args.wshape = wshape #needed for calculating image patch size\n",
    "#     print(\"Output shape: \", proto_features['root'].shape, flush=True)\n",
    "    \n",
    "args.wshape = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c709d461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'cub_001_Black_footed_Albatross': 30, 'cub_002_Laysan_Albatross': 30, 'cub_003_Sooty_Albatross': 30, 'cub_004_Groove_billed_Ani': 30, 'cub_023_Brandt_Cormorant': 30, 'cub_024_Red_faced_Cormorant': 30, 'cub_025_Pelagic_Cormorant': 30, 'cub_031_Black_billed_Cuckoo': 30, 'cub_032_Mangrove_Cuckoo': 30, 'cub_033_Yellow_billed_Cuckoo': 30, 'cub_045_Northern_Fulmar': 30, 'cub_050_Eared_Grebe': 30, 'cub_051_Horned_Grebe': 30, 'cub_052_Pied_billed_Grebe': 30, 'cub_053_Western_Grebe': 30, 'cub_086_Pacific_Loon': 30, 'cub_100_Brown_Pelican': 30, 'cub_101_White_Pelican': 30})\n"
     ]
    }
   ],
   "source": [
    "root.get_node('004+086').descendents\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming 'dataloader' is your DataLoader instance that has already been created\n",
    "dataset = trainloader.dataset.dataset.dataset\n",
    "\n",
    "# Get the mapping from class indices to names\n",
    "# This assumes that your dataset has the 'classes' and 'class_to_idx' attributes\n",
    "# which is the case for many built-in PyTorch datasets\n",
    "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "\n",
    "# Initialize a counter with class names\n",
    "class_counts = Counter({class_name: 0 for class_name in dataset.classes})\n",
    "\n",
    "# Iterate over the DataLoader\n",
    "for *_, targets in trainloader:\n",
    "    # Convert indices to class names\n",
    "    targets = targets.numpy() if not isinstance(targets, list) else targets\n",
    "    class_names = [idx_to_class[idx] for idx in targets]\n",
    "    class_counts.update(class_names)\n",
    "\n",
    "# Now class_counts has class names as keys and counts as values\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f5a2a",
   "metadata": {},
   "source": [
    "# ConvNext checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d15300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Load the pre-trained ConvNeXt Tiny model\n",
    "# model = torchvision.models.convnext_tiny(pretrained=True).cuda()\n",
    "model = net.module._net\n",
    "\n",
    "# Define a hook function that will print the shape of the inputs to each layer\n",
    "def print_shape_hook(module, input, output):\n",
    "    print(f\"{module.__class__.__name__}: {output.shape}\")\n",
    "\n",
    "# Assuming you want to check the output after each stage\n",
    "# The stages in the ConvNeXt Tiny model are contained in the 'features' module\n",
    "for name, layer in model.named_children():\n",
    "    if name == 'features':\n",
    "        for idx, block in enumerate(layer):\n",
    "            # Register hook to each block\n",
    "            block.register_forward_hook(print_shape_hook)\n",
    "\n",
    "# Turn off gradients as we are not doing training to save computation\n",
    "with torch.no_grad():\n",
    "    # Create a dummy input tensor of the correct size\n",
    "    input_tensor = torch.randn(1, 3, 224, 224).cuda()\n",
    "    \n",
    "    # Get the model's output (forward pass) and triggers hooks\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Remove hooks after use if you're going to reuse this model and don't want the prints anymore\n",
    "# This step is not necessary if the script ends after this since all objects will be deleted anyway\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67095dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Load the pre-trained ConvNeXt Tiny model\n",
    "model = torchvision.models.convnext_tiny(pretrained=True).cuda()\n",
    "# model = net.module._net\n",
    "\n",
    "# Define a hook function that will print the shape of the inputs to each layer\n",
    "def print_shape_hook(module, input, output):\n",
    "    print(f\"{module.__class__.__name__}: {output.shape}\")\n",
    "\n",
    "# Assuming you want to check the output after each stage\n",
    "# The stages in the ConvNeXt Tiny model are contained in the 'features' module\n",
    "for name, layer in model.named_children():\n",
    "    if name == 'features':\n",
    "        for idx, block in enumerate(layer):\n",
    "            # Register hook to each block\n",
    "            block.register_forward_hook(print_shape_hook)\n",
    "\n",
    "# Turn off gradients as we are not doing training to save computation\n",
    "with torch.no_grad():\n",
    "    # Create a dummy input tensor of the correct size\n",
    "    input_tensor = torch.randn(1, 3, 224, 224).cuda()\n",
    "    \n",
    "    # Get the model's output (forward pass) and triggers hooks\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Remove hooks after use if you're going to reuse this model and don't want the prints anymore\n",
    "# This step is not necessary if the script ends after this since all objects will be deleted anyway\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8769d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "242cbbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_128407/3201622953.py\u001b[0m(1)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> x\n",
      "[tensor([[[[ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[ 0.0256,  0.0256,  0.0256,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          [ 0.0256,  0.0256,  0.0256,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          [ 0.0256,  0.0256,  0.0256,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[-1.3473, -1.3473, -1.3473,  ..., -1.3473, -1.3473, -1.3473],\n",
      "          [-1.3473, -1.3473, -1.3473,  ..., -1.3473, -1.3473, -1.3473],\n",
      "          [-1.3473, -1.3473, -1.3473,  ..., -1.3473, -1.3473, -1.3473],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-1.3354, -1.3354, -1.3354,  ..., -1.3354, -1.3354, -1.3354],\n",
      "          [-1.3354, -1.3354, -1.3354,  ..., -1.3354, -1.3354, -1.3354],\n",
      "          [-1.3354, -1.3354, -1.3354,  ..., -1.3354, -1.3354, -1.3354],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.1247, -1.1247, -1.1247,  ..., -1.1247, -1.1247, -1.1247],\n",
      "          [-1.1247, -1.1247, -1.1247,  ..., -1.1247, -1.1247, -1.1247],\n",
      "          [-1.1247, -1.1247, -1.1247,  ..., -1.1247, -1.1247, -1.1247],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[ 0.0256,  0.0256,  0.0256,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          [ 0.0256,  0.0256,  0.0256,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          [ 0.0256,  0.0256,  0.0256,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          ...,\n",
      "          [ 0.0056,  0.0056,  0.0056,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 0.0056,  0.0056,  0.0056,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [ 0.0056,  0.0056,  0.0056,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          ...,\n",
      "          [-0.0049, -0.0049, -0.0049,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-0.0049, -0.0049, -0.0049,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-0.0049, -0.0049, -0.0049,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[ 0.0256,  0.0256,  0.0256,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          [ 0.0256,  0.0256,  0.0256,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          [ 0.0256,  0.0256,  0.0256,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          ...,\n",
      "          [ 0.0256,  0.0256,  0.0256,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 0.0256,  0.0256,  0.0256,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [ 0.0256,  0.0256,  0.0256,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-0.0049, -0.0224, -0.0224,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          [-0.0049, -0.0224, -0.0224,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          [-0.0049, -0.0049, -0.0224,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[ 0.0256,  0.0431,  0.0431,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          [ 0.0256,  0.0431,  0.0431,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          [ 0.0256,  0.0256,  0.0431,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]]), tensor([[[[ 0.3481,  0.3481,  0.3481,  ...,  0.3481,  0.3481,  0.3481],\n",
      "          [ 0.3481,  0.3481,  0.3481,  ...,  0.3481,  0.3481,  0.3481],\n",
      "          [ 0.3481,  0.3481,  0.3481,  ...,  0.3481,  0.3481,  0.3481],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[ 0.3277,  0.3277,  0.3277,  ...,  0.3277,  0.3277,  0.3277],\n",
      "          [ 0.3277,  0.3277,  0.3277,  ...,  0.3277,  0.3277,  0.3277],\n",
      "          [ 0.3277,  0.3277,  0.3277,  ...,  0.3277,  0.3277,  0.3277],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[ 0.3219,  0.3219,  0.3219,  ...,  0.3219,  0.3219,  0.3219],\n",
      "          [ 0.3219,  0.3219,  0.3219,  ...,  0.3219,  0.3219,  0.3219],\n",
      "          [ 0.3219,  0.3219,  0.3219,  ...,  0.3219,  0.3219,  0.3219],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          [ 0.0056,  0.0056,  0.0056,  ...,  0.0056,  0.0056,  0.0056],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[ 0.0256,  0.0256,  0.0256,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          [ 0.0256,  0.0256,  0.0256,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          [ 0.0256,  0.0256,  0.0256,  ...,  0.0256,  0.0256,  0.0256],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[-0.1657, -0.1657, -0.1657,  ..., -0.1657, -0.1657, -0.1657],\n",
      "          [-0.1657, -0.1657, -0.1657,  ..., -0.1657, -0.1657, -0.1657],\n",
      "          [-0.1657, -0.1657, -0.1657,  ..., -0.1657, -0.1657, -0.1657],\n",
      "          ...,\n",
      "          [-1.2959, -1.2959, -1.2959,  ..., -1.2959, -1.2959, -1.2959],\n",
      "          [-1.2959, -1.2959, -1.2959,  ..., -1.2959, -1.2959, -1.2959],\n",
      "          [-1.2959, -1.2959, -1.2959,  ..., -1.2959, -1.2959, -1.2959]],\n",
      "\n",
      "         [[-0.1099, -0.1099, -0.1099,  ..., -0.1099, -0.1099, -0.1099],\n",
      "          [-0.1099, -0.1099, -0.1099,  ..., -0.1099, -0.1099, -0.1099],\n",
      "          [-0.1099, -0.1099, -0.1099,  ..., -0.1099, -0.1099, -0.1099],\n",
      "          ...,\n",
      "          [-1.1954, -1.1954, -1.1954,  ..., -1.1954, -1.1954, -1.1954],\n",
      "          [-1.1954, -1.1954, -1.1954,  ..., -1.1954, -1.1954, -1.1954],\n",
      "          [-1.1954, -1.1954, -1.1954,  ..., -1.1954, -1.1954, -1.1954]],\n",
      "\n",
      "         [[ 0.0082,  0.0082,  0.0082,  ...,  0.0082,  0.0082,  0.0082],\n",
      "          [ 0.0082,  0.0082,  0.0082,  ...,  0.0082,  0.0082,  0.0082],\n",
      "          [ 0.0082,  0.0082,  0.0082,  ...,  0.0082,  0.0082,  0.0082],\n",
      "          ...,\n",
      "          [-0.9678, -0.9678, -0.9678,  ..., -0.9678, -0.9678, -0.9678],\n",
      "          [-0.9678, -0.9678, -0.9678,  ..., -0.9678, -0.9678, -0.9678],\n",
      "          [-0.9678, -0.9678, -0.9678,  ..., -0.9678, -0.9678, -0.9678]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[-0.8849, -0.8849, -0.8849,  ..., -0.8849, -0.8849, -0.8849],\n",
      "          [-0.8849, -0.8849, -0.8849,  ..., -0.8849, -0.8849, -0.8849],\n",
      "          [-0.8849, -0.8849, -0.8849,  ..., -0.8849, -0.8849, -0.8849],\n",
      "          ...,\n",
      "          [-0.8849, -0.8849, -0.8849,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-0.8849, -0.8849, -0.8849,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-0.8849, -0.8849, -0.8849,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-0.7927, -0.7927, -0.7927,  ..., -0.7927, -0.7927, -0.7927],\n",
      "          [-0.7927, -0.7927, -0.7927,  ..., -0.7927, -0.7927, -0.7927],\n",
      "          [-0.7927, -0.7927, -0.7927,  ..., -0.7927, -0.7927, -0.7927],\n",
      "          ...,\n",
      "          [-0.7927, -0.7927, -0.7927,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-0.7927, -0.7927, -0.7927,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-0.7927, -0.7927, -0.7927,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-0.5844, -0.5844, -0.5844,  ..., -0.5844, -0.5844, -0.5844],\n",
      "          [-0.5844, -0.5844, -0.5844,  ..., -0.5844, -0.5844, -0.5844],\n",
      "          [-0.5844, -0.5844, -0.5844,  ..., -0.5844, -0.5844, -0.5844],\n",
      "          ...,\n",
      "          [-0.5844, -0.5844, -0.5844,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-0.5844, -0.5844, -0.5844,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-0.5844, -0.5844, -0.5844,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[-1.1589, -1.1589, -1.1589,  ..., -1.1589, -1.1589, -1.1589],\n",
      "          [-1.1589, -1.1589, -1.1589,  ..., -1.1589, -1.1589, -1.1589],\n",
      "          [-1.1589, -1.1589, -1.1589,  ..., -1.1589, -1.1589, -1.1589],\n",
      "          ...,\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "         [[-0.8627, -0.8627, -0.9678,  ..., -0.8627, -0.8627, -0.8627],\n",
      "          [-0.8627, -0.8627, -0.9678,  ..., -0.8627, -0.8627, -0.8627],\n",
      "          [-0.8627, -0.8627, -0.9678,  ..., -0.8627, -0.8627, -0.8627],\n",
      "          ...,\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "         [[-0.6541, -0.5495,  2.0997,  ..., -0.5495, -0.5495, -0.5495],\n",
      "          [-0.6018, -0.5495,  2.0997,  ..., -0.5495, -0.5495, -0.5495],\n",
      "          [-0.5495, -0.5495,  2.0997,  ..., -0.5495, -0.5495, -0.5495],\n",
      "          ...,\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]]), tensor([13, 15, 13, 14, 12, 12,  8,  0,  0,  1,  9,  6, 12,  1,  5,  8, 16, 16,\n",
      "        12,  8])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> len(x)\n",
      "3\n",
      "ipdb> type(x[0])\n",
      "<class 'torch.Tensor'>\n",
      "ipdb> type(x[1])\n",
      "<class 'torch.Tensor'>\n",
      "ipdb> type(x[2])\n",
      "<class 'torch.Tensor'>\n",
      "ipdb> x[0].shape\n",
      "torch.Size([20, 3, 224, 224])\n",
      "ipdb> x[1].shape\n",
      "torch.Size([20, 3, 224, 224])\n",
      "ipdb> x[3].shape\n",
      "*** IndexError: list index out of range\n",
      "ipdb> x[2].shape\n",
      "torch.Size([20])\n",
      "ipdb> x[2]\n",
      "tensor([13, 15, 13, 14, 12, 12,  8,  0,  0,  1,  9,  6, 12,  1,  5,  8, 16, 16,\n",
      "        12,  8])\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "for x in trainloader:\n",
    "    pdb.set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9152c0",
   "metadata": {},
   "source": [
    "# Weighted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ce0a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "outputs = torch.randn(10, 3, requires_grad=True)  # batch size of 10, 3 classes\n",
    "labels = torch.randint(0, 3, (10,))  # batch size of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cc38b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs torch.Size([10, 3])\n",
      "batch_loss torch.Size([10])\n",
      "class_mask torch.Size([10, 3])\n",
      "weights torch.Size([3])\n",
      "weighted_losses torch.Size([10])\n",
      "tensor(1.6013, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class WeightedCrossEntropyLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WeightedCrossEntropyLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, weights):\n",
    "        print('inputs', inputs.shape)\n",
    "        # Calculate cross entropy loss for each instance without reduction\n",
    "        batch_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        print('batch_loss', batch_loss.shape)\n",
    "        \n",
    "        # Create a mask based on the targets\n",
    "        class_mask = F.one_hot(targets, num_classes=inputs.size(1)).type(inputs.dtype)\n",
    "        \n",
    "        print('class_mask', class_mask.shape)\n",
    "        \n",
    "        print('weights', weights.shape)\n",
    "        \n",
    "        # Multiply the loss by the weights vector\n",
    "        weighted_losses = (batch_loss.unsqueeze(1) * class_mask * weights).sum(dim=1)\n",
    "        \n",
    "        print('weighted_losses', weighted_losses.shape)\n",
    "        \n",
    "        # Perform the final averaging over the batch\n",
    "        loss = weighted_losses.mean()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "# Create an instance of the custom loss\n",
    "custom_loss_function = WeightedCrossEntropyLoss()\n",
    "\n",
    "# Example model output and target labels\n",
    "# outputs = torch.randn(10, 3, requires_grad=True)  # batch size of 10, 3 classes\n",
    "# labels = torch.randint(0, 3, (10,))  # batch size of 10\n",
    "\n",
    "# Example weights for 3 classes\n",
    "weights = torch.tensor([0.5, 2.0, 0.5], requires_grad=False)\n",
    "\n",
    "# Calculate loss\n",
    "loss = custom_loss_function(outputs, labels, weights)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "436fbba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.2500])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "num_images_of_each_child = [60, 240]\n",
    "weights = min(num_images_of_each_child) / torch.tensor(num_images_of_each_child, requires_grad=False)\n",
    "print(weights)\n",
    "print(weights.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff88a8",
   "metadata": {},
   "source": [
    "# Freezing weights of dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8027e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Trainable: dense.weight on cuda:0\n",
      "Trainable: dense.bias on cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple neural network with one dense layer\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.dense = nn.Linear(10, 5)  # Dense layer with 10 inputs and 5 outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)\n",
    "\n",
    "# Instantiate the network\n",
    "net = MyNetwork()\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Transfer the model to the chosen device (GPU or CPU if GPU is not available)\n",
    "net.to(device)\n",
    "\n",
    "# Freeze the first two weights of the dense layer\n",
    "with torch.no_grad():\n",
    "    for i in range(2):\n",
    "        net.dense.weight[i].requires_grad = False\n",
    "\n",
    "# Transfer the modified weights back to the device\n",
    "net.dense.weight = net.dense.weight.to(device)\n",
    "\n",
    "# You can check which parameters are trainable\n",
    "for name, param in net.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Trainable: {name} on {param.device}\")\n",
    "    else:\n",
    "        print(f\"Non-trainable: {name} on {param.device}\")\n",
    "\n",
    "# Continue with your training process...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9316fbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.dense.weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78726605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  1.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((2, 6))\n",
    "x[0, :0] = -1\n",
    "x[0, 3:] = -1\n",
    "x[1, :3] = -1\n",
    "x[1, 6:] = -1\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12de295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
